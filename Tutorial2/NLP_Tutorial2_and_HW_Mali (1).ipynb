{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_It9C2TJ05K"
   },
   "source": [
    "# Mathematical Formulation for IMDB Text Classification using an MLP\n",
    "# Instructor: Dr. Ankur Mali\n",
    "# University of South Florida (Spring 2025)\n",
    "\n",
    "This document describes the mathematical framework for processing IMDB text data using a character-level bag-of-characters representation, passing it through a multi-layer perceptron (MLP), and training the model via gradient descent. The evaluation metrics include loss, accuracy, precision, and recall.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Tokenization and Input Representation\n",
    "\n",
    "Given a raw text review \\( T \\), we first tokenize it at the character level. Let \\( V \\) be the vocabulary (i.e., the set of unique characters) extracted from the training data with size \\( |V| = d \\).\n",
    "\n",
    "For each text review \\( T \\), we construct a binary bag-of-characters vector \\( x \\in \\{0,1\\}^d \\) such that:\n",
    "\n",
    "$$\n",
    "x_j =\n",
    "\\begin{cases}\n",
    "1, & \\text{if the } j\\text{-th character in } V \\text{ appears in } T, \\\\\n",
    "0, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Thus, each review is represented as:\n",
    "\n",
    "$$\n",
    "x = \\mathrm{BOW}(T) \\in \\mathbb{R}^d.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. MLP Model\n",
    "\n",
    "The MLP we consider has the following structure:\n",
    "- **Input layer:** Receives $$( x \\in \\mathbb{R}^d )$$.\n",
    "- **Hidden Layer 1:** With $h_1$ or $z_1$ (Post-activation) neurons.\n",
    "- **Hidden Layer 2:** With \\( h_2 \\) neurons.\n",
    "- **Output Layer:** With \\( c \\) neurons (for \\( c = 2 \\) classes in binary classification).\n",
    "\n",
    "### 2.1. Model Parameters\n",
    "\n",
    "- **First Hidden Layer:**\n",
    "  - Weight matrix: $$(W^{(1)} \\in \\mathbb{R}^{d \\times h_1} )$$\n",
    "  - Bias vector: $$( b^{(1)} \\in \\mathbb{R}^{h_1} )$$\n",
    "\n",
    "- **Second Hidden Layer:**\n",
    "  - Weight matrix: $$( W^{(2)} \\in \\mathbb{R}^{h_1 \\times h_2} )$$\n",
    "  - Bias vector: $$( b^{(2)} \\in \\mathbb{R}^{h_2} )$$\n",
    "\n",
    "- **Output Layer:**\n",
    "  - Weight matrix: $$( W^{(3)} \\in \\mathbb{R}^{h_2 \\times c} )$$\n",
    "  - Bias vector: $$( b^{(3)} \\in \\mathbb{R}^{c} )$$\n",
    "\n",
    "> **Note:** In the original code, a third hidden layer size (\\( h_3 \\)) is provided as a parameter but is not used in the forward computation. Here, the model uses two hidden layers. You can add any N layers, to this pipeline, remember to modify the pipeline accordingly.\n",
    "\n",
    "### 2.2. Forward Pass\n",
    "\n",
    "For an input vector \\( x \\), the forward propagation through the network is as follows:\n",
    "\n",
    "1. **First Hidden Layer:**\n",
    "\n",
    "   $$\n",
    "   h^{(1)} = \\text{ReLU}\\Big( x\\, W^{(1)} + b^{(1)} \\Big)\n",
    "   $$\n",
    "\n",
    "2. **Second Hidden Layer:**\n",
    "\n",
    "   $$\n",
    "   h^{(2)} = \\text{ReLU}\\Big( h^{(1)}\\, W^{(2)} + b^{(2)} \\Big)\n",
    "   $$\n",
    "\n",
    "3. **Output Layer (Logits):**\n",
    "\n",
    "   $$\n",
    "   z = h^{(2)}\\, W^{(3)} + b^{(3)}\n",
    "   $$\n",
    "\n",
    "The logits \\( z \\) are then converted to class probabilities using the softmax function:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\text{softmax}(z) = \\frac{\\exp(z)}{\\sum_{j=1}^{c} \\exp(z_j)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Loss Function\n",
    "\n",
    "We use the **Categorical Cross Entropy Loss** (with logits) for training. For a single sample with true one-hot label \\( y \\) and predicted probabilities \\( \\hat{y} \\), the loss is:\n",
    "\n",
    "$$\n",
    "L(y, \\hat{y}) = -\\sum_{j=1}^{c} y_j \\log(\\hat{y}_j)\n",
    "$$\n",
    "\n",
    "For a batch of \\( N \\) samples, the average loss is computed as:\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{i=1}^{N} L(y^{(i)}, \\hat{y}^{(i)})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Training via Gradient Descent\n",
    "\n",
    "The goal is to minimize the loss \\( \\mathcal{L} \\) with respect to the model parameters:\n",
    "\n",
    "$$\n",
    "\\Theta = \\{ W^{(1)},\\, b^{(1)},\\, W^{(2)},\\, b^{(2)},\\, W^{(3)},\\, b^{(3)} \\}\n",
    "$$\n",
    "\n",
    "Using gradient descent (or an adaptive method like Adam), each parameter \\( \\theta \\in \\Theta \\) is updated as:\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta - \\eta\\, \\nabla_\\theta L\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\eta$ is the learning rate.\n",
    "- $\\nabla_\\theta L $ denotes the gradient of the loss with respect to $\\theta $.\n",
    "\n",
    "Backpropagation is used to compute these gradients efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Evaluation Metrics\n",
    "\n",
    "In addition to monitoring the loss during training, we evaluate the model performance using:\n",
    "\n",
    "- **Accuracy:**\n",
    "\n",
    "  $$\n",
    "  \\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}\n",
    "  $$\n",
    "\n",
    "- **Precision:**\n",
    "\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "  $$\n",
    "\n",
    "- **Recall:**\n",
    "\n",
    "  $$\n",
    "  \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "  $$\n",
    "\n",
    "These metrics are computed on the validation and test sets to assess the model’s generalization performance.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Summary of the Pipeline\n",
    "\n",
    "1. **Tokenization:**  \n",
    "   Each review \\( T \\) is tokenized at the character level and converted into a binary vector $$x \\in \\{0,1\\}^d$$ representing the presence of each character in the vocabulary \\( V \\).\n",
    "\n",
    "2. **MLP Forward Propagation:**  \n",
    "   The input vector \\( x \\) is propagated through the MLP:\n",
    "   - First hidden layer: $$ h^{(1)} = \\text{ReLU}\\big( x\\, W^{(1)} + b^{(1)} \\big) $$\n",
    "   - Second hidden layer: $$ h^{(2)} = \\text{ReLU}\\big( h^{(1)}\\, W^{(2)} + b^{(2)} \\big) $$\n",
    "   - Output layer: $$ z = h^{(2)}\\, W^{(3)} + b^{(3)} $$\n",
    "   - Softmax conversion: $$ \\hat{y} = \\text{softmax}(z) $$\n",
    "\n",
    "3. **Loss Computation:**  \n",
    "   The categorical cross entropy loss L is computed using the true labels and the predicted probabilities.\n",
    "\n",
    "4. **Training:**  \n",
    "   The model parameters $\\Theta$ are updated using gradient descent (or Adam), where:\n",
    "\n",
    "   $$\n",
    "   \\theta \\leftarrow \\theta - \\eta\\, \\nabla_\\theta L\n",
    "   $$\n",
    "\n",
    "5. **Evaluation:**  \n",
    "   After training, the model is evaluated on the validation and test sets using the loss, accuracy, precision, and recall metrics.\n",
    "\n",
    "---\n",
    "\n",
    "This formulation captures the entire process—from transforming raw text into a numeric representation, through the forward and backward passes of an MLP, to the training and evaluation of the system. Shorter version of your slides :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T06:44:54.431817Z",
     "iopub.status.busy": "2025-02-19T06:44:54.431446Z",
     "iopub.status.idle": "2025-02-19T07:03:55.678710Z",
     "shell.execute_reply": "2025-02-19T07:03:55.677811Z",
     "shell.execute_reply.started": "2025-02-19T06:44:54.431782Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/84/76/c55967ac9968ddaede25a4dce37aba37e9030656f02c12676151ce1b6f22/tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tensorflow_datasets\n",
      "  Obtaining dependency information for tensorflow_datasets from https://files.pythonhosted.org/packages/43/e6/a85c9a2d8ce72c09c8c8bf231c75e6e12e0e0848df336b28d1ec0beae1fe/tensorflow_datasets-4.9.7-py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_datasets-4.9.7-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: scikit-learn in /data/hvaidya/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: pandas in /data/hvaidya/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=24.3.25 from https://files.pythonhosted.org/packages/b8/25/155f9f080d5e4bc0082edfda032ea2bc2b8fab3f4d25d46c1e9dd22a1a89/flatbuffers-25.2.10-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/a3/61/8001b38461d751cd1a0c3a6ae84346796a5758123f3ed97a1b121dfbf4f3/gast-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/1d/fc/716c1e62e512ef1c160e7984a73a5fc7df45166f2ff3f254e71c58076f7c/libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/23/cd/066e86230ae37ed0be70aae89aabf03ca8d9f39c8aea0dec8029455b5540/opt_einsum-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/a8/45/2ebbde52ad2be18d3675b6bee50e68cd73c9e0654de77d595540b5129df8/protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/7f/be/df630c387a0a054815d60be6a97eb4e8f17385d5d6fe660e1c02750062b4/termcolor-2.5.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/9f/e5/5316b239380b8b2ad30373eb5bb25d9fd36c0375e94a98a0a60ea357d254/grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.19,>=2.18 from https://files.pythonhosted.org/packages/b1/de/021c1d407befb505791764ad2cbd56ceaaa53a746baed01d2e2143f05f18/tensorboard-2.18.0-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Obtaining dependency information for keras>=3.5.0 from https://files.pythonhosted.org/packages/fe/cf/aea9087c4d7fafe956a0cc0ff6c3327d10fb8442cda50f992a2186921fa0/keras-3.8.0-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Obtaining dependency information for numpy<2.1.0,>=1.26.0 from https://files.pythonhosted.org/packages/ba/a8/c17acf65a931ce551fee11b72e8de63bf7e8a6f0e21add4c937c83563538/numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n",
      "  Obtaining dependency information for h5py>=3.11.0 from https://files.pythonhosted.org/packages/03/71/c99f662d4832c8835453cf3476f95daa28372023bda4aa1fca9e97c24f09/h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes<0.5.0,>=0.4.0 from https://files.pythonhosted.org/packages/28/bc/6a2344338ea7b61cd7b46fb24ec459360a5a0903b57c55b156c1e46c644a/ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/66/7f/e36ae148c2f03d61ca1bff24bc13a0fef6d6825c966abef73fc6f880a23b/tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: click in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (8.0.4)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Obtaining dependency information for dm-tree from https://files.pythonhosted.org/packages/e8/46/939fbf81177c7cb3b1e5ddebd696237b3be9520769cce882f064de497103/dm_tree-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading dm_tree-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting immutabledict (from tensorflow_datasets)\n",
      "  Obtaining dependency information for immutabledict from https://files.pythonhosted.org/packages/59/56/25ca7b848164b7d93dbd5fc97dd7751700c93e324fe854afbeb562ee2f98/immutabledict-4.2.1-py3-none-any.whl.metadata\n",
      "  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (11.0.0)\n",
      "Collecting simple-parsing (from tensorflow_datasets)\n",
      "  Obtaining dependency information for simple-parsing from https://files.pythonhosted.org/packages/4f/9c/e9ea38750027a6de3e3c5e68a19fda0e7b0cd3db8045f30d0f6bc113b911/simple_parsing-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Obtaining dependency information for tensorflow-metadata from https://files.pythonhosted.org/packages/e0/57/393aa9dde72347cde9e01f665bac344f14adefd5c748be45b23aa5804f6d/tensorflow_metadata-1.16.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: toml in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (4.65.0)\n",
      "Collecting array-record>=0.5.0 (from tensorflow_datasets)\n",
      "  Obtaining dependency information for array-record>=0.5.0 from https://files.pythonhosted.org/packages/0c/df/16d19d8aaa61c24896ec94313b271fc16320e402a311bcc54c42ee190a70/array_record-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading array_record-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (692 bytes)\n",
      "Collecting etils[edc,enp,epath,epy,etree]>=1.9.1 (from tensorflow_datasets)\n",
      "  Obtaining dependency information for etils[edc,enp,epath,epy,etree]>=1.9.1 from https://files.pythonhosted.org/packages/05/83/bb4a4518bfa32a160dc455d8d944a6e00a7eb6759f449cb20c7b7879090e/etils-1.12.0-py3-none-any.whl.metadata\n",
      "  Downloading etils-1.12.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: fsspec in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1->tensorflow_datasets) (2023.4.0)\n",
      "Collecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.9.1->tensorflow_datasets)\n",
      "  Obtaining dependency information for importlib_resources from https://files.pythonhosted.org/packages/a4/ed/1f1afb2e9e7f38a545d628f864d562a5ae64fe6f7a10e28ffb9b185b4e89/importlib_resources-6.5.2-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1->tensorflow_datasets) (3.11.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/73/59/7854fbfb59f8ae35483ce93493708be5942ebb6328cd85b3a609df629736/namex-0.0.8-py3-none-any.whl.metadata\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/b3/9b/b2420d5830d3e65c98543e69dbcebdc903830b897bd601dfab8481fa0b5b/optree-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading optree-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Obtaining dependency information for numpy<2.1.0,>=1.26.0 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: attrs>=18.2.0 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from dm-tree->tensorflow_datasets) (22.1.0)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from simple-parsing->tensorflow_datasets)\n",
      "  Obtaining dependency information for docstring-parser<1.0,>=0.15 from https://files.pythonhosted.org/packages/d5/7c/e9fcff7623954d86bdc17782036cbf715ecab1bec4847c008557affe1ca8/docstring_parser-0.16-py3-none-any.whl.metadata\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Obtaining dependency information for googleapis-common-protos<2,>=1.56.4 from https://files.pythonhosted.org/packages/89/30/2bd0eb03a7dee7727cd2ec643d1e992979e62d5e7443507381cce0455132/googleapis_common_protos-1.67.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /data/hvaidya/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_datasets-4.9.7-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading array_record-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading dm_tree-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.8/112.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading etils-1.12.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (405 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.5/405.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=492d2d80f4f7a0f9f92ebdbf7ed60a6631c6c451b3cbde0122218403409e3a40\n",
      "  Stored in directory: /home/h/hvaidya/.cache/pip/wheels/90/74/b1/9b54c896b8d9409e9268329d4d45ede8a8040abe91c8879932\n",
      "Successfully built promise\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, promise, optree, opt-einsum, numpy, importlib_resources, immutabledict, grpcio, google-pasta, gast, etils, docstring-parser, astunparse, absl-py, tensorboard, simple-parsing, rich, ml-dtypes, h5py, googleapis-common-protos, dm-tree, tensorflow-metadata, keras, tensorflow, array-record, tensorflow_datasets\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 array-record-0.6.0 astunparse-1.6.3 dm-tree-0.1.9 docstring-parser-0.16 etils-1.12.0 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 googleapis-common-protos-1.67.0 grpcio-1.70.0 h5py-3.13.0 immutabledict-4.2.1 importlib_resources-6.5.2 keras-3.8.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 numpy-1.26.4 opt-einsum-3.4.0 optree-0.14.0 promise-2.3 protobuf-5.29.3 rich-13.9.4 simple-parsing-0.1.7 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-metadata-1.16.1 tensorflow_datasets-4.9.7 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow_datasets scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-19T07:16:53.026027Z",
     "iopub.status.busy": "2025-02-19T07:16:53.025760Z",
     "iopub.status.idle": "2025-02-19T07:16:53.620309Z",
     "shell.execute_reply": "2025-02-19T07:16:53.619714Z",
     "shell.execute_reply.started": "2025-02-19T07:16:53.026004Z"
    },
    "id": "ad5HQaMorFuu",
    "outputId": "d7b126e4-6872-405c-f188-5bdcc247ee4b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hvaidya/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "  File \"/tmp/ipykernel_22745/3879283748.py\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hvaidya/miniconda3/envs/tf/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hvaidya/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"/home/hvaidya/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"/home/hvaidya/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"/home/hvaidya/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"/home/hvaidya/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"/home/hvaidya/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1136, in get_records\n",
      "  File \"/home/hvaidya/miniconda3/envs/tf/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "# -------------------------------\n",
    "# MLP Class Definition (look at slides)\n",
    "# -------------------------------\n",
    "class MLP(object):\n",
    "    def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
    "        \"\"\"\n",
    "        size_input: int, size of input layer\n",
    "        size_hidden1: int, size of the 1st hidden layer\n",
    "        size_hidden2: int, size of the 2nd hidden layer\n",
    "        size_hidden3: int, size of the 3rd hidden layer (Note: Not used in compute_output in this example)\n",
    "        size_output: int, size of output layer\n",
    "        device: str or None, either 'cpu' or 'gpu' or None. If None, the device is decided automatically.\n",
    "        \"\"\"\n",
    "        self.size_input = size_input\n",
    "        self.size_hidden1 = size_hidden1\n",
    "        self.size_hidden2 = size_hidden2\n",
    "        self.size_hidden3 = size_hidden3  # (Currently not used)\n",
    "        self.size_output = size_output\n",
    "        self.device = device\n",
    "\n",
    "        # Initialize weights and biases for first hidden layer\n",
    "        self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1], stddev=0.1))\n",
    "        self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1]))\n",
    "\n",
    "        # Initialize weights and biases for second hidden layer\n",
    "        self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2], stddev=0.1))\n",
    "        self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
    "\n",
    "        # Initialize weights and biases for output layer\n",
    "        self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_output], stddev=0.1))\n",
    "        self.b3 = tf.Variable(tf.zeros([1, self.size_output]))\n",
    "\n",
    "        # Define variables to be updated during backpropagation\n",
    "        self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        X: Tensor, inputs.\n",
    "        \"\"\"\n",
    "        if self.device is not None:\n",
    "            with tf.device('gpu:0' if self.device == 'gpu' else 'cpu'):\n",
    "                self.y = self.compute_output(X)\n",
    "        else:\n",
    "            self.y = self.compute_output(X)\n",
    "        return self.y\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Computes the loss between predicted and true outputs.\n",
    "        y_pred - Tensor of shape (batch_size, size_output)\n",
    "        y_true - Tensor of shape (batch_size, size_output)\n",
    "        \"\"\"\n",
    "        y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
    "        y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        loss_x = cce(y_true_tf, y_pred_tf)\n",
    "        return loss_x\n",
    "\n",
    "    def backward(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients of the loss with respect to the variables.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            predicted = self.forward(X_train)\n",
    "            current_loss = self.loss(predicted, y_train)\n",
    "        grads = tape.gradient(current_loss, self.variables)\n",
    "        return grads\n",
    "\n",
    "    def compute_output(self, X):\n",
    "        \"\"\"\n",
    "        Custom method to obtain output tensor during the forward pass.\n",
    "        \"\"\"\n",
    "        # Cast X to float32\n",
    "        X_tf = tf.cast(X, dtype=tf.float32)\n",
    "        # First hidden layer\n",
    "        h1 = tf.matmul(X_tf, self.W1) + self.b1\n",
    "        z1 = tf.nn.relu(h1)\n",
    "        # Second hidden layer\n",
    "        h2 = tf.matmul(z1, self.W2) + self.b2\n",
    "        z2 = tf.nn.relu(h2)\n",
    "        # Output layer (logits)\n",
    "        output = tf.matmul(z2, self.W3) + self.b3\n",
    "        return output\n",
    "\n",
    "# -------------------------------\n",
    "# Character-Level Tokenizer and Preprocessing Functions\n",
    "# -------------------------------\n",
    "def char_level_tokenizer(texts, num_words=None):\n",
    "    \"\"\"\n",
    "    Create and fit a character-level tokenizer.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): List of texts (e.g., movie reviews).\n",
    "        num_words (int or None): Maximum number of tokens to keep (based on frequency).\n",
    "\n",
    "    Returns:\n",
    "        tokenizer: A fitted Tokenizer instance.\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(num_words=num_words, char_level=True, lower=True)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer\n",
    "\n",
    "def texts_to_bow(tokenizer, texts):\n",
    "    \"\"\"\n",
    "    Convert texts to a bag-of-characters representation.\n",
    "\n",
    "    Args:\n",
    "        tokenizer: A fitted character-level Tokenizer.\n",
    "        texts (list of str): List of texts.\n",
    "\n",
    "    Returns:\n",
    "        Numpy array representing binary presence of characters.\n",
    "    \"\"\"\n",
    "    # Use texts_to_matrix with mode 'binary' to create fixed-length vectors.\n",
    "    matrix = tokenizer.texts_to_matrix(texts, mode='binary')\n",
    "    return matrix\n",
    "\n",
    "# -------------------------------\n",
    "# Example Usage for IMDB Classification\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example IMDB reviews (In practice, load your dataset here)\n",
    "    texts = [\n",
    "        \"I loved this movie! It was fantastic.\",\n",
    "        \"The film was terrible and boring.\"\n",
    "    ]\n",
    "    # One-hot encoded labels for 2 classes (e.g., positive: [0,1], negative: [1,0])\n",
    "    labels = np.array([[0, 1], [1, 0]])\n",
    "\n",
    "    # Create and fit a character-level tokenizer\n",
    "    tokenizer = char_level_tokenizer(texts)\n",
    "\n",
    "    # Convert texts to bag-of-characters representation\n",
    "    X = texts_to_bow(tokenizer, texts)\n",
    "    print(\"Input shape:\", X.shape)\n",
    "\n",
    "    # Set model hyperparameters.\n",
    "    # The input size is equal to the dimension of the bag-of-characters vector.\n",
    "    size_input = X.shape[1]\n",
    "    size_hidden1 = 64\n",
    "    size_hidden2 = 32\n",
    "    size_hidden3 = 16  # Not used in compute_output (placeholder for a potential extra layer)\n",
    "    size_output = 2\n",
    "\n",
    "    # Instantiate the MLP model.\n",
    "    model = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
    "\n",
    "    # Define an optimizer.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    # Training loop (for demonstration purposes; adjust epochs and batch size as needed)\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass: compute predictions\n",
    "        predictions = model.forward(X)\n",
    "        # Compute loss\n",
    "        current_loss = model.loss(predictions, labels)\n",
    "        # Backward pass: compute gradients\n",
    "        grads = model.backward(X, labels)\n",
    "        # Update weights manually using the optimizer.\n",
    "        optimizer.apply_gradients(zip(grads, model.variables))\n",
    "        print(f\"Epoch {epoch+1}, Loss: {current_loss.numpy()}\")\n",
    "\n",
    "    # Testing the model on a new review.\n",
    "    new_text = [\"An amazing film with a thrilling plot.\"]\n",
    "    X_new = texts_to_bow(tokenizer, new_text)\n",
    "    logits = model.forward(X_new)\n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "    print(\"Predicted probabilities:\", probabilities.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNGpqID8UZaW"
   },
   "source": [
    "## MLP on IMDB Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## character level tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476,
     "referenced_widgets": [
      "cb2ca4b8eae746b6990b7a11c90db810",
      "df2756a1e35540abb553129c3b904709",
      "fb9fd2e2a9be4d0d98b6f796cd5f830a",
      "3ebcc18d220745338c4ec8de6127e48e",
      "caf08b27977a4c188e92ea34166acfc8",
      "f60316df87ba4b64bef0b47f95e8d30f",
      "f212087a14d84bd7a5a91d14775a75eb",
      "a85a9cfd1b254b7b98ce7a81661b96ed",
      "ec25dadc702141049913b810b7fde1c7",
      "7ec9320a7eb74e4c98b230fba6d8a2ce",
      "21b3131b402b4b14991f046d9a3a8be0",
      "20a84906121842f48543c1bad206d799",
      "cb85ef2782754246b66058f75317feed",
      "5138ab3ff1dc4cc883a434e1a7caa14a",
      "a7ea683bf59f4687bd3eadba6298a883",
      "d074fc35f4864f55a1e4ebdca6e07530",
      "444ec309e9cc4828b3ae669d28901abc",
      "b594fbc34d5d40d4abae1759c81972af",
      "250a431c05cb4878a428cf415f702b36",
      "e8c785ed43d84e4e856476928b2a49e9",
      "677c67b52ca14e2d88114d167d065797",
      "3db2d29d0c1649218f2f2c604993727a",
      "77a48de94d2948b0ae340c92000cf7e8",
      "3bdad631a663468e947008ba9a952299",
      "9610d42f53d441c8940e894954e11339",
      "b36275d5ce954d7ab7b442bb60729146",
      "aad3c5ae005a4124acd9285769a215e1",
      "bb323561a3de4b8f85a43a075d00119e",
      "d704ab225ada4134bf1ce4bb830a6354",
      "1a10d0b1fd154491a8888340c8ebfe38",
      "85cfedddc7914481a99c93ae7f349851",
      "40845adffae1455689ad5a1559559fa0",
      "35d8ba6f21ab445e856039f4c75082b1",
      "bd5890b2ca084272990e5e16f6b81d8c",
      "f3cbd7d3127f4cefb81665e7f7d7c004",
      "40d486058c5d47a38ac3adb0cf2bc6d2",
      "5b130b325efa49f99be9b52994686a0c",
      "8f11f250de6448ad87a3363ffcb4e243",
      "b71a01539a0f4b0c89bf87eba3780fcc",
      "816a5390057d4567915bf34ad0b54c41",
      "40019e582a064de589847a3da1175eca",
      "7eb9b35910a64aecaa958983ea078dad",
      "e9b7a63ccc5f462abb99fa20caa65cc4",
      "0e66320306b44c65bce10ade0c4d2eeb",
      "88bf3f3840dd4be894756fc2474b84ed",
      "4b056533e06a48a5a81d15cf44b961b7",
      "a4903235f0f0406d9c0bee0678bf8805",
      "3dec77d473c84931836cfa6a0db79ecb",
      "62010f0361854b66afd987c8bd7e15f5",
      "a8e3a8be14b742209b8ef74200a2cd9f",
      "1853768c4e554ae0b1ade9b6e62d771b",
      "43b6dbdb5b6a42d198d384ee7fa4dd29",
      "259e6840f71c4a29b64725a4d921965f",
      "a6ea7ea17fe443ed816de452ba64b2f1",
      "5af6d5859b724a3ba77f579df40b71d4",
      "9fc72e5be2694018a37b7861ccea3ade",
      "2f96003dea1542f58a9ff716fe8713ee",
      "79cd58e72bd4406698ad3979a6c9ba6d",
      "ad10809f5e9045d9905cd083bb346f21",
      "0ee8c01d75c541218b8bc09ff1f94cde",
      "94a33644645a4c27a8b781908bb5c92b",
      "c96784cc747c4dd6b95621289526af8a",
      "25795eca2fe34d14845d14f3295a9ec2",
      "d0a178cf8e0d4bbdb4b521a693ccadbe",
      "98a5b8121fe341299996d32f52261fe6",
      "1547a0be80f84b32a254aea474d6867a",
      "5e72ea42a5714ba5bf783e99af1ffe8b",
      "b411ae301a9c4cac9336c8f1bb18c135",
      "ca846e4a00d5439b89615b29b94dd268",
      "be89b15c9d9e48dda2b0819689faa365",
      "e0716ea457b54fa58b4eef100fab9335",
      "3c9c79a8361a48ea9128f738e67941b4",
      "12dc246bd54c4e3ea3747c65c2e17014",
      "fa3b427945774e91bbaf99d8cbdaf10d",
      "b379d846511c4e17b6ca15c1f6662aae",
      "d91ce7676d13401fb58641aa4e71602c",
      "a614a6f07a7e42baaea992036e16612e",
      "da94d8894e6b4feabcd3d191ffbde635",
      "825e86dc8b6046a0b60e728a911f99f9",
      "26b2ec9c903547f886effcacfeea8629",
      "e19bf5cbd5ce4377939f080e7aafa25f",
      "7df5f5059e5f49c9968599942999833b",
      "708aac86918f45aaa50940f7122b36ab",
      "46836bd062e74b14a9e5ae1f1d48a184",
      "e014cd8004684dd0bf2513e8dcb9e9f8",
      "ff5c2c87b086478295f9aa8ab1b83908",
      "b6cc22bec624493cb11da8a6369b11a8",
      "8d682b2a66a14e1ab3345c27b969de1e",
      "df8df8420bc342369e233a8a16385efc",
      "e236994a32f244b88030884c0495a72e",
      "3aa278af5eb54745a56e4b61af3beac2",
      "fa14c3851c6447c0a28ea94314a832ad",
      "29edf5a4a8884ce5a18f71def1ae921b",
      "505a0b8197ab4680a3c51aff901b1569",
      "94e07dc24c01434aa319100832e9d21c",
      "8ff989a5005542a3a737c38f7959f2ce",
      "37c4db5b41c94c99b58627004c25e12d",
      "54eef9cd5ba54636ba508be7c5e65d70",
      "2a83a645921d4970b8ed0b4b29f123bc"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-02-19T13:31:49.656494Z",
     "iopub.status.busy": "2025-02-19T13:31:49.656160Z"
    },
    "id": "qb0sCnSFsHJl",
    "outputId": "d60f00f4-16a8-448f-f3bb-4bc152a7165f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 13:46:59.090890: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-19 13:46:59.091243: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-19 13:46:59.093019: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-19 13:46:59.102028: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739990819.112433   10649 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739990819.115420   10649 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-19 13:46:59.125748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1739990820.790838   10649 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-02-19 13:47:00.881853: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-02-19 13:47:02.915873: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-02-19 13:47:05.017416: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 20000, Validation samples: 5000, Test samples: 25000\n",
      "Tokenizer vocabulary size: 134\n",
      "\n",
      "Training for parameter combination:  1, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7129 | Val Loss: 0.7162 | Accuracy: 0.4804 | Precision: 0.4792 | Recall: 0.8288\n",
      "Epoch 02 | Training Loss: 0.7086 | Val Loss: 0.7119 | Accuracy: 0.4820 | Precision: 0.4788 | Recall: 0.7719\n",
      "Epoch 03 | Training Loss: 0.7061 | Val Loss: 0.7092 | Accuracy: 0.4838 | Precision: 0.4786 | Recall: 0.7232\n",
      "Epoch 04 | Training Loss: 0.7047 | Val Loss: 0.7075 | Accuracy: 0.4800 | Precision: 0.4744 | Recall: 0.6737\n",
      "Epoch 05 | Training Loss: 0.7038 | Val Loss: 0.7063 | Accuracy: 0.4848 | Precision: 0.4767 | Recall: 0.6419\n",
      "Epoch 06 | Training Loss: 0.7032 | Val Loss: 0.7054 | Accuracy: 0.4864 | Precision: 0.4768 | Recall: 0.6106\n",
      "Epoch 07 | Training Loss: 0.7028 | Val Loss: 0.7048 | Accuracy: 0.4872 | Precision: 0.4767 | Recall: 0.5903\n",
      "Epoch 08 | Training Loss: 0.7024 | Val Loss: 0.7044 | Accuracy: 0.4900 | Precision: 0.4785 | Recall: 0.5792\n",
      "Epoch 09 | Training Loss: 0.7022 | Val Loss: 0.7040 | Accuracy: 0.4920 | Precision: 0.4800 | Recall: 0.5738\n",
      "Epoch 10 | Training Loss: 0.7019 | Val Loss: 0.7036 | Accuracy: 0.4928 | Precision: 0.4804 | Recall: 0.5664\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7233 | Test Accuracy: 0.4960 | Test Precision: 0.4965 | Test Recall: 0.5737\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7241 | Val Loss: 0.7104 | Accuracy: 0.5122 | Precision: 0.4096 | Recall: 0.0140\n",
      "Epoch 02 | Training Loss: 0.7125 | Val Loss: 0.7042 | Accuracy: 0.5052 | Precision: 0.4132 | Recall: 0.0491\n",
      "Epoch 03 | Training Loss: 0.7065 | Val Loss: 0.7013 | Accuracy: 0.4958 | Precision: 0.4168 | Recall: 0.1002\n",
      "Epoch 04 | Training Loss: 0.7032 | Val Loss: 0.6999 | Accuracy: 0.4842 | Precision: 0.4157 | Recall: 0.1576\n",
      "Epoch 05 | Training Loss: 0.7014 | Val Loss: 0.6994 | Accuracy: 0.4826 | Precision: 0.4387 | Recall: 0.2405\n",
      "Epoch 06 | Training Loss: 0.7004 | Val Loss: 0.6991 | Accuracy: 0.4780 | Precision: 0.4417 | Recall: 0.2904\n",
      "Epoch 07 | Training Loss: 0.6998 | Val Loss: 0.6991 | Accuracy: 0.4728 | Precision: 0.4434 | Recall: 0.3424\n",
      "Epoch 08 | Training Loss: 0.6994 | Val Loss: 0.6990 | Accuracy: 0.4746 | Precision: 0.4514 | Recall: 0.3886\n",
      "Epoch 09 | Training Loss: 0.6992 | Val Loss: 0.6990 | Accuracy: 0.4746 | Precision: 0.4543 | Recall: 0.4167\n",
      "Epoch 10 | Training Loss: 0.6990 | Val Loss: 0.6990 | Accuracy: 0.4754 | Precision: 0.4570 | Recall: 0.4361\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6959 | Test Accuracy: 0.4814 | Test Precision: 0.4799 | Test Recall: 0.4447\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6995 | Val Loss: 0.6874 | Accuracy: 0.5544 | Precision: 0.5939 | Recall: 0.2558\n",
      "Epoch 02 | Training Loss: 0.6928 | Val Loss: 0.6840 | Accuracy: 0.5600 | Precision: 0.5788 | Recall: 0.3395\n",
      "Epoch 03 | Training Loss: 0.6893 | Val Loss: 0.6826 | Accuracy: 0.5648 | Precision: 0.5732 | Recall: 0.4006\n",
      "Epoch 04 | Training Loss: 0.6875 | Val Loss: 0.6821 | Accuracy: 0.5670 | Precision: 0.5674 | Recall: 0.4497\n",
      "Epoch 05 | Training Loss: 0.6866 | Val Loss: 0.6819 | Accuracy: 0.5692 | Precision: 0.5649 | Recall: 0.4847\n",
      "Epoch 06 | Training Loss: 0.6861 | Val Loss: 0.6818 | Accuracy: 0.5690 | Precision: 0.5611 | Recall: 0.5099\n",
      "Epoch 07 | Training Loss: 0.6857 | Val Loss: 0.6818 | Accuracy: 0.5664 | Precision: 0.5558 | Recall: 0.5260\n",
      "Epoch 08 | Training Loss: 0.6855 | Val Loss: 0.6818 | Accuracy: 0.5658 | Precision: 0.5543 | Recall: 0.5330\n",
      "Epoch 09 | Training Loss: 0.6853 | Val Loss: 0.6818 | Accuracy: 0.5656 | Precision: 0.5531 | Recall: 0.5417\n",
      "Epoch 10 | Training Loss: 0.6852 | Val Loss: 0.6817 | Accuracy: 0.5670 | Precision: 0.5538 | Recall: 0.5495\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6891 | Test Accuracy: 0.5567 | Test Precision: 0.5585 | Test Recall: 0.5407\n",
      "\n",
      "Training for parameter combination:  2, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7029 | Val Loss: 0.6866 | Accuracy: 0.5496 | Precision: 0.5370 | Recall: 0.5149\n",
      "Epoch 02 | Training Loss: 0.6804 | Val Loss: 0.6771 | Accuracy: 0.5820 | Precision: 0.5698 | Recall: 0.5623\n",
      "Epoch 03 | Training Loss: 0.6733 | Val Loss: 0.6735 | Accuracy: 0.5906 | Precision: 0.5620 | Recall: 0.7050\n",
      "Epoch 04 | Training Loss: 0.6689 | Val Loss: 0.6699 | Accuracy: 0.5982 | Precision: 0.5712 | Recall: 0.6869\n",
      "Epoch 05 | Training Loss: 0.6659 | Val Loss: 0.6688 | Accuracy: 0.6012 | Precision: 0.5699 | Recall: 0.7228\n",
      "Epoch 06 | Training Loss: 0.6638 | Val Loss: 0.6685 | Accuracy: 0.6008 | Precision: 0.5674 | Recall: 0.7434\n",
      "Epoch 07 | Training Loss: 0.6627 | Val Loss: 0.6691 | Accuracy: 0.5984 | Precision: 0.5641 | Recall: 0.7554\n",
      "Epoch 08 | Training Loss: 0.6620 | Val Loss: 0.6642 | Accuracy: 0.6066 | Precision: 0.5857 | Recall: 0.6444\n",
      "Epoch 09 | Training Loss: 0.6611 | Val Loss: 0.6638 | Accuracy: 0.6094 | Precision: 0.5888 | Recall: 0.6444\n",
      "Epoch 10 | Training Loss: 0.6609 | Val Loss: 0.6637 | Accuracy: 0.6122 | Precision: 0.5873 | Recall: 0.6733\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6423 | Test Accuracy: 0.6080 | Test Precision: 0.5952 | Test Recall: 0.6755\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6851 | Val Loss: 0.6789 | Accuracy: 0.5722 | Precision: 0.5580 | Recall: 0.5660\n",
      "Epoch 02 | Training Loss: 0.6750 | Val Loss: 0.6748 | Accuracy: 0.5846 | Precision: 0.5558 | Recall: 0.7125\n",
      "Epoch 03 | Training Loss: 0.6694 | Val Loss: 0.6692 | Accuracy: 0.5936 | Precision: 0.5726 | Recall: 0.6378\n",
      "Epoch 04 | Training Loss: 0.6659 | Val Loss: 0.6667 | Accuracy: 0.5994 | Precision: 0.5919 | Recall: 0.5594\n",
      "Epoch 05 | Training Loss: 0.6640 | Val Loss: 0.6654 | Accuracy: 0.6022 | Precision: 0.5868 | Recall: 0.6064\n",
      "Epoch 06 | Training Loss: 0.6626 | Val Loss: 0.6648 | Accuracy: 0.6054 | Precision: 0.5829 | Recall: 0.6543\n",
      "Epoch 07 | Training Loss: 0.6616 | Val Loss: 0.6646 | Accuracy: 0.6046 | Precision: 0.5781 | Recall: 0.6823\n",
      "Epoch 08 | Training Loss: 0.6611 | Val Loss: 0.6639 | Accuracy: 0.6080 | Precision: 0.5850 | Recall: 0.6584\n",
      "Epoch 09 | Training Loss: 0.6604 | Val Loss: 0.6640 | Accuracy: 0.6080 | Precision: 0.5818 | Recall: 0.6807\n",
      "Epoch 10 | Training Loss: 0.6601 | Val Loss: 0.6635 | Accuracy: 0.6078 | Precision: 0.5825 | Recall: 0.6745\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6465 | Test Accuracy: 0.6080 | Test Precision: 0.5950 | Test Recall: 0.6770\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6972 | Val Loss: 0.6847 | Accuracy: 0.5554 | Precision: 0.5472 | Recall: 0.4802\n",
      "Epoch 02 | Training Loss: 0.6814 | Val Loss: 0.6787 | Accuracy: 0.5788 | Precision: 0.5484 | Recall: 0.7438\n",
      "Epoch 03 | Training Loss: 0.6736 | Val Loss: 0.6704 | Accuracy: 0.5884 | Precision: 0.5757 | Recall: 0.5743\n",
      "Epoch 04 | Training Loss: 0.6686 | Val Loss: 0.6673 | Accuracy: 0.5966 | Precision: 0.5768 | Recall: 0.6304\n",
      "Epoch 05 | Training Loss: 0.6659 | Val Loss: 0.6667 | Accuracy: 0.5996 | Precision: 0.5692 | Recall: 0.7158\n",
      "Epoch 06 | Training Loss: 0.6639 | Val Loss: 0.6641 | Accuracy: 0.6034 | Precision: 0.5851 | Recall: 0.6254\n",
      "Epoch 07 | Training Loss: 0.6628 | Val Loss: 0.6636 | Accuracy: 0.6082 | Precision: 0.5826 | Recall: 0.6766\n",
      "Epoch 08 | Training Loss: 0.6620 | Val Loss: 0.6629 | Accuracy: 0.6088 | Precision: 0.5914 | Recall: 0.6246\n",
      "Epoch 09 | Training Loss: 0.6613 | Val Loss: 0.6663 | Accuracy: 0.6012 | Precision: 0.5671 | Recall: 0.7500\n",
      "Epoch 10 | Training Loss: 0.6609 | Val Loss: 0.6650 | Accuracy: 0.6028 | Precision: 0.5700 | Recall: 0.7360\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6479 | Test Accuracy: 0.6032 | Test Precision: 0.5817 | Test Recall: 0.7352\n",
      "\n",
      "Training for parameter combination:  3, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6803 | Val Loss: 0.6659 | Accuracy: 0.5964 | Precision: 0.5771 | Recall: 0.6267\n",
      "Epoch 02 | Training Loss: 0.6633 | Val Loss: 0.6613 | Accuracy: 0.6046 | Precision: 0.5734 | Recall: 0.7207\n",
      "Epoch 03 | Training Loss: 0.6590 | Val Loss: 0.6662 | Accuracy: 0.5974 | Precision: 0.5634 | Recall: 0.7529\n",
      "Epoch 04 | Training Loss: 0.6573 | Val Loss: 0.6711 | Accuracy: 0.5944 | Precision: 0.5607 | Recall: 0.7550\n",
      "Epoch 05 | Training Loss: 0.6518 | Val Loss: 0.6646 | Accuracy: 0.5978 | Precision: 0.5698 | Recall: 0.6951\n",
      "Epoch 06 | Training Loss: 0.6505 | Val Loss: 0.6618 | Accuracy: 0.6040 | Precision: 0.5771 | Recall: 0.6852\n",
      "Epoch 07 | Training Loss: 0.6479 | Val Loss: 0.6648 | Accuracy: 0.6004 | Precision: 0.5725 | Recall: 0.6939\n",
      "Epoch 08 | Training Loss: 0.6456 | Val Loss: 0.6774 | Accuracy: 0.6024 | Precision: 0.5676 | Recall: 0.7550\n",
      "Epoch 09 | Training Loss: 0.6437 | Val Loss: 0.6651 | Accuracy: 0.6022 | Precision: 0.5954 | Recall: 0.5602\n",
      "Epoch 10 | Training Loss: 0.6413 | Val Loss: 0.6848 | Accuracy: 0.6002 | Precision: 0.5918 | Recall: 0.5652\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6858 | Test Accuracy: 0.6008 | Test Precision: 0.6108 | Test Recall: 0.5561\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6821 | Val Loss: 0.6749 | Accuracy: 0.5748 | Precision: 0.5419 | Recall: 0.7950\n",
      "Epoch 02 | Training Loss: 0.6648 | Val Loss: 0.6668 | Accuracy: 0.6052 | Precision: 0.6041 | Recall: 0.5388\n",
      "Epoch 03 | Training Loss: 0.6582 | Val Loss: 0.6629 | Accuracy: 0.6048 | Precision: 0.5785 | Recall: 0.6811\n",
      "Epoch 04 | Training Loss: 0.6562 | Val Loss: 0.6575 | Accuracy: 0.6076 | Precision: 0.6047 | Recall: 0.5503\n",
      "Epoch 05 | Training Loss: 0.6522 | Val Loss: 0.6624 | Accuracy: 0.6004 | Precision: 0.5684 | Recall: 0.7306\n",
      "Epoch 06 | Training Loss: 0.6499 | Val Loss: 0.6600 | Accuracy: 0.6044 | Precision: 0.5740 | Recall: 0.7137\n",
      "Epoch 07 | Training Loss: 0.6466 | Val Loss: 0.6636 | Accuracy: 0.6030 | Precision: 0.5803 | Recall: 0.6547\n",
      "Epoch 08 | Training Loss: 0.6448 | Val Loss: 0.6925 | Accuracy: 0.5854 | Precision: 0.5487 | Recall: 0.8152\n",
      "Epoch 09 | Training Loss: 0.6407 | Val Loss: 0.6679 | Accuracy: 0.6018 | Precision: 0.5732 | Recall: 0.6993\n",
      "Epoch 10 | Training Loss: 0.6395 | Val Loss: 0.6665 | Accuracy: 0.6038 | Precision: 0.5724 | Recall: 0.7224\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6944 | Test Accuracy: 0.6078 | Test Precision: 0.5869 | Test Recall: 0.7278\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6832 | Val Loss: 0.6643 | Accuracy: 0.6024 | Precision: 0.5816 | Recall: 0.6411\n",
      "Epoch 02 | Training Loss: 0.6639 | Val Loss: 0.6628 | Accuracy: 0.6030 | Precision: 0.5812 | Recall: 0.6481\n",
      "Epoch 03 | Training Loss: 0.6599 | Val Loss: 0.6721 | Accuracy: 0.5906 | Precision: 0.5536 | Recall: 0.8036\n",
      "Epoch 04 | Training Loss: 0.6553 | Val Loss: 0.6603 | Accuracy: 0.6050 | Precision: 0.5776 | Recall: 0.6894\n",
      "Epoch 05 | Training Loss: 0.6542 | Val Loss: 0.6599 | Accuracy: 0.6000 | Precision: 0.5670 | Recall: 0.7397\n",
      "Epoch 06 | Training Loss: 0.6489 | Val Loss: 0.6690 | Accuracy: 0.5928 | Precision: 0.5614 | Recall: 0.7323\n",
      "Epoch 07 | Training Loss: 0.6480 | Val Loss: 0.6610 | Accuracy: 0.6124 | Precision: 0.5912 | Recall: 0.6498\n",
      "Epoch 08 | Training Loss: 0.6446 | Val Loss: 0.6695 | Accuracy: 0.5948 | Precision: 0.6392 | Recall: 0.3771\n",
      "Epoch 09 | Training Loss: 0.6412 | Val Loss: 0.6856 | Accuracy: 0.5940 | Precision: 0.5623 | Recall: 0.7331\n",
      "Epoch 10 | Training Loss: 0.6387 | Val Loss: 0.6702 | Accuracy: 0.6040 | Precision: 0.5722 | Recall: 0.7257\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6890 | Test Accuracy: 0.6096 | Test Precision: 0.5883 | Test Recall: 0.7299\n",
      "\n",
      "Training for parameter combination:  4, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6871 | Val Loss: 0.6876 | Accuracy: 0.5886 | Precision: 0.5505 | Recall: 0.8251\n",
      "Epoch 02 | Training Loss: 0.6660 | Val Loss: 0.6739 | Accuracy: 0.5912 | Precision: 0.5554 | Recall: 0.7859\n",
      "Epoch 03 | Training Loss: 0.6578 | Val Loss: 0.6672 | Accuracy: 0.5990 | Precision: 0.5652 | Recall: 0.7488\n",
      "Epoch 04 | Training Loss: 0.6538 | Val Loss: 0.6759 | Accuracy: 0.5908 | Precision: 0.6196 | Recall: 0.4039\n",
      "Epoch 05 | Training Loss: 0.6506 | Val Loss: 0.6611 | Accuracy: 0.6008 | Precision: 0.5800 | Recall: 0.6399\n",
      "Epoch 06 | Training Loss: 0.6464 | Val Loss: 0.6579 | Accuracy: 0.6094 | Precision: 0.5896 | Recall: 0.6394\n",
      "Epoch 07 | Training Loss: 0.6419 | Val Loss: 0.6655 | Accuracy: 0.6056 | Precision: 0.5856 | Recall: 0.6378\n",
      "Epoch 08 | Training Loss: 0.6382 | Val Loss: 0.6662 | Accuracy: 0.5966 | Precision: 0.5644 | Recall: 0.7360\n",
      "Epoch 09 | Training Loss: 0.6374 | Val Loss: 0.6634 | Accuracy: 0.5994 | Precision: 0.5942 | Recall: 0.5479\n",
      "Epoch 10 | Training Loss: 0.6345 | Val Loss: 0.6643 | Accuracy: 0.6032 | Precision: 0.5822 | Recall: 0.6427\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6267 | Test Accuracy: 0.6066 | Test Precision: 0.5988 | Test Recall: 0.6459\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6874 | Val Loss: 0.6672 | Accuracy: 0.5954 | Precision: 0.5911 | Recall: 0.5367\n",
      "Epoch 02 | Training Loss: 0.6640 | Val Loss: 0.6651 | Accuracy: 0.5948 | Precision: 0.6018 | Recall: 0.4851\n",
      "Epoch 03 | Training Loss: 0.6576 | Val Loss: 0.6594 | Accuracy: 0.6088 | Precision: 0.5936 | Recall: 0.6122\n",
      "Epoch 04 | Training Loss: 0.6536 | Val Loss: 0.6642 | Accuracy: 0.5970 | Precision: 0.5665 | Recall: 0.7186\n",
      "Epoch 05 | Training Loss: 0.6496 | Val Loss: 0.6612 | Accuracy: 0.6020 | Precision: 0.5914 | Recall: 0.5792\n",
      "Epoch 06 | Training Loss: 0.6463 | Val Loss: 0.6745 | Accuracy: 0.5874 | Precision: 0.5506 | Recall: 0.8102\n",
      "Epoch 07 | Training Loss: 0.6449 | Val Loss: 0.6605 | Accuracy: 0.6080 | Precision: 0.5826 | Recall: 0.6753\n",
      "Epoch 08 | Training Loss: 0.6396 | Val Loss: 0.6756 | Accuracy: 0.5966 | Precision: 0.5639 | Recall: 0.7413\n",
      "Epoch 09 | Training Loss: 0.6379 | Val Loss: 0.6655 | Accuracy: 0.6026 | Precision: 0.5717 | Recall: 0.7191\n",
      "Epoch 10 | Training Loss: 0.6327 | Val Loss: 0.6715 | Accuracy: 0.6034 | Precision: 0.5717 | Recall: 0.7252\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6257 | Test Accuracy: 0.6048 | Test Precision: 0.5851 | Test Recall: 0.7206\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6885 | Val Loss: 0.6650 | Accuracy: 0.6020 | Precision: 0.5688 | Recall: 0.7397\n",
      "Epoch 02 | Training Loss: 0.6636 | Val Loss: 0.6827 | Accuracy: 0.5724 | Precision: 0.5380 | Recall: 0.8354\n",
      "Epoch 03 | Training Loss: 0.6582 | Val Loss: 0.6670 | Accuracy: 0.5940 | Precision: 0.6178 | Recall: 0.4262\n",
      "Epoch 04 | Training Loss: 0.6539 | Val Loss: 0.6717 | Accuracy: 0.5992 | Precision: 0.5723 | Recall: 0.6861\n",
      "Epoch 05 | Training Loss: 0.6519 | Val Loss: 0.6667 | Accuracy: 0.5990 | Precision: 0.5693 | Recall: 0.7096\n",
      "Epoch 06 | Training Loss: 0.6470 | Val Loss: 0.6622 | Accuracy: 0.6054 | Precision: 0.5926 | Recall: 0.5953\n",
      "Epoch 07 | Training Loss: 0.6435 | Val Loss: 0.6788 | Accuracy: 0.5974 | Precision: 0.6225 | Recall: 0.4307\n",
      "Epoch 08 | Training Loss: 0.6400 | Val Loss: 0.6698 | Accuracy: 0.6016 | Precision: 0.6036 | Recall: 0.5190\n",
      "Epoch 09 | Training Loss: 0.6373 | Val Loss: 0.6910 | Accuracy: 0.5750 | Precision: 0.5404 | Recall: 0.8255\n",
      "Epoch 10 | Training Loss: 0.6339 | Val Loss: 0.6669 | Accuracy: 0.5914 | Precision: 0.5583 | Recall: 0.7521\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6391 | Test Accuracy: 0.6041 | Test Precision: 0.5796 | Test Recall: 0.7582\n",
      "\n",
      "Training for parameter combination:  5, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7054 | Val Loss: 0.6894 | Accuracy: 0.5402 | Precision: 0.5241 | Recall: 0.5602\n",
      "Epoch 02 | Training Loss: 0.6890 | Val Loss: 0.6877 | Accuracy: 0.5446 | Precision: 0.5286 | Recall: 0.5598\n",
      "Epoch 03 | Training Loss: 0.6873 | Val Loss: 0.6869 | Accuracy: 0.5476 | Precision: 0.5280 | Recall: 0.6295\n",
      "Epoch 04 | Training Loss: 0.6856 | Val Loss: 0.6844 | Accuracy: 0.5534 | Precision: 0.5407 | Recall: 0.5231\n",
      "Epoch 05 | Training Loss: 0.6842 | Val Loss: 0.6838 | Accuracy: 0.5582 | Precision: 0.5392 | Recall: 0.6106\n",
      "Epoch 06 | Training Loss: 0.6828 | Val Loss: 0.6838 | Accuracy: 0.5588 | Precision: 0.5351 | Recall: 0.6848\n",
      "Epoch 07 | Training Loss: 0.6816 | Val Loss: 0.6813 | Accuracy: 0.5648 | Precision: 0.5471 | Recall: 0.5936\n",
      "Epoch 08 | Training Loss: 0.6805 | Val Loss: 0.6808 | Accuracy: 0.5692 | Precision: 0.5473 | Recall: 0.6448\n",
      "Epoch 09 | Training Loss: 0.6794 | Val Loss: 0.6793 | Accuracy: 0.5716 | Precision: 0.5531 | Recall: 0.6060\n",
      "Epoch 10 | Training Loss: 0.6784 | Val Loss: 0.6788 | Accuracy: 0.5760 | Precision: 0.5547 | Recall: 0.6361\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6688 | Test Accuracy: 0.5755 | Test Precision: 0.5682 | Test Recall: 0.6292\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7425 | Val Loss: 0.7023 | Accuracy: 0.4850 | Precision: 0.4654 | Recall: 0.4196\n",
      "Epoch 02 | Training Loss: 0.6994 | Val Loss: 0.6996 | Accuracy: 0.4906 | Precision: 0.4753 | Recall: 0.4884\n",
      "Epoch 03 | Training Loss: 0.6967 | Val Loss: 0.6968 | Accuracy: 0.4986 | Precision: 0.4831 | Recall: 0.4897\n",
      "Epoch 04 | Training Loss: 0.6943 | Val Loss: 0.6947 | Accuracy: 0.5106 | Precision: 0.4955 | Recall: 0.5272\n",
      "Epoch 05 | Training Loss: 0.6922 | Val Loss: 0.6929 | Accuracy: 0.5134 | Precision: 0.4983 | Recall: 0.5578\n",
      "Epoch 06 | Training Loss: 0.6904 | Val Loss: 0.6907 | Accuracy: 0.5178 | Precision: 0.5026 | Recall: 0.5256\n",
      "Epoch 07 | Training Loss: 0.6887 | Val Loss: 0.6890 | Accuracy: 0.5276 | Precision: 0.5123 | Recall: 0.5326\n",
      "Epoch 08 | Training Loss: 0.6872 | Val Loss: 0.6875 | Accuracy: 0.5324 | Precision: 0.5170 | Recall: 0.5380\n",
      "Epoch 09 | Training Loss: 0.6859 | Val Loss: 0.6864 | Accuracy: 0.5368 | Precision: 0.5201 | Recall: 0.5759\n",
      "Epoch 10 | Training Loss: 0.6847 | Val Loss: 0.6853 | Accuracy: 0.5426 | Precision: 0.5248 | Recall: 0.5974\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6796 | Test Accuracy: 0.5550 | Test Precision: 0.5500 | Test Recall: 0.6047\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7043 | Val Loss: 0.6989 | Accuracy: 0.5006 | Precision: 0.4868 | Recall: 0.5549\n",
      "Epoch 02 | Training Loss: 0.6975 | Val Loss: 0.6962 | Accuracy: 0.5068 | Precision: 0.4925 | Recall: 0.5697\n",
      "Epoch 03 | Training Loss: 0.6946 | Val Loss: 0.6938 | Accuracy: 0.5158 | Precision: 0.5005 | Recall: 0.5677\n",
      "Epoch 04 | Training Loss: 0.6921 | Val Loss: 0.6924 | Accuracy: 0.5184 | Precision: 0.5028 | Recall: 0.6031\n",
      "Epoch 05 | Training Loss: 0.6901 | Val Loss: 0.6899 | Accuracy: 0.5306 | Precision: 0.5152 | Recall: 0.5367\n",
      "Epoch 06 | Training Loss: 0.6881 | Val Loss: 0.6893 | Accuracy: 0.5290 | Precision: 0.5117 | Recall: 0.6209\n",
      "Epoch 07 | Training Loss: 0.6866 | Val Loss: 0.6872 | Accuracy: 0.5420 | Precision: 0.5260 | Recall: 0.5598\n",
      "Epoch 08 | Training Loss: 0.6851 | Val Loss: 0.6864 | Accuracy: 0.5478 | Precision: 0.5298 | Recall: 0.5982\n",
      "Epoch 09 | Training Loss: 0.6837 | Val Loss: 0.6855 | Accuracy: 0.5470 | Precision: 0.5283 | Recall: 0.6122\n",
      "Epoch 10 | Training Loss: 0.6825 | Val Loss: 0.6847 | Accuracy: 0.5522 | Precision: 0.5318 | Recall: 0.6382\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6735 | Test Accuracy: 0.5649 | Test Precision: 0.5545 | Test Recall: 0.6596\n",
      "\n",
      "Training for parameter combination:  6, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6999 | Val Loss: 0.6910 | Accuracy: 0.5330 | Precision: 0.5165 | Recall: 0.5751\n",
      "Epoch 02 | Training Loss: 0.6916 | Val Loss: 0.6868 | Accuracy: 0.5438 | Precision: 0.5297 | Recall: 0.5268\n",
      "Epoch 03 | Training Loss: 0.6880 | Val Loss: 0.6843 | Accuracy: 0.5488 | Precision: 0.5343 | Recall: 0.5392\n",
      "Epoch 04 | Training Loss: 0.6853 | Val Loss: 0.6827 | Accuracy: 0.5602 | Precision: 0.5429 | Recall: 0.5870\n",
      "Epoch 05 | Training Loss: 0.6830 | Val Loss: 0.6812 | Accuracy: 0.5636 | Precision: 0.5449 | Recall: 0.6060\n",
      "Epoch 06 | Training Loss: 0.6812 | Val Loss: 0.6800 | Accuracy: 0.5660 | Precision: 0.5463 | Recall: 0.6180\n",
      "Epoch 07 | Training Loss: 0.6795 | Val Loss: 0.6787 | Accuracy: 0.5692 | Precision: 0.5496 | Recall: 0.6172\n",
      "Epoch 08 | Training Loss: 0.6782 | Val Loss: 0.6771 | Accuracy: 0.5728 | Precision: 0.5582 | Recall: 0.5697\n",
      "Epoch 09 | Training Loss: 0.6770 | Val Loss: 0.6761 | Accuracy: 0.5750 | Precision: 0.5611 | Recall: 0.5664\n",
      "Epoch 10 | Training Loss: 0.6758 | Val Loss: 0.6761 | Accuracy: 0.5772 | Precision: 0.5561 | Recall: 0.6341\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6877 | Test Accuracy: 0.5743 | Test Precision: 0.5673 | Test Recall: 0.6263\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7026 | Val Loss: 0.7019 | Accuracy: 0.5040 | Precision: 0.4903 | Recall: 0.5850\n",
      "Epoch 02 | Training Loss: 0.6975 | Val Loss: 0.6968 | Accuracy: 0.5142 | Precision: 0.4990 | Recall: 0.4909\n",
      "Epoch 03 | Training Loss: 0.6941 | Val Loss: 0.6942 | Accuracy: 0.5192 | Precision: 0.5037 | Recall: 0.5582\n",
      "Epoch 04 | Training Loss: 0.6913 | Val Loss: 0.6913 | Accuracy: 0.5304 | Precision: 0.5150 | Recall: 0.5384\n",
      "Epoch 05 | Training Loss: 0.6888 | Val Loss: 0.6890 | Accuracy: 0.5406 | Precision: 0.5249 | Recall: 0.5532\n",
      "Epoch 06 | Training Loss: 0.6867 | Val Loss: 0.6880 | Accuracy: 0.5420 | Precision: 0.5232 | Recall: 0.6229\n",
      "Epoch 07 | Training Loss: 0.6850 | Val Loss: 0.6861 | Accuracy: 0.5478 | Precision: 0.5284 | Recall: 0.6254\n",
      "Epoch 08 | Training Loss: 0.6834 | Val Loss: 0.6842 | Accuracy: 0.5532 | Precision: 0.5346 | Recall: 0.6048\n",
      "Epoch 09 | Training Loss: 0.6819 | Val Loss: 0.6834 | Accuracy: 0.5550 | Precision: 0.5343 | Recall: 0.6390\n",
      "Epoch 10 | Training Loss: 0.6807 | Val Loss: 0.6823 | Accuracy: 0.5570 | Precision: 0.5357 | Recall: 0.6473\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6747 | Test Accuracy: 0.5649 | Test Precision: 0.5553 | Test Recall: 0.6520\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7266 | Val Loss: 0.7010 | Accuracy: 0.4972 | Precision: 0.4799 | Recall: 0.4422\n",
      "Epoch 02 | Training Loss: 0.6994 | Val Loss: 0.6979 | Accuracy: 0.5104 | Precision: 0.4954 | Recall: 0.5388\n",
      "Epoch 03 | Training Loss: 0.6961 | Val Loss: 0.6943 | Accuracy: 0.5210 | Precision: 0.5058 | Recall: 0.5256\n",
      "Epoch 04 | Training Loss: 0.6933 | Val Loss: 0.6919 | Accuracy: 0.5290 | Precision: 0.5129 | Recall: 0.5672\n",
      "Epoch 05 | Training Loss: 0.6909 | Val Loss: 0.6897 | Accuracy: 0.5352 | Precision: 0.5186 | Recall: 0.5763\n",
      "Epoch 06 | Training Loss: 0.6889 | Val Loss: 0.6871 | Accuracy: 0.5444 | Precision: 0.5303 | Recall: 0.5268\n",
      "Epoch 07 | Training Loss: 0.6870 | Val Loss: 0.6853 | Accuracy: 0.5462 | Precision: 0.5332 | Recall: 0.5136\n",
      "Epoch 08 | Training Loss: 0.6855 | Val Loss: 0.6840 | Accuracy: 0.5552 | Precision: 0.5400 | Recall: 0.5565\n",
      "Epoch 09 | Training Loss: 0.6841 | Val Loss: 0.6829 | Accuracy: 0.5588 | Precision: 0.5418 | Recall: 0.5829\n",
      "Epoch 10 | Training Loss: 0.6828 | Val Loss: 0.6813 | Accuracy: 0.5628 | Precision: 0.5489 | Recall: 0.5516\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6762 | Test Accuracy: 0.5596 | Test Precision: 0.5607 | Test Recall: 0.5510\n",
      "\n",
      "Training for parameter combination:  7, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6788 | Val Loss: 0.6686 | Accuracy: 0.5952 | Precision: 0.5850 | Recall: 0.5677\n",
      "Epoch 02 | Training Loss: 0.6640 | Val Loss: 0.6793 | Accuracy: 0.5890 | Precision: 0.5563 | Recall: 0.7521\n",
      "Epoch 03 | Training Loss: 0.6608 | Val Loss: 0.6613 | Accuracy: 0.6092 | Precision: 0.5805 | Recall: 0.6988\n",
      "Epoch 04 | Training Loss: 0.6569 | Val Loss: 0.6685 | Accuracy: 0.5972 | Precision: 0.5607 | Recall: 0.7814\n",
      "Epoch 05 | Training Loss: 0.6547 | Val Loss: 0.6600 | Accuracy: 0.6084 | Precision: 0.6118 | Recall: 0.5260\n",
      "Epoch 06 | Training Loss: 0.6510 | Val Loss: 0.6633 | Accuracy: 0.6030 | Precision: 0.5764 | Recall: 0.6832\n",
      "Epoch 07 | Training Loss: 0.6508 | Val Loss: 0.6584 | Accuracy: 0.6090 | Precision: 0.5882 | Recall: 0.6452\n",
      "Epoch 08 | Training Loss: 0.6485 | Val Loss: 0.6605 | Accuracy: 0.6126 | Precision: 0.5887 | Recall: 0.6667\n",
      "Epoch 09 | Training Loss: 0.6469 | Val Loss: 0.6619 | Accuracy: 0.6004 | Precision: 0.5829 | Recall: 0.6180\n",
      "Epoch 10 | Training Loss: 0.6453 | Val Loss: 0.6634 | Accuracy: 0.6028 | Precision: 0.5703 | Recall: 0.7327\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6666 | Test Accuracy: 0.6076 | Test Precision: 0.5855 | Test Recall: 0.7363\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6790 | Val Loss: 0.6638 | Accuracy: 0.6038 | Precision: 0.5734 | Recall: 0.7137\n",
      "Epoch 02 | Training Loss: 0.6644 | Val Loss: 0.6627 | Accuracy: 0.6082 | Precision: 0.5857 | Recall: 0.6555\n",
      "Epoch 03 | Training Loss: 0.6602 | Val Loss: 0.6603 | Accuracy: 0.6086 | Precision: 0.5881 | Recall: 0.6427\n",
      "Epoch 04 | Training Loss: 0.6574 | Val Loss: 0.6624 | Accuracy: 0.6082 | Precision: 0.5784 | Recall: 0.7075\n",
      "Epoch 05 | Training Loss: 0.6546 | Val Loss: 0.6939 | Accuracy: 0.5808 | Precision: 0.5478 | Recall: 0.7748\n",
      "Epoch 06 | Training Loss: 0.6517 | Val Loss: 0.6679 | Accuracy: 0.6002 | Precision: 0.5674 | Recall: 0.7376\n",
      "Epoch 07 | Training Loss: 0.6505 | Val Loss: 0.6692 | Accuracy: 0.5898 | Precision: 0.6089 | Recall: 0.4303\n",
      "Epoch 08 | Training Loss: 0.6478 | Val Loss: 0.6742 | Accuracy: 0.5942 | Precision: 0.6248 | Recall: 0.4080\n",
      "Epoch 09 | Training Loss: 0.6473 | Val Loss: 0.6617 | Accuracy: 0.6006 | Precision: 0.6011 | Recall: 0.5235\n",
      "Epoch 10 | Training Loss: 0.6455 | Val Loss: 0.6614 | Accuracy: 0.6132 | Precision: 0.5960 | Recall: 0.6275\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6646 | Test Accuracy: 0.6078 | Test Precision: 0.6060 | Test Recall: 0.6163\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6802 | Val Loss: 0.6807 | Accuracy: 0.5868 | Precision: 0.5496 | Recall: 0.8177\n",
      "Epoch 02 | Training Loss: 0.6645 | Val Loss: 0.6665 | Accuracy: 0.5954 | Precision: 0.5648 | Recall: 0.7207\n",
      "Epoch 03 | Training Loss: 0.6595 | Val Loss: 0.6674 | Accuracy: 0.5956 | Precision: 0.5593 | Recall: 0.7818\n",
      "Epoch 04 | Training Loss: 0.6561 | Val Loss: 0.6598 | Accuracy: 0.6010 | Precision: 0.6144 | Recall: 0.4752\n",
      "Epoch 05 | Training Loss: 0.6548 | Val Loss: 0.6702 | Accuracy: 0.6004 | Precision: 0.5905 | Recall: 0.5734\n",
      "Epoch 06 | Training Loss: 0.6520 | Val Loss: 0.6627 | Accuracy: 0.6038 | Precision: 0.5826 | Recall: 0.6444\n",
      "Epoch 07 | Training Loss: 0.6505 | Val Loss: 0.6610 | Accuracy: 0.6054 | Precision: 0.5800 | Recall: 0.6745\n",
      "Epoch 08 | Training Loss: 0.6495 | Val Loss: 0.6660 | Accuracy: 0.6122 | Precision: 0.5852 | Recall: 0.6873\n",
      "Epoch 09 | Training Loss: 0.6468 | Val Loss: 0.6646 | Accuracy: 0.6080 | Precision: 0.5819 | Recall: 0.6799\n",
      "Epoch 10 | Training Loss: 0.6463 | Val Loss: 0.6609 | Accuracy: 0.6098 | Precision: 0.5843 | Recall: 0.6762\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6483 | Test Accuracy: 0.6043 | Test Precision: 0.5920 | Test Recall: 0.6711\n",
      "\n",
      "Training for parameter combination:  8, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6859 | Val Loss: 0.7091 | Accuracy: 0.5360 | Precision: 0.6320 | Recall: 0.1027\n",
      "Epoch 02 | Training Loss: 0.6712 | Val Loss: 0.6896 | Accuracy: 0.5734 | Precision: 0.5377 | Recall: 0.8560\n",
      "Epoch 03 | Training Loss: 0.6684 | Val Loss: 0.6686 | Accuracy: 0.5952 | Precision: 0.6093 | Recall: 0.4600\n",
      "Epoch 04 | Training Loss: 0.6658 | Val Loss: 0.6633 | Accuracy: 0.6058 | Precision: 0.5864 | Recall: 0.6341\n",
      "Epoch 05 | Training Loss: 0.6633 | Val Loss: 0.6733 | Accuracy: 0.5908 | Precision: 0.5568 | Recall: 0.7644\n",
      "Epoch 06 | Training Loss: 0.6619 | Val Loss: 0.6687 | Accuracy: 0.5982 | Precision: 0.5707 | Recall: 0.6910\n",
      "Epoch 07 | Training Loss: 0.6598 | Val Loss: 0.6672 | Accuracy: 0.6002 | Precision: 0.5818 | Recall: 0.6233\n",
      "Epoch 08 | Training Loss: 0.6592 | Val Loss: 0.6668 | Accuracy: 0.6048 | Precision: 0.5780 | Recall: 0.6844\n",
      "Epoch 09 | Training Loss: 0.6571 | Val Loss: 0.6616 | Accuracy: 0.6050 | Precision: 0.5823 | Recall: 0.6555\n",
      "Epoch 10 | Training Loss: 0.6563 | Val Loss: 0.6604 | Accuracy: 0.6050 | Precision: 0.5967 | Recall: 0.5714\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6407 | Test Accuracy: 0.6024 | Test Precision: 0.6080 | Test Recall: 0.5761\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6881 | Val Loss: 0.7031 | Accuracy: 0.5388 | Precision: 0.6317 | Recall: 0.1167\n",
      "Epoch 02 | Training Loss: 0.6720 | Val Loss: 0.7116 | Accuracy: 0.5444 | Precision: 0.5174 | Recall: 0.8948\n",
      "Epoch 03 | Training Loss: 0.6691 | Val Loss: 0.6728 | Accuracy: 0.5936 | Precision: 0.5605 | Recall: 0.7488\n",
      "Epoch 04 | Training Loss: 0.6658 | Val Loss: 0.6788 | Accuracy: 0.5752 | Precision: 0.6200 | Recall: 0.3197\n",
      "Epoch 05 | Training Loss: 0.6638 | Val Loss: 0.6961 | Accuracy: 0.5660 | Precision: 0.5325 | Recall: 0.8585\n",
      "Epoch 06 | Training Loss: 0.6614 | Val Loss: 0.6930 | Accuracy: 0.5596 | Precision: 0.5285 | Recall: 0.8486\n",
      "Epoch 07 | Training Loss: 0.6611 | Val Loss: 0.6635 | Accuracy: 0.6014 | Precision: 0.5717 | Recall: 0.7092\n",
      "Epoch 08 | Training Loss: 0.6576 | Val Loss: 0.6763 | Accuracy: 0.5900 | Precision: 0.6328 | Recall: 0.3676\n",
      "Epoch 09 | Training Loss: 0.6558 | Val Loss: 0.6683 | Accuracy: 0.5936 | Precision: 0.5682 | Recall: 0.6737\n",
      "Epoch 10 | Training Loss: 0.6551 | Val Loss: 0.6623 | Accuracy: 0.6024 | Precision: 0.5829 | Recall: 0.6324\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6383 | Test Accuracy: 0.6086 | Test Precision: 0.6026 | Test Recall: 0.6380\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6906 | Val Loss: 0.6650 | Accuracy: 0.6020 | Precision: 0.6072 | Recall: 0.5070\n",
      "Epoch 02 | Training Loss: 0.6752 | Val Loss: 0.6677 | Accuracy: 0.5980 | Precision: 0.5647 | Recall: 0.7455\n",
      "Epoch 03 | Training Loss: 0.6690 | Val Loss: 0.6772 | Accuracy: 0.5936 | Precision: 0.5575 | Recall: 0.7834\n",
      "Epoch 04 | Training Loss: 0.6654 | Val Loss: 0.6838 | Accuracy: 0.5756 | Precision: 0.6329 | Recall: 0.2966\n",
      "Epoch 05 | Training Loss: 0.6644 | Val Loss: 0.6757 | Accuracy: 0.5872 | Precision: 0.5516 | Recall: 0.7937\n",
      "Epoch 06 | Training Loss: 0.6624 | Val Loss: 0.6677 | Accuracy: 0.5978 | Precision: 0.5662 | Recall: 0.7281\n",
      "Epoch 07 | Training Loss: 0.6606 | Val Loss: 0.6897 | Accuracy: 0.5762 | Precision: 0.5406 | Recall: 0.8370\n",
      "Epoch 08 | Training Loss: 0.6600 | Val Loss: 0.6679 | Accuracy: 0.5946 | Precision: 0.5622 | Recall: 0.7401\n",
      "Epoch 09 | Training Loss: 0.6571 | Val Loss: 0.6721 | Accuracy: 0.5894 | Precision: 0.5570 | Recall: 0.7479\n",
      "Epoch 10 | Training Loss: 0.6556 | Val Loss: 0.6611 | Accuracy: 0.6032 | Precision: 0.5857 | Recall: 0.6205\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6364 | Test Accuracy: 0.6088 | Test Precision: 0.6047 | Test Recall: 0.6285\n",
      "\n",
      "Training for parameter combination:  9, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6912 | Val Loss: 0.6840 | Accuracy: 0.5570 | Precision: 0.5397 | Recall: 0.5866\n",
      "Epoch 02 | Training Loss: 0.6780 | Val Loss: 0.6748 | Accuracy: 0.5782 | Precision: 0.5630 | Recall: 0.5809\n",
      "Epoch 03 | Training Loss: 0.6708 | Val Loss: 0.6695 | Accuracy: 0.5924 | Precision: 0.5887 | Recall: 0.5285\n",
      "Epoch 04 | Training Loss: 0.6669 | Val Loss: 0.6679 | Accuracy: 0.5948 | Precision: 0.5689 | Recall: 0.6782\n",
      "Epoch 05 | Training Loss: 0.6641 | Val Loss: 0.6650 | Accuracy: 0.6012 | Precision: 0.5842 | Recall: 0.6151\n",
      "Epoch 06 | Training Loss: 0.6629 | Val Loss: 0.6641 | Accuracy: 0.6020 | Precision: 0.5845 | Recall: 0.6192\n",
      "Epoch 07 | Training Loss: 0.6618 | Val Loss: 0.6634 | Accuracy: 0.6048 | Precision: 0.5864 | Recall: 0.6271\n",
      "Epoch 08 | Training Loss: 0.6609 | Val Loss: 0.6631 | Accuracy: 0.6028 | Precision: 0.5910 | Recall: 0.5866\n",
      "Epoch 09 | Training Loss: 0.6604 | Val Loss: 0.6633 | Accuracy: 0.6090 | Precision: 0.5827 | Recall: 0.6819\n",
      "Epoch 10 | Training Loss: 0.6601 | Val Loss: 0.6627 | Accuracy: 0.6092 | Precision: 0.5843 | Recall: 0.6720\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6499 | Test Accuracy: 0.6091 | Test Precision: 0.5964 | Test Recall: 0.6753\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6892 | Val Loss: 0.6829 | Accuracy: 0.5648 | Precision: 0.5454 | Recall: 0.6143\n",
      "Epoch 02 | Training Loss: 0.6769 | Val Loss: 0.6743 | Accuracy: 0.5922 | Precision: 0.5683 | Recall: 0.6605\n",
      "Epoch 03 | Training Loss: 0.6699 | Val Loss: 0.6685 | Accuracy: 0.6010 | Precision: 0.5782 | Recall: 0.6543\n",
      "Epoch 04 | Training Loss: 0.6658 | Val Loss: 0.6655 | Accuracy: 0.6056 | Precision: 0.5850 | Recall: 0.6419\n",
      "Epoch 05 | Training Loss: 0.6639 | Val Loss: 0.6642 | Accuracy: 0.6050 | Precision: 0.5946 | Recall: 0.5821\n",
      "Epoch 06 | Training Loss: 0.6620 | Val Loss: 0.6633 | Accuracy: 0.6078 | Precision: 0.5932 | Recall: 0.6077\n",
      "Epoch 07 | Training Loss: 0.6607 | Val Loss: 0.6659 | Accuracy: 0.6022 | Precision: 0.5689 | Recall: 0.7413\n",
      "Epoch 08 | Training Loss: 0.6602 | Val Loss: 0.6629 | Accuracy: 0.6090 | Precision: 0.5821 | Recall: 0.6861\n",
      "Epoch 09 | Training Loss: 0.6599 | Val Loss: 0.6629 | Accuracy: 0.6094 | Precision: 0.5817 | Recall: 0.6914\n",
      "Epoch 10 | Training Loss: 0.6594 | Val Loss: 0.6621 | Accuracy: 0.6114 | Precision: 0.5881 | Recall: 0.6625\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6453 | Test Accuracy: 0.6091 | Test Precision: 0.5985 | Test Recall: 0.6630\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6919 | Val Loss: 0.6829 | Accuracy: 0.5628 | Precision: 0.5410 | Recall: 0.6481\n",
      "Epoch 02 | Training Loss: 0.6780 | Val Loss: 0.6720 | Accuracy: 0.5932 | Precision: 0.5846 | Recall: 0.5557\n",
      "Epoch 03 | Training Loss: 0.6700 | Val Loss: 0.6678 | Accuracy: 0.6086 | Precision: 0.5799 | Recall: 0.6993\n",
      "Epoch 04 | Training Loss: 0.6652 | Val Loss: 0.6644 | Accuracy: 0.6128 | Precision: 0.5882 | Recall: 0.6712\n",
      "Epoch 05 | Training Loss: 0.6627 | Val Loss: 0.6626 | Accuracy: 0.6138 | Precision: 0.5957 | Recall: 0.6328\n",
      "Epoch 06 | Training Loss: 0.6611 | Val Loss: 0.6627 | Accuracy: 0.6112 | Precision: 0.5846 | Recall: 0.6844\n",
      "Epoch 07 | Training Loss: 0.6604 | Val Loss: 0.6619 | Accuracy: 0.6072 | Precision: 0.5951 | Recall: 0.5936\n",
      "Epoch 08 | Training Loss: 0.6596 | Val Loss: 0.6619 | Accuracy: 0.6108 | Precision: 0.5860 | Recall: 0.6716\n",
      "Epoch 09 | Training Loss: 0.6592 | Val Loss: 0.6616 | Accuracy: 0.6114 | Precision: 0.5885 | Recall: 0.6597\n",
      "Epoch 10 | Training Loss: 0.6589 | Val Loss: 0.6632 | Accuracy: 0.6092 | Precision: 0.5784 | Recall: 0.7153\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6455 | Test Accuracy: 0.6057 | Test Precision: 0.5867 | Test Recall: 0.7151\n",
      "\n",
      "Training for parameter combination:  10, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6827 | Val Loss: 0.6739 | Accuracy: 0.5876 | Precision: 0.5706 | Recall: 0.6031\n",
      "Epoch 02 | Training Loss: 0.6704 | Val Loss: 0.6683 | Accuracy: 0.5984 | Precision: 0.5757 | Recall: 0.6526\n",
      "Epoch 03 | Training Loss: 0.6655 | Val Loss: 0.6664 | Accuracy: 0.6030 | Precision: 0.5747 | Recall: 0.6968\n",
      "Epoch 04 | Training Loss: 0.6630 | Val Loss: 0.6661 | Accuracy: 0.6046 | Precision: 0.5734 | Recall: 0.7207\n",
      "Epoch 05 | Training Loss: 0.6614 | Val Loss: 0.6659 | Accuracy: 0.6040 | Precision: 0.5718 | Recall: 0.7290\n",
      "Epoch 06 | Training Loss: 0.6600 | Val Loss: 0.6635 | Accuracy: 0.6080 | Precision: 0.5822 | Recall: 0.6778\n",
      "Epoch 07 | Training Loss: 0.6598 | Val Loss: 0.6636 | Accuracy: 0.6088 | Precision: 0.5804 | Recall: 0.6972\n",
      "Epoch 08 | Training Loss: 0.6589 | Val Loss: 0.6638 | Accuracy: 0.6090 | Precision: 0.5791 | Recall: 0.7079\n",
      "Epoch 09 | Training Loss: 0.6585 | Val Loss: 0.6626 | Accuracy: 0.6090 | Precision: 0.5833 | Recall: 0.6774\n",
      "Epoch 10 | Training Loss: 0.6577 | Val Loss: 0.6628 | Accuracy: 0.6094 | Precision: 0.5813 | Recall: 0.6947\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6480 | Test Accuracy: 0.6075 | Test Precision: 0.5912 | Test Recall: 0.6970\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6932 | Val Loss: 0.6890 | Accuracy: 0.5458 | Precision: 0.5214 | Recall: 0.7677\n",
      "Epoch 02 | Training Loss: 0.6770 | Val Loss: 0.6746 | Accuracy: 0.5850 | Precision: 0.5906 | Recall: 0.4691\n",
      "Epoch 03 | Training Loss: 0.6687 | Val Loss: 0.6705 | Accuracy: 0.5992 | Precision: 0.5688 | Recall: 0.7162\n",
      "Epoch 04 | Training Loss: 0.6643 | Val Loss: 0.6678 | Accuracy: 0.6016 | Precision: 0.5704 | Recall: 0.7219\n",
      "Epoch 05 | Training Loss: 0.6622 | Val Loss: 0.6657 | Accuracy: 0.6066 | Precision: 0.6021 | Recall: 0.5557\n",
      "Epoch 06 | Training Loss: 0.6610 | Val Loss: 0.6685 | Accuracy: 0.5964 | Precision: 0.5630 | Recall: 0.7483\n",
      "Epoch 07 | Training Loss: 0.6600 | Val Loss: 0.6656 | Accuracy: 0.6030 | Precision: 0.5715 | Recall: 0.7236\n",
      "Epoch 08 | Training Loss: 0.6590 | Val Loss: 0.6636 | Accuracy: 0.6092 | Precision: 0.5799 | Recall: 0.7038\n",
      "Epoch 09 | Training Loss: 0.6587 | Val Loss: 0.6624 | Accuracy: 0.6126 | Precision: 0.5926 | Recall: 0.6427\n",
      "Epoch 10 | Training Loss: 0.6584 | Val Loss: 0.6621 | Accuracy: 0.6110 | Precision: 0.5883 | Recall: 0.6584\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6454 | Test Accuracy: 0.6076 | Test Precision: 0.5982 | Test Recall: 0.6555\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6860 | Val Loss: 0.6776 | Accuracy: 0.5780 | Precision: 0.5713 | Recall: 0.5190\n",
      "Epoch 02 | Training Loss: 0.6704 | Val Loss: 0.6696 | Accuracy: 0.5894 | Precision: 0.5818 | Recall: 0.5446\n",
      "Epoch 03 | Training Loss: 0.6649 | Val Loss: 0.6671 | Accuracy: 0.5966 | Precision: 0.5685 | Recall: 0.6964\n",
      "Epoch 04 | Training Loss: 0.6623 | Val Loss: 0.6649 | Accuracy: 0.6024 | Precision: 0.5759 | Recall: 0.6828\n",
      "Epoch 05 | Training Loss: 0.6608 | Val Loss: 0.6677 | Accuracy: 0.6012 | Precision: 0.5671 | Recall: 0.7492\n",
      "Epoch 06 | Training Loss: 0.6599 | Val Loss: 0.6640 | Accuracy: 0.6046 | Precision: 0.5767 | Recall: 0.6935\n",
      "Epoch 07 | Training Loss: 0.6594 | Val Loss: 0.6639 | Accuracy: 0.6054 | Precision: 0.5763 | Recall: 0.7030\n",
      "Epoch 08 | Training Loss: 0.6592 | Val Loss: 0.6639 | Accuracy: 0.6052 | Precision: 0.5756 | Recall: 0.7067\n",
      "Epoch 09 | Training Loss: 0.6585 | Val Loss: 0.6625 | Accuracy: 0.6076 | Precision: 0.5810 | Recall: 0.6836\n",
      "Epoch 10 | Training Loss: 0.6579 | Val Loss: 0.6633 | Accuracy: 0.6048 | Precision: 0.5750 | Recall: 0.7087\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6475 | Test Accuracy: 0.6072 | Test Precision: 0.5875 | Test Recall: 0.7194\n",
      "\n",
      "Training for parameter combination:  11, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6730 | Val Loss: 0.6713 | Accuracy: 0.5882 | Precision: 0.5526 | Recall: 0.7904\n",
      "Epoch 02 | Training Loss: 0.6630 | Val Loss: 0.6723 | Accuracy: 0.5854 | Precision: 0.5497 | Recall: 0.8007\n",
      "Epoch 03 | Training Loss: 0.6587 | Val Loss: 0.6628 | Accuracy: 0.5996 | Precision: 0.5664 | Recall: 0.7426\n",
      "Epoch 04 | Training Loss: 0.6565 | Val Loss: 0.6665 | Accuracy: 0.6002 | Precision: 0.5665 | Recall: 0.7467\n",
      "Epoch 05 | Training Loss: 0.6536 | Val Loss: 0.6723 | Accuracy: 0.5918 | Precision: 0.5538 | Recall: 0.8131\n",
      "Epoch 06 | Training Loss: 0.6507 | Val Loss: 0.6609 | Accuracy: 0.6044 | Precision: 0.5779 | Recall: 0.6828\n",
      "Epoch 07 | Training Loss: 0.6467 | Val Loss: 0.6605 | Accuracy: 0.6068 | Precision: 0.5754 | Recall: 0.7207\n",
      "Epoch 08 | Training Loss: 0.6434 | Val Loss: 0.6654 | Accuracy: 0.6038 | Precision: 0.5708 | Recall: 0.7364\n",
      "Epoch 09 | Training Loss: 0.6408 | Val Loss: 0.6604 | Accuracy: 0.6080 | Precision: 0.5802 | Recall: 0.6927\n",
      "Epoch 10 | Training Loss: 0.6358 | Val Loss: 0.6646 | Accuracy: 0.5958 | Precision: 0.5627 | Recall: 0.7463\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6692 | Test Accuracy: 0.6036 | Test Precision: 0.5803 | Test Recall: 0.7490\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6739 | Val Loss: 0.6616 | Accuracy: 0.6124 | Precision: 0.5915 | Recall: 0.6481\n",
      "Epoch 02 | Training Loss: 0.6627 | Val Loss: 0.6627 | Accuracy: 0.6074 | Precision: 0.5904 | Recall: 0.6213\n",
      "Epoch 03 | Training Loss: 0.6598 | Val Loss: 0.6590 | Accuracy: 0.6086 | Precision: 0.5838 | Recall: 0.6712\n",
      "Epoch 04 | Training Loss: 0.6577 | Val Loss: 0.6639 | Accuracy: 0.6010 | Precision: 0.5844 | Recall: 0.6126\n",
      "Epoch 05 | Training Loss: 0.6542 | Val Loss: 0.6697 | Accuracy: 0.5940 | Precision: 0.5587 | Recall: 0.7735\n",
      "Epoch 06 | Training Loss: 0.6516 | Val Loss: 0.6689 | Accuracy: 0.5966 | Precision: 0.5619 | Recall: 0.7616\n",
      "Epoch 07 | Training Loss: 0.6489 | Val Loss: 0.6620 | Accuracy: 0.6080 | Precision: 0.5775 | Recall: 0.7133\n",
      "Epoch 08 | Training Loss: 0.6445 | Val Loss: 0.6583 | Accuracy: 0.6056 | Precision: 0.5913 | Recall: 0.6040\n",
      "Epoch 09 | Training Loss: 0.6415 | Val Loss: 0.6609 | Accuracy: 0.6074 | Precision: 0.5835 | Recall: 0.6646\n",
      "Epoch 10 | Training Loss: 0.6400 | Val Loss: 0.6640 | Accuracy: 0.6108 | Precision: 0.5910 | Recall: 0.6403\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6357 | Test Accuracy: 0.6056 | Test Precision: 0.6009 | Test Recall: 0.6293\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6731 | Val Loss: 0.6646 | Accuracy: 0.6016 | Precision: 0.5699 | Recall: 0.7265\n",
      "Epoch 02 | Training Loss: 0.6611 | Val Loss: 0.6599 | Accuracy: 0.6106 | Precision: 0.5953 | Recall: 0.6147\n",
      "Epoch 03 | Training Loss: 0.6575 | Val Loss: 0.6689 | Accuracy: 0.5992 | Precision: 0.5628 | Recall: 0.7768\n",
      "Epoch 04 | Training Loss: 0.6553 | Val Loss: 0.6658 | Accuracy: 0.5998 | Precision: 0.5682 | Recall: 0.7269\n",
      "Epoch 05 | Training Loss: 0.6509 | Val Loss: 0.6643 | Accuracy: 0.6014 | Precision: 0.5656 | Recall: 0.7661\n",
      "Epoch 06 | Training Loss: 0.6498 | Val Loss: 0.6605 | Accuracy: 0.6082 | Precision: 0.5770 | Recall: 0.7191\n",
      "Epoch 07 | Training Loss: 0.6457 | Val Loss: 0.6604 | Accuracy: 0.6146 | Precision: 0.6026 | Recall: 0.6019\n",
      "Epoch 08 | Training Loss: 0.6430 | Val Loss: 0.6583 | Accuracy: 0.6138 | Precision: 0.5909 | Recall: 0.6609\n",
      "Epoch 09 | Training Loss: 0.6392 | Val Loss: 0.6633 | Accuracy: 0.6088 | Precision: 0.5871 | Recall: 0.6506\n",
      "Epoch 10 | Training Loss: 0.6369 | Val Loss: 0.6725 | Accuracy: 0.6010 | Precision: 0.5704 | Recall: 0.7166\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6963 | Test Accuracy: 0.6060 | Test Precision: 0.5863 | Test Recall: 0.7195\n",
      "\n",
      "Training for parameter combination:  12, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7010 | Val Loss: 0.6661 | Accuracy: 0.5972 | Precision: 0.5926 | Recall: 0.5413\n",
      "Epoch 02 | Training Loss: 0.6677 | Val Loss: 0.6624 | Accuracy: 0.6032 | Precision: 0.5828 | Recall: 0.6386\n",
      "Epoch 03 | Training Loss: 0.6609 | Val Loss: 0.6739 | Accuracy: 0.5868 | Precision: 0.5554 | Recall: 0.7405\n",
      "Epoch 04 | Training Loss: 0.6550 | Val Loss: 0.6785 | Accuracy: 0.5910 | Precision: 0.5574 | Recall: 0.7591\n",
      "Epoch 05 | Training Loss: 0.6515 | Val Loss: 0.6644 | Accuracy: 0.5996 | Precision: 0.5881 | Recall: 0.5809\n",
      "Epoch 06 | Training Loss: 0.6486 | Val Loss: 0.6651 | Accuracy: 0.5976 | Precision: 0.5679 | Recall: 0.7112\n",
      "Epoch 07 | Training Loss: 0.6436 | Val Loss: 0.7037 | Accuracy: 0.5514 | Precision: 0.5220 | Recall: 0.8870\n",
      "Epoch 08 | Training Loss: 0.6402 | Val Loss: 0.6711 | Accuracy: 0.5840 | Precision: 0.6225 | Recall: 0.3606\n",
      "Epoch 09 | Training Loss: 0.6355 | Val Loss: 0.6755 | Accuracy: 0.5874 | Precision: 0.5601 | Recall: 0.6939\n",
      "Epoch 10 | Training Loss: 0.6318 | Val Loss: 0.6784 | Accuracy: 0.6008 | Precision: 0.5897 | Recall: 0.5804\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5991 | Test Accuracy: 0.6030 | Test Precision: 0.6075 | Test Recall: 0.5817\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7127 | Val Loss: 0.6697 | Accuracy: 0.5886 | Precision: 0.5539 | Recall: 0.7785\n",
      "Epoch 02 | Training Loss: 0.6653 | Val Loss: 0.6640 | Accuracy: 0.5972 | Precision: 0.6033 | Recall: 0.4938\n",
      "Epoch 03 | Training Loss: 0.6599 | Val Loss: 0.6656 | Accuracy: 0.6006 | Precision: 0.6192 | Recall: 0.4575\n",
      "Epoch 04 | Training Loss: 0.6540 | Val Loss: 0.6690 | Accuracy: 0.5946 | Precision: 0.6195 | Recall: 0.4245\n",
      "Epoch 05 | Training Loss: 0.6507 | Val Loss: 0.6781 | Accuracy: 0.5806 | Precision: 0.5450 | Recall: 0.8172\n",
      "Epoch 06 | Training Loss: 0.6471 | Val Loss: 0.6653 | Accuracy: 0.6078 | Precision: 0.5907 | Recall: 0.6221\n",
      "Epoch 07 | Training Loss: 0.6452 | Val Loss: 0.6719 | Accuracy: 0.5966 | Precision: 0.5969 | Recall: 0.5173\n",
      "Epoch 08 | Training Loss: 0.6415 | Val Loss: 0.6721 | Accuracy: 0.5990 | Precision: 0.5674 | Recall: 0.7273\n",
      "Epoch 09 | Training Loss: 0.6388 | Val Loss: 0.6729 | Accuracy: 0.5986 | Precision: 0.5684 | Recall: 0.7149\n",
      "Epoch 10 | Training Loss: 0.6351 | Val Loss: 0.7096 | Accuracy: 0.5710 | Precision: 0.5379 | Recall: 0.8160\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6461 | Test Accuracy: 0.5893 | Test Precision: 0.5615 | Test Recall: 0.8157\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7042 | Val Loss: 0.7100 | Accuracy: 0.5352 | Precision: 0.6923 | Recall: 0.0743\n",
      "Epoch 02 | Training Loss: 0.6654 | Val Loss: 0.6639 | Accuracy: 0.6058 | Precision: 0.6075 | Recall: 0.5281\n",
      "Epoch 03 | Training Loss: 0.6593 | Val Loss: 0.6605 | Accuracy: 0.6088 | Precision: 0.5967 | Recall: 0.5957\n",
      "Epoch 04 | Training Loss: 0.6551 | Val Loss: 0.6642 | Accuracy: 0.6092 | Precision: 0.5818 | Recall: 0.6894\n",
      "Epoch 05 | Training Loss: 0.6511 | Val Loss: 0.6885 | Accuracy: 0.5682 | Precision: 0.5340 | Recall: 0.8577\n",
      "Epoch 06 | Training Loss: 0.6466 | Val Loss: 0.6738 | Accuracy: 0.5926 | Precision: 0.6330 | Recall: 0.3800\n",
      "Epoch 07 | Training Loss: 0.6437 | Val Loss: 0.6772 | Accuracy: 0.5894 | Precision: 0.5533 | Recall: 0.7946\n",
      "Epoch 08 | Training Loss: 0.6396 | Val Loss: 0.6674 | Accuracy: 0.5976 | Precision: 0.6036 | Recall: 0.4950\n",
      "Epoch 09 | Training Loss: 0.6363 | Val Loss: 0.6759 | Accuracy: 0.5812 | Precision: 0.5618 | Recall: 0.6192\n",
      "Epoch 10 | Training Loss: 0.6337 | Val Loss: 0.6702 | Accuracy: 0.6054 | Precision: 0.5862 | Recall: 0.6328\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6422 | Test Accuracy: 0.6010 | Test Precision: 0.5963 | Test Recall: 0.6250\n",
      "\n",
      "Training for parameter combination:  13, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7801 | Val Loss: 0.7626 | Accuracy: 0.5054 | Precision: 0.4907 | Recall: 0.5355\n",
      "Epoch 02 | Training Loss: 0.7644 | Val Loss: 0.7538 | Accuracy: 0.5078 | Precision: 0.4927 | Recall: 0.5149\n",
      "Epoch 03 | Training Loss: 0.7563 | Val Loss: 0.7467 | Accuracy: 0.5084 | Precision: 0.4934 | Recall: 0.5231\n",
      "Epoch 04 | Training Loss: 0.7490 | Val Loss: 0.7402 | Accuracy: 0.5088 | Precision: 0.4937 | Recall: 0.5182\n",
      "Epoch 05 | Training Loss: 0.7424 | Val Loss: 0.7348 | Accuracy: 0.5114 | Precision: 0.4964 | Recall: 0.5351\n",
      "Epoch 06 | Training Loss: 0.7365 | Val Loss: 0.7294 | Accuracy: 0.5122 | Precision: 0.4971 | Recall: 0.5235\n",
      "Epoch 07 | Training Loss: 0.7313 | Val Loss: 0.7248 | Accuracy: 0.5172 | Precision: 0.5020 | Recall: 0.5305\n",
      "Epoch 08 | Training Loss: 0.7265 | Val Loss: 0.7205 | Accuracy: 0.5192 | Precision: 0.5039 | Recall: 0.5314\n",
      "Epoch 09 | Training Loss: 0.7221 | Val Loss: 0.7174 | Accuracy: 0.5228 | Precision: 0.5070 | Recall: 0.5652\n",
      "Epoch 10 | Training Loss: 0.7181 | Val Loss: 0.7132 | Accuracy: 0.5226 | Precision: 0.5072 | Recall: 0.5355\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6899 | Test Accuracy: 0.5184 | Test Precision: 0.5183 | Test Recall: 0.5210\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.8280 | Val Loss: 0.7252 | Accuracy: 0.4934 | Precision: 0.4754 | Recall: 0.4336\n",
      "Epoch 02 | Training Loss: 0.7232 | Val Loss: 0.7225 | Accuracy: 0.4960 | Precision: 0.4818 | Recall: 0.5256\n",
      "Epoch 03 | Training Loss: 0.7195 | Val Loss: 0.7188 | Accuracy: 0.5014 | Precision: 0.4865 | Recall: 0.5144\n",
      "Epoch 04 | Training Loss: 0.7164 | Val Loss: 0.7157 | Accuracy: 0.5050 | Precision: 0.4899 | Recall: 0.5107\n",
      "Epoch 05 | Training Loss: 0.7135 | Val Loss: 0.7127 | Accuracy: 0.5080 | Precision: 0.4927 | Recall: 0.5000\n",
      "Epoch 06 | Training Loss: 0.7110 | Val Loss: 0.7106 | Accuracy: 0.5136 | Precision: 0.4984 | Recall: 0.5223\n",
      "Epoch 07 | Training Loss: 0.7086 | Val Loss: 0.7081 | Accuracy: 0.5152 | Precision: 0.5000 | Recall: 0.5153\n",
      "Epoch 08 | Training Loss: 0.7065 | Val Loss: 0.7070 | Accuracy: 0.5166 | Precision: 0.5013 | Recall: 0.5561\n",
      "Epoch 09 | Training Loss: 0.7046 | Val Loss: 0.7045 | Accuracy: 0.5206 | Precision: 0.5052 | Recall: 0.5388\n",
      "Epoch 10 | Training Loss: 0.7028 | Val Loss: 0.7024 | Accuracy: 0.5238 | Precision: 0.5086 | Recall: 0.5223\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6980 | Test Accuracy: 0.5215 | Test Precision: 0.5214 | Test Recall: 0.5234\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7940 | Val Loss: 0.7485 | Accuracy: 0.5074 | Precision: 0.4929 | Recall: 0.5594\n",
      "Epoch 02 | Training Loss: 0.7404 | Val Loss: 0.7341 | Accuracy: 0.5138 | Precision: 0.4986 | Recall: 0.5305\n",
      "Epoch 03 | Training Loss: 0.7290 | Val Loss: 0.7239 | Accuracy: 0.5180 | Precision: 0.5028 | Recall: 0.5252\n",
      "Epoch 04 | Training Loss: 0.7199 | Val Loss: 0.7157 | Accuracy: 0.5264 | Precision: 0.5113 | Recall: 0.5248\n",
      "Epoch 05 | Training Loss: 0.7126 | Val Loss: 0.7090 | Accuracy: 0.5352 | Precision: 0.5204 | Recall: 0.5252\n",
      "Epoch 06 | Training Loss: 0.7067 | Val Loss: 0.7044 | Accuracy: 0.5386 | Precision: 0.5224 | Recall: 0.5619\n",
      "Epoch 07 | Training Loss: 0.7018 | Val Loss: 0.6994 | Accuracy: 0.5442 | Precision: 0.5294 | Recall: 0.5380\n",
      "Epoch 08 | Training Loss: 0.6979 | Val Loss: 0.6963 | Accuracy: 0.5464 | Precision: 0.5306 | Recall: 0.5582\n",
      "Epoch 09 | Training Loss: 0.6946 | Val Loss: 0.6931 | Accuracy: 0.5514 | Precision: 0.5362 | Recall: 0.5536\n",
      "Epoch 10 | Training Loss: 0.6919 | Val Loss: 0.6903 | Accuracy: 0.5558 | Precision: 0.5426 | Recall: 0.5334\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7048 | Test Accuracy: 0.5463 | Test Precision: 0.5485 | Test Recall: 0.5232\n",
      "\n",
      "Training for parameter combination:  14, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6814 | Val Loss: 0.6660 | Accuracy: 0.5964 | Precision: 0.6093 | Recall: 0.4670\n",
      "Epoch 02 | Training Loss: 0.6650 | Val Loss: 0.6696 | Accuracy: 0.5894 | Precision: 0.5552 | Recall: 0.7698\n",
      "Epoch 03 | Training Loss: 0.6601 | Val Loss: 0.6621 | Accuracy: 0.6062 | Precision: 0.5774 | Recall: 0.7005\n",
      "Epoch 04 | Training Loss: 0.6563 | Val Loss: 0.6717 | Accuracy: 0.5882 | Precision: 0.5527 | Recall: 0.7896\n",
      "Epoch 05 | Training Loss: 0.6532 | Val Loss: 0.6596 | Accuracy: 0.6102 | Precision: 0.5855 | Recall: 0.6708\n",
      "Epoch 06 | Training Loss: 0.6501 | Val Loss: 0.6599 | Accuracy: 0.6052 | Precision: 0.5790 | Recall: 0.6803\n",
      "Epoch 07 | Training Loss: 0.6470 | Val Loss: 0.6776 | Accuracy: 0.5838 | Precision: 0.5477 | Recall: 0.8123\n",
      "Epoch 08 | Training Loss: 0.6453 | Val Loss: 0.6592 | Accuracy: 0.6074 | Precision: 0.5801 | Recall: 0.6885\n",
      "Epoch 09 | Training Loss: 0.6409 | Val Loss: 0.6653 | Accuracy: 0.5992 | Precision: 0.6382 | Recall: 0.4002\n",
      "Epoch 10 | Training Loss: 0.6402 | Val Loss: 0.6576 | Accuracy: 0.6086 | Precision: 0.5870 | Recall: 0.6502\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6265 | Test Accuracy: 0.6050 | Test Precision: 0.5971 | Test Recall: 0.6454\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6765 | Val Loss: 0.6665 | Accuracy: 0.5946 | Precision: 0.5987 | Recall: 0.4967\n",
      "Epoch 02 | Training Loss: 0.6625 | Val Loss: 0.6685 | Accuracy: 0.5986 | Precision: 0.5652 | Recall: 0.7455\n",
      "Epoch 03 | Training Loss: 0.6594 | Val Loss: 0.6728 | Accuracy: 0.5938 | Precision: 0.5585 | Recall: 0.7735\n",
      "Epoch 04 | Training Loss: 0.6559 | Val Loss: 0.6640 | Accuracy: 0.6046 | Precision: 0.6057 | Recall: 0.5285\n",
      "Epoch 05 | Training Loss: 0.6524 | Val Loss: 0.6623 | Accuracy: 0.6046 | Precision: 0.5825 | Recall: 0.6510\n",
      "Epoch 06 | Training Loss: 0.6513 | Val Loss: 0.6622 | Accuracy: 0.6038 | Precision: 0.5796 | Recall: 0.6654\n",
      "Epoch 07 | Training Loss: 0.6487 | Val Loss: 0.6626 | Accuracy: 0.6024 | Precision: 0.6107 | Recall: 0.4963\n",
      "Epoch 08 | Training Loss: 0.6448 | Val Loss: 0.6612 | Accuracy: 0.6022 | Precision: 0.5971 | Recall: 0.5520\n",
      "Epoch 09 | Training Loss: 0.6419 | Val Loss: 0.6625 | Accuracy: 0.5988 | Precision: 0.5813 | Recall: 0.6167\n",
      "Epoch 10 | Training Loss: 0.6391 | Val Loss: 0.6605 | Accuracy: 0.6020 | Precision: 0.5830 | Recall: 0.6291\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6394 | Test Accuracy: 0.6074 | Test Precision: 0.6025 | Test Recall: 0.6314\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6777 | Val Loss: 0.6675 | Accuracy: 0.5950 | Precision: 0.5830 | Recall: 0.5780\n",
      "Epoch 02 | Training Loss: 0.6632 | Val Loss: 0.6714 | Accuracy: 0.5934 | Precision: 0.5603 | Recall: 0.7496\n",
      "Epoch 03 | Training Loss: 0.6583 | Val Loss: 0.6648 | Accuracy: 0.6010 | Precision: 0.5720 | Recall: 0.7034\n",
      "Epoch 04 | Training Loss: 0.6560 | Val Loss: 0.6712 | Accuracy: 0.5912 | Precision: 0.5570 | Recall: 0.7661\n",
      "Epoch 05 | Training Loss: 0.6527 | Val Loss: 0.6657 | Accuracy: 0.5984 | Precision: 0.5676 | Recall: 0.7207\n",
      "Epoch 06 | Training Loss: 0.6497 | Val Loss: 0.6662 | Accuracy: 0.5978 | Precision: 0.5690 | Recall: 0.7021\n",
      "Epoch 07 | Training Loss: 0.6473 | Val Loss: 0.6618 | Accuracy: 0.6054 | Precision: 0.5795 | Recall: 0.6782\n",
      "Epoch 08 | Training Loss: 0.6437 | Val Loss: 0.6623 | Accuracy: 0.6014 | Precision: 0.5765 | Recall: 0.6700\n",
      "Epoch 09 | Training Loss: 0.6428 | Val Loss: 0.6629 | Accuracy: 0.5980 | Precision: 0.5694 | Recall: 0.7009\n",
      "Epoch 10 | Training Loss: 0.6403 | Val Loss: 0.6630 | Accuracy: 0.6050 | Precision: 0.5994 | Recall: 0.5586\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6389 | Test Accuracy: 0.6033 | Test Precision: 0.6159 | Test Recall: 0.5490\n",
      "\n",
      "Training for parameter combination:  15, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6787 | Val Loss: 0.6746 | Accuracy: 0.5828 | Precision: 0.5481 | Recall: 0.7937\n",
      "Epoch 02 | Training Loss: 0.6657 | Val Loss: 0.6686 | Accuracy: 0.5932 | Precision: 0.5604 | Recall: 0.7467\n",
      "Epoch 03 | Training Loss: 0.6622 | Val Loss: 0.6673 | Accuracy: 0.5926 | Precision: 0.6099 | Recall: 0.4431\n",
      "Epoch 04 | Training Loss: 0.6611 | Val Loss: 0.6648 | Accuracy: 0.5994 | Precision: 0.5678 | Recall: 0.7269\n",
      "Epoch 05 | Training Loss: 0.6603 | Val Loss: 0.6682 | Accuracy: 0.5928 | Precision: 0.5585 | Recall: 0.7640\n",
      "Epoch 06 | Training Loss: 0.6594 | Val Loss: 0.6717 | Accuracy: 0.5890 | Precision: 0.5536 | Recall: 0.7867\n",
      "Epoch 07 | Training Loss: 0.6584 | Val Loss: 0.6612 | Accuracy: 0.6062 | Precision: 0.5929 | Recall: 0.5990\n",
      "Epoch 08 | Training Loss: 0.6579 | Val Loss: 0.6645 | Accuracy: 0.6014 | Precision: 0.5681 | Recall: 0.7413\n",
      "Epoch 09 | Training Loss: 0.6574 | Val Loss: 0.6601 | Accuracy: 0.6104 | Precision: 0.5897 | Recall: 0.6456\n",
      "Epoch 10 | Training Loss: 0.6568 | Val Loss: 0.6614 | Accuracy: 0.6110 | Precision: 0.6063 | Recall: 0.5635\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6420 | Test Accuracy: 0.6030 | Test Precision: 0.6134 | Test Recall: 0.5570\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6818 | Val Loss: 0.6710 | Accuracy: 0.5830 | Precision: 0.6079 | Recall: 0.3940\n",
      "Epoch 02 | Training Loss: 0.6656 | Val Loss: 0.6638 | Accuracy: 0.6016 | Precision: 0.5878 | Recall: 0.5965\n",
      "Epoch 03 | Training Loss: 0.6626 | Val Loss: 0.6689 | Accuracy: 0.5958 | Precision: 0.6275 | Recall: 0.4092\n",
      "Epoch 04 | Training Loss: 0.6618 | Val Loss: 0.6646 | Accuracy: 0.6104 | Precision: 0.5804 | Recall: 0.7092\n",
      "Epoch 05 | Training Loss: 0.6606 | Val Loss: 0.6625 | Accuracy: 0.6110 | Precision: 0.5897 | Recall: 0.6498\n",
      "Epoch 06 | Training Loss: 0.6595 | Val Loss: 0.6638 | Accuracy: 0.6070 | Precision: 0.5780 | Recall: 0.7013\n",
      "Epoch 07 | Training Loss: 0.6587 | Val Loss: 0.6629 | Accuracy: 0.6100 | Precision: 0.5845 | Recall: 0.6766\n",
      "Epoch 08 | Training Loss: 0.6576 | Val Loss: 0.6634 | Accuracy: 0.6064 | Precision: 0.5769 | Recall: 0.7059\n",
      "Epoch 09 | Training Loss: 0.6568 | Val Loss: 0.6622 | Accuracy: 0.6084 | Precision: 0.5991 | Recall: 0.5813\n",
      "Epoch 10 | Training Loss: 0.6560 | Val Loss: 0.6663 | Accuracy: 0.5992 | Precision: 0.6163 | Recall: 0.4592\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6417 | Test Accuracy: 0.5937 | Test Precision: 0.6313 | Test Recall: 0.4507\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6823 | Val Loss: 0.6685 | Accuracy: 0.5948 | Precision: 0.5872 | Recall: 0.5528\n",
      "Epoch 02 | Training Loss: 0.6653 | Val Loss: 0.6644 | Accuracy: 0.6076 | Precision: 0.5949 | Recall: 0.5974\n",
      "Epoch 03 | Training Loss: 0.6626 | Val Loss: 0.6636 | Accuracy: 0.6068 | Precision: 0.6020 | Recall: 0.5578\n",
      "Epoch 04 | Training Loss: 0.6614 | Val Loss: 0.6628 | Accuracy: 0.6100 | Precision: 0.5894 | Recall: 0.6448\n",
      "Epoch 05 | Training Loss: 0.6599 | Val Loss: 0.6671 | Accuracy: 0.5992 | Precision: 0.5667 | Recall: 0.7364\n",
      "Epoch 06 | Training Loss: 0.6585 | Val Loss: 0.6619 | Accuracy: 0.6104 | Precision: 0.5933 | Recall: 0.6242\n",
      "Epoch 07 | Training Loss: 0.6578 | Val Loss: 0.6806 | Accuracy: 0.5766 | Precision: 0.5420 | Recall: 0.8172\n",
      "Epoch 08 | Training Loss: 0.6570 | Val Loss: 0.6675 | Accuracy: 0.5980 | Precision: 0.5651 | Recall: 0.7417\n",
      "Epoch 09 | Training Loss: 0.6568 | Val Loss: 0.6675 | Accuracy: 0.5948 | Precision: 0.5620 | Recall: 0.7438\n",
      "Epoch 10 | Training Loss: 0.6548 | Val Loss: 0.6649 | Accuracy: 0.6024 | Precision: 0.5715 | Recall: 0.7191\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6467 | Test Accuracy: 0.6076 | Test Precision: 0.5859 | Test Recall: 0.7339\n",
      "\n",
      "Training for parameter combination:  16, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7092 | Val Loss: 0.7007 | Accuracy: 0.5014 | Precision: 0.4848 | Recall: 0.4534\n",
      "Epoch 02 | Training Loss: 0.6982 | Val Loss: 0.6994 | Accuracy: 0.5014 | Precision: 0.4868 | Recall: 0.5248\n",
      "Epoch 03 | Training Loss: 0.6963 | Val Loss: 0.6974 | Accuracy: 0.5086 | Precision: 0.4935 | Recall: 0.5182\n",
      "Epoch 04 | Training Loss: 0.6946 | Val Loss: 0.6956 | Accuracy: 0.5138 | Precision: 0.4986 | Recall: 0.5128\n",
      "Epoch 05 | Training Loss: 0.6930 | Val Loss: 0.6941 | Accuracy: 0.5180 | Precision: 0.5028 | Recall: 0.5202\n",
      "Epoch 06 | Training Loss: 0.6915 | Val Loss: 0.6926 | Accuracy: 0.5242 | Precision: 0.5092 | Recall: 0.5161\n",
      "Epoch 07 | Training Loss: 0.6902 | Val Loss: 0.6914 | Accuracy: 0.5260 | Precision: 0.5110 | Recall: 0.5194\n",
      "Epoch 08 | Training Loss: 0.6889 | Val Loss: 0.6910 | Accuracy: 0.5264 | Precision: 0.5099 | Recall: 0.5974\n",
      "Epoch 09 | Training Loss: 0.6877 | Val Loss: 0.6893 | Accuracy: 0.5330 | Precision: 0.5170 | Recall: 0.5594\n",
      "Epoch 10 | Training Loss: 0.6866 | Val Loss: 0.6885 | Accuracy: 0.5366 | Precision: 0.5195 | Recall: 0.5870\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6824 | Test Accuracy: 0.5491 | Test Precision: 0.5444 | Test Recall: 0.6014\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7094 | Val Loss: 0.7020 | Accuracy: 0.5200 | Precision: 0.5049 | Recall: 0.5095\n",
      "Epoch 02 | Training Loss: 0.7042 | Val Loss: 0.6996 | Accuracy: 0.5238 | Precision: 0.5087 | Recall: 0.5173\n",
      "Epoch 03 | Training Loss: 0.7017 | Val Loss: 0.6975 | Accuracy: 0.5286 | Precision: 0.5134 | Recall: 0.5281\n",
      "Epoch 04 | Training Loss: 0.6994 | Val Loss: 0.6956 | Accuracy: 0.5316 | Precision: 0.5164 | Recall: 0.5314\n",
      "Epoch 05 | Training Loss: 0.6973 | Val Loss: 0.6941 | Accuracy: 0.5352 | Precision: 0.5191 | Recall: 0.5594\n",
      "Epoch 06 | Training Loss: 0.6954 | Val Loss: 0.6922 | Accuracy: 0.5382 | Precision: 0.5223 | Recall: 0.5545\n",
      "Epoch 07 | Training Loss: 0.6936 | Val Loss: 0.6907 | Accuracy: 0.5394 | Precision: 0.5234 | Recall: 0.5578\n",
      "Epoch 08 | Training Loss: 0.6920 | Val Loss: 0.6889 | Accuracy: 0.5434 | Precision: 0.5290 | Recall: 0.5297\n",
      "Epoch 09 | Training Loss: 0.6905 | Val Loss: 0.6880 | Accuracy: 0.5438 | Precision: 0.5277 | Recall: 0.5627\n",
      "Epoch 10 | Training Loss: 0.6891 | Val Loss: 0.6868 | Accuracy: 0.5476 | Precision: 0.5312 | Recall: 0.5689\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6679 | Test Accuracy: 0.5452 | Test Precision: 0.5433 | Test Recall: 0.5676\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7186 | Val Loss: 0.6957 | Accuracy: 0.5296 | Precision: 0.5163 | Recall: 0.4699\n",
      "Epoch 02 | Training Loss: 0.6955 | Val Loss: 0.6945 | Accuracy: 0.5292 | Precision: 0.5141 | Recall: 0.5260\n",
      "Epoch 03 | Training Loss: 0.6937 | Val Loss: 0.6923 | Accuracy: 0.5336 | Precision: 0.5209 | Recall: 0.4728\n",
      "Epoch 04 | Training Loss: 0.6921 | Val Loss: 0.6913 | Accuracy: 0.5366 | Precision: 0.5218 | Recall: 0.5272\n",
      "Epoch 05 | Training Loss: 0.6906 | Val Loss: 0.6900 | Accuracy: 0.5388 | Precision: 0.5241 | Recall: 0.5285\n",
      "Epoch 06 | Training Loss: 0.6893 | Val Loss: 0.6891 | Accuracy: 0.5360 | Precision: 0.5200 | Recall: 0.5590\n",
      "Epoch 07 | Training Loss: 0.6882 | Val Loss: 0.6879 | Accuracy: 0.5400 | Precision: 0.5240 | Recall: 0.5590\n",
      "Epoch 08 | Training Loss: 0.6870 | Val Loss: 0.6870 | Accuracy: 0.5446 | Precision: 0.5277 | Recall: 0.5784\n",
      "Epoch 09 | Training Loss: 0.6859 | Val Loss: 0.6856 | Accuracy: 0.5478 | Precision: 0.5334 | Recall: 0.5363\n",
      "Epoch 10 | Training Loss: 0.6850 | Val Loss: 0.6850 | Accuracy: 0.5518 | Precision: 0.5354 | Recall: 0.5714\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6724 | Test Accuracy: 0.5522 | Test Precision: 0.5492 | Test Recall: 0.5819\n",
      "\n",
      "Training for parameter combination:  17, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6809 | Val Loss: 0.6794 | Accuracy: 0.5684 | Precision: 0.5368 | Recall: 0.8012\n",
      "Epoch 02 | Training Loss: 0.6671 | Val Loss: 0.6793 | Accuracy: 0.5726 | Precision: 0.5392 | Recall: 0.8144\n",
      "Epoch 03 | Training Loss: 0.6634 | Val Loss: 0.6669 | Accuracy: 0.5952 | Precision: 0.6043 | Recall: 0.4781\n",
      "Epoch 04 | Training Loss: 0.6620 | Val Loss: 0.6647 | Accuracy: 0.6042 | Precision: 0.6005 | Recall: 0.5487\n",
      "Epoch 05 | Training Loss: 0.6604 | Val Loss: 0.6634 | Accuracy: 0.6090 | Precision: 0.5959 | Recall: 0.6011\n",
      "Epoch 06 | Training Loss: 0.6599 | Val Loss: 0.6651 | Accuracy: 0.6020 | Precision: 0.5706 | Recall: 0.7236\n",
      "Epoch 07 | Training Loss: 0.6590 | Val Loss: 0.6633 | Accuracy: 0.6108 | Precision: 0.5821 | Recall: 0.6993\n",
      "Epoch 08 | Training Loss: 0.6586 | Val Loss: 0.6630 | Accuracy: 0.6120 | Precision: 0.5832 | Recall: 0.7001\n",
      "Epoch 09 | Training Loss: 0.6580 | Val Loss: 0.6622 | Accuracy: 0.6060 | Precision: 0.5924 | Recall: 0.6007\n",
      "Epoch 10 | Training Loss: 0.6576 | Val Loss: 0.6619 | Accuracy: 0.6108 | Precision: 0.5890 | Recall: 0.6522\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6394 | Test Accuracy: 0.6074 | Test Precision: 0.5992 | Test Recall: 0.6487\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6815 | Val Loss: 0.6761 | Accuracy: 0.5800 | Precision: 0.5489 | Recall: 0.7500\n",
      "Epoch 02 | Training Loss: 0.6674 | Val Loss: 0.6667 | Accuracy: 0.6036 | Precision: 0.5936 | Recall: 0.5780\n",
      "Epoch 03 | Training Loss: 0.6635 | Val Loss: 0.6651 | Accuracy: 0.6068 | Precision: 0.5816 | Recall: 0.6733\n",
      "Epoch 04 | Training Loss: 0.6624 | Val Loss: 0.6714 | Accuracy: 0.5920 | Precision: 0.5572 | Recall: 0.7715\n",
      "Epoch 05 | Training Loss: 0.6608 | Val Loss: 0.6638 | Accuracy: 0.6108 | Precision: 0.5839 | Recall: 0.6865\n",
      "Epoch 06 | Training Loss: 0.6597 | Val Loss: 0.6667 | Accuracy: 0.6026 | Precision: 0.5697 | Recall: 0.7372\n",
      "Epoch 07 | Training Loss: 0.6591 | Val Loss: 0.6768 | Accuracy: 0.5832 | Precision: 0.5481 | Recall: 0.7987\n",
      "Epoch 08 | Training Loss: 0.6586 | Val Loss: 0.6669 | Accuracy: 0.5992 | Precision: 0.5660 | Recall: 0.7434\n",
      "Epoch 09 | Training Loss: 0.6578 | Val Loss: 0.6854 | Accuracy: 0.5768 | Precision: 0.5413 | Recall: 0.8333\n",
      "Epoch 10 | Training Loss: 0.6576 | Val Loss: 0.6616 | Accuracy: 0.6094 | Precision: 0.5944 | Recall: 0.6118\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6458 | Test Accuracy: 0.6047 | Test Precision: 0.6030 | Test Recall: 0.6131\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6915 | Val Loss: 0.6878 | Accuracy: 0.5508 | Precision: 0.5223 | Recall: 0.8614\n",
      "Epoch 02 | Training Loss: 0.6700 | Val Loss: 0.6781 | Accuracy: 0.5784 | Precision: 0.5447 | Recall: 0.7941\n",
      "Epoch 03 | Training Loss: 0.6653 | Val Loss: 0.6665 | Accuracy: 0.5996 | Precision: 0.5894 | Recall: 0.5738\n",
      "Epoch 04 | Training Loss: 0.6634 | Val Loss: 0.6689 | Accuracy: 0.5926 | Precision: 0.6067 | Recall: 0.4538\n",
      "Epoch 05 | Training Loss: 0.6621 | Val Loss: 0.6646 | Accuracy: 0.6066 | Precision: 0.5813 | Recall: 0.6741\n",
      "Epoch 06 | Training Loss: 0.6606 | Val Loss: 0.6655 | Accuracy: 0.6050 | Precision: 0.5747 | Recall: 0.7129\n",
      "Epoch 07 | Training Loss: 0.6604 | Val Loss: 0.6640 | Accuracy: 0.6082 | Precision: 0.5810 | Recall: 0.6877\n",
      "Epoch 08 | Training Loss: 0.6593 | Val Loss: 0.6648 | Accuracy: 0.6000 | Precision: 0.6009 | Recall: 0.5210\n",
      "Epoch 09 | Training Loss: 0.6590 | Val Loss: 0.6646 | Accuracy: 0.6070 | Precision: 0.5763 | Recall: 0.7149\n",
      "Epoch 10 | Training Loss: 0.6583 | Val Loss: 0.6649 | Accuracy: 0.6064 | Precision: 0.5748 | Recall: 0.7232\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6450 | Test Accuracy: 0.6050 | Test Precision: 0.5845 | Test Recall: 0.7257\n",
      "\n",
      "Training for parameter combination:  18, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6798 | Val Loss: 0.6699 | Accuracy: 0.5874 | Precision: 0.5635 | Recall: 0.6605\n",
      "Epoch 02 | Training Loss: 0.6623 | Val Loss: 0.6647 | Accuracy: 0.6010 | Precision: 0.5825 | Recall: 0.6246\n",
      "Epoch 03 | Training Loss: 0.6564 | Val Loss: 0.6666 | Accuracy: 0.5958 | Precision: 0.5714 | Recall: 0.6650\n",
      "Epoch 04 | Training Loss: 0.6528 | Val Loss: 0.6641 | Accuracy: 0.6004 | Precision: 0.5756 | Recall: 0.6687\n",
      "Epoch 05 | Training Loss: 0.6503 | Val Loss: 0.6641 | Accuracy: 0.5996 | Precision: 0.6030 | Recall: 0.5095\n",
      "Epoch 06 | Training Loss: 0.6468 | Val Loss: 0.6625 | Accuracy: 0.5992 | Precision: 0.5900 | Recall: 0.5681\n",
      "Epoch 07 | Training Loss: 0.6435 | Val Loss: 0.6666 | Accuracy: 0.5998 | Precision: 0.5680 | Recall: 0.7290\n",
      "Epoch 08 | Training Loss: 0.6396 | Val Loss: 0.6630 | Accuracy: 0.5978 | Precision: 0.5940 | Recall: 0.5384\n",
      "Epoch 09 | Training Loss: 0.6374 | Val Loss: 0.6741 | Accuracy: 0.5890 | Precision: 0.6342 | Recall: 0.3597\n",
      "Epoch 10 | Training Loss: 0.6338 | Val Loss: 0.6620 | Accuracy: 0.5990 | Precision: 0.5893 | Recall: 0.5701\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7035 | Test Accuracy: 0.6050 | Test Precision: 0.6107 | Test Recall: 0.5791\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6752 | Val Loss: 0.6663 | Accuracy: 0.6004 | Precision: 0.5864 | Recall: 0.5965\n",
      "Epoch 02 | Training Loss: 0.6624 | Val Loss: 0.6687 | Accuracy: 0.5976 | Precision: 0.5638 | Recall: 0.7508\n",
      "Epoch 03 | Training Loss: 0.6576 | Val Loss: 0.6691 | Accuracy: 0.5988 | Precision: 0.5645 | Recall: 0.7541\n",
      "Epoch 04 | Training Loss: 0.6528 | Val Loss: 0.6777 | Accuracy: 0.5828 | Precision: 0.5471 | Recall: 0.8102\n",
      "Epoch 05 | Training Loss: 0.6500 | Val Loss: 0.6816 | Accuracy: 0.5840 | Precision: 0.5467 | Recall: 0.8304\n",
      "Epoch 06 | Training Loss: 0.6464 | Val Loss: 0.6607 | Accuracy: 0.6062 | Precision: 0.5840 | Recall: 0.6522\n",
      "Epoch 07 | Training Loss: 0.6418 | Val Loss: 0.6619 | Accuracy: 0.6078 | Precision: 0.5759 | Recall: 0.7244\n",
      "Epoch 08 | Training Loss: 0.6383 | Val Loss: 0.6630 | Accuracy: 0.6072 | Precision: 0.5733 | Recall: 0.7422\n",
      "Epoch 09 | Training Loss: 0.6355 | Val Loss: 0.6588 | Accuracy: 0.6082 | Precision: 0.6022 | Recall: 0.5652\n",
      "Epoch 10 | Training Loss: 0.6318 | Val Loss: 0.6621 | Accuracy: 0.6092 | Precision: 0.5925 | Recall: 0.6209\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6794 | Test Accuracy: 0.6032 | Test Precision: 0.6024 | Test Recall: 0.6071\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6770 | Val Loss: 0.6676 | Accuracy: 0.5972 | Precision: 0.5913 | Recall: 0.5479\n",
      "Epoch 02 | Training Loss: 0.6633 | Val Loss: 0.6679 | Accuracy: 0.5964 | Precision: 0.5640 | Recall: 0.7376\n",
      "Epoch 03 | Training Loss: 0.6595 | Val Loss: 0.6652 | Accuracy: 0.6004 | Precision: 0.5717 | Recall: 0.7009\n",
      "Epoch 04 | Training Loss: 0.6553 | Val Loss: 0.6614 | Accuracy: 0.6064 | Precision: 0.5835 | Recall: 0.6576\n",
      "Epoch 05 | Training Loss: 0.6527 | Val Loss: 0.6636 | Accuracy: 0.6002 | Precision: 0.5950 | Recall: 0.5491\n",
      "Epoch 06 | Training Loss: 0.6499 | Val Loss: 0.6743 | Accuracy: 0.5848 | Precision: 0.5516 | Recall: 0.7669\n",
      "Epoch 07 | Training Loss: 0.6470 | Val Loss: 0.6610 | Accuracy: 0.6020 | Precision: 0.5848 | Recall: 0.6176\n",
      "Epoch 08 | Training Loss: 0.6422 | Val Loss: 0.6634 | Accuracy: 0.6042 | Precision: 0.6060 | Recall: 0.5248\n",
      "Epoch 09 | Training Loss: 0.6393 | Val Loss: 0.6628 | Accuracy: 0.6032 | Precision: 0.5853 | Recall: 0.6225\n",
      "Epoch 10 | Training Loss: 0.6346 | Val Loss: 0.6669 | Accuracy: 0.5914 | Precision: 0.5610 | Recall: 0.7224\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6409 | Test Accuracy: 0.6004 | Test Precision: 0.5795 | Test Recall: 0.7319\n",
      "\n",
      "Training for parameter combination:  19, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6886 | Val Loss: 0.6796 | Accuracy: 0.5752 | Precision: 0.5621 | Recall: 0.5598\n",
      "Epoch 02 | Training Loss: 0.6743 | Val Loss: 0.6730 | Accuracy: 0.5936 | Precision: 0.5638 | Recall: 0.7145\n",
      "Epoch 03 | Training Loss: 0.6680 | Val Loss: 0.6676 | Accuracy: 0.6004 | Precision: 0.5911 | Recall: 0.5701\n",
      "Epoch 04 | Training Loss: 0.6647 | Val Loss: 0.6657 | Accuracy: 0.6036 | Precision: 0.5790 | Recall: 0.6683\n",
      "Epoch 05 | Training Loss: 0.6623 | Val Loss: 0.6669 | Accuracy: 0.5990 | Precision: 0.5672 | Recall: 0.7298\n",
      "Epoch 06 | Training Loss: 0.6612 | Val Loss: 0.6651 | Accuracy: 0.6030 | Precision: 0.5729 | Recall: 0.7120\n",
      "Epoch 07 | Training Loss: 0.6600 | Val Loss: 0.6628 | Accuracy: 0.6074 | Precision: 0.5897 | Recall: 0.6250\n",
      "Epoch 08 | Training Loss: 0.6594 | Val Loss: 0.6626 | Accuracy: 0.6112 | Precision: 0.5875 | Recall: 0.6650\n",
      "Epoch 09 | Training Loss: 0.6588 | Val Loss: 0.6625 | Accuracy: 0.6106 | Precision: 0.5858 | Recall: 0.6720\n",
      "Epoch 10 | Training Loss: 0.6581 | Val Loss: 0.6630 | Accuracy: 0.6112 | Precision: 0.5816 | Recall: 0.7059\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6433 | Test Accuracy: 0.6073 | Test Precision: 0.5896 | Test Recall: 0.7062\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6952 | Val Loss: 0.6812 | Accuracy: 0.5648 | Precision: 0.5617 | Recall: 0.4658\n",
      "Epoch 02 | Training Loss: 0.6767 | Val Loss: 0.6716 | Accuracy: 0.5886 | Precision: 0.5652 | Recall: 0.6559\n",
      "Epoch 03 | Training Loss: 0.6688 | Val Loss: 0.6669 | Accuracy: 0.6034 | Precision: 0.5776 | Recall: 0.6770\n",
      "Epoch 04 | Training Loss: 0.6647 | Val Loss: 0.6649 | Accuracy: 0.6040 | Precision: 0.5766 | Recall: 0.6898\n",
      "Epoch 05 | Training Loss: 0.6629 | Val Loss: 0.6640 | Accuracy: 0.6058 | Precision: 0.5790 | Recall: 0.6848\n",
      "Epoch 06 | Training Loss: 0.6615 | Val Loss: 0.6638 | Accuracy: 0.6070 | Precision: 0.5781 | Recall: 0.7005\n",
      "Epoch 07 | Training Loss: 0.6607 | Val Loss: 0.6631 | Accuracy: 0.6104 | Precision: 0.5835 | Recall: 0.6865\n",
      "Epoch 08 | Training Loss: 0.6601 | Val Loss: 0.6623 | Accuracy: 0.6102 | Precision: 0.5865 | Recall: 0.6646\n",
      "Epoch 09 | Training Loss: 0.6596 | Val Loss: 0.6621 | Accuracy: 0.6072 | Precision: 0.5858 | Recall: 0.6477\n",
      "Epoch 10 | Training Loss: 0.6591 | Val Loss: 0.6622 | Accuracy: 0.6116 | Precision: 0.5856 | Recall: 0.6803\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6480 | Test Accuracy: 0.6072 | Test Precision: 0.5939 | Test Recall: 0.6782\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6917 | Val Loss: 0.6792 | Accuracy: 0.5822 | Precision: 0.5608 | Recall: 0.6370\n",
      "Epoch 02 | Training Loss: 0.6728 | Val Loss: 0.6687 | Accuracy: 0.5992 | Precision: 0.5928 | Recall: 0.5532\n",
      "Epoch 03 | Training Loss: 0.6661 | Val Loss: 0.6654 | Accuracy: 0.6072 | Precision: 0.5860 | Recall: 0.6465\n",
      "Epoch 04 | Training Loss: 0.6633 | Val Loss: 0.6650 | Accuracy: 0.6038 | Precision: 0.5751 | Recall: 0.7001\n",
      "Epoch 05 | Training Loss: 0.6615 | Val Loss: 0.6638 | Accuracy: 0.6054 | Precision: 0.5787 | Recall: 0.6840\n",
      "Epoch 06 | Training Loss: 0.6608 | Val Loss: 0.6638 | Accuracy: 0.6066 | Precision: 0.5782 | Recall: 0.6972\n",
      "Epoch 07 | Training Loss: 0.6600 | Val Loss: 0.6639 | Accuracy: 0.6066 | Precision: 0.5768 | Recall: 0.7079\n",
      "Epoch 08 | Training Loss: 0.6595 | Val Loss: 0.6646 | Accuracy: 0.6044 | Precision: 0.5731 | Recall: 0.7211\n",
      "Epoch 09 | Training Loss: 0.6593 | Val Loss: 0.6640 | Accuracy: 0.6052 | Precision: 0.5752 | Recall: 0.7104\n",
      "Epoch 10 | Training Loss: 0.6589 | Val Loss: 0.6623 | Accuracy: 0.6092 | Precision: 0.5947 | Recall: 0.6089\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6435 | Test Accuracy: 0.6091 | Test Precision: 0.6080 | Test Recall: 0.6140\n",
      "\n",
      "Training for parameter combination:  20, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6939 | Val Loss: 0.6741 | Accuracy: 0.5920 | Precision: 0.5596 | Recall: 0.7434\n",
      "Epoch 02 | Training Loss: 0.6723 | Val Loss: 0.6799 | Accuracy: 0.5884 | Precision: 0.5553 | Recall: 0.7583\n",
      "Epoch 03 | Training Loss: 0.6658 | Val Loss: 0.6907 | Accuracy: 0.5698 | Precision: 0.5352 | Recall: 0.8556\n",
      "Epoch 04 | Training Loss: 0.6644 | Val Loss: 0.6701 | Accuracy: 0.5902 | Precision: 0.6113 | Recall: 0.4249\n",
      "Epoch 05 | Training Loss: 0.6613 | Val Loss: 0.6715 | Accuracy: 0.5882 | Precision: 0.5870 | Recall: 0.5078\n",
      "Epoch 06 | Training Loss: 0.6591 | Val Loss: 0.6744 | Accuracy: 0.5836 | Precision: 0.5500 | Recall: 0.7764\n",
      "Epoch 07 | Training Loss: 0.6597 | Val Loss: 0.6632 | Accuracy: 0.6020 | Precision: 0.5975 | Recall: 0.5487\n",
      "Epoch 08 | Training Loss: 0.6539 | Val Loss: 0.6777 | Accuracy: 0.5812 | Precision: 0.5483 | Recall: 0.7731\n",
      "Epoch 09 | Training Loss: 0.6548 | Val Loss: 0.6656 | Accuracy: 0.6046 | Precision: 0.6061 | Recall: 0.5268\n",
      "Epoch 10 | Training Loss: 0.6526 | Val Loss: 0.6669 | Accuracy: 0.5912 | Precision: 0.5916 | Recall: 0.5062\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6221 | Test Accuracy: 0.5941 | Test Precision: 0.6136 | Test Recall: 0.5084\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6934 | Val Loss: 0.6668 | Accuracy: 0.6024 | Precision: 0.5713 | Recall: 0.7203\n",
      "Epoch 02 | Training Loss: 0.6744 | Val Loss: 0.6634 | Accuracy: 0.6012 | Precision: 0.5935 | Recall: 0.5631\n",
      "Epoch 03 | Training Loss: 0.6684 | Val Loss: 0.6662 | Accuracy: 0.6040 | Precision: 0.5738 | Recall: 0.7125\n",
      "Epoch 04 | Training Loss: 0.6641 | Val Loss: 0.6648 | Accuracy: 0.6062 | Precision: 0.5870 | Recall: 0.6333\n",
      "Epoch 05 | Training Loss: 0.6651 | Val Loss: 0.6599 | Accuracy: 0.6138 | Precision: 0.5917 | Recall: 0.6564\n",
      "Epoch 06 | Training Loss: 0.6581 | Val Loss: 0.6616 | Accuracy: 0.6058 | Precision: 0.5928 | Recall: 0.5969\n",
      "Epoch 07 | Training Loss: 0.6594 | Val Loss: 0.6694 | Accuracy: 0.5994 | Precision: 0.6164 | Recall: 0.4600\n",
      "Epoch 08 | Training Loss: 0.6531 | Val Loss: 0.6658 | Accuracy: 0.5954 | Precision: 0.5727 | Recall: 0.6514\n",
      "Epoch 09 | Training Loss: 0.6542 | Val Loss: 0.6680 | Accuracy: 0.5982 | Precision: 0.5698 | Recall: 0.6988\n",
      "Epoch 10 | Training Loss: 0.6517 | Val Loss: 0.6601 | Accuracy: 0.6078 | Precision: 0.5963 | Recall: 0.5912\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6459 | Test Accuracy: 0.6048 | Test Precision: 0.6100 | Test Recall: 0.5810\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6975 | Val Loss: 0.6701 | Accuracy: 0.5972 | Precision: 0.5636 | Recall: 0.7492\n",
      "Epoch 02 | Training Loss: 0.6782 | Val Loss: 0.6621 | Accuracy: 0.6042 | Precision: 0.5785 | Recall: 0.6762\n",
      "Epoch 03 | Training Loss: 0.6652 | Val Loss: 0.6652 | Accuracy: 0.6004 | Precision: 0.5710 | Recall: 0.7071\n",
      "Epoch 04 | Training Loss: 0.6671 | Val Loss: 0.6670 | Accuracy: 0.5912 | Precision: 0.5971 | Recall: 0.4818\n",
      "Epoch 05 | Training Loss: 0.6649 | Val Loss: 0.6643 | Accuracy: 0.5972 | Precision: 0.6250 | Recall: 0.4229\n",
      "Epoch 06 | Training Loss: 0.6597 | Val Loss: 0.6816 | Accuracy: 0.5818 | Precision: 0.5479 | Recall: 0.7859\n",
      "Epoch 07 | Training Loss: 0.6563 | Val Loss: 0.6633 | Accuracy: 0.5988 | Precision: 0.5845 | Recall: 0.5961\n",
      "Epoch 08 | Training Loss: 0.6547 | Val Loss: 0.6657 | Accuracy: 0.6064 | Precision: 0.6150 | Recall: 0.5029\n",
      "Epoch 09 | Training Loss: 0.6504 | Val Loss: 0.6690 | Accuracy: 0.5996 | Precision: 0.5790 | Recall: 0.6378\n",
      "Epoch 10 | Training Loss: 0.6468 | Val Loss: 0.6643 | Accuracy: 0.6020 | Precision: 0.5935 | Recall: 0.5685\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6432 | Test Accuracy: 0.6042 | Test Precision: 0.6116 | Test Recall: 0.5709\n",
      "\n",
      "Training for parameter combination:  21, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6913 | Val Loss: 0.6679 | Accuracy: 0.5974 | Precision: 0.5813 | Recall: 0.6064\n",
      "Epoch 02 | Training Loss: 0.6649 | Val Loss: 0.6699 | Accuracy: 0.5928 | Precision: 0.5600 | Recall: 0.7475\n",
      "Epoch 03 | Training Loss: 0.6609 | Val Loss: 0.6627 | Accuracy: 0.6072 | Precision: 0.5941 | Recall: 0.5990\n",
      "Epoch 04 | Training Loss: 0.6579 | Val Loss: 0.6756 | Accuracy: 0.5868 | Precision: 0.5518 | Recall: 0.7863\n",
      "Epoch 05 | Training Loss: 0.6546 | Val Loss: 0.6622 | Accuracy: 0.6062 | Precision: 0.5916 | Recall: 0.6060\n",
      "Epoch 06 | Training Loss: 0.6535 | Val Loss: 0.6642 | Accuracy: 0.6020 | Precision: 0.6069 | Recall: 0.5083\n",
      "Epoch 07 | Training Loss: 0.6509 | Val Loss: 0.6633 | Accuracy: 0.6010 | Precision: 0.5740 | Recall: 0.6861\n",
      "Epoch 08 | Training Loss: 0.6488 | Val Loss: 0.6603 | Accuracy: 0.6048 | Precision: 0.5822 | Recall: 0.6547\n",
      "Epoch 09 | Training Loss: 0.6475 | Val Loss: 0.6635 | Accuracy: 0.6030 | Precision: 0.5732 | Recall: 0.7092\n",
      "Epoch 10 | Training Loss: 0.6467 | Val Loss: 0.6595 | Accuracy: 0.6048 | Precision: 0.5942 | Recall: 0.5829\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6395 | Test Accuracy: 0.6060 | Test Precision: 0.6090 | Test Recall: 0.5920\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6790 | Val Loss: 0.6658 | Accuracy: 0.6036 | Precision: 0.5870 | Recall: 0.6151\n",
      "Epoch 02 | Training Loss: 0.6650 | Val Loss: 0.6814 | Accuracy: 0.5792 | Precision: 0.5443 | Recall: 0.8106\n",
      "Epoch 03 | Training Loss: 0.6599 | Val Loss: 0.6628 | Accuracy: 0.6118 | Precision: 0.5917 | Recall: 0.6427\n",
      "Epoch 04 | Training Loss: 0.6574 | Val Loss: 0.6694 | Accuracy: 0.5950 | Precision: 0.5632 | Recall: 0.7331\n",
      "Epoch 05 | Training Loss: 0.6545 | Val Loss: 0.6638 | Accuracy: 0.6060 | Precision: 0.5870 | Recall: 0.6320\n",
      "Epoch 06 | Training Loss: 0.6528 | Val Loss: 0.6612 | Accuracy: 0.6070 | Precision: 0.6022 | Recall: 0.5578\n",
      "Epoch 07 | Training Loss: 0.6514 | Val Loss: 0.6608 | Accuracy: 0.6042 | Precision: 0.5817 | Recall: 0.6539\n",
      "Epoch 08 | Training Loss: 0.6489 | Val Loss: 0.6613 | Accuracy: 0.6080 | Precision: 0.5809 | Recall: 0.6869\n",
      "Epoch 09 | Training Loss: 0.6479 | Val Loss: 0.6620 | Accuracy: 0.6060 | Precision: 0.5990 | Recall: 0.5668\n",
      "Epoch 10 | Training Loss: 0.6450 | Val Loss: 0.6667 | Accuracy: 0.5972 | Precision: 0.5650 | Recall: 0.7347\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6456 | Test Accuracy: 0.6032 | Test Precision: 0.5808 | Test Recall: 0.7419\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6783 | Val Loss: 0.6719 | Accuracy: 0.5870 | Precision: 0.6048 | Recall: 0.4274\n",
      "Epoch 02 | Training Loss: 0.6653 | Val Loss: 0.6673 | Accuracy: 0.6056 | Precision: 0.5797 | Recall: 0.6778\n",
      "Epoch 03 | Training Loss: 0.6614 | Val Loss: 0.6774 | Accuracy: 0.5832 | Precision: 0.5487 | Recall: 0.7900\n",
      "Epoch 04 | Training Loss: 0.6589 | Val Loss: 0.6718 | Accuracy: 0.5996 | Precision: 0.5659 | Recall: 0.7475\n",
      "Epoch 05 | Training Loss: 0.6589 | Val Loss: 0.6615 | Accuracy: 0.6034 | Precision: 0.5821 | Recall: 0.6448\n",
      "Epoch 06 | Training Loss: 0.6548 | Val Loss: 0.6643 | Accuracy: 0.5964 | Precision: 0.5696 | Recall: 0.6852\n",
      "Epoch 07 | Training Loss: 0.6548 | Val Loss: 0.6664 | Accuracy: 0.6018 | Precision: 0.6156 | Recall: 0.4757\n",
      "Epoch 08 | Training Loss: 0.6528 | Val Loss: 0.6742 | Accuracy: 0.5928 | Precision: 0.5565 | Recall: 0.7888\n",
      "Epoch 09 | Training Loss: 0.6499 | Val Loss: 0.6627 | Accuracy: 0.5982 | Precision: 0.5707 | Recall: 0.6914\n",
      "Epoch 10 | Training Loss: 0.6482 | Val Loss: 0.6631 | Accuracy: 0.6080 | Precision: 0.6143 | Recall: 0.5144\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6329 | Test Accuracy: 0.5985 | Test Precision: 0.6207 | Test Recall: 0.5066\n",
      "\n",
      "Training for parameter combination:  22, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6792 | Val Loss: 0.6664 | Accuracy: 0.6058 | Precision: 0.5967 | Recall: 0.5767\n",
      "Epoch 02 | Training Loss: 0.6664 | Val Loss: 0.6693 | Accuracy: 0.5916 | Precision: 0.6245 | Recall: 0.3952\n",
      "Epoch 03 | Training Loss: 0.6636 | Val Loss: 0.6695 | Accuracy: 0.5890 | Precision: 0.6223 | Recall: 0.3874\n",
      "Epoch 04 | Training Loss: 0.6630 | Val Loss: 0.6632 | Accuracy: 0.6080 | Precision: 0.5836 | Recall: 0.6683\n",
      "Epoch 05 | Training Loss: 0.6621 | Val Loss: 0.6627 | Accuracy: 0.6084 | Precision: 0.6003 | Recall: 0.5755\n",
      "Epoch 06 | Training Loss: 0.6609 | Val Loss: 0.6661 | Accuracy: 0.6028 | Precision: 0.5707 | Recall: 0.7290\n",
      "Epoch 07 | Training Loss: 0.6607 | Val Loss: 0.6624 | Accuracy: 0.6084 | Precision: 0.5944 | Recall: 0.6052\n",
      "Epoch 08 | Training Loss: 0.6606 | Val Loss: 0.6626 | Accuracy: 0.6076 | Precision: 0.5794 | Recall: 0.6955\n",
      "Epoch 09 | Training Loss: 0.6598 | Val Loss: 0.6633 | Accuracy: 0.6056 | Precision: 0.6130 | Recall: 0.5058\n",
      "Epoch 10 | Training Loss: 0.6592 | Val Loss: 0.6618 | Accuracy: 0.6098 | Precision: 0.5921 | Recall: 0.6275\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6392 | Test Accuracy: 0.6076 | Test Precision: 0.6042 | Test Recall: 0.6238\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6795 | Val Loss: 0.6650 | Accuracy: 0.6030 | Precision: 0.5856 | Recall: 0.6192\n",
      "Epoch 02 | Training Loss: 0.6657 | Val Loss: 0.6651 | Accuracy: 0.6052 | Precision: 0.5815 | Recall: 0.6625\n",
      "Epoch 03 | Training Loss: 0.6647 | Val Loss: 0.6644 | Accuracy: 0.6084 | Precision: 0.5805 | Recall: 0.6931\n",
      "Epoch 04 | Training Loss: 0.6637 | Val Loss: 0.6635 | Accuracy: 0.6010 | Precision: 0.5984 | Recall: 0.5380\n",
      "Epoch 05 | Training Loss: 0.6628 | Val Loss: 0.6734 | Accuracy: 0.5902 | Precision: 0.5550 | Recall: 0.7801\n",
      "Epoch 06 | Training Loss: 0.6616 | Val Loss: 0.6700 | Accuracy: 0.5956 | Precision: 0.5605 | Recall: 0.7686\n",
      "Epoch 07 | Training Loss: 0.6613 | Val Loss: 0.6636 | Accuracy: 0.6034 | Precision: 0.5736 | Recall: 0.7092\n",
      "Epoch 08 | Training Loss: 0.6607 | Val Loss: 0.6611 | Accuracy: 0.6084 | Precision: 0.5964 | Recall: 0.5945\n",
      "Epoch 09 | Training Loss: 0.6609 | Val Loss: 0.6623 | Accuracy: 0.6068 | Precision: 0.5802 | Recall: 0.6832\n",
      "Epoch 10 | Training Loss: 0.6596 | Val Loss: 0.6612 | Accuracy: 0.6072 | Precision: 0.5988 | Recall: 0.5751\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6430 | Test Accuracy: 0.6048 | Test Precision: 0.6106 | Test Recall: 0.5783\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6826 | Val Loss: 0.6803 | Accuracy: 0.5510 | Precision: 0.6044 | Recall: 0.2137\n",
      "Epoch 02 | Training Loss: 0.6664 | Val Loss: 0.6668 | Accuracy: 0.5992 | Precision: 0.5678 | Recall: 0.7257\n",
      "Epoch 03 | Training Loss: 0.6648 | Val Loss: 0.6712 | Accuracy: 0.5946 | Precision: 0.5597 | Recall: 0.7673\n",
      "Epoch 04 | Training Loss: 0.6634 | Val Loss: 0.6623 | Accuracy: 0.6048 | Precision: 0.5811 | Recall: 0.6621\n",
      "Epoch 05 | Training Loss: 0.6626 | Val Loss: 0.6700 | Accuracy: 0.5942 | Precision: 0.5593 | Recall: 0.7690\n",
      "Epoch 06 | Training Loss: 0.6614 | Val Loss: 0.6662 | Accuracy: 0.6012 | Precision: 0.5684 | Recall: 0.7372\n",
      "Epoch 07 | Training Loss: 0.6610 | Val Loss: 0.6613 | Accuracy: 0.6066 | Precision: 0.5968 | Recall: 0.5813\n",
      "Epoch 08 | Training Loss: 0.6609 | Val Loss: 0.6642 | Accuracy: 0.6064 | Precision: 0.5754 | Recall: 0.7174\n",
      "Epoch 09 | Training Loss: 0.6603 | Val Loss: 0.6647 | Accuracy: 0.6034 | Precision: 0.5708 | Recall: 0.7331\n",
      "Epoch 10 | Training Loss: 0.6599 | Val Loss: 0.6609 | Accuracy: 0.6102 | Precision: 0.5873 | Recall: 0.6588\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6420 | Test Accuracy: 0.6102 | Test Precision: 0.6000 | Test Recall: 0.6614\n",
      "\n",
      "Training for parameter combination:  23, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7298 | Val Loss: 0.7212 | Accuracy: 0.4828 | Precision: 0.4763 | Recall: 0.6708\n",
      "Epoch 02 | Training Loss: 0.7145 | Val Loss: 0.7145 | Accuracy: 0.4888 | Precision: 0.4766 | Recall: 0.5553\n",
      "Epoch 03 | Training Loss: 0.7118 | Val Loss: 0.7122 | Accuracy: 0.4920 | Precision: 0.4787 | Recall: 0.5367\n",
      "Epoch 04 | Training Loss: 0.7099 | Val Loss: 0.7103 | Accuracy: 0.4938 | Precision: 0.4798 | Recall: 0.5231\n",
      "Epoch 05 | Training Loss: 0.7082 | Val Loss: 0.7087 | Accuracy: 0.4970 | Precision: 0.4828 | Recall: 0.5260\n",
      "Epoch 06 | Training Loss: 0.7066 | Val Loss: 0.7071 | Accuracy: 0.4980 | Precision: 0.4838 | Recall: 0.5293\n",
      "Epoch 07 | Training Loss: 0.7050 | Val Loss: 0.7057 | Accuracy: 0.4992 | Precision: 0.4850 | Recall: 0.5318\n",
      "Epoch 08 | Training Loss: 0.7036 | Val Loss: 0.7043 | Accuracy: 0.5018 | Precision: 0.4873 | Recall: 0.5309\n",
      "Epoch 09 | Training Loss: 0.7022 | Val Loss: 0.7030 | Accuracy: 0.5032 | Precision: 0.4887 | Recall: 0.5351\n",
      "Epoch 10 | Training Loss: 0.7009 | Val Loss: 0.7017 | Accuracy: 0.5030 | Precision: 0.4885 | Recall: 0.5330\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6724 | Test Accuracy: 0.5102 | Test Precision: 0.5095 | Test Recall: 0.5480\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7431 | Val Loss: 0.7036 | Accuracy: 0.5114 | Precision: 0.4918 | Recall: 0.2360\n",
      "Epoch 02 | Training Loss: 0.7000 | Val Loss: 0.6992 | Accuracy: 0.5170 | Precision: 0.5021 | Recall: 0.4414\n",
      "Epoch 03 | Training Loss: 0.6969 | Val Loss: 0.6985 | Accuracy: 0.5236 | Precision: 0.5087 | Recall: 0.5074\n",
      "Epoch 04 | Training Loss: 0.6958 | Val Loss: 0.6977 | Accuracy: 0.5254 | Precision: 0.5102 | Recall: 0.5285\n",
      "Epoch 05 | Training Loss: 0.6948 | Val Loss: 0.6969 | Accuracy: 0.5276 | Precision: 0.5123 | Recall: 0.5342\n",
      "Epoch 06 | Training Loss: 0.6940 | Val Loss: 0.6960 | Accuracy: 0.5294 | Precision: 0.5140 | Recall: 0.5359\n",
      "Epoch 07 | Training Loss: 0.6931 | Val Loss: 0.6952 | Accuracy: 0.5306 | Precision: 0.5150 | Recall: 0.5466\n",
      "Epoch 08 | Training Loss: 0.6923 | Val Loss: 0.6943 | Accuracy: 0.5348 | Precision: 0.5193 | Recall: 0.5446\n",
      "Epoch 09 | Training Loss: 0.6916 | Val Loss: 0.6935 | Accuracy: 0.5402 | Precision: 0.5248 | Recall: 0.5462\n",
      "Epoch 10 | Training Loss: 0.6908 | Val Loss: 0.6927 | Accuracy: 0.5430 | Precision: 0.5280 | Recall: 0.5413\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6916 | Test Accuracy: 0.5344 | Test Precision: 0.5339 | Test Recall: 0.5418\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7529 | Val Loss: 0.7101 | Accuracy: 0.4906 | Precision: 0.4478 | Recall: 0.2178\n",
      "Epoch 02 | Training Loss: 0.7112 | Val Loss: 0.7071 | Accuracy: 0.4968 | Precision: 0.4786 | Recall: 0.4245\n",
      "Epoch 03 | Training Loss: 0.7084 | Val Loss: 0.7064 | Accuracy: 0.4976 | Precision: 0.4826 | Recall: 0.5029\n",
      "Epoch 04 | Training Loss: 0.7070 | Val Loss: 0.7051 | Accuracy: 0.4996 | Precision: 0.4846 | Recall: 0.5066\n",
      "Epoch 05 | Training Loss: 0.7057 | Val Loss: 0.7040 | Accuracy: 0.5036 | Precision: 0.4885 | Recall: 0.5095\n",
      "Epoch 06 | Training Loss: 0.7045 | Val Loss: 0.7027 | Accuracy: 0.5062 | Precision: 0.4908 | Recall: 0.4967\n",
      "Epoch 07 | Training Loss: 0.7033 | Val Loss: 0.7018 | Accuracy: 0.5066 | Precision: 0.4916 | Recall: 0.5173\n",
      "Epoch 08 | Training Loss: 0.7021 | Val Loss: 0.7009 | Accuracy: 0.5092 | Precision: 0.4942 | Recall: 0.5305\n",
      "Epoch 09 | Training Loss: 0.7010 | Val Loss: 0.6998 | Accuracy: 0.5100 | Precision: 0.4950 | Recall: 0.5264\n",
      "Epoch 10 | Training Loss: 0.7000 | Val Loss: 0.6986 | Accuracy: 0.5168 | Precision: 0.5016 | Recall: 0.5149\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6843 | Test Accuracy: 0.5132 | Test Precision: 0.5132 | Test Recall: 0.5143\n",
      "\n",
      "Training for parameter combination:  24, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6743 | Val Loss: 0.6680 | Accuracy: 0.5936 | Precision: 0.6161 | Recall: 0.4290\n",
      "Epoch 02 | Training Loss: 0.6664 | Val Loss: 0.6727 | Accuracy: 0.5866 | Precision: 0.6283 | Recall: 0.3606\n",
      "Epoch 03 | Training Loss: 0.6670 | Val Loss: 0.6625 | Accuracy: 0.6100 | Precision: 0.5908 | Recall: 0.6361\n",
      "Epoch 04 | Training Loss: 0.6650 | Val Loss: 0.6616 | Accuracy: 0.6068 | Precision: 0.5818 | Recall: 0.6720\n",
      "Epoch 05 | Training Loss: 0.6615 | Val Loss: 0.6631 | Accuracy: 0.6044 | Precision: 0.6103 | Recall: 0.5091\n",
      "Epoch 06 | Training Loss: 0.6671 | Val Loss: 0.6616 | Accuracy: 0.6098 | Precision: 0.6003 | Recall: 0.5842\n",
      "Epoch 07 | Training Loss: 0.6590 | Val Loss: 0.6614 | Accuracy: 0.6010 | Precision: 0.5902 | Recall: 0.5788\n",
      "Epoch 08 | Training Loss: 0.6576 | Val Loss: 0.6663 | Accuracy: 0.6018 | Precision: 0.5704 | Recall: 0.7236\n",
      "Epoch 09 | Training Loss: 0.6573 | Val Loss: 0.6614 | Accuracy: 0.6066 | Precision: 0.5824 | Recall: 0.6663\n",
      "Epoch 10 | Training Loss: 0.6582 | Val Loss: 0.6681 | Accuracy: 0.5978 | Precision: 0.5662 | Recall: 0.7290\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6514 | Test Accuracy: 0.6048 | Test Precision: 0.5822 | Test Recall: 0.7416\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6869 | Val Loss: 0.6654 | Accuracy: 0.6034 | Precision: 0.6009 | Recall: 0.5417\n",
      "Epoch 02 | Training Loss: 0.6635 | Val Loss: 0.6683 | Accuracy: 0.5988 | Precision: 0.5659 | Recall: 0.7405\n",
      "Epoch 03 | Training Loss: 0.6644 | Val Loss: 0.6631 | Accuracy: 0.6086 | Precision: 0.5774 | Recall: 0.7186\n",
      "Epoch 04 | Training Loss: 0.6626 | Val Loss: 0.6625 | Accuracy: 0.6018 | Precision: 0.5709 | Recall: 0.7195\n",
      "Epoch 05 | Training Loss: 0.6611 | Val Loss: 0.6685 | Accuracy: 0.5894 | Precision: 0.6194 | Recall: 0.3969\n",
      "Epoch 06 | Training Loss: 0.6608 | Val Loss: 0.6651 | Accuracy: 0.6030 | Precision: 0.6208 | Recall: 0.4653\n",
      "Epoch 07 | Training Loss: 0.6585 | Val Loss: 0.6594 | Accuracy: 0.6098 | Precision: 0.5895 | Recall: 0.6427\n",
      "Epoch 08 | Training Loss: 0.6615 | Val Loss: 0.6611 | Accuracy: 0.6104 | Precision: 0.5881 | Recall: 0.6555\n",
      "Epoch 09 | Training Loss: 0.6594 | Val Loss: 0.6592 | Accuracy: 0.6056 | Precision: 0.5845 | Recall: 0.6448\n",
      "Epoch 10 | Training Loss: 0.6564 | Val Loss: 0.6698 | Accuracy: 0.5944 | Precision: 0.5603 | Recall: 0.7587\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6527 | Test Accuracy: 0.6000 | Test Precision: 0.5758 | Test Recall: 0.7598\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6770 | Val Loss: 0.6762 | Accuracy: 0.5858 | Precision: 0.5504 | Recall: 0.7958\n",
      "Epoch 02 | Training Loss: 0.6665 | Val Loss: 0.6718 | Accuracy: 0.5806 | Precision: 0.6346 | Recall: 0.3181\n",
      "Epoch 03 | Training Loss: 0.6637 | Val Loss: 0.6630 | Accuracy: 0.5966 | Precision: 0.5913 | Recall: 0.5437\n",
      "Epoch 04 | Training Loss: 0.6648 | Val Loss: 0.6715 | Accuracy: 0.5960 | Precision: 0.5583 | Recall: 0.7974\n",
      "Epoch 05 | Training Loss: 0.6618 | Val Loss: 0.6616 | Accuracy: 0.6090 | Precision: 0.5989 | Recall: 0.5858\n",
      "Epoch 06 | Training Loss: 0.6597 | Val Loss: 0.6642 | Accuracy: 0.6084 | Precision: 0.5749 | Recall: 0.7376\n",
      "Epoch 07 | Training Loss: 0.6609 | Val Loss: 0.6615 | Accuracy: 0.6032 | Precision: 0.5919 | Recall: 0.5846\n",
      "Epoch 08 | Training Loss: 0.6599 | Val Loss: 0.6662 | Accuracy: 0.6036 | Precision: 0.5679 | Recall: 0.7624\n",
      "Epoch 09 | Training Loss: 0.6562 | Val Loss: 0.6613 | Accuracy: 0.6066 | Precision: 0.5778 | Recall: 0.7001\n",
      "Epoch 10 | Training Loss: 0.6583 | Val Loss: 0.6584 | Accuracy: 0.6148 | Precision: 0.5970 | Recall: 0.6320\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6386 | Test Accuracy: 0.6076 | Test Precision: 0.6037 | Test Recall: 0.6263\n",
      "\n",
      "Training for parameter combination:  25, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6736 | Val Loss: 0.6726 | Accuracy: 0.5786 | Precision: 0.6198 | Recall: 0.3383\n",
      "Epoch 02 | Training Loss: 0.6641 | Val Loss: 0.6665 | Accuracy: 0.6014 | Precision: 0.5684 | Recall: 0.7389\n",
      "Epoch 03 | Training Loss: 0.6619 | Val Loss: 0.6627 | Accuracy: 0.6072 | Precision: 0.5842 | Recall: 0.6584\n",
      "Epoch 04 | Training Loss: 0.6592 | Val Loss: 0.6746 | Accuracy: 0.5938 | Precision: 0.5562 | Recall: 0.8028\n",
      "Epoch 05 | Training Loss: 0.6580 | Val Loss: 0.6650 | Accuracy: 0.5966 | Precision: 0.5652 | Recall: 0.7273\n",
      "Epoch 06 | Training Loss: 0.6564 | Val Loss: 0.6617 | Accuracy: 0.6036 | Precision: 0.6030 | Recall: 0.5338\n",
      "Epoch 07 | Training Loss: 0.6545 | Val Loss: 0.6618 | Accuracy: 0.6020 | Precision: 0.5745 | Recall: 0.6902\n",
      "Epoch 08 | Training Loss: 0.6530 | Val Loss: 0.6603 | Accuracy: 0.6120 | Precision: 0.5911 | Recall: 0.6477\n",
      "Epoch 09 | Training Loss: 0.6507 | Val Loss: 0.6595 | Accuracy: 0.6118 | Precision: 0.5962 | Recall: 0.6176\n",
      "Epoch 10 | Training Loss: 0.6494 | Val Loss: 0.6594 | Accuracy: 0.6112 | Precision: 0.5935 | Recall: 0.6287\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6753 | Test Accuracy: 0.6094 | Test Precision: 0.6050 | Test Recall: 0.6302\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6715 | Val Loss: 0.6640 | Accuracy: 0.6102 | Precision: 0.5914 | Recall: 0.6341\n",
      "Epoch 02 | Training Loss: 0.6637 | Val Loss: 0.6710 | Accuracy: 0.5932 | Precision: 0.5577 | Recall: 0.7781\n",
      "Epoch 03 | Training Loss: 0.6617 | Val Loss: 0.6622 | Accuracy: 0.6064 | Precision: 0.5817 | Recall: 0.6700\n",
      "Epoch 04 | Training Loss: 0.6602 | Val Loss: 0.6628 | Accuracy: 0.6038 | Precision: 0.6136 | Recall: 0.4934\n",
      "Epoch 05 | Training Loss: 0.6587 | Val Loss: 0.6625 | Accuracy: 0.6066 | Precision: 0.5764 | Recall: 0.7108\n",
      "Epoch 06 | Training Loss: 0.6566 | Val Loss: 0.6594 | Accuracy: 0.6124 | Precision: 0.6046 | Recall: 0.5796\n",
      "Epoch 07 | Training Loss: 0.6547 | Val Loss: 0.6668 | Accuracy: 0.6014 | Precision: 0.6373 | Recall: 0.4125\n",
      "Epoch 08 | Training Loss: 0.6535 | Val Loss: 0.6593 | Accuracy: 0.6066 | Precision: 0.5818 | Recall: 0.6704\n",
      "Epoch 09 | Training Loss: 0.6524 | Val Loss: 0.6662 | Accuracy: 0.6046 | Precision: 0.6287 | Recall: 0.4505\n",
      "Epoch 10 | Training Loss: 0.6501 | Val Loss: 0.6616 | Accuracy: 0.6058 | Precision: 0.5766 | Recall: 0.7034\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6632 | Test Accuracy: 0.6091 | Test Precision: 0.5907 | Test Recall: 0.7108\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6761 | Val Loss: 0.6626 | Accuracy: 0.6066 | Precision: 0.5806 | Recall: 0.6790\n",
      "Epoch 02 | Training Loss: 0.6647 | Val Loss: 0.6786 | Accuracy: 0.5842 | Precision: 0.5477 | Recall: 0.8168\n",
      "Epoch 03 | Training Loss: 0.6612 | Val Loss: 0.6684 | Accuracy: 0.5932 | Precision: 0.5594 | Recall: 0.7578\n",
      "Epoch 04 | Training Loss: 0.6598 | Val Loss: 0.6654 | Accuracy: 0.6042 | Precision: 0.6272 | Recall: 0.4526\n",
      "Epoch 05 | Training Loss: 0.6581 | Val Loss: 0.6721 | Accuracy: 0.5934 | Precision: 0.6340 | Recall: 0.3816\n",
      "Epoch 06 | Training Loss: 0.6565 | Val Loss: 0.6603 | Accuracy: 0.6092 | Precision: 0.6024 | Recall: 0.5701\n",
      "Epoch 07 | Training Loss: 0.6541 | Val Loss: 0.6610 | Accuracy: 0.6058 | Precision: 0.5766 | Recall: 0.7034\n",
      "Epoch 08 | Training Loss: 0.6519 | Val Loss: 0.6590 | Accuracy: 0.6076 | Precision: 0.5969 | Recall: 0.5870\n",
      "Epoch 09 | Training Loss: 0.6507 | Val Loss: 0.6597 | Accuracy: 0.6096 | Precision: 0.5883 | Recall: 0.6489\n",
      "Epoch 10 | Training Loss: 0.6497 | Val Loss: 0.6608 | Accuracy: 0.6054 | Precision: 0.6055 | Recall: 0.5338\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7009 | Test Accuracy: 0.6047 | Test Precision: 0.6225 | Test Recall: 0.5321\n",
      "\n",
      "Training for parameter combination:  26, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6732 | Val Loss: 0.6977 | Accuracy: 0.5600 | Precision: 0.5275 | Recall: 0.8853\n",
      "Epoch 02 | Training Loss: 0.6649 | Val Loss: 0.6606 | Accuracy: 0.6124 | Precision: 0.5916 | Recall: 0.6477\n",
      "Epoch 03 | Training Loss: 0.6592 | Val Loss: 0.6615 | Accuracy: 0.6092 | Precision: 0.5868 | Recall: 0.6555\n",
      "Epoch 04 | Training Loss: 0.6584 | Val Loss: 0.6601 | Accuracy: 0.6142 | Precision: 0.5998 | Recall: 0.6134\n",
      "Epoch 05 | Training Loss: 0.6568 | Val Loss: 0.6769 | Accuracy: 0.5866 | Precision: 0.5498 | Recall: 0.8135\n",
      "Epoch 06 | Training Loss: 0.6568 | Val Loss: 0.6598 | Accuracy: 0.6044 | Precision: 0.5773 | Recall: 0.6869\n",
      "Epoch 07 | Training Loss: 0.6517 | Val Loss: 0.6576 | Accuracy: 0.6178 | Precision: 0.5966 | Recall: 0.6535\n",
      "Epoch 08 | Training Loss: 0.6500 | Val Loss: 0.6585 | Accuracy: 0.6116 | Precision: 0.6009 | Recall: 0.5920\n",
      "Epoch 09 | Training Loss: 0.6484 | Val Loss: 0.6706 | Accuracy: 0.5952 | Precision: 0.5593 | Recall: 0.7776\n",
      "Epoch 10 | Training Loss: 0.6468 | Val Loss: 0.6676 | Accuracy: 0.6042 | Precision: 0.6235 | Recall: 0.4633\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6439 | Test Accuracy: 0.5986 | Test Precision: 0.6355 | Test Recall: 0.4624\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6720 | Val Loss: 0.6642 | Accuracy: 0.6074 | Precision: 0.5919 | Recall: 0.6122\n",
      "Epoch 02 | Training Loss: 0.6632 | Val Loss: 0.6642 | Accuracy: 0.6030 | Precision: 0.6118 | Recall: 0.4955\n",
      "Epoch 03 | Training Loss: 0.6614 | Val Loss: 0.6614 | Accuracy: 0.6078 | Precision: 0.5905 | Recall: 0.6229\n",
      "Epoch 04 | Training Loss: 0.6587 | Val Loss: 0.6612 | Accuracy: 0.6076 | Precision: 0.6021 | Recall: 0.5619\n",
      "Epoch 05 | Training Loss: 0.6548 | Val Loss: 0.6672 | Accuracy: 0.6034 | Precision: 0.6238 | Recall: 0.4583\n",
      "Epoch 06 | Training Loss: 0.6541 | Val Loss: 0.6616 | Accuracy: 0.5974 | Precision: 0.5688 | Recall: 0.7013\n",
      "Epoch 07 | Training Loss: 0.6520 | Val Loss: 0.6668 | Accuracy: 0.5970 | Precision: 0.5657 | Recall: 0.7261\n",
      "Epoch 08 | Training Loss: 0.6493 | Val Loss: 0.6659 | Accuracy: 0.5962 | Precision: 0.5639 | Recall: 0.7372\n",
      "Epoch 09 | Training Loss: 0.6483 | Val Loss: 0.6621 | Accuracy: 0.5990 | Precision: 0.5689 | Recall: 0.7133\n",
      "Epoch 10 | Training Loss: 0.6455 | Val Loss: 0.6596 | Accuracy: 0.6074 | Precision: 0.5842 | Recall: 0.6597\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6371 | Test Accuracy: 0.6098 | Test Precision: 0.5990 | Test Recall: 0.6638\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6700 | Val Loss: 0.6624 | Accuracy: 0.6096 | Precision: 0.5966 | Recall: 0.6011\n",
      "Epoch 02 | Training Loss: 0.6619 | Val Loss: 0.6661 | Accuracy: 0.6018 | Precision: 0.6049 | Recall: 0.5149\n",
      "Epoch 03 | Training Loss: 0.6596 | Val Loss: 0.6599 | Accuracy: 0.6134 | Precision: 0.5928 | Recall: 0.6469\n",
      "Epoch 04 | Training Loss: 0.6606 | Val Loss: 0.6672 | Accuracy: 0.5956 | Precision: 0.5640 | Recall: 0.7310\n",
      "Epoch 05 | Training Loss: 0.6555 | Val Loss: 0.6633 | Accuracy: 0.6022 | Precision: 0.5709 | Recall: 0.7228\n",
      "Epoch 06 | Training Loss: 0.6528 | Val Loss: 0.6676 | Accuracy: 0.5942 | Precision: 0.5606 | Recall: 0.7541\n",
      "Epoch 07 | Training Loss: 0.6508 | Val Loss: 0.6661 | Accuracy: 0.5946 | Precision: 0.5604 | Recall: 0.7599\n",
      "Epoch 08 | Training Loss: 0.6496 | Val Loss: 0.6612 | Accuracy: 0.6080 | Precision: 0.6102 | Recall: 0.5301\n",
      "Epoch 09 | Training Loss: 0.6477 | Val Loss: 0.6596 | Accuracy: 0.6050 | Precision: 0.5948 | Recall: 0.5813\n",
      "Epoch 10 | Training Loss: 0.6454 | Val Loss: 0.6609 | Accuracy: 0.6038 | Precision: 0.5837 | Recall: 0.6370\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6366 | Test Accuracy: 0.6078 | Test Precision: 0.6015 | Test Recall: 0.6389\n",
      "\n",
      "Training for parameter combination:  27, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6717 | Val Loss: 0.6673 | Accuracy: 0.5982 | Precision: 0.5651 | Recall: 0.7426\n",
      "Epoch 02 | Training Loss: 0.6641 | Val Loss: 0.6627 | Accuracy: 0.6084 | Precision: 0.5891 | Recall: 0.6353\n",
      "Epoch 03 | Training Loss: 0.6623 | Val Loss: 0.6641 | Accuracy: 0.6026 | Precision: 0.6029 | Recall: 0.5281\n",
      "Epoch 04 | Training Loss: 0.6595 | Val Loss: 0.6625 | Accuracy: 0.6084 | Precision: 0.5786 | Recall: 0.7079\n",
      "Epoch 05 | Training Loss: 0.6581 | Val Loss: 0.6599 | Accuracy: 0.6102 | Precision: 0.5969 | Recall: 0.6035\n",
      "Epoch 06 | Training Loss: 0.6568 | Val Loss: 0.6641 | Accuracy: 0.5998 | Precision: 0.5734 | Recall: 0.6819\n",
      "Epoch 07 | Training Loss: 0.6544 | Val Loss: 0.6656 | Accuracy: 0.5978 | Precision: 0.5655 | Recall: 0.7356\n",
      "Epoch 08 | Training Loss: 0.6536 | Val Loss: 0.6609 | Accuracy: 0.6024 | Precision: 0.5778 | Recall: 0.6679\n",
      "Epoch 09 | Training Loss: 0.6518 | Val Loss: 0.6585 | Accuracy: 0.6104 | Precision: 0.5906 | Recall: 0.6399\n",
      "Epoch 10 | Training Loss: 0.6502 | Val Loss: 0.6583 | Accuracy: 0.6080 | Precision: 0.5902 | Recall: 0.6262\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6458 | Test Accuracy: 0.6080 | Test Precision: 0.6030 | Test Recall: 0.6321\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6726 | Val Loss: 0.6633 | Accuracy: 0.6064 | Precision: 0.5979 | Recall: 0.5743\n",
      "Epoch 02 | Training Loss: 0.6642 | Val Loss: 0.6610 | Accuracy: 0.6036 | Precision: 0.5962 | Recall: 0.5652\n",
      "Epoch 03 | Training Loss: 0.6612 | Val Loss: 0.6852 | Accuracy: 0.5818 | Precision: 0.5448 | Recall: 0.8350\n",
      "Epoch 04 | Training Loss: 0.6604 | Val Loss: 0.6654 | Accuracy: 0.5972 | Precision: 0.5643 | Recall: 0.7417\n",
      "Epoch 05 | Training Loss: 0.6581 | Val Loss: 0.6617 | Accuracy: 0.5996 | Precision: 0.5688 | Recall: 0.7195\n",
      "Epoch 06 | Training Loss: 0.6567 | Val Loss: 0.6598 | Accuracy: 0.6110 | Precision: 0.6019 | Recall: 0.5837\n",
      "Epoch 07 | Training Loss: 0.6556 | Val Loss: 0.6650 | Accuracy: 0.5998 | Precision: 0.5682 | Recall: 0.7265\n",
      "Epoch 08 | Training Loss: 0.6531 | Val Loss: 0.6669 | Accuracy: 0.5968 | Precision: 0.5611 | Recall: 0.7727\n",
      "Epoch 09 | Training Loss: 0.6515 | Val Loss: 0.6588 | Accuracy: 0.6078 | Precision: 0.6020 | Recall: 0.5635\n",
      "Epoch 10 | Training Loss: 0.6506 | Val Loss: 0.6619 | Accuracy: 0.6038 | Precision: 0.5702 | Recall: 0.7426\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6460 | Test Accuracy: 0.6071 | Test Precision: 0.5837 | Test Recall: 0.7469\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6736 | Val Loss: 0.6632 | Accuracy: 0.6084 | Precision: 0.5820 | Recall: 0.6819\n",
      "Epoch 02 | Training Loss: 0.6622 | Val Loss: 0.6631 | Accuracy: 0.6046 | Precision: 0.5930 | Recall: 0.5879\n",
      "Epoch 03 | Training Loss: 0.6612 | Val Loss: 0.6610 | Accuracy: 0.6108 | Precision: 0.5844 | Recall: 0.6828\n",
      "Epoch 04 | Training Loss: 0.6597 | Val Loss: 0.6603 | Accuracy: 0.6138 | Precision: 0.5913 | Recall: 0.6584\n",
      "Epoch 05 | Training Loss: 0.6573 | Val Loss: 0.6615 | Accuracy: 0.6078 | Precision: 0.6018 | Recall: 0.5648\n",
      "Epoch 06 | Training Loss: 0.6556 | Val Loss: 0.6727 | Accuracy: 0.5872 | Precision: 0.5524 | Recall: 0.7822\n",
      "Epoch 07 | Training Loss: 0.6548 | Val Loss: 0.6600 | Accuracy: 0.6070 | Precision: 0.5793 | Recall: 0.6918\n",
      "Epoch 08 | Training Loss: 0.6520 | Val Loss: 0.6629 | Accuracy: 0.5964 | Precision: 0.5679 | Recall: 0.7001\n",
      "Epoch 09 | Training Loss: 0.6508 | Val Loss: 0.6617 | Accuracy: 0.6040 | Precision: 0.5780 | Recall: 0.6786\n",
      "Epoch 10 | Training Loss: 0.6498 | Val Loss: 0.6598 | Accuracy: 0.6102 | Precision: 0.5862 | Recall: 0.6663\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6377 | Test Accuracy: 0.6091 | Test Precision: 0.5983 | Test Recall: 0.6642\n",
      "\n",
      "Training for parameter combination:  28, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6889 | Val Loss: 0.6812 | Accuracy: 0.5758 | Precision: 0.5642 | Recall: 0.5495\n",
      "Epoch 02 | Training Loss: 0.6770 | Val Loss: 0.6766 | Accuracy: 0.5828 | Precision: 0.5514 | Recall: 0.7483\n",
      "Epoch 03 | Training Loss: 0.6706 | Val Loss: 0.6717 | Accuracy: 0.5894 | Precision: 0.5587 | Recall: 0.7285\n",
      "Epoch 04 | Training Loss: 0.6665 | Val Loss: 0.6670 | Accuracy: 0.6012 | Precision: 0.5777 | Recall: 0.6597\n",
      "Epoch 05 | Training Loss: 0.6638 | Val Loss: 0.6656 | Accuracy: 0.6034 | Precision: 0.5799 | Recall: 0.6605\n",
      "Epoch 06 | Training Loss: 0.6620 | Val Loss: 0.6643 | Accuracy: 0.6050 | Precision: 0.5914 | Recall: 0.5994\n",
      "Epoch 07 | Training Loss: 0.6613 | Val Loss: 0.6637 | Accuracy: 0.6088 | Precision: 0.5874 | Recall: 0.6485\n",
      "Epoch 08 | Training Loss: 0.6601 | Val Loss: 0.6633 | Accuracy: 0.6090 | Precision: 0.5857 | Recall: 0.6609\n",
      "Epoch 09 | Training Loss: 0.6597 | Val Loss: 0.6632 | Accuracy: 0.6102 | Precision: 0.5857 | Recall: 0.6696\n",
      "Epoch 10 | Training Loss: 0.6590 | Val Loss: 0.6627 | Accuracy: 0.6084 | Precision: 0.5934 | Recall: 0.6106\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6440 | Test Accuracy: 0.6067 | Test Precision: 0.6059 | Test Recall: 0.6105\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6932 | Val Loss: 0.6849 | Accuracy: 0.5540 | Precision: 0.5360 | Recall: 0.5961\n",
      "Epoch 02 | Training Loss: 0.6804 | Val Loss: 0.6791 | Accuracy: 0.5730 | Precision: 0.5425 | Recall: 0.7616\n",
      "Epoch 03 | Training Loss: 0.6723 | Val Loss: 0.6724 | Accuracy: 0.5932 | Precision: 0.5638 | Recall: 0.7108\n",
      "Epoch 04 | Training Loss: 0.6675 | Val Loss: 0.6684 | Accuracy: 0.6038 | Precision: 0.5767 | Recall: 0.6869\n",
      "Epoch 05 | Training Loss: 0.6644 | Val Loss: 0.6665 | Accuracy: 0.6022 | Precision: 0.5762 | Recall: 0.6782\n",
      "Epoch 06 | Training Loss: 0.6624 | Val Loss: 0.6653 | Accuracy: 0.6060 | Precision: 0.5802 | Recall: 0.6778\n",
      "Epoch 07 | Training Loss: 0.6612 | Val Loss: 0.6655 | Accuracy: 0.6032 | Precision: 0.5734 | Recall: 0.7087\n",
      "Epoch 08 | Training Loss: 0.6604 | Val Loss: 0.6641 | Accuracy: 0.6068 | Precision: 0.5798 | Recall: 0.6861\n",
      "Epoch 09 | Training Loss: 0.6595 | Val Loss: 0.6634 | Accuracy: 0.6098 | Precision: 0.5846 | Recall: 0.6741\n",
      "Epoch 10 | Training Loss: 0.6588 | Val Loss: 0.6633 | Accuracy: 0.6102 | Precision: 0.5838 | Recall: 0.6828\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6490 | Test Accuracy: 0.6074 | Test Precision: 0.5928 | Test Recall: 0.6862\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6982 | Val Loss: 0.6908 | Accuracy: 0.5302 | Precision: 0.5132 | Recall: 0.6035\n",
      "Epoch 02 | Training Loss: 0.6825 | Val Loss: 0.6792 | Accuracy: 0.5746 | Precision: 0.5556 | Recall: 0.6126\n",
      "Epoch 03 | Training Loss: 0.6737 | Val Loss: 0.6735 | Accuracy: 0.5942 | Precision: 0.5675 | Recall: 0.6848\n",
      "Epoch 04 | Training Loss: 0.6681 | Val Loss: 0.6693 | Accuracy: 0.5942 | Precision: 0.5788 | Recall: 0.5982\n",
      "Epoch 05 | Training Loss: 0.6648 | Val Loss: 0.6685 | Accuracy: 0.5950 | Precision: 0.5658 | Recall: 0.7075\n",
      "Epoch 06 | Training Loss: 0.6630 | Val Loss: 0.6677 | Accuracy: 0.5934 | Precision: 0.5631 | Recall: 0.7195\n",
      "Epoch 07 | Training Loss: 0.6617 | Val Loss: 0.6663 | Accuracy: 0.6002 | Precision: 0.5709 | Recall: 0.7063\n",
      "Epoch 08 | Training Loss: 0.6608 | Val Loss: 0.6646 | Accuracy: 0.6054 | Precision: 0.5853 | Recall: 0.6382\n",
      "Epoch 09 | Training Loss: 0.6601 | Val Loss: 0.6648 | Accuracy: 0.6058 | Precision: 0.5781 | Recall: 0.6918\n",
      "Epoch 10 | Training Loss: 0.6593 | Val Loss: 0.6638 | Accuracy: 0.6072 | Precision: 0.5857 | Recall: 0.6485\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6428 | Test Accuracy: 0.6074 | Test Precision: 0.5989 | Test Recall: 0.6506\n",
      "\n",
      "Training for parameter combination:  29, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6853 | Val Loss: 0.7520 | Accuracy: 0.5082 | Precision: 0.4963 | Recall: 0.9728\n",
      "Epoch 02 | Training Loss: 0.6663 | Val Loss: 0.6959 | Accuracy: 0.5530 | Precision: 0.6780 | Recall: 0.1485\n",
      "Epoch 03 | Training Loss: 0.6609 | Val Loss: 0.6686 | Accuracy: 0.5902 | Precision: 0.6248 | Recall: 0.3874\n",
      "Epoch 04 | Training Loss: 0.6572 | Val Loss: 0.6617 | Accuracy: 0.6104 | Precision: 0.6012 | Recall: 0.5833\n",
      "Epoch 05 | Training Loss: 0.6543 | Val Loss: 0.6737 | Accuracy: 0.5990 | Precision: 0.5607 | Recall: 0.7987\n",
      "Epoch 06 | Training Loss: 0.6512 | Val Loss: 0.6693 | Accuracy: 0.6060 | Precision: 0.6249 | Recall: 0.4686\n",
      "Epoch 07 | Training Loss: 0.6477 | Val Loss: 0.6924 | Accuracy: 0.5772 | Precision: 0.5419 | Recall: 0.8276\n",
      "Epoch 08 | Training Loss: 0.6438 | Val Loss: 0.6661 | Accuracy: 0.6078 | Precision: 0.5965 | Recall: 0.5903\n",
      "Epoch 09 | Training Loss: 0.6408 | Val Loss: 0.6750 | Accuracy: 0.5924 | Precision: 0.5555 | Recall: 0.7974\n",
      "Epoch 10 | Training Loss: 0.6380 | Val Loss: 0.6651 | Accuracy: 0.5984 | Precision: 0.5867 | Recall: 0.5809\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6386 | Test Accuracy: 0.5945 | Test Precision: 0.5979 | Test Recall: 0.5768\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6867 | Val Loss: 0.6891 | Accuracy: 0.5510 | Precision: 0.5217 | Recall: 0.8886\n",
      "Epoch 02 | Training Loss: 0.6658 | Val Loss: 0.6687 | Accuracy: 0.5906 | Precision: 0.5581 | Recall: 0.7467\n",
      "Epoch 03 | Training Loss: 0.6602 | Val Loss: 0.6640 | Accuracy: 0.6030 | Precision: 0.6066 | Recall: 0.5153\n",
      "Epoch 04 | Training Loss: 0.6564 | Val Loss: 0.6615 | Accuracy: 0.6034 | Precision: 0.6025 | Recall: 0.5347\n",
      "Epoch 05 | Training Loss: 0.6528 | Val Loss: 0.6853 | Accuracy: 0.5614 | Precision: 0.5301 | Recall: 0.8395\n",
      "Epoch 06 | Training Loss: 0.6484 | Val Loss: 0.6652 | Accuracy: 0.6000 | Precision: 0.5912 | Recall: 0.5668\n",
      "Epoch 07 | Training Loss: 0.6467 | Val Loss: 0.6617 | Accuracy: 0.6048 | Precision: 0.5971 | Recall: 0.5685\n",
      "Epoch 08 | Training Loss: 0.6422 | Val Loss: 0.6749 | Accuracy: 0.5910 | Precision: 0.5564 | Recall: 0.7710\n",
      "Epoch 09 | Training Loss: 0.6393 | Val Loss: 0.6734 | Accuracy: 0.6016 | Precision: 0.5732 | Recall: 0.6980\n",
      "Epoch 10 | Training Loss: 0.6360 | Val Loss: 0.6701 | Accuracy: 0.5882 | Precision: 0.5590 | Recall: 0.7137\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6368 | Test Accuracy: 0.6000 | Test Precision: 0.5800 | Test Recall: 0.7246\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6802 | Val Loss: 0.6906 | Accuracy: 0.5538 | Precision: 0.6438 | Recall: 0.1782\n",
      "Epoch 02 | Training Loss: 0.6659 | Val Loss: 0.6773 | Accuracy: 0.5764 | Precision: 0.6326 | Recall: 0.3012\n",
      "Epoch 03 | Training Loss: 0.6595 | Val Loss: 0.6609 | Accuracy: 0.6024 | Precision: 0.5926 | Recall: 0.5755\n",
      "Epoch 04 | Training Loss: 0.6560 | Val Loss: 0.6709 | Accuracy: 0.6018 | Precision: 0.6018 | Recall: 0.5281\n",
      "Epoch 05 | Training Loss: 0.6528 | Val Loss: 0.6696 | Accuracy: 0.5958 | Precision: 0.5642 | Recall: 0.7306\n",
      "Epoch 06 | Training Loss: 0.6499 | Val Loss: 0.6617 | Accuracy: 0.6026 | Precision: 0.6015 | Recall: 0.5342\n",
      "Epoch 07 | Training Loss: 0.6454 | Val Loss: 0.6590 | Accuracy: 0.6080 | Precision: 0.5839 | Recall: 0.6658\n",
      "Epoch 08 | Training Loss: 0.6432 | Val Loss: 0.6609 | Accuracy: 0.5958 | Precision: 0.5717 | Recall: 0.6625\n",
      "Epoch 09 | Training Loss: 0.6404 | Val Loss: 0.6711 | Accuracy: 0.5956 | Precision: 0.6188 | Recall: 0.4319\n",
      "Epoch 10 | Training Loss: 0.6378 | Val Loss: 0.6800 | Accuracy: 0.5956 | Precision: 0.5617 | Recall: 0.7550\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6305 | Test Accuracy: 0.5954 | Test Precision: 0.5730 | Test Recall: 0.7487\n",
      "\n",
      "Training for parameter combination:  30, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7052 | Val Loss: 0.6849 | Accuracy: 0.5820 | Precision: 0.5481 | Recall: 0.7855\n",
      "Epoch 02 | Training Loss: 0.6715 | Val Loss: 0.6753 | Accuracy: 0.5880 | Precision: 0.5533 | Recall: 0.7789\n",
      "Epoch 03 | Training Loss: 0.6617 | Val Loss: 0.6736 | Accuracy: 0.5940 | Precision: 0.5608 | Recall: 0.7500\n",
      "Epoch 04 | Training Loss: 0.6561 | Val Loss: 0.6665 | Accuracy: 0.6018 | Precision: 0.6264 | Recall: 0.4427\n",
      "Epoch 05 | Training Loss: 0.6513 | Val Loss: 0.6688 | Accuracy: 0.5850 | Precision: 0.6218 | Recall: 0.3676\n",
      "Epoch 06 | Training Loss: 0.6474 | Val Loss: 0.6655 | Accuracy: 0.6034 | Precision: 0.5815 | Recall: 0.6489\n",
      "Epoch 07 | Training Loss: 0.6428 | Val Loss: 0.6764 | Accuracy: 0.5888 | Precision: 0.6228 | Recall: 0.3849\n",
      "Epoch 08 | Training Loss: 0.6381 | Val Loss: 0.7053 | Accuracy: 0.5602 | Precision: 0.5280 | Recall: 0.8754\n",
      "Epoch 09 | Training Loss: 0.6358 | Val Loss: 0.6786 | Accuracy: 0.6052 | Precision: 0.6141 | Recall: 0.4996\n",
      "Epoch 10 | Training Loss: 0.6330 | Val Loss: 0.6716 | Accuracy: 0.6032 | Precision: 0.6218 | Recall: 0.4633\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6229 | Test Accuracy: 0.5888 | Test Precision: 0.6251 | Test Recall: 0.4436\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7088 | Val Loss: 0.7182 | Accuracy: 0.5290 | Precision: 0.5078 | Recall: 0.9303\n",
      "Epoch 02 | Training Loss: 0.6678 | Val Loss: 0.6738 | Accuracy: 0.5886 | Precision: 0.5565 | Recall: 0.7455\n",
      "Epoch 03 | Training Loss: 0.6610 | Val Loss: 0.6695 | Accuracy: 0.5938 | Precision: 0.5613 | Recall: 0.7417\n",
      "Epoch 04 | Training Loss: 0.6546 | Val Loss: 0.6656 | Accuracy: 0.5926 | Precision: 0.6364 | Recall: 0.3725\n",
      "Epoch 05 | Training Loss: 0.6506 | Val Loss: 0.6795 | Accuracy: 0.5828 | Precision: 0.5473 | Recall: 0.8073\n",
      "Epoch 06 | Training Loss: 0.6468 | Val Loss: 0.6651 | Accuracy: 0.6048 | Precision: 0.5805 | Recall: 0.6667\n",
      "Epoch 07 | Training Loss: 0.6417 | Val Loss: 0.6859 | Accuracy: 0.5910 | Precision: 0.6160 | Recall: 0.4150\n",
      "Epoch 08 | Training Loss: 0.6385 | Val Loss: 0.6874 | Accuracy: 0.5838 | Precision: 0.5490 | Recall: 0.7929\n",
      "Epoch 09 | Training Loss: 0.6358 | Val Loss: 0.6782 | Accuracy: 0.5974 | Precision: 0.5635 | Recall: 0.7525\n",
      "Epoch 10 | Training Loss: 0.6318 | Val Loss: 0.7063 | Accuracy: 0.5664 | Precision: 0.5327 | Recall: 0.8606\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6522 | Test Accuracy: 0.5766 | Test Precision: 0.5485 | Test Recall: 0.8661\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7051 | Val Loss: 0.7120 | Accuracy: 0.5332 | Precision: 0.5102 | Recall: 0.9278\n",
      "Epoch 02 | Training Loss: 0.6686 | Val Loss: 0.6670 | Accuracy: 0.5952 | Precision: 0.5812 | Recall: 0.5908\n",
      "Epoch 03 | Training Loss: 0.6610 | Val Loss: 0.6662 | Accuracy: 0.5984 | Precision: 0.5749 | Recall: 0.6584\n",
      "Epoch 04 | Training Loss: 0.6561 | Val Loss: 0.6656 | Accuracy: 0.5954 | Precision: 0.6050 | Recall: 0.4765\n",
      "Epoch 05 | Training Loss: 0.6521 | Val Loss: 0.6632 | Accuracy: 0.6078 | Precision: 0.5997 | Recall: 0.5747\n",
      "Epoch 06 | Training Loss: 0.6487 | Val Loss: 0.6795 | Accuracy: 0.5828 | Precision: 0.5475 | Recall: 0.8040\n",
      "Epoch 07 | Training Loss: 0.6441 | Val Loss: 0.6670 | Accuracy: 0.5982 | Precision: 0.6058 | Recall: 0.4901\n",
      "Epoch 08 | Training Loss: 0.6406 | Val Loss: 0.6632 | Accuracy: 0.6022 | Precision: 0.5751 | Recall: 0.6873\n",
      "Epoch 09 | Training Loss: 0.6360 | Val Loss: 0.7019 | Accuracy: 0.5772 | Precision: 0.5413 | Recall: 0.8379\n",
      "Epoch 10 | Training Loss: 0.6333 | Val Loss: 0.6659 | Accuracy: 0.6108 | Precision: 0.6058 | Recall: 0.5644\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6286 | Test Accuracy: 0.6004 | Test Precision: 0.6115 | Test Recall: 0.5509\n",
      "\n",
      "Training for parameter combination:  31, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6714 | Val Loss: 0.6747 | Accuracy: 0.5878 | Precision: 0.5527 | Recall: 0.7847\n",
      "Epoch 02 | Training Loss: 0.6617 | Val Loss: 0.6769 | Accuracy: 0.5872 | Precision: 0.5503 | Recall: 0.8131\n",
      "Epoch 03 | Training Loss: 0.6595 | Val Loss: 0.6844 | Accuracy: 0.5790 | Precision: 0.5429 | Recall: 0.8325\n",
      "Epoch 04 | Training Loss: 0.6589 | Val Loss: 0.6636 | Accuracy: 0.6068 | Precision: 0.5798 | Recall: 0.6861\n",
      "Epoch 05 | Training Loss: 0.6559 | Val Loss: 0.6668 | Accuracy: 0.5994 | Precision: 0.5647 | Recall: 0.7574\n",
      "Epoch 06 | Training Loss: 0.6549 | Val Loss: 0.6601 | Accuracy: 0.6104 | Precision: 0.6047 | Recall: 0.5672\n",
      "Epoch 07 | Training Loss: 0.6536 | Val Loss: 0.6613 | Accuracy: 0.6054 | Precision: 0.5780 | Recall: 0.6894\n",
      "Epoch 08 | Training Loss: 0.6506 | Val Loss: 0.6592 | Accuracy: 0.6100 | Precision: 0.5879 | Recall: 0.6539\n",
      "Epoch 09 | Training Loss: 0.6475 | Val Loss: 0.6618 | Accuracy: 0.6036 | Precision: 0.5747 | Recall: 0.7017\n",
      "Epoch 10 | Training Loss: 0.6467 | Val Loss: 0.6586 | Accuracy: 0.6080 | Precision: 0.5946 | Recall: 0.6015\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6321 | Test Accuracy: 0.6081 | Test Precision: 0.6090 | Test Recall: 0.6041\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6758 | Val Loss: 0.6700 | Accuracy: 0.5900 | Precision: 0.6206 | Recall: 0.3969\n",
      "Epoch 02 | Training Loss: 0.6627 | Val Loss: 0.6626 | Accuracy: 0.6092 | Precision: 0.5839 | Recall: 0.6745\n",
      "Epoch 03 | Training Loss: 0.6600 | Val Loss: 0.6644 | Accuracy: 0.5992 | Precision: 0.6071 | Recall: 0.4909\n",
      "Epoch 04 | Training Loss: 0.6590 | Val Loss: 0.6623 | Accuracy: 0.6036 | Precision: 0.5771 | Recall: 0.6823\n",
      "Epoch 05 | Training Loss: 0.6603 | Val Loss: 0.6833 | Accuracy: 0.5780 | Precision: 0.5423 | Recall: 0.8296\n",
      "Epoch 06 | Training Loss: 0.6553 | Val Loss: 0.6618 | Accuracy: 0.6076 | Precision: 0.6021 | Recall: 0.5619\n",
      "Epoch 07 | Training Loss: 0.6538 | Val Loss: 0.6636 | Accuracy: 0.6036 | Precision: 0.5753 | Recall: 0.6968\n",
      "Epoch 08 | Training Loss: 0.6530 | Val Loss: 0.6643 | Accuracy: 0.6020 | Precision: 0.5725 | Recall: 0.7071\n",
      "Epoch 09 | Training Loss: 0.6511 | Val Loss: 0.6643 | Accuracy: 0.6006 | Precision: 0.5706 | Recall: 0.7120\n",
      "Epoch 10 | Training Loss: 0.6497 | Val Loss: 0.6602 | Accuracy: 0.6066 | Precision: 0.5861 | Recall: 0.6419\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6439 | Test Accuracy: 0.6099 | Test Precision: 0.6016 | Test Recall: 0.6504\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6738 | Val Loss: 0.6681 | Accuracy: 0.5966 | Precision: 0.5627 | Recall: 0.7537\n",
      "Epoch 02 | Training Loss: 0.6610 | Val Loss: 0.6728 | Accuracy: 0.5924 | Precision: 0.5551 | Recall: 0.8024\n",
      "Epoch 03 | Training Loss: 0.6610 | Val Loss: 0.6645 | Accuracy: 0.6018 | Precision: 0.5696 | Recall: 0.7310\n",
      "Epoch 04 | Training Loss: 0.6571 | Val Loss: 0.6606 | Accuracy: 0.6066 | Precision: 0.5798 | Recall: 0.6848\n",
      "Epoch 05 | Training Loss: 0.6561 | Val Loss: 0.6608 | Accuracy: 0.6104 | Precision: 0.5859 | Recall: 0.6696\n",
      "Epoch 06 | Training Loss: 0.6525 | Val Loss: 0.6602 | Accuracy: 0.6064 | Precision: 0.5988 | Recall: 0.5701\n",
      "Epoch 07 | Training Loss: 0.6523 | Val Loss: 0.6575 | Accuracy: 0.6146 | Precision: 0.5947 | Recall: 0.6436\n",
      "Epoch 08 | Training Loss: 0.6489 | Val Loss: 0.6575 | Accuracy: 0.6152 | Precision: 0.5923 | Recall: 0.6621\n",
      "Epoch 09 | Training Loss: 0.6473 | Val Loss: 0.6660 | Accuracy: 0.6026 | Precision: 0.5673 | Recall: 0.7603\n",
      "Epoch 10 | Training Loss: 0.6472 | Val Loss: 0.6654 | Accuracy: 0.6004 | Precision: 0.5647 | Recall: 0.7669\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6513 | Test Accuracy: 0.6054 | Test Precision: 0.5795 | Test Recall: 0.7687\n",
      "\n",
      "Training for parameter combination:  32, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6785 | Val Loss: 0.6987 | Accuracy: 0.5526 | Precision: 0.5227 | Recall: 0.8882\n",
      "Epoch 02 | Training Loss: 0.6668 | Val Loss: 0.6692 | Accuracy: 0.5920 | Precision: 0.6007 | Recall: 0.4724\n",
      "Epoch 03 | Training Loss: 0.6626 | Val Loss: 0.7005 | Accuracy: 0.5544 | Precision: 0.5240 | Recall: 0.8824\n",
      "Epoch 04 | Training Loss: 0.6598 | Val Loss: 0.6609 | Accuracy: 0.6094 | Precision: 0.5924 | Recall: 0.6229\n",
      "Epoch 05 | Training Loss: 0.6565 | Val Loss: 0.6654 | Accuracy: 0.5994 | Precision: 0.5676 | Recall: 0.7294\n",
      "Epoch 06 | Training Loss: 0.6553 | Val Loss: 0.7159 | Accuracy: 0.5538 | Precision: 0.5232 | Recall: 0.8985\n",
      "Epoch 07 | Training Loss: 0.6543 | Val Loss: 0.6618 | Accuracy: 0.6022 | Precision: 0.5837 | Recall: 0.6258\n",
      "Epoch 08 | Training Loss: 0.6518 | Val Loss: 0.6756 | Accuracy: 0.5900 | Precision: 0.5553 | Recall: 0.7752\n",
      "Epoch 09 | Training Loss: 0.6498 | Val Loss: 0.6653 | Accuracy: 0.5942 | Precision: 0.5641 | Recall: 0.7170\n",
      "Epoch 10 | Training Loss: 0.6490 | Val Loss: 0.6602 | Accuracy: 0.6062 | Precision: 0.6144 | Recall: 0.5041\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6422 | Test Accuracy: 0.6028 | Test Precision: 0.6269 | Test Recall: 0.5078\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6819 | Val Loss: 0.6723 | Accuracy: 0.5912 | Precision: 0.5569 | Recall: 0.7669\n",
      "Epoch 02 | Training Loss: 0.6682 | Val Loss: 0.6667 | Accuracy: 0.6002 | Precision: 0.6189 | Recall: 0.4563\n",
      "Epoch 03 | Training Loss: 0.6628 | Val Loss: 0.6639 | Accuracy: 0.6048 | Precision: 0.5758 | Recall: 0.7017\n",
      "Epoch 04 | Training Loss: 0.6612 | Val Loss: 0.6948 | Accuracy: 0.5674 | Precision: 0.5333 | Recall: 0.8626\n",
      "Epoch 05 | Training Loss: 0.6587 | Val Loss: 0.6933 | Accuracy: 0.5614 | Precision: 0.5284 | Recall: 0.8853\n",
      "Epoch 06 | Training Loss: 0.6564 | Val Loss: 0.6639 | Accuracy: 0.5952 | Precision: 0.5658 | Recall: 0.7096\n",
      "Epoch 07 | Training Loss: 0.6539 | Val Loss: 0.6816 | Accuracy: 0.5762 | Precision: 0.5405 | Recall: 0.8399\n",
      "Epoch 08 | Training Loss: 0.6528 | Val Loss: 0.6621 | Accuracy: 0.6058 | Precision: 0.6063 | Recall: 0.5330\n",
      "Epoch 09 | Training Loss: 0.6510 | Val Loss: 0.6668 | Accuracy: 0.5930 | Precision: 0.5594 | Recall: 0.7558\n",
      "Epoch 10 | Training Loss: 0.6485 | Val Loss: 0.6704 | Accuracy: 0.5952 | Precision: 0.6456 | Recall: 0.3659\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6345 | Test Accuracy: 0.5822 | Test Precision: 0.6493 | Test Recall: 0.3577\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6817 | Val Loss: 0.6656 | Accuracy: 0.6018 | Precision: 0.5947 | Recall: 0.5606\n",
      "Epoch 02 | Training Loss: 0.6683 | Val Loss: 0.6820 | Accuracy: 0.5772 | Precision: 0.5417 | Recall: 0.8309\n",
      "Epoch 03 | Training Loss: 0.6654 | Val Loss: 0.6696 | Accuracy: 0.5910 | Precision: 0.6211 | Recall: 0.4010\n",
      "Epoch 04 | Training Loss: 0.6619 | Val Loss: 0.6823 | Accuracy: 0.5694 | Precision: 0.6511 | Recall: 0.2409\n",
      "Epoch 05 | Training Loss: 0.6603 | Val Loss: 0.6673 | Accuracy: 0.5936 | Precision: 0.5598 | Recall: 0.7574\n",
      "Epoch 06 | Training Loss: 0.6575 | Val Loss: 0.6693 | Accuracy: 0.5936 | Precision: 0.6489 | Recall: 0.3523\n",
      "Epoch 07 | Training Loss: 0.6561 | Val Loss: 0.6874 | Accuracy: 0.5710 | Precision: 0.5358 | Recall: 0.8618\n",
      "Epoch 08 | Training Loss: 0.6532 | Val Loss: 0.6613 | Accuracy: 0.6038 | Precision: 0.5754 | Recall: 0.6972\n",
      "Epoch 09 | Training Loss: 0.6521 | Val Loss: 0.6614 | Accuracy: 0.6046 | Precision: 0.5732 | Recall: 0.7219\n",
      "Epoch 10 | Training Loss: 0.6493 | Val Loss: 0.6716 | Accuracy: 0.5922 | Precision: 0.5571 | Recall: 0.7748\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6435 | Test Accuracy: 0.6025 | Test Precision: 0.5755 | Test Recall: 0.7814\n",
      "\n",
      "Training for parameter combination:  33, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6897 | Val Loss: 0.7045 | Accuracy: 0.5504 | Precision: 0.5220 | Recall: 0.8626\n",
      "Epoch 02 | Training Loss: 0.6722 | Val Loss: 0.6655 | Accuracy: 0.6022 | Precision: 0.5913 | Recall: 0.5809\n",
      "Epoch 03 | Training Loss: 0.6717 | Val Loss: 0.6964 | Accuracy: 0.5614 | Precision: 0.5294 | Recall: 0.8577\n",
      "Epoch 04 | Training Loss: 0.6695 | Val Loss: 0.7166 | Accuracy: 0.5304 | Precision: 0.6210 | Recall: 0.0804\n",
      "Epoch 05 | Training Loss: 0.6670 | Val Loss: 0.7301 | Accuracy: 0.5412 | Precision: 0.5150 | Recall: 0.9187\n",
      "Epoch 06 | Training Loss: 0.6647 | Val Loss: 0.7135 | Accuracy: 0.5418 | Precision: 0.6400 | Recall: 0.1254\n",
      "Epoch 07 | Training Loss: 0.6644 | Val Loss: 0.6743 | Accuracy: 0.5814 | Precision: 0.6469 | Recall: 0.3007\n",
      "Epoch 08 | Training Loss: 0.6626 | Val Loss: 0.6841 | Accuracy: 0.5796 | Precision: 0.5442 | Recall: 0.8185\n",
      "Epoch 09 | Training Loss: 0.6606 | Val Loss: 0.6917 | Accuracy: 0.5694 | Precision: 0.5352 | Recall: 0.8494\n",
      "Epoch 10 | Training Loss: 0.6590 | Val Loss: 0.6989 | Accuracy: 0.5784 | Precision: 0.5422 | Recall: 0.8370\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6635 | Test Accuracy: 0.5814 | Test Precision: 0.5532 | Test Recall: 0.8457\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6963 | Val Loss: 0.7183 | Accuracy: 0.5282 | Precision: 0.6117 | Recall: 0.0734\n",
      "Epoch 02 | Training Loss: 0.6785 | Val Loss: 0.6827 | Accuracy: 0.5846 | Precision: 0.5487 | Recall: 0.8065\n",
      "Epoch 03 | Training Loss: 0.6755 | Val Loss: 0.6644 | Accuracy: 0.6040 | Precision: 0.5967 | Recall: 0.5652\n",
      "Epoch 04 | Training Loss: 0.6724 | Val Loss: 0.6624 | Accuracy: 0.6074 | Precision: 0.5922 | Recall: 0.6106\n",
      "Epoch 05 | Training Loss: 0.6678 | Val Loss: 0.6643 | Accuracy: 0.6020 | Precision: 0.5846 | Recall: 0.6184\n",
      "Epoch 06 | Training Loss: 0.6671 | Val Loss: 0.6620 | Accuracy: 0.6088 | Precision: 0.5926 | Recall: 0.6180\n",
      "Epoch 07 | Training Loss: 0.6670 | Val Loss: 0.7092 | Accuracy: 0.5474 | Precision: 0.6716 | Recall: 0.1300\n",
      "Epoch 08 | Training Loss: 0.6658 | Val Loss: 0.6647 | Accuracy: 0.6008 | Precision: 0.5703 | Recall: 0.7158\n",
      "Epoch 09 | Training Loss: 0.6641 | Val Loss: 0.6944 | Accuracy: 0.5638 | Precision: 0.6676 | Recall: 0.1997\n",
      "Epoch 10 | Training Loss: 0.6634 | Val Loss: 0.6622 | Accuracy: 0.6070 | Precision: 0.5991 | Recall: 0.5722\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6389 | Test Accuracy: 0.6068 | Test Precision: 0.6146 | Test Recall: 0.5726\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6925 | Val Loss: 0.6725 | Accuracy: 0.5922 | Precision: 0.6132 | Recall: 0.4303\n",
      "Epoch 02 | Training Loss: 0.6764 | Val Loss: 0.7011 | Accuracy: 0.5450 | Precision: 0.6441 | Recall: 0.1374\n",
      "Epoch 03 | Training Loss: 0.6720 | Val Loss: 0.7440 | Accuracy: 0.5244 | Precision: 0.5051 | Recall: 0.9348\n",
      "Epoch 04 | Training Loss: 0.6686 | Val Loss: 0.6642 | Accuracy: 0.6036 | Precision: 0.5790 | Recall: 0.6679\n",
      "Epoch 05 | Training Loss: 0.6667 | Val Loss: 0.6647 | Accuracy: 0.6052 | Precision: 0.6098 | Recall: 0.5157\n",
      "Epoch 06 | Training Loss: 0.6650 | Val Loss: 0.6817 | Accuracy: 0.5742 | Precision: 0.5408 | Recall: 0.8073\n",
      "Epoch 07 | Training Loss: 0.6634 | Val Loss: 0.6663 | Accuracy: 0.6036 | Precision: 0.5792 | Recall: 0.6667\n",
      "Epoch 08 | Training Loss: 0.6630 | Val Loss: 0.6756 | Accuracy: 0.5886 | Precision: 0.6325 | Recall: 0.3614\n",
      "Epoch 09 | Training Loss: 0.6612 | Val Loss: 0.6651 | Accuracy: 0.6062 | Precision: 0.6123 | Recall: 0.5116\n",
      "Epoch 10 | Training Loss: 0.6592 | Val Loss: 0.7103 | Accuracy: 0.5536 | Precision: 0.5234 | Recall: 0.8845\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6628 | Test Accuracy: 0.5704 | Test Precision: 0.5429 | Test Recall: 0.8912\n",
      "\n",
      "Training for parameter combination:  34, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6971 | Val Loss: 0.6885 | Accuracy: 0.5460 | Precision: 0.5328 | Recall: 0.5161\n",
      "Epoch 02 | Training Loss: 0.6881 | Val Loss: 0.6855 | Accuracy: 0.5520 | Precision: 0.5357 | Recall: 0.5693\n",
      "Epoch 03 | Training Loss: 0.6845 | Val Loss: 0.6821 | Accuracy: 0.5548 | Precision: 0.5400 | Recall: 0.5507\n",
      "Epoch 04 | Training Loss: 0.6815 | Val Loss: 0.6797 | Accuracy: 0.5608 | Precision: 0.5456 | Recall: 0.5627\n",
      "Epoch 05 | Training Loss: 0.6789 | Val Loss: 0.6779 | Accuracy: 0.5678 | Precision: 0.5500 | Recall: 0.5969\n",
      "Epoch 06 | Training Loss: 0.6766 | Val Loss: 0.6774 | Accuracy: 0.5710 | Precision: 0.5467 | Recall: 0.6741\n",
      "Epoch 07 | Training Loss: 0.6746 | Val Loss: 0.6744 | Accuracy: 0.5856 | Precision: 0.5668 | Recall: 0.6159\n",
      "Epoch 08 | Training Loss: 0.6732 | Val Loss: 0.6727 | Accuracy: 0.5922 | Precision: 0.5782 | Recall: 0.5870\n",
      "Epoch 09 | Training Loss: 0.6718 | Val Loss: 0.6714 | Accuracy: 0.5930 | Precision: 0.5800 | Recall: 0.5817\n",
      "Epoch 10 | Training Loss: 0.6704 | Val Loss: 0.6707 | Accuracy: 0.5958 | Precision: 0.5769 | Recall: 0.6238\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6879 | Test Accuracy: 0.5889 | Test Precision: 0.5848 | Test Recall: 0.6130\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6968 | Val Loss: 0.6883 | Accuracy: 0.5390 | Precision: 0.5230 | Recall: 0.5578\n",
      "Epoch 02 | Training Loss: 0.6891 | Val Loss: 0.6846 | Accuracy: 0.5554 | Precision: 0.5385 | Recall: 0.5796\n",
      "Epoch 03 | Training Loss: 0.6856 | Val Loss: 0.6819 | Accuracy: 0.5678 | Precision: 0.5491 | Recall: 0.6068\n",
      "Epoch 04 | Training Loss: 0.6826 | Val Loss: 0.6792 | Accuracy: 0.5722 | Precision: 0.5677 | Recall: 0.4930\n",
      "Epoch 05 | Training Loss: 0.6804 | Val Loss: 0.6775 | Accuracy: 0.5824 | Precision: 0.5666 | Recall: 0.5895\n",
      "Epoch 06 | Training Loss: 0.6784 | Val Loss: 0.6782 | Accuracy: 0.5822 | Precision: 0.5511 | Recall: 0.7459\n",
      "Epoch 07 | Training Loss: 0.6766 | Val Loss: 0.6746 | Accuracy: 0.5874 | Precision: 0.5781 | Recall: 0.5512\n",
      "Epoch 08 | Training Loss: 0.6754 | Val Loss: 0.6743 | Accuracy: 0.5928 | Precision: 0.5658 | Recall: 0.6885\n",
      "Epoch 09 | Training Loss: 0.6740 | Val Loss: 0.6725 | Accuracy: 0.5906 | Precision: 0.5740 | Recall: 0.6035\n",
      "Epoch 10 | Training Loss: 0.6730 | Val Loss: 0.6725 | Accuracy: 0.5966 | Precision: 0.5687 | Recall: 0.6947\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6913 | Test Accuracy: 0.5917 | Test Precision: 0.5770 | Test Recall: 0.6866\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6930 | Val Loss: 0.6889 | Accuracy: 0.5436 | Precision: 0.5290 | Recall: 0.5347\n",
      "Epoch 02 | Training Loss: 0.6849 | Val Loss: 0.6866 | Accuracy: 0.5462 | Precision: 0.5263 | Recall: 0.6390\n",
      "Epoch 03 | Training Loss: 0.6815 | Val Loss: 0.6827 | Accuracy: 0.5590 | Precision: 0.5408 | Recall: 0.5994\n",
      "Epoch 04 | Training Loss: 0.6788 | Val Loss: 0.6804 | Accuracy: 0.5634 | Precision: 0.5448 | Recall: 0.6048\n",
      "Epoch 05 | Training Loss: 0.6766 | Val Loss: 0.6791 | Accuracy: 0.5662 | Precision: 0.5444 | Recall: 0.6452\n",
      "Epoch 06 | Training Loss: 0.6748 | Val Loss: 0.6763 | Accuracy: 0.5744 | Precision: 0.5602 | Recall: 0.5685\n",
      "Epoch 07 | Training Loss: 0.6733 | Val Loss: 0.6756 | Accuracy: 0.5742 | Precision: 0.5539 | Recall: 0.6258\n",
      "Epoch 08 | Training Loss: 0.6721 | Val Loss: 0.6743 | Accuracy: 0.5784 | Precision: 0.5581 | Recall: 0.6262\n",
      "Epoch 09 | Training Loss: 0.6709 | Val Loss: 0.6734 | Accuracy: 0.5814 | Precision: 0.5603 | Recall: 0.6341\n",
      "Epoch 10 | Training Loss: 0.6700 | Val Loss: 0.6723 | Accuracy: 0.5844 | Precision: 0.5653 | Recall: 0.6180\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6912 | Test Accuracy: 0.5903 | Test Precision: 0.5842 | Test Recall: 0.6264\n",
      "\n",
      "Training for parameter combination:  35, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6736 | Val Loss: 0.6648 | Accuracy: 0.6038 | Precision: 0.5894 | Recall: 0.6023\n",
      "Epoch 02 | Training Loss: 0.6635 | Val Loss: 0.6633 | Accuracy: 0.6008 | Precision: 0.5947 | Recall: 0.5545\n",
      "Epoch 03 | Training Loss: 0.6600 | Val Loss: 0.6629 | Accuracy: 0.6090 | Precision: 0.5808 | Recall: 0.6955\n",
      "Epoch 04 | Training Loss: 0.6588 | Val Loss: 0.6625 | Accuracy: 0.6070 | Precision: 0.5795 | Recall: 0.6898\n",
      "Epoch 05 | Training Loss: 0.6577 | Val Loss: 0.6613 | Accuracy: 0.6118 | Precision: 0.5912 | Recall: 0.6456\n",
      "Epoch 06 | Training Loss: 0.6572 | Val Loss: 0.6613 | Accuracy: 0.6084 | Precision: 0.5809 | Recall: 0.6902\n",
      "Epoch 07 | Training Loss: 0.6555 | Val Loss: 0.6608 | Accuracy: 0.6100 | Precision: 0.5832 | Recall: 0.6852\n",
      "Epoch 08 | Training Loss: 0.6551 | Val Loss: 0.6617 | Accuracy: 0.6102 | Precision: 0.6084 | Recall: 0.5499\n",
      "Epoch 09 | Training Loss: 0.6537 | Val Loss: 0.6601 | Accuracy: 0.6090 | Precision: 0.5849 | Recall: 0.6663\n",
      "Epoch 10 | Training Loss: 0.6540 | Val Loss: 0.6589 | Accuracy: 0.6120 | Precision: 0.6018 | Recall: 0.5903\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6870 | Test Accuracy: 0.6042 | Test Precision: 0.6083 | Test Recall: 0.5850\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6773 | Val Loss: 0.6659 | Accuracy: 0.6018 | Precision: 0.5714 | Recall: 0.7145\n",
      "Epoch 02 | Training Loss: 0.6637 | Val Loss: 0.6711 | Accuracy: 0.5958 | Precision: 0.5592 | Recall: 0.7855\n",
      "Epoch 03 | Training Loss: 0.6610 | Val Loss: 0.6629 | Accuracy: 0.6002 | Precision: 0.5941 | Recall: 0.5536\n",
      "Epoch 04 | Training Loss: 0.6594 | Val Loss: 0.6605 | Accuracy: 0.6124 | Precision: 0.5883 | Recall: 0.6679\n",
      "Epoch 05 | Training Loss: 0.6583 | Val Loss: 0.6608 | Accuracy: 0.6098 | Precision: 0.5828 | Recall: 0.6865\n",
      "Epoch 06 | Training Loss: 0.6562 | Val Loss: 0.6619 | Accuracy: 0.6046 | Precision: 0.5777 | Recall: 0.6852\n",
      "Epoch 07 | Training Loss: 0.6551 | Val Loss: 0.6601 | Accuracy: 0.6058 | Precision: 0.5865 | Recall: 0.6337\n",
      "Epoch 08 | Training Loss: 0.6539 | Val Loss: 0.6593 | Accuracy: 0.6094 | Precision: 0.5927 | Recall: 0.6213\n",
      "Epoch 09 | Training Loss: 0.6530 | Val Loss: 0.6602 | Accuracy: 0.6066 | Precision: 0.5812 | Recall: 0.6749\n",
      "Epoch 10 | Training Loss: 0.6521 | Val Loss: 0.6597 | Accuracy: 0.6090 | Precision: 0.5966 | Recall: 0.5974\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6970 | Test Accuracy: 0.6074 | Test Precision: 0.6091 | Test Recall: 0.5996\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6777 | Val Loss: 0.6677 | Accuracy: 0.5910 | Precision: 0.5883 | Recall: 0.5206\n",
      "Epoch 02 | Training Loss: 0.6653 | Val Loss: 0.6642 | Accuracy: 0.6030 | Precision: 0.5999 | Recall: 0.5437\n",
      "Epoch 03 | Training Loss: 0.6612 | Val Loss: 0.6693 | Accuracy: 0.5958 | Precision: 0.5605 | Recall: 0.7706\n",
      "Epoch 04 | Training Loss: 0.6602 | Val Loss: 0.6615 | Accuracy: 0.6094 | Precision: 0.5917 | Recall: 0.6267\n",
      "Epoch 05 | Training Loss: 0.6577 | Val Loss: 0.6611 | Accuracy: 0.6034 | Precision: 0.5952 | Recall: 0.5685\n",
      "Epoch 06 | Training Loss: 0.6568 | Val Loss: 0.6650 | Accuracy: 0.5998 | Precision: 0.5663 | Recall: 0.7450\n",
      "Epoch 07 | Training Loss: 0.6567 | Val Loss: 0.6599 | Accuracy: 0.6068 | Precision: 0.5940 | Recall: 0.5969\n",
      "Epoch 08 | Training Loss: 0.6545 | Val Loss: 0.6611 | Accuracy: 0.6076 | Precision: 0.5787 | Recall: 0.7005\n",
      "Epoch 09 | Training Loss: 0.6541 | Val Loss: 0.6609 | Accuracy: 0.6098 | Precision: 0.5820 | Recall: 0.6927\n",
      "Epoch 10 | Training Loss: 0.6517 | Val Loss: 0.6589 | Accuracy: 0.6078 | Precision: 0.5971 | Recall: 0.5875\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6980 | Test Accuracy: 0.6102 | Test Precision: 0.6147 | Test Recall: 0.5904\n",
      "\n",
      "Training for parameter combination:  36, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6820 | Val Loss: 0.6719 | Accuracy: 0.5822 | Precision: 0.5877 | Recall: 0.4633\n",
      "Epoch 02 | Training Loss: 0.6674 | Val Loss: 0.6658 | Accuracy: 0.6036 | Precision: 0.5836 | Recall: 0.6361\n",
      "Epoch 03 | Training Loss: 0.6641 | Val Loss: 0.6648 | Accuracy: 0.6060 | Precision: 0.5814 | Recall: 0.6691\n",
      "Epoch 04 | Training Loss: 0.6624 | Val Loss: 0.6648 | Accuracy: 0.6058 | Precision: 0.5783 | Recall: 0.6902\n",
      "Epoch 05 | Training Loss: 0.6621 | Val Loss: 0.6645 | Accuracy: 0.6054 | Precision: 0.5768 | Recall: 0.6988\n",
      "Epoch 06 | Training Loss: 0.6614 | Val Loss: 0.6648 | Accuracy: 0.6062 | Precision: 0.5755 | Recall: 0.7158\n",
      "Epoch 07 | Training Loss: 0.6611 | Val Loss: 0.6676 | Accuracy: 0.6002 | Precision: 0.5668 | Recall: 0.7434\n",
      "Epoch 08 | Training Loss: 0.6610 | Val Loss: 0.6657 | Accuracy: 0.6024 | Precision: 0.5703 | Recall: 0.7298\n",
      "Epoch 09 | Training Loss: 0.6605 | Val Loss: 0.6636 | Accuracy: 0.6062 | Precision: 0.5782 | Recall: 0.6943\n",
      "Epoch 10 | Training Loss: 0.6604 | Val Loss: 0.6661 | Accuracy: 0.6016 | Precision: 0.5687 | Recall: 0.7372\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6733 | Test Accuracy: 0.6068 | Test Precision: 0.5832 | Test Recall: 0.7483\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6862 | Val Loss: 0.6729 | Accuracy: 0.5908 | Precision: 0.5638 | Recall: 0.6894\n",
      "Epoch 02 | Training Loss: 0.6675 | Val Loss: 0.6694 | Accuracy: 0.5932 | Precision: 0.5598 | Recall: 0.7529\n",
      "Epoch 03 | Training Loss: 0.6640 | Val Loss: 0.6694 | Accuracy: 0.5958 | Precision: 0.5618 | Recall: 0.7558\n",
      "Epoch 04 | Training Loss: 0.6624 | Val Loss: 0.6639 | Accuracy: 0.6086 | Precision: 0.5848 | Recall: 0.6642\n",
      "Epoch 05 | Training Loss: 0.6617 | Val Loss: 0.6644 | Accuracy: 0.6064 | Precision: 0.5778 | Recall: 0.6984\n",
      "Epoch 06 | Training Loss: 0.6607 | Val Loss: 0.6636 | Accuracy: 0.6030 | Precision: 0.5935 | Recall: 0.5747\n",
      "Epoch 07 | Training Loss: 0.6608 | Val Loss: 0.6634 | Accuracy: 0.6058 | Precision: 0.5908 | Recall: 0.6081\n",
      "Epoch 08 | Training Loss: 0.6606 | Val Loss: 0.6653 | Accuracy: 0.6042 | Precision: 0.5727 | Recall: 0.7228\n",
      "Epoch 09 | Training Loss: 0.6600 | Val Loss: 0.6644 | Accuracy: 0.6046 | Precision: 0.5754 | Recall: 0.7038\n",
      "Epoch 10 | Training Loss: 0.6601 | Val Loss: 0.6684 | Accuracy: 0.5998 | Precision: 0.5656 | Recall: 0.7525\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6685 | Test Accuracy: 0.6038 | Test Precision: 0.5790 | Test Recall: 0.7614\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6908 | Val Loss: 0.6712 | Accuracy: 0.5968 | Precision: 0.5769 | Recall: 0.6312\n",
      "Epoch 02 | Training Loss: 0.6674 | Val Loss: 0.6651 | Accuracy: 0.6054 | Precision: 0.5749 | Recall: 0.7141\n",
      "Epoch 03 | Training Loss: 0.6632 | Val Loss: 0.6676 | Accuracy: 0.5972 | Precision: 0.5628 | Recall: 0.7578\n",
      "Epoch 04 | Training Loss: 0.6616 | Val Loss: 0.6623 | Accuracy: 0.6106 | Precision: 0.5902 | Recall: 0.6436\n",
      "Epoch 05 | Training Loss: 0.6611 | Val Loss: 0.6635 | Accuracy: 0.6046 | Precision: 0.5762 | Recall: 0.6972\n",
      "Epoch 06 | Training Loss: 0.6604 | Val Loss: 0.6629 | Accuracy: 0.6064 | Precision: 0.5786 | Recall: 0.6927\n",
      "Epoch 07 | Training Loss: 0.6605 | Val Loss: 0.6622 | Accuracy: 0.6094 | Precision: 0.5843 | Recall: 0.6733\n",
      "Epoch 08 | Training Loss: 0.6599 | Val Loss: 0.6638 | Accuracy: 0.6062 | Precision: 0.5747 | Recall: 0.7219\n",
      "Epoch 09 | Training Loss: 0.6601 | Val Loss: 0.6622 | Accuracy: 0.6058 | Precision: 0.5791 | Recall: 0.6840\n",
      "Epoch 10 | Training Loss: 0.6596 | Val Loss: 0.6624 | Accuracy: 0.6056 | Precision: 0.5777 | Recall: 0.6931\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6806 | Test Accuracy: 0.6071 | Test Precision: 0.5909 | Test Recall: 0.6964\n",
      "\n",
      "Training for parameter combination:  37, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6761 | Val Loss: 0.6646 | Accuracy: 0.6042 | Precision: 0.5777 | Recall: 0.6823\n",
      "Epoch 02 | Training Loss: 0.6640 | Val Loss: 0.6901 | Accuracy: 0.5500 | Precision: 0.6299 | Recall: 0.1741\n",
      "Epoch 03 | Training Loss: 0.6601 | Val Loss: 0.6619 | Accuracy: 0.6038 | Precision: 0.5773 | Recall: 0.6828\n",
      "Epoch 04 | Training Loss: 0.6569 | Val Loss: 0.6689 | Accuracy: 0.6044 | Precision: 0.6202 | Recall: 0.4748\n",
      "Epoch 05 | Training Loss: 0.6532 | Val Loss: 0.6589 | Accuracy: 0.6130 | Precision: 0.6058 | Recall: 0.5776\n",
      "Epoch 06 | Training Loss: 0.6497 | Val Loss: 0.6601 | Accuracy: 0.6118 | Precision: 0.5880 | Recall: 0.6654\n",
      "Epoch 07 | Training Loss: 0.6470 | Val Loss: 0.6593 | Accuracy: 0.6080 | Precision: 0.5852 | Recall: 0.6576\n",
      "Epoch 08 | Training Loss: 0.6436 | Val Loss: 0.6596 | Accuracy: 0.6048 | Precision: 0.5977 | Recall: 0.5652\n",
      "Epoch 09 | Training Loss: 0.6412 | Val Loss: 0.6595 | Accuracy: 0.6080 | Precision: 0.5812 | Recall: 0.6848\n",
      "Epoch 10 | Training Loss: 0.6392 | Val Loss: 0.6577 | Accuracy: 0.6122 | Precision: 0.5959 | Recall: 0.6217\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6414 | Test Accuracy: 0.6089 | Test Precision: 0.6064 | Test Recall: 0.6209\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6763 | Val Loss: 0.6665 | Accuracy: 0.5992 | Precision: 0.5668 | Recall: 0.7356\n",
      "Epoch 02 | Training Loss: 0.6641 | Val Loss: 0.6848 | Accuracy: 0.5760 | Precision: 0.6360 | Recall: 0.2933\n",
      "Epoch 03 | Training Loss: 0.6605 | Val Loss: 0.6649 | Accuracy: 0.5982 | Precision: 0.5705 | Recall: 0.6927\n",
      "Epoch 04 | Training Loss: 0.6574 | Val Loss: 0.6629 | Accuracy: 0.6034 | Precision: 0.5936 | Recall: 0.5767\n",
      "Epoch 05 | Training Loss: 0.6551 | Val Loss: 0.6730 | Accuracy: 0.5932 | Precision: 0.5572 | Recall: 0.7842\n",
      "Epoch 06 | Training Loss: 0.6513 | Val Loss: 0.6797 | Accuracy: 0.5870 | Precision: 0.6495 | Recall: 0.3218\n",
      "Epoch 07 | Training Loss: 0.6490 | Val Loss: 0.6741 | Accuracy: 0.5908 | Precision: 0.6234 | Recall: 0.3940\n",
      "Epoch 08 | Training Loss: 0.6460 | Val Loss: 0.6650 | Accuracy: 0.6080 | Precision: 0.5929 | Recall: 0.6110\n",
      "Epoch 09 | Training Loss: 0.6428 | Val Loss: 0.6728 | Accuracy: 0.5868 | Precision: 0.5514 | Recall: 0.7917\n",
      "Epoch 10 | Training Loss: 0.6394 | Val Loss: 0.6800 | Accuracy: 0.5824 | Precision: 0.5471 | Recall: 0.8057\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6405 | Test Accuracy: 0.5951 | Test Precision: 0.5661 | Test Recall: 0.8147\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6748 | Val Loss: 0.6737 | Accuracy: 0.5884 | Precision: 0.5534 | Recall: 0.7826\n",
      "Epoch 02 | Training Loss: 0.6644 | Val Loss: 0.6642 | Accuracy: 0.6026 | Precision: 0.5742 | Recall: 0.6976\n",
      "Epoch 03 | Training Loss: 0.6613 | Val Loss: 0.6634 | Accuracy: 0.6030 | Precision: 0.5839 | Recall: 0.6300\n",
      "Epoch 04 | Training Loss: 0.6577 | Val Loss: 0.6702 | Accuracy: 0.5944 | Precision: 0.5589 | Recall: 0.7752\n",
      "Epoch 05 | Training Loss: 0.6552 | Val Loss: 0.6688 | Accuracy: 0.5940 | Precision: 0.5608 | Recall: 0.7496\n",
      "Epoch 06 | Training Loss: 0.6514 | Val Loss: 0.6591 | Accuracy: 0.6060 | Precision: 0.5928 | Recall: 0.5982\n",
      "Epoch 07 | Training Loss: 0.6485 | Val Loss: 0.6601 | Accuracy: 0.6074 | Precision: 0.5891 | Recall: 0.6287\n",
      "Epoch 08 | Training Loss: 0.6461 | Val Loss: 0.6583 | Accuracy: 0.6076 | Precision: 0.5894 | Recall: 0.6283\n",
      "Epoch 09 | Training Loss: 0.6432 | Val Loss: 0.6621 | Accuracy: 0.6054 | Precision: 0.5782 | Recall: 0.6877\n",
      "Epoch 10 | Training Loss: 0.6411 | Val Loss: 0.6605 | Accuracy: 0.6104 | Precision: 0.5933 | Recall: 0.6246\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6302 | Test Accuracy: 0.6048 | Test Precision: 0.6024 | Test Recall: 0.6166\n",
      "\n",
      "Training for parameter combination:  38, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7071 | Val Loss: 0.7030 | Accuracy: 0.5012 | Precision: 0.4679 | Recall: 0.2108\n",
      "Epoch 02 | Training Loss: 0.7007 | Val Loss: 0.7014 | Accuracy: 0.4890 | Precision: 0.4636 | Recall: 0.3441\n",
      "Epoch 03 | Training Loss: 0.6988 | Val Loss: 0.7010 | Accuracy: 0.4894 | Precision: 0.4709 | Recall: 0.4303\n",
      "Epoch 04 | Training Loss: 0.6978 | Val Loss: 0.7006 | Accuracy: 0.4894 | Precision: 0.4728 | Recall: 0.4633\n",
      "Epoch 05 | Training Loss: 0.6972 | Val Loss: 0.7002 | Accuracy: 0.4954 | Precision: 0.4800 | Recall: 0.4889\n",
      "Epoch 06 | Training Loss: 0.6966 | Val Loss: 0.6997 | Accuracy: 0.4958 | Precision: 0.4804 | Recall: 0.4901\n",
      "Epoch 07 | Training Loss: 0.6960 | Val Loss: 0.6991 | Accuracy: 0.4988 | Precision: 0.4837 | Recall: 0.5004\n",
      "Epoch 08 | Training Loss: 0.6955 | Val Loss: 0.6986 | Accuracy: 0.5008 | Precision: 0.4858 | Recall: 0.5078\n",
      "Epoch 09 | Training Loss: 0.6949 | Val Loss: 0.6981 | Accuracy: 0.4992 | Precision: 0.4842 | Recall: 0.5070\n",
      "Epoch 10 | Training Loss: 0.6944 | Val Loss: 0.6976 | Accuracy: 0.5000 | Precision: 0.4850 | Recall: 0.5074\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6990 | Test Accuracy: 0.5138 | Test Precision: 0.5136 | Test Recall: 0.5226\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7325 | Val Loss: 0.7089 | Accuracy: 0.5152 | Precision: 0.5000 | Recall: 0.0586\n",
      "Epoch 02 | Training Loss: 0.7089 | Val Loss: 0.7007 | Accuracy: 0.5096 | Precision: 0.4867 | Recall: 0.2112\n",
      "Epoch 03 | Training Loss: 0.7023 | Val Loss: 0.6989 | Accuracy: 0.5040 | Precision: 0.4835 | Recall: 0.3379\n",
      "Epoch 04 | Training Loss: 0.7002 | Val Loss: 0.6984 | Accuracy: 0.5024 | Precision: 0.4846 | Recall: 0.4146\n",
      "Epoch 05 | Training Loss: 0.6991 | Val Loss: 0.6980 | Accuracy: 0.5074 | Precision: 0.4914 | Recall: 0.4575\n",
      "Epoch 06 | Training Loss: 0.6983 | Val Loss: 0.6975 | Accuracy: 0.5078 | Precision: 0.4921 | Recall: 0.4740\n",
      "Epoch 07 | Training Loss: 0.6977 | Val Loss: 0.6970 | Accuracy: 0.5104 | Precision: 0.4950 | Recall: 0.4946\n",
      "Epoch 08 | Training Loss: 0.6970 | Val Loss: 0.6964 | Accuracy: 0.5130 | Precision: 0.4977 | Recall: 0.4992\n",
      "Epoch 09 | Training Loss: 0.6965 | Val Loss: 0.6959 | Accuracy: 0.5124 | Precision: 0.4972 | Recall: 0.5070\n",
      "Epoch 10 | Training Loss: 0.6959 | Val Loss: 0.6954 | Accuracy: 0.5166 | Precision: 0.5014 | Recall: 0.5173\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6800 | Test Accuracy: 0.5063 | Test Precision: 0.5064 | Test Recall: 0.4945\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6997 | Val Loss: 0.6948 | Accuracy: 0.5174 | Precision: 0.5034 | Recall: 0.3333\n",
      "Epoch 02 | Training Loss: 0.6955 | Val Loss: 0.6942 | Accuracy: 0.5124 | Precision: 0.4968 | Recall: 0.4414\n",
      "Epoch 03 | Training Loss: 0.6944 | Val Loss: 0.6940 | Accuracy: 0.5120 | Precision: 0.4967 | Recall: 0.4979\n",
      "Epoch 04 | Training Loss: 0.6938 | Val Loss: 0.6937 | Accuracy: 0.5168 | Precision: 0.5016 | Recall: 0.5186\n",
      "Epoch 05 | Training Loss: 0.6933 | Val Loss: 0.6933 | Accuracy: 0.5172 | Precision: 0.5019 | Recall: 0.5355\n",
      "Epoch 06 | Training Loss: 0.6928 | Val Loss: 0.6929 | Accuracy: 0.5180 | Precision: 0.5027 | Recall: 0.5417\n",
      "Epoch 07 | Training Loss: 0.6923 | Val Loss: 0.6925 | Accuracy: 0.5186 | Precision: 0.5032 | Recall: 0.5466\n",
      "Epoch 08 | Training Loss: 0.6919 | Val Loss: 0.6921 | Accuracy: 0.5206 | Precision: 0.5051 | Recall: 0.5491\n",
      "Epoch 09 | Training Loss: 0.6914 | Val Loss: 0.6916 | Accuracy: 0.5224 | Precision: 0.5069 | Recall: 0.5491\n",
      "Epoch 10 | Training Loss: 0.6910 | Val Loss: 0.6913 | Accuracy: 0.5270 | Precision: 0.5111 | Recall: 0.5598\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6887 | Test Accuracy: 0.5286 | Test Precision: 0.5261 | Test Recall: 0.5748\n",
      "\n",
      "Training for parameter combination:  39, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6943 | Val Loss: 0.7156 | Accuracy: 0.5344 | Precision: 0.7017 | Recall: 0.0689\n",
      "Epoch 02 | Training Loss: 0.6701 | Val Loss: 0.6760 | Accuracy: 0.5836 | Precision: 0.5486 | Recall: 0.7970\n",
      "Epoch 03 | Training Loss: 0.6597 | Val Loss: 0.6819 | Accuracy: 0.5770 | Precision: 0.6476 | Recall: 0.2797\n",
      "Epoch 04 | Training Loss: 0.6545 | Val Loss: 0.6628 | Accuracy: 0.6006 | Precision: 0.5697 | Recall: 0.7199\n",
      "Epoch 05 | Training Loss: 0.6493 | Val Loss: 0.6919 | Accuracy: 0.5826 | Precision: 0.6487 | Recall: 0.3032\n",
      "Epoch 06 | Training Loss: 0.6445 | Val Loss: 0.6724 | Accuracy: 0.5880 | Precision: 0.5575 | Recall: 0.7277\n",
      "Epoch 07 | Training Loss: 0.6383 | Val Loss: 0.6796 | Accuracy: 0.5854 | Precision: 0.5528 | Recall: 0.7587\n",
      "Epoch 08 | Training Loss: 0.6332 | Val Loss: 0.6647 | Accuracy: 0.5954 | Precision: 0.5773 | Recall: 0.6180\n",
      "Epoch 09 | Training Loss: 0.6275 | Val Loss: 0.6832 | Accuracy: 0.5812 | Precision: 0.6384 | Recall: 0.3139\n",
      "Epoch 10 | Training Loss: 0.6235 | Val Loss: 0.6769 | Accuracy: 0.5866 | Precision: 0.5538 | Recall: 0.7583\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6433 | Test Accuracy: 0.5918 | Test Precision: 0.5683 | Test Recall: 0.7636\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6975 | Val Loss: 0.6750 | Accuracy: 0.5720 | Precision: 0.6111 | Recall: 0.3222\n",
      "Epoch 02 | Training Loss: 0.6690 | Val Loss: 0.6718 | Accuracy: 0.5868 | Precision: 0.6153 | Recall: 0.3940\n",
      "Epoch 03 | Training Loss: 0.6611 | Val Loss: 0.6813 | Accuracy: 0.5712 | Precision: 0.5365 | Recall: 0.8498\n",
      "Epoch 04 | Training Loss: 0.6552 | Val Loss: 0.7248 | Accuracy: 0.5534 | Precision: 0.6937 | Recall: 0.1411\n",
      "Epoch 05 | Training Loss: 0.6502 | Val Loss: 0.6627 | Accuracy: 0.6050 | Precision: 0.5922 | Recall: 0.5949\n",
      "Epoch 06 | Training Loss: 0.6440 | Val Loss: 0.6734 | Accuracy: 0.5938 | Precision: 0.6264 | Recall: 0.4018\n",
      "Epoch 07 | Training Loss: 0.6400 | Val Loss: 0.6816 | Accuracy: 0.5778 | Precision: 0.6509 | Recall: 0.2785\n",
      "Epoch 08 | Training Loss: 0.6368 | Val Loss: 0.6666 | Accuracy: 0.5976 | Precision: 0.6052 | Recall: 0.4889\n",
      "Epoch 09 | Training Loss: 0.6302 | Val Loss: 0.6719 | Accuracy: 0.5902 | Precision: 0.6258 | Recall: 0.3849\n",
      "Epoch 10 | Training Loss: 0.6255 | Val Loss: 0.6911 | Accuracy: 0.5862 | Precision: 0.5513 | Recall: 0.7871\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6316 | Test Accuracy: 0.5926 | Test Precision: 0.5667 | Test Recall: 0.7869\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6959 | Val Loss: 0.6797 | Accuracy: 0.5778 | Precision: 0.5449 | Recall: 0.7830\n",
      "Epoch 02 | Training Loss: 0.6672 | Val Loss: 0.7103 | Accuracy: 0.5536 | Precision: 0.5228 | Recall: 0.9092\n",
      "Epoch 03 | Training Loss: 0.6592 | Val Loss: 0.6625 | Accuracy: 0.6024 | Precision: 0.5846 | Recall: 0.6213\n",
      "Epoch 04 | Training Loss: 0.6537 | Val Loss: 0.6746 | Accuracy: 0.5898 | Precision: 0.6012 | Recall: 0.4571\n",
      "Epoch 05 | Training Loss: 0.6491 | Val Loss: 0.6659 | Accuracy: 0.5980 | Precision: 0.5989 | Recall: 0.5169\n",
      "Epoch 06 | Training Loss: 0.6430 | Val Loss: 0.6650 | Accuracy: 0.5978 | Precision: 0.5715 | Recall: 0.6811\n",
      "Epoch 07 | Training Loss: 0.6384 | Val Loss: 0.6678 | Accuracy: 0.6004 | Precision: 0.5691 | Recall: 0.7240\n",
      "Epoch 08 | Training Loss: 0.6358 | Val Loss: 0.6756 | Accuracy: 0.5952 | Precision: 0.5600 | Recall: 0.7706\n",
      "Epoch 09 | Training Loss: 0.6293 | Val Loss: 0.6653 | Accuracy: 0.6042 | Precision: 0.5910 | Recall: 0.5961\n",
      "Epoch 10 | Training Loss: 0.6248 | Val Loss: 0.6668 | Accuracy: 0.5996 | Precision: 0.5750 | Recall: 0.6671\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6526 | Test Accuracy: 0.6021 | Test Precision: 0.5905 | Test Recall: 0.6660\n",
      "\n",
      "Training for parameter combination:  40, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7269 | Val Loss: 0.7065 | Accuracy: 0.5184 | Precision: 0.5351 | Recall: 0.0503\n",
      "Epoch 02 | Training Loss: 0.7052 | Val Loss: 0.6991 | Accuracy: 0.5046 | Precision: 0.4742 | Recall: 0.2009\n",
      "Epoch 03 | Training Loss: 0.6994 | Val Loss: 0.6978 | Accuracy: 0.4916 | Precision: 0.4689 | Recall: 0.3667\n",
      "Epoch 04 | Training Loss: 0.6977 | Val Loss: 0.6977 | Accuracy: 0.4968 | Precision: 0.4806 | Recall: 0.4691\n",
      "Epoch 05 | Training Loss: 0.6971 | Val Loss: 0.6977 | Accuracy: 0.4952 | Precision: 0.4809 | Recall: 0.5194\n",
      "Epoch 06 | Training Loss: 0.6967 | Val Loss: 0.6975 | Accuracy: 0.4924 | Precision: 0.4787 | Recall: 0.5281\n",
      "Epoch 07 | Training Loss: 0.6965 | Val Loss: 0.6974 | Accuracy: 0.4932 | Precision: 0.4800 | Recall: 0.5458\n",
      "Epoch 08 | Training Loss: 0.6962 | Val Loss: 0.6972 | Accuracy: 0.4948 | Precision: 0.4817 | Recall: 0.5536\n",
      "Epoch 09 | Training Loss: 0.6960 | Val Loss: 0.6970 | Accuracy: 0.4936 | Precision: 0.4807 | Recall: 0.5545\n",
      "Epoch 10 | Training Loss: 0.6958 | Val Loss: 0.6968 | Accuracy: 0.4958 | Precision: 0.4827 | Recall: 0.5598\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6946 | Test Accuracy: 0.5070 | Test Precision: 0.5061 | Test Recall: 0.5834\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7286 | Val Loss: 0.7103 | Accuracy: 0.5116 | Precision: 0.4861 | Recall: 0.1295\n",
      "Epoch 02 | Training Loss: 0.7096 | Val Loss: 0.7029 | Accuracy: 0.5040 | Precision: 0.4803 | Recall: 0.2809\n",
      "Epoch 03 | Training Loss: 0.7034 | Val Loss: 0.7011 | Accuracy: 0.4998 | Precision: 0.4798 | Recall: 0.3771\n",
      "Epoch 04 | Training Loss: 0.7014 | Val Loss: 0.7006 | Accuracy: 0.5018 | Precision: 0.4846 | Recall: 0.4356\n",
      "Epoch 05 | Training Loss: 0.7005 | Val Loss: 0.7004 | Accuracy: 0.5046 | Precision: 0.4888 | Recall: 0.4785\n",
      "Epoch 06 | Training Loss: 0.7000 | Val Loss: 0.7002 | Accuracy: 0.5062 | Precision: 0.4909 | Recall: 0.5004\n",
      "Epoch 07 | Training Loss: 0.6996 | Val Loss: 0.6999 | Accuracy: 0.5056 | Precision: 0.4905 | Recall: 0.5099\n",
      "Epoch 08 | Training Loss: 0.6992 | Val Loss: 0.6996 | Accuracy: 0.5052 | Precision: 0.4902 | Recall: 0.5161\n",
      "Epoch 09 | Training Loss: 0.6989 | Val Loss: 0.6992 | Accuracy: 0.5058 | Precision: 0.4908 | Recall: 0.5173\n",
      "Epoch 10 | Training Loss: 0.6985 | Val Loss: 0.6989 | Accuracy: 0.5050 | Precision: 0.4901 | Recall: 0.5186\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7011 | Test Accuracy: 0.5125 | Test Precision: 0.5119 | Test Recall: 0.5374\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7228 | Val Loss: 0.7226 | Accuracy: 0.4662 | Precision: 0.4660 | Recall: 0.6918\n",
      "Epoch 02 | Training Loss: 0.7144 | Val Loss: 0.7161 | Accuracy: 0.4690 | Precision: 0.4614 | Recall: 0.5689\n",
      "Epoch 03 | Training Loss: 0.7113 | Val Loss: 0.7133 | Accuracy: 0.4734 | Precision: 0.4611 | Recall: 0.5111\n",
      "Epoch 04 | Training Loss: 0.7099 | Val Loss: 0.7118 | Accuracy: 0.4780 | Precision: 0.4627 | Recall: 0.4765\n",
      "Epoch 05 | Training Loss: 0.7089 | Val Loss: 0.7106 | Accuracy: 0.4776 | Precision: 0.4605 | Recall: 0.4521\n",
      "Epoch 06 | Training Loss: 0.7081 | Val Loss: 0.7097 | Accuracy: 0.4810 | Precision: 0.4631 | Recall: 0.4427\n",
      "Epoch 07 | Training Loss: 0.7073 | Val Loss: 0.7088 | Accuracy: 0.4836 | Precision: 0.4653 | Recall: 0.4369\n",
      "Epoch 08 | Training Loss: 0.7066 | Val Loss: 0.7080 | Accuracy: 0.4826 | Precision: 0.4632 | Recall: 0.4229\n",
      "Epoch 09 | Training Loss: 0.7059 | Val Loss: 0.7073 | Accuracy: 0.4826 | Precision: 0.4634 | Recall: 0.4257\n",
      "Epoch 10 | Training Loss: 0.7052 | Val Loss: 0.7066 | Accuracy: 0.4834 | Precision: 0.4645 | Recall: 0.4295\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6911 | Test Accuracy: 0.4876 | Test Precision: 0.4866 | Test Recall: 0.4507\n",
      "\n",
      "Training for parameter combination:  41, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6733 | Val Loss: 0.6664 | Accuracy: 0.6024 | Precision: 0.5698 | Recall: 0.7339\n",
      "Epoch 02 | Training Loss: 0.6635 | Val Loss: 0.6663 | Accuracy: 0.5964 | Precision: 0.6000 | Recall: 0.5025\n",
      "Epoch 03 | Training Loss: 0.6624 | Val Loss: 0.6646 | Accuracy: 0.6048 | Precision: 0.5739 | Recall: 0.7174\n",
      "Epoch 04 | Training Loss: 0.6612 | Val Loss: 0.6614 | Accuracy: 0.6056 | Precision: 0.5758 | Recall: 0.7083\n",
      "Epoch 05 | Training Loss: 0.6587 | Val Loss: 0.6605 | Accuracy: 0.6116 | Precision: 0.5940 | Recall: 0.6283\n",
      "Epoch 06 | Training Loss: 0.6568 | Val Loss: 0.6642 | Accuracy: 0.6030 | Precision: 0.5687 | Recall: 0.7496\n",
      "Epoch 07 | Training Loss: 0.6540 | Val Loss: 0.6615 | Accuracy: 0.6070 | Precision: 0.5776 | Recall: 0.7050\n",
      "Epoch 08 | Training Loss: 0.6524 | Val Loss: 0.6611 | Accuracy: 0.6034 | Precision: 0.5760 | Recall: 0.6898\n",
      "Epoch 09 | Training Loss: 0.6495 | Val Loss: 0.6589 | Accuracy: 0.6080 | Precision: 0.5822 | Recall: 0.6778\n",
      "Epoch 10 | Training Loss: 0.6485 | Val Loss: 0.6606 | Accuracy: 0.6076 | Precision: 0.5966 | Recall: 0.5887\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6820 | Test Accuracy: 0.6073 | Test Precision: 0.6116 | Test Recall: 0.5878\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6735 | Val Loss: 0.6648 | Accuracy: 0.6000 | Precision: 0.5673 | Recall: 0.7368\n",
      "Epoch 02 | Training Loss: 0.6647 | Val Loss: 0.6621 | Accuracy: 0.6084 | Precision: 0.6003 | Recall: 0.5751\n",
      "Epoch 03 | Training Loss: 0.6622 | Val Loss: 0.6618 | Accuracy: 0.6058 | Precision: 0.5822 | Recall: 0.6621\n",
      "Epoch 04 | Training Loss: 0.6601 | Val Loss: 0.6604 | Accuracy: 0.6112 | Precision: 0.5904 | Recall: 0.6465\n",
      "Epoch 05 | Training Loss: 0.6574 | Val Loss: 0.6634 | Accuracy: 0.5990 | Precision: 0.5661 | Recall: 0.7401\n",
      "Epoch 06 | Training Loss: 0.6554 | Val Loss: 0.6617 | Accuracy: 0.6062 | Precision: 0.5746 | Recall: 0.7228\n",
      "Epoch 07 | Training Loss: 0.6533 | Val Loss: 0.6615 | Accuracy: 0.6052 | Precision: 0.5754 | Recall: 0.7087\n",
      "Epoch 08 | Training Loss: 0.6513 | Val Loss: 0.6699 | Accuracy: 0.5950 | Precision: 0.5594 | Recall: 0.7748\n",
      "Epoch 09 | Training Loss: 0.6490 | Val Loss: 0.6594 | Accuracy: 0.6110 | Precision: 0.5992 | Recall: 0.5969\n",
      "Epoch 10 | Training Loss: 0.6480 | Val Loss: 0.6575 | Accuracy: 0.6078 | Precision: 0.5805 | Recall: 0.6885\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6872 | Test Accuracy: 0.6110 | Test Precision: 0.5958 | Test Recall: 0.6905\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6721 | Val Loss: 0.6662 | Accuracy: 0.6038 | Precision: 0.6028 | Recall: 0.5359\n",
      "Epoch 02 | Training Loss: 0.6638 | Val Loss: 0.6610 | Accuracy: 0.6134 | Precision: 0.5879 | Recall: 0.6774\n",
      "Epoch 03 | Training Loss: 0.6610 | Val Loss: 0.6614 | Accuracy: 0.6100 | Precision: 0.5842 | Recall: 0.6782\n",
      "Epoch 04 | Training Loss: 0.6602 | Val Loss: 0.6604 | Accuracy: 0.6126 | Precision: 0.5880 | Recall: 0.6712\n",
      "Epoch 05 | Training Loss: 0.6571 | Val Loss: 0.6600 | Accuracy: 0.6098 | Precision: 0.5853 | Recall: 0.6691\n",
      "Epoch 06 | Training Loss: 0.6558 | Val Loss: 0.6623 | Accuracy: 0.6064 | Precision: 0.6073 | Recall: 0.5322\n",
      "Epoch 07 | Training Loss: 0.6548 | Val Loss: 0.6584 | Accuracy: 0.6120 | Precision: 0.5904 | Recall: 0.6522\n",
      "Epoch 08 | Training Loss: 0.6525 | Val Loss: 0.6644 | Accuracy: 0.5976 | Precision: 0.5626 | Recall: 0.7640\n",
      "Epoch 09 | Training Loss: 0.6520 | Val Loss: 0.6569 | Accuracy: 0.6096 | Precision: 0.6021 | Recall: 0.5743\n",
      "Epoch 10 | Training Loss: 0.6502 | Val Loss: 0.6586 | Accuracy: 0.6128 | Precision: 0.5826 | Recall: 0.7100\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6564 | Test Accuracy: 0.6086 | Test Precision: 0.5912 | Test Recall: 0.7039\n",
      "\n",
      "Training for parameter combination:  42, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6827 | Val Loss: 0.6625 | Accuracy: 0.5986 | Precision: 0.5890 | Recall: 0.5693\n",
      "Epoch 02 | Training Loss: 0.6635 | Val Loss: 0.6909 | Accuracy: 0.5720 | Precision: 0.5357 | Recall: 0.8791\n",
      "Epoch 03 | Training Loss: 0.6586 | Val Loss: 0.6596 | Accuracy: 0.6052 | Precision: 0.5820 | Recall: 0.6588\n",
      "Epoch 04 | Training Loss: 0.6510 | Val Loss: 0.6665 | Accuracy: 0.5916 | Precision: 0.5565 | Recall: 0.7756\n",
      "Epoch 05 | Training Loss: 0.6477 | Val Loss: 0.6583 | Accuracy: 0.6066 | Precision: 0.5788 | Recall: 0.6922\n",
      "Epoch 06 | Training Loss: 0.6412 | Val Loss: 0.6610 | Accuracy: 0.5988 | Precision: 0.5794 | Recall: 0.6291\n",
      "Epoch 07 | Training Loss: 0.6372 | Val Loss: 0.6616 | Accuracy: 0.6084 | Precision: 0.5979 | Recall: 0.5870\n",
      "Epoch 08 | Training Loss: 0.6291 | Val Loss: 0.6632 | Accuracy: 0.6056 | Precision: 0.5743 | Recall: 0.7203\n",
      "Epoch 09 | Training Loss: 0.6226 | Val Loss: 0.6704 | Accuracy: 0.6010 | Precision: 0.5748 | Recall: 0.6799\n",
      "Epoch 10 | Training Loss: 0.6167 | Val Loss: 0.6713 | Accuracy: 0.6006 | Precision: 0.5756 | Recall: 0.6704\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6239 | Test Accuracy: 0.5987 | Test Precision: 0.5862 | Test Recall: 0.6710\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6764 | Val Loss: 0.6702 | Accuracy: 0.5870 | Precision: 0.6058 | Recall: 0.4241\n",
      "Epoch 02 | Training Loss: 0.6639 | Val Loss: 0.6901 | Accuracy: 0.5568 | Precision: 0.5260 | Recall: 0.8680\n",
      "Epoch 03 | Training Loss: 0.6573 | Val Loss: 0.6647 | Accuracy: 0.5970 | Precision: 0.5726 | Recall: 0.6650\n",
      "Epoch 04 | Training Loss: 0.6520 | Val Loss: 0.6664 | Accuracy: 0.5996 | Precision: 0.6115 | Recall: 0.4773\n",
      "Epoch 05 | Training Loss: 0.6480 | Val Loss: 0.6636 | Accuracy: 0.6026 | Precision: 0.6170 | Recall: 0.4752\n",
      "Epoch 06 | Training Loss: 0.6416 | Val Loss: 0.6660 | Accuracy: 0.6010 | Precision: 0.5968 | Recall: 0.5454\n",
      "Epoch 07 | Training Loss: 0.6371 | Val Loss: 0.6670 | Accuracy: 0.6048 | Precision: 0.5912 | Recall: 0.5990\n",
      "Epoch 08 | Training Loss: 0.6290 | Val Loss: 0.6735 | Accuracy: 0.5916 | Precision: 0.5607 | Recall: 0.7277\n",
      "Epoch 09 | Training Loss: 0.6237 | Val Loss: 0.6813 | Accuracy: 0.5776 | Precision: 0.5484 | Recall: 0.7285\n",
      "Epoch 10 | Training Loss: 0.6167 | Val Loss: 0.6870 | Accuracy: 0.5944 | Precision: 0.5637 | Recall: 0.7232\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6235 | Test Accuracy: 0.5988 | Test Precision: 0.5796 | Test Recall: 0.7190\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6818 | Val Loss: 0.6663 | Accuracy: 0.6006 | Precision: 0.5983 | Recall: 0.5359\n",
      "Epoch 02 | Training Loss: 0.6642 | Val Loss: 0.6612 | Accuracy: 0.6082 | Precision: 0.5973 | Recall: 0.5887\n",
      "Epoch 03 | Training Loss: 0.6572 | Val Loss: 0.6626 | Accuracy: 0.6074 | Precision: 0.5805 | Recall: 0.6861\n",
      "Epoch 04 | Training Loss: 0.6521 | Val Loss: 0.6667 | Accuracy: 0.6002 | Precision: 0.6162 | Recall: 0.4649\n",
      "Epoch 05 | Training Loss: 0.6473 | Val Loss: 0.6742 | Accuracy: 0.5850 | Precision: 0.5509 | Recall: 0.7785\n",
      "Epoch 06 | Training Loss: 0.6421 | Val Loss: 0.6693 | Accuracy: 0.5962 | Precision: 0.5682 | Recall: 0.6964\n",
      "Epoch 07 | Training Loss: 0.6370 | Val Loss: 0.6665 | Accuracy: 0.5998 | Precision: 0.5798 | Recall: 0.6337\n",
      "Epoch 08 | Training Loss: 0.6310 | Val Loss: 0.6790 | Accuracy: 0.5850 | Precision: 0.5519 | Recall: 0.7653\n",
      "Epoch 09 | Training Loss: 0.6246 | Val Loss: 0.6701 | Accuracy: 0.5958 | Precision: 0.5843 | Recall: 0.5759\n",
      "Epoch 10 | Training Loss: 0.6171 | Val Loss: 0.6698 | Accuracy: 0.5958 | Precision: 0.5731 | Recall: 0.6514\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6485 | Test Accuracy: 0.5969 | Test Precision: 0.5883 | Test Recall: 0.6460\n",
      "\n",
      "Training for parameter combination:  43, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7209 | Val Loss: 0.6876 | Accuracy: 0.5566 | Precision: 0.5407 | Recall: 0.5677\n",
      "Epoch 02 | Training Loss: 0.6817 | Val Loss: 0.6745 | Accuracy: 0.5814 | Precision: 0.5686 | Recall: 0.5660\n",
      "Epoch 03 | Training Loss: 0.6727 | Val Loss: 0.6709 | Accuracy: 0.5916 | Precision: 0.5943 | Recall: 0.4967\n",
      "Epoch 04 | Training Loss: 0.6692 | Val Loss: 0.6704 | Accuracy: 0.5876 | Precision: 0.5595 | Recall: 0.7017\n",
      "Epoch 05 | Training Loss: 0.6666 | Val Loss: 0.6667 | Accuracy: 0.5968 | Precision: 0.5901 | Recall: 0.5512\n",
      "Epoch 06 | Training Loss: 0.6658 | Val Loss: 0.6658 | Accuracy: 0.5988 | Precision: 0.5853 | Recall: 0.5916\n",
      "Epoch 07 | Training Loss: 0.6648 | Val Loss: 0.6655 | Accuracy: 0.6028 | Precision: 0.5821 | Recall: 0.6403\n",
      "Epoch 08 | Training Loss: 0.6643 | Val Loss: 0.6665 | Accuracy: 0.5974 | Precision: 0.5702 | Recall: 0.6889\n",
      "Epoch 09 | Training Loss: 0.6635 | Val Loss: 0.6647 | Accuracy: 0.6010 | Precision: 0.5811 | Recall: 0.6341\n",
      "Epoch 10 | Training Loss: 0.6628 | Val Loss: 0.6645 | Accuracy: 0.6038 | Precision: 0.5857 | Recall: 0.6246\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6463 | Test Accuracy: 0.6056 | Test Precision: 0.6003 | Test Recall: 0.6321\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7108 | Val Loss: 0.6972 | Accuracy: 0.5262 | Precision: 0.5215 | Recall: 0.2756\n",
      "Epoch 02 | Training Loss: 0.6870 | Val Loss: 0.6844 | Accuracy: 0.5596 | Precision: 0.5341 | Recall: 0.7170\n",
      "Epoch 03 | Training Loss: 0.6773 | Val Loss: 0.6757 | Accuracy: 0.5870 | Precision: 0.5624 | Recall: 0.6675\n",
      "Epoch 04 | Training Loss: 0.6720 | Val Loss: 0.6720 | Accuracy: 0.5884 | Precision: 0.5670 | Recall: 0.6390\n",
      "Epoch 05 | Training Loss: 0.6694 | Val Loss: 0.6703 | Accuracy: 0.5898 | Precision: 0.5797 | Recall: 0.5594\n",
      "Epoch 06 | Training Loss: 0.6673 | Val Loss: 0.6699 | Accuracy: 0.5908 | Precision: 0.5904 | Recall: 0.5091\n",
      "Epoch 07 | Training Loss: 0.6666 | Val Loss: 0.6706 | Accuracy: 0.5948 | Precision: 0.5641 | Recall: 0.7224\n",
      "Epoch 08 | Training Loss: 0.6657 | Val Loss: 0.6673 | Accuracy: 0.5974 | Precision: 0.5831 | Recall: 0.5949\n",
      "Epoch 09 | Training Loss: 0.6648 | Val Loss: 0.6666 | Accuracy: 0.5992 | Precision: 0.5795 | Recall: 0.6316\n",
      "Epoch 10 | Training Loss: 0.6645 | Val Loss: 0.6691 | Accuracy: 0.5952 | Precision: 0.5646 | Recall: 0.7215\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6420 | Test Accuracy: 0.5996 | Test Precision: 0.5790 | Test Recall: 0.7294\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7173 | Val Loss: 0.6978 | Accuracy: 0.5370 | Precision: 0.5157 | Recall: 0.7364\n",
      "Epoch 02 | Training Loss: 0.6874 | Val Loss: 0.6778 | Accuracy: 0.5824 | Precision: 0.5665 | Recall: 0.5908\n",
      "Epoch 03 | Training Loss: 0.6774 | Val Loss: 0.6786 | Accuracy: 0.5824 | Precision: 0.5497 | Recall: 0.7669\n",
      "Epoch 04 | Training Loss: 0.6727 | Val Loss: 0.6712 | Accuracy: 0.5914 | Precision: 0.5646 | Recall: 0.6869\n",
      "Epoch 05 | Training Loss: 0.6701 | Val Loss: 0.6690 | Accuracy: 0.5996 | Precision: 0.5776 | Recall: 0.6477\n",
      "Epoch 06 | Training Loss: 0.6684 | Val Loss: 0.6680 | Accuracy: 0.6016 | Precision: 0.5784 | Recall: 0.6572\n",
      "Epoch 07 | Training Loss: 0.6674 | Val Loss: 0.6696 | Accuracy: 0.5994 | Precision: 0.5686 | Recall: 0.7195\n",
      "Epoch 08 | Training Loss: 0.6665 | Val Loss: 0.6713 | Accuracy: 0.5936 | Precision: 0.5609 | Recall: 0.7442\n",
      "Epoch 09 | Training Loss: 0.6662 | Val Loss: 0.6664 | Accuracy: 0.6068 | Precision: 0.5867 | Recall: 0.6390\n",
      "Epoch 10 | Training Loss: 0.6656 | Val Loss: 0.6765 | Accuracy: 0.5918 | Precision: 0.5559 | Recall: 0.7859\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6627 | Test Accuracy: 0.5951 | Test Precision: 0.5685 | Test Recall: 0.7894\n",
      "\n",
      "Training for parameter combination:  44, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6808 | Val Loss: 0.6831 | Accuracy: 0.5792 | Precision: 0.5435 | Recall: 0.8238\n",
      "Epoch 02 | Training Loss: 0.6695 | Val Loss: 0.6646 | Accuracy: 0.6046 | Precision: 0.5866 | Recall: 0.6246\n",
      "Epoch 03 | Training Loss: 0.6663 | Val Loss: 0.6718 | Accuracy: 0.5970 | Precision: 0.5597 | Recall: 0.7913\n",
      "Epoch 04 | Training Loss: 0.6609 | Val Loss: 0.6871 | Accuracy: 0.5704 | Precision: 0.5370 | Recall: 0.8263\n",
      "Epoch 05 | Training Loss: 0.6624 | Val Loss: 0.6715 | Accuracy: 0.5928 | Precision: 0.5572 | Recall: 0.7793\n",
      "Epoch 06 | Training Loss: 0.6605 | Val Loss: 0.6617 | Accuracy: 0.6094 | Precision: 0.5868 | Recall: 0.6568\n",
      "Epoch 07 | Training Loss: 0.6599 | Val Loss: 0.6621 | Accuracy: 0.6098 | Precision: 0.5880 | Recall: 0.6522\n",
      "Epoch 08 | Training Loss: 0.6566 | Val Loss: 0.6699 | Accuracy: 0.5988 | Precision: 0.5669 | Recall: 0.7310\n",
      "Epoch 09 | Training Loss: 0.6572 | Val Loss: 0.6724 | Accuracy: 0.5934 | Precision: 0.5590 | Recall: 0.7644\n",
      "Epoch 10 | Training Loss: 0.6548 | Val Loss: 0.6628 | Accuracy: 0.6028 | Precision: 0.5838 | Recall: 0.6291\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6415 | Test Accuracy: 0.6056 | Test Precision: 0.6007 | Test Recall: 0.6304\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6828 | Val Loss: 0.6737 | Accuracy: 0.5916 | Precision: 0.5576 | Recall: 0.7632\n",
      "Epoch 02 | Training Loss: 0.6685 | Val Loss: 0.6766 | Accuracy: 0.5822 | Precision: 0.5476 | Recall: 0.7954\n",
      "Epoch 03 | Training Loss: 0.6665 | Val Loss: 0.6632 | Accuracy: 0.6112 | Precision: 0.5911 | Recall: 0.6423\n",
      "Epoch 04 | Training Loss: 0.6627 | Val Loss: 0.6722 | Accuracy: 0.5956 | Precision: 0.5593 | Recall: 0.7822\n",
      "Epoch 05 | Training Loss: 0.6603 | Val Loss: 0.6634 | Accuracy: 0.6062 | Precision: 0.5773 | Recall: 0.7009\n",
      "Epoch 06 | Training Loss: 0.6602 | Val Loss: 0.6635 | Accuracy: 0.6024 | Precision: 0.5753 | Recall: 0.6873\n",
      "Epoch 07 | Training Loss: 0.6559 | Val Loss: 0.6613 | Accuracy: 0.6076 | Precision: 0.5822 | Recall: 0.6749\n",
      "Epoch 08 | Training Loss: 0.6568 | Val Loss: 0.6644 | Accuracy: 0.6002 | Precision: 0.5694 | Recall: 0.7191\n",
      "Epoch 09 | Training Loss: 0.6560 | Val Loss: 0.6628 | Accuracy: 0.6030 | Precision: 0.5726 | Recall: 0.7145\n",
      "Epoch 10 | Training Loss: 0.6548 | Val Loss: 0.6579 | Accuracy: 0.6074 | Precision: 0.5896 | Recall: 0.6258\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6352 | Test Accuracy: 0.6071 | Test Precision: 0.6019 | Test Recall: 0.6326\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6858 | Val Loss: 0.6999 | Accuracy: 0.5560 | Precision: 0.5257 | Recall: 0.8618\n",
      "Epoch 02 | Training Loss: 0.6691 | Val Loss: 0.6661 | Accuracy: 0.5986 | Precision: 0.5750 | Recall: 0.6592\n",
      "Epoch 03 | Training Loss: 0.6666 | Val Loss: 0.7127 | Accuracy: 0.5340 | Precision: 0.6822 | Recall: 0.0726\n",
      "Epoch 04 | Training Loss: 0.6662 | Val Loss: 0.6725 | Accuracy: 0.5962 | Precision: 0.5613 | Recall: 0.7649\n",
      "Epoch 05 | Training Loss: 0.6664 | Val Loss: 0.6640 | Accuracy: 0.5988 | Precision: 0.6126 | Recall: 0.4691\n",
      "Epoch 06 | Training Loss: 0.6614 | Val Loss: 0.6628 | Accuracy: 0.6046 | Precision: 0.5808 | Recall: 0.6630\n",
      "Epoch 07 | Training Loss: 0.6603 | Val Loss: 0.6618 | Accuracy: 0.6090 | Precision: 0.6121 | Recall: 0.5281\n",
      "Epoch 08 | Training Loss: 0.6577 | Val Loss: 0.6707 | Accuracy: 0.5904 | Precision: 0.6497 | Recall: 0.3366\n",
      "Epoch 09 | Training Loss: 0.6570 | Val Loss: 0.6909 | Accuracy: 0.5732 | Precision: 0.5374 | Recall: 0.8593\n",
      "Epoch 10 | Training Loss: 0.6545 | Val Loss: 0.6641 | Accuracy: 0.6010 | Precision: 0.5722 | Recall: 0.7013\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6445 | Test Accuracy: 0.6035 | Test Precision: 0.5858 | Test Recall: 0.7067\n",
      "\n",
      "Training for parameter combination:  45, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6728 | Val Loss: 0.6645 | Accuracy: 0.6080 | Precision: 0.5816 | Recall: 0.6823\n",
      "Epoch 02 | Training Loss: 0.6657 | Val Loss: 0.6634 | Accuracy: 0.6074 | Precision: 0.5978 | Recall: 0.5813\n",
      "Epoch 03 | Training Loss: 0.6637 | Val Loss: 0.6701 | Accuracy: 0.5940 | Precision: 0.5587 | Recall: 0.7739\n",
      "Epoch 04 | Training Loss: 0.6633 | Val Loss: 0.6630 | Accuracy: 0.6086 | Precision: 0.5793 | Recall: 0.7038\n",
      "Epoch 05 | Training Loss: 0.6627 | Val Loss: 0.6805 | Accuracy: 0.5832 | Precision: 0.5473 | Recall: 0.8115\n",
      "Epoch 06 | Training Loss: 0.6624 | Val Loss: 0.6625 | Accuracy: 0.6096 | Precision: 0.6074 | Recall: 0.5507\n",
      "Epoch 07 | Training Loss: 0.6615 | Val Loss: 0.6645 | Accuracy: 0.6018 | Precision: 0.6165 | Recall: 0.4728\n",
      "Epoch 08 | Training Loss: 0.6612 | Val Loss: 0.6637 | Accuracy: 0.6040 | Precision: 0.5725 | Recall: 0.7228\n",
      "Epoch 09 | Training Loss: 0.6604 | Val Loss: 0.6627 | Accuracy: 0.6060 | Precision: 0.6057 | Recall: 0.5367\n",
      "Epoch 10 | Training Loss: 0.6600 | Val Loss: 0.6617 | Accuracy: 0.6084 | Precision: 0.5813 | Recall: 0.6873\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6476 | Test Accuracy: 0.6080 | Test Precision: 0.5921 | Test Recall: 0.6941\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6739 | Val Loss: 0.6676 | Accuracy: 0.5974 | Precision: 0.5648 | Recall: 0.7384\n",
      "Epoch 02 | Training Loss: 0.6654 | Val Loss: 0.6733 | Accuracy: 0.5888 | Precision: 0.5535 | Recall: 0.7855\n",
      "Epoch 03 | Training Loss: 0.6646 | Val Loss: 0.6626 | Accuracy: 0.6060 | Precision: 0.5956 | Recall: 0.5833\n",
      "Epoch 04 | Training Loss: 0.6625 | Val Loss: 0.6653 | Accuracy: 0.6008 | Precision: 0.5698 | Recall: 0.7211\n",
      "Epoch 05 | Training Loss: 0.6623 | Val Loss: 0.6816 | Accuracy: 0.5780 | Precision: 0.5427 | Recall: 0.8234\n",
      "Epoch 06 | Training Loss: 0.6623 | Val Loss: 0.6633 | Accuracy: 0.6044 | Precision: 0.5997 | Recall: 0.5532\n",
      "Epoch 07 | Training Loss: 0.6616 | Val Loss: 0.6659 | Accuracy: 0.5964 | Precision: 0.5628 | Recall: 0.7508\n",
      "Epoch 08 | Training Loss: 0.6609 | Val Loss: 0.6610 | Accuracy: 0.6074 | Precision: 0.5941 | Recall: 0.6002\n",
      "Epoch 09 | Training Loss: 0.6606 | Val Loss: 0.6634 | Accuracy: 0.6052 | Precision: 0.5739 | Recall: 0.7211\n",
      "Epoch 10 | Training Loss: 0.6595 | Val Loss: 0.6623 | Accuracy: 0.6038 | Precision: 0.6017 | Recall: 0.5408\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6392 | Test Accuracy: 0.6028 | Test Precision: 0.6186 | Test Recall: 0.5366\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6752 | Val Loss: 0.6934 | Accuracy: 0.5408 | Precision: 0.6350 | Recall: 0.1242\n",
      "Epoch 02 | Training Loss: 0.6654 | Val Loss: 0.6627 | Accuracy: 0.6118 | Precision: 0.5837 | Recall: 0.6951\n",
      "Epoch 03 | Training Loss: 0.6633 | Val Loss: 0.6666 | Accuracy: 0.5918 | Precision: 0.6117 | Recall: 0.4328\n",
      "Epoch 04 | Training Loss: 0.6629 | Val Loss: 0.6635 | Accuracy: 0.6048 | Precision: 0.5754 | Recall: 0.7054\n",
      "Epoch 05 | Training Loss: 0.6627 | Val Loss: 0.6635 | Accuracy: 0.6042 | Precision: 0.5732 | Recall: 0.7191\n",
      "Epoch 06 | Training Loss: 0.6623 | Val Loss: 0.6633 | Accuracy: 0.6030 | Precision: 0.6082 | Recall: 0.5091\n",
      "Epoch 07 | Training Loss: 0.6616 | Val Loss: 0.6601 | Accuracy: 0.6122 | Precision: 0.5911 | Recall: 0.6493\n",
      "Epoch 08 | Training Loss: 0.6600 | Val Loss: 0.6658 | Accuracy: 0.5968 | Precision: 0.6176 | Recall: 0.4418\n",
      "Epoch 09 | Training Loss: 0.6604 | Val Loss: 0.6628 | Accuracy: 0.6048 | Precision: 0.6107 | Recall: 0.5099\n",
      "Epoch 10 | Training Loss: 0.6601 | Val Loss: 0.6671 | Accuracy: 0.6012 | Precision: 0.5653 | Recall: 0.7677\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6457 | Test Accuracy: 0.6016 | Test Precision: 0.5756 | Test Recall: 0.7736\n",
      "\n",
      "Training for parameter combination:  46, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7199 | Val Loss: 0.7185 | Accuracy: 0.4822 | Precision: 0.4700 | Recall: 0.5338\n",
      "Epoch 02 | Training Loss: 0.7149 | Val Loss: 0.7146 | Accuracy: 0.4870 | Precision: 0.4738 | Recall: 0.5256\n",
      "Epoch 03 | Training Loss: 0.7115 | Val Loss: 0.7110 | Accuracy: 0.4902 | Precision: 0.4757 | Recall: 0.5041\n",
      "Epoch 04 | Training Loss: 0.7084 | Val Loss: 0.7081 | Accuracy: 0.4936 | Precision: 0.4792 | Recall: 0.5136\n",
      "Epoch 05 | Training Loss: 0.7056 | Val Loss: 0.7053 | Accuracy: 0.4980 | Precision: 0.4833 | Recall: 0.5140\n",
      "Epoch 06 | Training Loss: 0.7031 | Val Loss: 0.7031 | Accuracy: 0.4994 | Precision: 0.4852 | Recall: 0.5351\n",
      "Epoch 07 | Training Loss: 0.7007 | Val Loss: 0.7004 | Accuracy: 0.5042 | Precision: 0.4891 | Recall: 0.5083\n",
      "Epoch 08 | Training Loss: 0.6986 | Val Loss: 0.6985 | Accuracy: 0.5098 | Precision: 0.4949 | Recall: 0.5371\n",
      "Epoch 09 | Training Loss: 0.6965 | Val Loss: 0.6967 | Accuracy: 0.5158 | Precision: 0.5006 | Recall: 0.5578\n",
      "Epoch 10 | Training Loss: 0.6947 | Val Loss: 0.6949 | Accuracy: 0.5216 | Precision: 0.5060 | Recall: 0.5569\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6660 | Test Accuracy: 0.5245 | Test Precision: 0.5225 | Test Recall: 0.5680\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7366 | Val Loss: 0.7059 | Accuracy: 0.4970 | Precision: 0.4807 | Recall: 0.4678\n",
      "Epoch 02 | Training Loss: 0.7022 | Val Loss: 0.7039 | Accuracy: 0.5004 | Precision: 0.4861 | Recall: 0.5347\n",
      "Epoch 03 | Training Loss: 0.6997 | Val Loss: 0.7015 | Accuracy: 0.5030 | Precision: 0.4882 | Recall: 0.5198\n",
      "Epoch 04 | Training Loss: 0.6976 | Val Loss: 0.6994 | Accuracy: 0.5060 | Precision: 0.4912 | Recall: 0.5272\n",
      "Epoch 05 | Training Loss: 0.6955 | Val Loss: 0.6971 | Accuracy: 0.5126 | Precision: 0.4973 | Recall: 0.4901\n",
      "Epoch 06 | Training Loss: 0.6938 | Val Loss: 0.6959 | Accuracy: 0.5122 | Precision: 0.4972 | Recall: 0.5466\n",
      "Epoch 07 | Training Loss: 0.6921 | Val Loss: 0.6945 | Accuracy: 0.5168 | Precision: 0.5015 | Recall: 0.5598\n",
      "Epoch 08 | Training Loss: 0.6906 | Val Loss: 0.6927 | Accuracy: 0.5256 | Precision: 0.5102 | Recall: 0.5380\n",
      "Epoch 09 | Training Loss: 0.6892 | Val Loss: 0.6915 | Accuracy: 0.5266 | Precision: 0.5108 | Recall: 0.5565\n",
      "Epoch 10 | Training Loss: 0.6879 | Val Loss: 0.6903 | Accuracy: 0.5300 | Precision: 0.5139 | Recall: 0.5648\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6737 | Test Accuracy: 0.5488 | Test Precision: 0.5465 | Test Recall: 0.5734\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7083 | Val Loss: 0.7130 | Accuracy: 0.5108 | Precision: 0.4955 | Recall: 0.4979\n",
      "Epoch 02 | Training Loss: 0.7052 | Val Loss: 0.7105 | Accuracy: 0.5112 | Precision: 0.4961 | Recall: 0.5206\n",
      "Epoch 03 | Training Loss: 0.7025 | Val Loss: 0.7077 | Accuracy: 0.5138 | Precision: 0.4986 | Recall: 0.5136\n",
      "Epoch 04 | Training Loss: 0.7001 | Val Loss: 0.7056 | Accuracy: 0.5180 | Precision: 0.5027 | Recall: 0.5388\n",
      "Epoch 05 | Training Loss: 0.6979 | Val Loss: 0.7031 | Accuracy: 0.5206 | Precision: 0.5054 | Recall: 0.5260\n",
      "Epoch 06 | Training Loss: 0.6959 | Val Loss: 0.7012 | Accuracy: 0.5258 | Precision: 0.5104 | Recall: 0.5351\n",
      "Epoch 07 | Training Loss: 0.6940 | Val Loss: 0.6993 | Accuracy: 0.5286 | Precision: 0.5132 | Recall: 0.5392\n",
      "Epoch 08 | Training Loss: 0.6923 | Val Loss: 0.6978 | Accuracy: 0.5312 | Precision: 0.5154 | Recall: 0.5528\n",
      "Epoch 09 | Training Loss: 0.6906 | Val Loss: 0.6965 | Accuracy: 0.5342 | Precision: 0.5177 | Recall: 0.5726\n",
      "Epoch 10 | Training Loss: 0.6892 | Val Loss: 0.6943 | Accuracy: 0.5376 | Precision: 0.5227 | Recall: 0.5322\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6794 | Test Accuracy: 0.5460 | Test Precision: 0.5455 | Test Recall: 0.5520\n",
      "\n",
      "Training for parameter combination:  47, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6988 | Val Loss: 0.6922 | Accuracy: 0.5300 | Precision: 0.5153 | Recall: 0.5157\n",
      "Epoch 02 | Training Loss: 0.6904 | Val Loss: 0.6871 | Accuracy: 0.5456 | Precision: 0.5304 | Recall: 0.5474\n",
      "Epoch 03 | Training Loss: 0.6854 | Val Loss: 0.6832 | Accuracy: 0.5612 | Precision: 0.5440 | Recall: 0.5862\n",
      "Epoch 04 | Training Loss: 0.6816 | Val Loss: 0.6804 | Accuracy: 0.5748 | Precision: 0.5533 | Recall: 0.6382\n",
      "Epoch 05 | Training Loss: 0.6786 | Val Loss: 0.6776 | Accuracy: 0.5886 | Precision: 0.5668 | Recall: 0.6419\n",
      "Epoch 06 | Training Loss: 0.6761 | Val Loss: 0.6751 | Accuracy: 0.5926 | Precision: 0.5772 | Recall: 0.5969\n",
      "Epoch 07 | Training Loss: 0.6740 | Val Loss: 0.6747 | Accuracy: 0.5950 | Precision: 0.5667 | Recall: 0.6997\n",
      "Epoch 08 | Training Loss: 0.6723 | Val Loss: 0.6724 | Accuracy: 0.5988 | Precision: 0.5756 | Recall: 0.6564\n",
      "Epoch 09 | Training Loss: 0.6710 | Val Loss: 0.6710 | Accuracy: 0.6020 | Precision: 0.5824 | Recall: 0.6324\n",
      "Epoch 10 | Training Loss: 0.6698 | Val Loss: 0.6699 | Accuracy: 0.6034 | Precision: 0.5894 | Recall: 0.5998\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6951 | Test Accuracy: 0.5995 | Test Precision: 0.6004 | Test Recall: 0.5950\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6980 | Val Loss: 0.6931 | Accuracy: 0.5254 | Precision: 0.5089 | Recall: 0.6031\n",
      "Epoch 02 | Training Loss: 0.6912 | Val Loss: 0.6875 | Accuracy: 0.5450 | Precision: 0.5310 | Recall: 0.5272\n",
      "Epoch 03 | Training Loss: 0.6867 | Val Loss: 0.6838 | Accuracy: 0.5546 | Precision: 0.5385 | Recall: 0.5689\n",
      "Epoch 04 | Training Loss: 0.6828 | Val Loss: 0.6812 | Accuracy: 0.5664 | Precision: 0.5468 | Recall: 0.6172\n",
      "Epoch 05 | Training Loss: 0.6799 | Val Loss: 0.6790 | Accuracy: 0.5750 | Precision: 0.5524 | Recall: 0.6506\n",
      "Epoch 06 | Training Loss: 0.6774 | Val Loss: 0.6759 | Accuracy: 0.5812 | Precision: 0.5694 | Recall: 0.5582\n",
      "Epoch 07 | Training Loss: 0.6755 | Val Loss: 0.6745 | Accuracy: 0.5874 | Precision: 0.5686 | Recall: 0.6176\n",
      "Epoch 08 | Training Loss: 0.6738 | Val Loss: 0.6733 | Accuracy: 0.5904 | Precision: 0.5679 | Recall: 0.6485\n",
      "Epoch 09 | Training Loss: 0.6722 | Val Loss: 0.6720 | Accuracy: 0.5936 | Precision: 0.5709 | Recall: 0.6514\n",
      "Epoch 10 | Training Loss: 0.6710 | Val Loss: 0.6718 | Accuracy: 0.5912 | Precision: 0.5637 | Recall: 0.6939\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7011 | Test Accuracy: 0.5964 | Test Precision: 0.5809 | Test Recall: 0.6917\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6894 | Val Loss: 0.6870 | Accuracy: 0.5440 | Precision: 0.5273 | Recall: 0.5743\n",
      "Epoch 02 | Training Loss: 0.6834 | Val Loss: 0.6827 | Accuracy: 0.5624 | Precision: 0.5411 | Recall: 0.6415\n",
      "Epoch 03 | Training Loss: 0.6795 | Val Loss: 0.6790 | Accuracy: 0.5732 | Precision: 0.5520 | Recall: 0.6345\n",
      "Epoch 04 | Training Loss: 0.6765 | Val Loss: 0.6763 | Accuracy: 0.5814 | Precision: 0.5590 | Recall: 0.6465\n",
      "Epoch 05 | Training Loss: 0.6743 | Val Loss: 0.6739 | Accuracy: 0.5884 | Precision: 0.5702 | Recall: 0.6130\n",
      "Epoch 06 | Training Loss: 0.6724 | Val Loss: 0.6723 | Accuracy: 0.5908 | Precision: 0.5724 | Recall: 0.6163\n",
      "Epoch 07 | Training Loss: 0.6710 | Val Loss: 0.6721 | Accuracy: 0.5868 | Precision: 0.5594 | Recall: 0.6951\n",
      "Epoch 08 | Training Loss: 0.6699 | Val Loss: 0.6701 | Accuracy: 0.5956 | Precision: 0.5723 | Recall: 0.6564\n",
      "Epoch 09 | Training Loss: 0.6686 | Val Loss: 0.6715 | Accuracy: 0.5880 | Precision: 0.5572 | Recall: 0.7310\n",
      "Epoch 10 | Training Loss: 0.6681 | Val Loss: 0.6690 | Accuracy: 0.5972 | Precision: 0.5702 | Recall: 0.6873\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6814 | Test Accuracy: 0.5952 | Test Precision: 0.5811 | Test Recall: 0.6823\n",
      "\n",
      "Training for parameter combination:  48, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7437 | Val Loss: 0.7318 | Accuracy: 0.4622 | Precision: 0.4345 | Recall: 0.3626\n",
      "Epoch 02 | Training Loss: 0.7298 | Val Loss: 0.7295 | Accuracy: 0.4670 | Precision: 0.4514 | Recall: 0.4612\n",
      "Epoch 03 | Training Loss: 0.7270 | Val Loss: 0.7272 | Accuracy: 0.4694 | Precision: 0.4548 | Recall: 0.4752\n",
      "Epoch 04 | Training Loss: 0.7247 | Val Loss: 0.7251 | Accuracy: 0.4694 | Precision: 0.4556 | Recall: 0.4843\n",
      "Epoch 05 | Training Loss: 0.7227 | Val Loss: 0.7229 | Accuracy: 0.4738 | Precision: 0.4595 | Recall: 0.4839\n",
      "Epoch 06 | Training Loss: 0.7207 | Val Loss: 0.7208 | Accuracy: 0.4772 | Precision: 0.4626 | Recall: 0.4851\n",
      "Epoch 07 | Training Loss: 0.7189 | Val Loss: 0.7190 | Accuracy: 0.4790 | Precision: 0.4647 | Recall: 0.4922\n",
      "Epoch 08 | Training Loss: 0.7171 | Val Loss: 0.7171 | Accuracy: 0.4810 | Precision: 0.4664 | Recall: 0.4889\n",
      "Epoch 09 | Training Loss: 0.7155 | Val Loss: 0.7155 | Accuracy: 0.4816 | Precision: 0.4674 | Recall: 0.4971\n",
      "Epoch 10 | Training Loss: 0.7139 | Val Loss: 0.7138 | Accuracy: 0.4820 | Precision: 0.4676 | Recall: 0.4934\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7139 | Test Accuracy: 0.4822 | Test Precision: 0.4829 | Test Recall: 0.5021\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7474 | Val Loss: 0.7120 | Accuracy: 0.4888 | Precision: 0.4568 | Recall: 0.2880\n",
      "Epoch 02 | Training Loss: 0.7097 | Val Loss: 0.7101 | Accuracy: 0.4832 | Precision: 0.4702 | Recall: 0.5202\n",
      "Epoch 03 | Training Loss: 0.7076 | Val Loss: 0.7094 | Accuracy: 0.4858 | Precision: 0.4735 | Recall: 0.5421\n",
      "Epoch 04 | Training Loss: 0.7067 | Val Loss: 0.7086 | Accuracy: 0.4854 | Precision: 0.4737 | Recall: 0.5545\n",
      "Epoch 05 | Training Loss: 0.7058 | Val Loss: 0.7075 | Accuracy: 0.4868 | Precision: 0.4746 | Recall: 0.5479\n",
      "Epoch 06 | Training Loss: 0.7049 | Val Loss: 0.7067 | Accuracy: 0.4876 | Precision: 0.4754 | Recall: 0.5503\n",
      "Epoch 07 | Training Loss: 0.7041 | Val Loss: 0.7059 | Accuracy: 0.4892 | Precision: 0.4771 | Recall: 0.5578\n",
      "Epoch 08 | Training Loss: 0.7033 | Val Loss: 0.7049 | Accuracy: 0.4928 | Precision: 0.4797 | Recall: 0.5458\n",
      "Epoch 09 | Training Loss: 0.7025 | Val Loss: 0.7042 | Accuracy: 0.4924 | Precision: 0.4798 | Recall: 0.5594\n",
      "Epoch 10 | Training Loss: 0.7018 | Val Loss: 0.7037 | Accuracy: 0.4926 | Precision: 0.4804 | Recall: 0.5705\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6772 | Test Accuracy: 0.5048 | Test Precision: 0.5042 | Test Recall: 0.5714\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7049 | Val Loss: 0.7019 | Accuracy: 0.5320 | Precision: 0.5154 | Recall: 0.5784\n",
      "Epoch 02 | Training Loss: 0.7017 | Val Loss: 0.6998 | Accuracy: 0.5330 | Precision: 0.5171 | Recall: 0.5561\n",
      "Epoch 03 | Training Loss: 0.7001 | Val Loss: 0.6983 | Accuracy: 0.5344 | Precision: 0.5185 | Recall: 0.5540\n",
      "Epoch 04 | Training Loss: 0.6987 | Val Loss: 0.6971 | Accuracy: 0.5350 | Precision: 0.5190 | Recall: 0.5582\n",
      "Epoch 05 | Training Loss: 0.6974 | Val Loss: 0.6958 | Accuracy: 0.5358 | Precision: 0.5202 | Recall: 0.5466\n",
      "Epoch 06 | Training Loss: 0.6962 | Val Loss: 0.6949 | Accuracy: 0.5358 | Precision: 0.5200 | Recall: 0.5532\n",
      "Epoch 07 | Training Loss: 0.6951 | Val Loss: 0.6940 | Accuracy: 0.5354 | Precision: 0.5193 | Recall: 0.5606\n",
      "Epoch 08 | Training Loss: 0.6940 | Val Loss: 0.6928 | Accuracy: 0.5350 | Precision: 0.5194 | Recall: 0.5454\n",
      "Epoch 09 | Training Loss: 0.6930 | Val Loss: 0.6917 | Accuracy: 0.5378 | Precision: 0.5226 | Recall: 0.5400\n",
      "Epoch 10 | Training Loss: 0.6921 | Val Loss: 0.6911 | Accuracy: 0.5386 | Precision: 0.5226 | Recall: 0.5569\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6994 | Test Accuracy: 0.5348 | Test Precision: 0.5342 | Test Recall: 0.5435\n",
      "\n",
      "Training for parameter combination:  49, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7119 | Val Loss: 0.7096 | Accuracy: 0.4980 | Precision: 0.4852 | Recall: 0.5804\n",
      "Epoch 02 | Training Loss: 0.7020 | Val Loss: 0.7075 | Accuracy: 0.5002 | Precision: 0.4876 | Recall: 0.6077\n",
      "Epoch 03 | Training Loss: 0.6997 | Val Loss: 0.7044 | Accuracy: 0.5056 | Precision: 0.4915 | Recall: 0.5705\n",
      "Epoch 04 | Training Loss: 0.6976 | Val Loss: 0.7022 | Accuracy: 0.5060 | Precision: 0.4916 | Recall: 0.5582\n",
      "Epoch 05 | Training Loss: 0.6958 | Val Loss: 0.7006 | Accuracy: 0.5068 | Precision: 0.4927 | Recall: 0.5879\n",
      "Epoch 06 | Training Loss: 0.6940 | Val Loss: 0.6989 | Accuracy: 0.5116 | Precision: 0.4968 | Recall: 0.5846\n",
      "Epoch 07 | Training Loss: 0.6925 | Val Loss: 0.6986 | Accuracy: 0.5140 | Precision: 0.4991 | Recall: 0.6502\n",
      "Epoch 08 | Training Loss: 0.6911 | Val Loss: 0.6958 | Accuracy: 0.5196 | Precision: 0.5039 | Recall: 0.5903\n",
      "Epoch 09 | Training Loss: 0.6898 | Val Loss: 0.6948 | Accuracy: 0.5238 | Precision: 0.5073 | Recall: 0.6151\n",
      "Epoch 10 | Training Loss: 0.6886 | Val Loss: 0.6933 | Accuracy: 0.5258 | Precision: 0.5094 | Recall: 0.5912\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6864 | Test Accuracy: 0.5378 | Test Precision: 0.5336 | Test Recall: 0.6003\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7106 | Val Loss: 0.7020 | Accuracy: 0.5332 | Precision: 0.5175 | Recall: 0.5495\n",
      "Epoch 02 | Training Loss: 0.7003 | Val Loss: 0.6987 | Accuracy: 0.5350 | Precision: 0.5179 | Recall: 0.5912\n",
      "Epoch 03 | Training Loss: 0.6967 | Val Loss: 0.6957 | Accuracy: 0.5416 | Precision: 0.5235 | Recall: 0.6056\n",
      "Epoch 04 | Training Loss: 0.6938 | Val Loss: 0.6935 | Accuracy: 0.5418 | Precision: 0.5231 | Recall: 0.6213\n",
      "Epoch 05 | Training Loss: 0.6915 | Val Loss: 0.6908 | Accuracy: 0.5452 | Precision: 0.5274 | Recall: 0.5957\n",
      "Epoch 06 | Training Loss: 0.6895 | Val Loss: 0.6894 | Accuracy: 0.5466 | Precision: 0.5278 | Recall: 0.6143\n",
      "Epoch 07 | Training Loss: 0.6878 | Val Loss: 0.6882 | Accuracy: 0.5482 | Precision: 0.5286 | Recall: 0.6300\n",
      "Epoch 08 | Training Loss: 0.6865 | Val Loss: 0.6864 | Accuracy: 0.5522 | Precision: 0.5336 | Recall: 0.6056\n",
      "Epoch 09 | Training Loss: 0.6852 | Val Loss: 0.6854 | Accuracy: 0.5532 | Precision: 0.5344 | Recall: 0.6089\n",
      "Epoch 10 | Training Loss: 0.6842 | Val Loss: 0.6842 | Accuracy: 0.5586 | Precision: 0.5399 | Recall: 0.6056\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6631 | Test Accuracy: 0.5615 | Test Precision: 0.5551 | Test Recall: 0.6198\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7590 | Val Loss: 0.7364 | Accuracy: 0.5266 | Precision: 0.5115 | Recall: 0.5252\n",
      "Epoch 02 | Training Loss: 0.7353 | Val Loss: 0.7212 | Accuracy: 0.5318 | Precision: 0.5168 | Recall: 0.5252\n",
      "Epoch 03 | Training Loss: 0.7229 | Val Loss: 0.7115 | Accuracy: 0.5350 | Precision: 0.5195 | Recall: 0.5437\n",
      "Epoch 04 | Training Loss: 0.7143 | Val Loss: 0.7047 | Accuracy: 0.5422 | Precision: 0.5261 | Recall: 0.5606\n",
      "Epoch 05 | Training Loss: 0.7081 | Val Loss: 0.6995 | Accuracy: 0.5488 | Precision: 0.5333 | Recall: 0.5549\n",
      "Epoch 06 | Training Loss: 0.7035 | Val Loss: 0.6960 | Accuracy: 0.5498 | Precision: 0.5336 | Recall: 0.5660\n",
      "Epoch 07 | Training Loss: 0.6999 | Val Loss: 0.6938 | Accuracy: 0.5534 | Precision: 0.5359 | Recall: 0.5887\n",
      "Epoch 08 | Training Loss: 0.6972 | Val Loss: 0.6910 | Accuracy: 0.5556 | Precision: 0.5394 | Recall: 0.5705\n",
      "Epoch 09 | Training Loss: 0.6948 | Val Loss: 0.6891 | Accuracy: 0.5566 | Precision: 0.5408 | Recall: 0.5656\n",
      "Epoch 10 | Training Loss: 0.6929 | Val Loss: 0.6876 | Accuracy: 0.5578 | Precision: 0.5424 | Recall: 0.5619\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6739 | Test Accuracy: 0.5481 | Test Precision: 0.5470 | Test Recall: 0.5594\n",
      "\n",
      "Training for parameter combination:  50, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7122 | Val Loss: 0.6998 | Accuracy: 0.4894 | Precision: 0.4719 | Recall: 0.4476\n",
      "Epoch 02 | Training Loss: 0.6967 | Val Loss: 0.6939 | Accuracy: 0.5146 | Precision: 0.4994 | Recall: 0.4913\n",
      "Epoch 03 | Training Loss: 0.6917 | Val Loss: 0.6898 | Accuracy: 0.5280 | Precision: 0.5138 | Recall: 0.4917\n",
      "Epoch 04 | Training Loss: 0.6881 | Val Loss: 0.6871 | Accuracy: 0.5408 | Precision: 0.5242 | Recall: 0.5718\n",
      "Epoch 05 | Training Loss: 0.6851 | Val Loss: 0.6842 | Accuracy: 0.5550 | Precision: 0.5413 | Recall: 0.5380\n",
      "Epoch 06 | Training Loss: 0.6826 | Val Loss: 0.6830 | Accuracy: 0.5626 | Precision: 0.5412 | Recall: 0.6415\n",
      "Epoch 07 | Training Loss: 0.6807 | Val Loss: 0.6809 | Accuracy: 0.5684 | Precision: 0.5489 | Recall: 0.6159\n",
      "Epoch 08 | Training Loss: 0.6789 | Val Loss: 0.6795 | Accuracy: 0.5712 | Precision: 0.5499 | Recall: 0.6370\n",
      "Epoch 09 | Training Loss: 0.6772 | Val Loss: 0.6785 | Accuracy: 0.5740 | Precision: 0.5508 | Recall: 0.6580\n",
      "Epoch 10 | Training Loss: 0.6758 | Val Loss: 0.6766 | Accuracy: 0.5808 | Precision: 0.5627 | Recall: 0.6073\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6904 | Test Accuracy: 0.5822 | Test Precision: 0.5778 | Test Recall: 0.6106\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6906 | Val Loss: 0.6863 | Accuracy: 0.5556 | Precision: 0.5383 | Recall: 0.5854\n",
      "Epoch 02 | Training Loss: 0.6871 | Val Loss: 0.6830 | Accuracy: 0.5622 | Precision: 0.5460 | Recall: 0.5751\n",
      "Epoch 03 | Training Loss: 0.6842 | Val Loss: 0.6805 | Accuracy: 0.5688 | Precision: 0.5530 | Recall: 0.5771\n",
      "Epoch 04 | Training Loss: 0.6817 | Val Loss: 0.6791 | Accuracy: 0.5768 | Precision: 0.5523 | Recall: 0.6704\n",
      "Epoch 05 | Training Loss: 0.6797 | Val Loss: 0.6771 | Accuracy: 0.5792 | Precision: 0.5561 | Recall: 0.6547\n",
      "Epoch 06 | Training Loss: 0.6777 | Val Loss: 0.6768 | Accuracy: 0.5790 | Precision: 0.5505 | Recall: 0.7174\n",
      "Epoch 07 | Training Loss: 0.6762 | Val Loss: 0.6748 | Accuracy: 0.5850 | Precision: 0.5583 | Recall: 0.6889\n",
      "Epoch 08 | Training Loss: 0.6747 | Val Loss: 0.6728 | Accuracy: 0.5834 | Precision: 0.5629 | Recall: 0.6295\n",
      "Epoch 09 | Training Loss: 0.6736 | Val Loss: 0.6723 | Accuracy: 0.5876 | Precision: 0.5625 | Recall: 0.6720\n",
      "Epoch 10 | Training Loss: 0.6724 | Val Loss: 0.6709 | Accuracy: 0.5888 | Precision: 0.5676 | Recall: 0.6374\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7070 | Test Accuracy: 0.5923 | Test Precision: 0.5840 | Test Recall: 0.6417\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6951 | Val Loss: 0.6911 | Accuracy: 0.5278 | Precision: 0.5112 | Recall: 0.5908\n",
      "Epoch 02 | Training Loss: 0.6891 | Val Loss: 0.6867 | Accuracy: 0.5448 | Precision: 0.5261 | Recall: 0.6143\n",
      "Epoch 03 | Training Loss: 0.6852 | Val Loss: 0.6835 | Accuracy: 0.5522 | Precision: 0.5321 | Recall: 0.6333\n",
      "Epoch 04 | Training Loss: 0.6820 | Val Loss: 0.6801 | Accuracy: 0.5692 | Precision: 0.5529 | Recall: 0.5817\n",
      "Epoch 05 | Training Loss: 0.6794 | Val Loss: 0.6778 | Accuracy: 0.5736 | Precision: 0.5569 | Recall: 0.5895\n",
      "Epoch 06 | Training Loss: 0.6773 | Val Loss: 0.6760 | Accuracy: 0.5774 | Precision: 0.5566 | Recall: 0.6304\n",
      "Epoch 07 | Training Loss: 0.6752 | Val Loss: 0.6750 | Accuracy: 0.5818 | Precision: 0.5566 | Recall: 0.6753\n",
      "Epoch 08 | Training Loss: 0.6738 | Val Loss: 0.6735 | Accuracy: 0.5836 | Precision: 0.5588 | Recall: 0.6708\n",
      "Epoch 09 | Training Loss: 0.6724 | Val Loss: 0.6720 | Accuracy: 0.5854 | Precision: 0.5622 | Recall: 0.6543\n",
      "Epoch 10 | Training Loss: 0.6713 | Val Loss: 0.6709 | Accuracy: 0.5860 | Precision: 0.5632 | Recall: 0.6506\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6874 | Test Accuracy: 0.5892 | Test Precision: 0.5781 | Test Recall: 0.6602\n",
      "\n",
      "Training for parameter combination:  51, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6745 | Val Loss: 0.6673 | Accuracy: 0.5942 | Precision: 0.5901 | Recall: 0.5338\n",
      "Epoch 02 | Training Loss: 0.6638 | Val Loss: 0.6643 | Accuracy: 0.5954 | Precision: 0.5655 | Recall: 0.7137\n",
      "Epoch 03 | Training Loss: 0.6581 | Val Loss: 0.6650 | Accuracy: 0.6028 | Precision: 0.6060 | Recall: 0.5165\n",
      "Epoch 04 | Training Loss: 0.6559 | Val Loss: 0.6617 | Accuracy: 0.6044 | Precision: 0.5806 | Recall: 0.6625\n",
      "Epoch 05 | Training Loss: 0.6526 | Val Loss: 0.6615 | Accuracy: 0.6082 | Precision: 0.5988 | Recall: 0.5813\n",
      "Epoch 06 | Training Loss: 0.6495 | Val Loss: 0.6630 | Accuracy: 0.5992 | Precision: 0.5766 | Recall: 0.6518\n",
      "Epoch 07 | Training Loss: 0.6491 | Val Loss: 0.6642 | Accuracy: 0.6072 | Precision: 0.5963 | Recall: 0.5875\n",
      "Epoch 08 | Training Loss: 0.6449 | Val Loss: 0.6602 | Accuracy: 0.6058 | Precision: 0.5845 | Recall: 0.6465\n",
      "Epoch 09 | Training Loss: 0.6415 | Val Loss: 0.6645 | Accuracy: 0.6050 | Precision: 0.5904 | Recall: 0.6048\n",
      "Epoch 10 | Training Loss: 0.6405 | Val Loss: 0.6614 | Accuracy: 0.6010 | Precision: 0.5837 | Recall: 0.6172\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6360 | Test Accuracy: 0.6014 | Test Precision: 0.5974 | Test Recall: 0.6222\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6719 | Val Loss: 0.6648 | Accuracy: 0.6042 | Precision: 0.5738 | Recall: 0.7137\n",
      "Epoch 02 | Training Loss: 0.6610 | Val Loss: 0.6625 | Accuracy: 0.6038 | Precision: 0.5734 | Recall: 0.7137\n",
      "Epoch 03 | Training Loss: 0.6585 | Val Loss: 0.6606 | Accuracy: 0.6066 | Precision: 0.5840 | Recall: 0.6555\n",
      "Epoch 04 | Training Loss: 0.6549 | Val Loss: 0.6608 | Accuracy: 0.6038 | Precision: 0.5905 | Recall: 0.5961\n",
      "Epoch 05 | Training Loss: 0.6523 | Val Loss: 0.6600 | Accuracy: 0.6024 | Precision: 0.5719 | Recall: 0.7153\n",
      "Epoch 06 | Training Loss: 0.6500 | Val Loss: 0.6583 | Accuracy: 0.6038 | Precision: 0.5802 | Recall: 0.6609\n",
      "Epoch 07 | Training Loss: 0.6477 | Val Loss: 0.6592 | Accuracy: 0.6044 | Precision: 0.5777 | Recall: 0.6840\n",
      "Epoch 08 | Training Loss: 0.6455 | Val Loss: 0.6582 | Accuracy: 0.6054 | Precision: 0.6020 | Recall: 0.5491\n",
      "Epoch 09 | Training Loss: 0.6420 | Val Loss: 0.6601 | Accuracy: 0.6000 | Precision: 0.5998 | Recall: 0.5256\n",
      "Epoch 10 | Training Loss: 0.6377 | Val Loss: 0.6598 | Accuracy: 0.6010 | Precision: 0.5988 | Recall: 0.5363\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6404 | Test Accuracy: 0.6010 | Test Precision: 0.6181 | Test Recall: 0.5286\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6706 | Val Loss: 0.6705 | Accuracy: 0.5868 | Precision: 0.6224 | Recall: 0.3754\n",
      "Epoch 02 | Training Loss: 0.6614 | Val Loss: 0.6606 | Accuracy: 0.6064 | Precision: 0.5848 | Recall: 0.6489\n",
      "Epoch 03 | Training Loss: 0.6563 | Val Loss: 0.6679 | Accuracy: 0.5986 | Precision: 0.5656 | Recall: 0.7417\n",
      "Epoch 04 | Training Loss: 0.6542 | Val Loss: 0.6821 | Accuracy: 0.5840 | Precision: 0.5465 | Recall: 0.8346\n",
      "Epoch 05 | Training Loss: 0.6518 | Val Loss: 0.6696 | Accuracy: 0.5908 | Precision: 0.5553 | Recall: 0.7834\n",
      "Epoch 06 | Training Loss: 0.6497 | Val Loss: 0.6599 | Accuracy: 0.6104 | Precision: 0.5905 | Recall: 0.6407\n",
      "Epoch 07 | Training Loss: 0.6457 | Val Loss: 0.6611 | Accuracy: 0.6060 | Precision: 0.5859 | Recall: 0.6390\n",
      "Epoch 08 | Training Loss: 0.6427 | Val Loss: 0.6680 | Accuracy: 0.5992 | Precision: 0.5984 | Recall: 0.5268\n",
      "Epoch 09 | Training Loss: 0.6395 | Val Loss: 0.6637 | Accuracy: 0.6032 | Precision: 0.5977 | Recall: 0.5553\n",
      "Epoch 10 | Training Loss: 0.6409 | Val Loss: 0.6626 | Accuracy: 0.6044 | Precision: 0.5782 | Recall: 0.6799\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6331 | Test Accuracy: 0.6063 | Test Precision: 0.5934 | Test Recall: 0.6756\n",
      "\n",
      "Training for parameter combination:  52, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6803 | Val Loss: 0.6934 | Accuracy: 0.5570 | Precision: 0.5258 | Recall: 0.8779\n",
      "Epoch 02 | Training Loss: 0.6660 | Val Loss: 0.6762 | Accuracy: 0.5892 | Precision: 0.5530 | Recall: 0.7966\n",
      "Epoch 03 | Training Loss: 0.6629 | Val Loss: 0.6646 | Accuracy: 0.6074 | Precision: 0.5800 | Recall: 0.6894\n",
      "Epoch 04 | Training Loss: 0.6616 | Val Loss: 0.6627 | Accuracy: 0.6086 | Precision: 0.5825 | Recall: 0.6799\n",
      "Epoch 05 | Training Loss: 0.6608 | Val Loss: 0.6670 | Accuracy: 0.5878 | Precision: 0.6050 | Recall: 0.4315\n",
      "Epoch 06 | Training Loss: 0.6597 | Val Loss: 0.6662 | Accuracy: 0.6006 | Precision: 0.5676 | Recall: 0.7397\n",
      "Epoch 07 | Training Loss: 0.6589 | Val Loss: 0.6615 | Accuracy: 0.6082 | Precision: 0.5881 | Recall: 0.6403\n",
      "Epoch 08 | Training Loss: 0.6575 | Val Loss: 0.6635 | Accuracy: 0.6028 | Precision: 0.6098 | Recall: 0.5017\n",
      "Epoch 09 | Training Loss: 0.6573 | Val Loss: 0.6702 | Accuracy: 0.5942 | Precision: 0.5589 | Recall: 0.7731\n",
      "Epoch 10 | Training Loss: 0.6567 | Val Loss: 0.6609 | Accuracy: 0.6098 | Precision: 0.5914 | Recall: 0.6312\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6423 | Test Accuracy: 0.6098 | Test Precision: 0.6055 | Test Recall: 0.6306\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6793 | Val Loss: 0.6770 | Accuracy: 0.5812 | Precision: 0.5453 | Recall: 0.8193\n",
      "Epoch 02 | Training Loss: 0.6660 | Val Loss: 0.6828 | Accuracy: 0.5752 | Precision: 0.5400 | Recall: 0.8354\n",
      "Epoch 03 | Training Loss: 0.6626 | Val Loss: 0.6619 | Accuracy: 0.6062 | Precision: 0.5890 | Recall: 0.6213\n",
      "Epoch 04 | Training Loss: 0.6614 | Val Loss: 0.6762 | Accuracy: 0.5852 | Precision: 0.5496 | Recall: 0.8003\n",
      "Epoch 05 | Training Loss: 0.6606 | Val Loss: 0.6698 | Accuracy: 0.5944 | Precision: 0.5594 | Recall: 0.7694\n",
      "Epoch 06 | Training Loss: 0.6596 | Val Loss: 0.6706 | Accuracy: 0.5914 | Precision: 0.5563 | Recall: 0.7764\n",
      "Epoch 07 | Training Loss: 0.6589 | Val Loss: 0.6701 | Accuracy: 0.5944 | Precision: 0.5588 | Recall: 0.7764\n",
      "Epoch 08 | Training Loss: 0.6587 | Val Loss: 0.6650 | Accuracy: 0.6040 | Precision: 0.6155 | Recall: 0.4880\n",
      "Epoch 09 | Training Loss: 0.6572 | Val Loss: 0.6711 | Accuracy: 0.5902 | Precision: 0.5556 | Recall: 0.7727\n",
      "Epoch 10 | Training Loss: 0.6565 | Val Loss: 0.6812 | Accuracy: 0.5814 | Precision: 0.5457 | Recall: 0.8160\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6529 | Test Accuracy: 0.5907 | Test Precision: 0.5615 | Test Recall: 0.8289\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6756 | Val Loss: 0.6746 | Accuracy: 0.5738 | Precision: 0.6284 | Recall: 0.2958\n",
      "Epoch 02 | Training Loss: 0.6639 | Val Loss: 0.6627 | Accuracy: 0.6128 | Precision: 0.5889 | Recall: 0.6667\n",
      "Epoch 03 | Training Loss: 0.6627 | Val Loss: 0.6749 | Accuracy: 0.5840 | Precision: 0.5489 | Recall: 0.7958\n",
      "Epoch 04 | Training Loss: 0.6611 | Val Loss: 0.6802 | Accuracy: 0.5822 | Precision: 0.5456 | Recall: 0.8276\n",
      "Epoch 05 | Training Loss: 0.6608 | Val Loss: 0.6707 | Accuracy: 0.5934 | Precision: 0.5573 | Recall: 0.7838\n",
      "Epoch 06 | Training Loss: 0.6596 | Val Loss: 0.6616 | Accuracy: 0.6082 | Precision: 0.5814 | Recall: 0.6852\n",
      "Epoch 07 | Training Loss: 0.6596 | Val Loss: 0.6610 | Accuracy: 0.6122 | Precision: 0.6018 | Recall: 0.5916\n",
      "Epoch 08 | Training Loss: 0.6594 | Val Loss: 0.6700 | Accuracy: 0.5912 | Precision: 0.5564 | Recall: 0.7735\n",
      "Epoch 09 | Training Loss: 0.6579 | Val Loss: 0.6678 | Accuracy: 0.5962 | Precision: 0.5613 | Recall: 0.7649\n",
      "Epoch 10 | Training Loss: 0.6575 | Val Loss: 0.6686 | Accuracy: 0.5962 | Precision: 0.5612 | Recall: 0.7665\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6527 | Test Accuracy: 0.6019 | Test Precision: 0.5754 | Test Recall: 0.7774\n",
      "\n",
      "Training for parameter combination:  53, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6772 | Val Loss: 0.6906 | Accuracy: 0.5586 | Precision: 0.5271 | Recall: 0.8721\n",
      "Epoch 02 | Training Loss: 0.6631 | Val Loss: 0.6763 | Accuracy: 0.5878 | Precision: 0.5544 | Recall: 0.7628\n",
      "Epoch 03 | Training Loss: 0.6560 | Val Loss: 0.7000 | Accuracy: 0.5706 | Precision: 0.5354 | Recall: 0.8630\n",
      "Epoch 04 | Training Loss: 0.6518 | Val Loss: 0.6627 | Accuracy: 0.6058 | Precision: 0.5805 | Recall: 0.6741\n",
      "Epoch 05 | Training Loss: 0.6473 | Val Loss: 0.6623 | Accuracy: 0.6060 | Precision: 0.5827 | Recall: 0.6597\n",
      "Epoch 06 | Training Loss: 0.6420 | Val Loss: 0.6641 | Accuracy: 0.5976 | Precision: 0.5673 | Recall: 0.7162\n",
      "Epoch 07 | Training Loss: 0.6367 | Val Loss: 0.6729 | Accuracy: 0.6024 | Precision: 0.5702 | Recall: 0.7302\n",
      "Epoch 08 | Training Loss: 0.6297 | Val Loss: 0.6666 | Accuracy: 0.6004 | Precision: 0.5864 | Recall: 0.5965\n",
      "Epoch 09 | Training Loss: 0.6241 | Val Loss: 0.6692 | Accuracy: 0.5996 | Precision: 0.5775 | Recall: 0.6489\n",
      "Epoch 10 | Training Loss: 0.6148 | Val Loss: 0.6823 | Accuracy: 0.5932 | Precision: 0.5679 | Recall: 0.6729\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6768 | Test Accuracy: 0.5974 | Test Precision: 0.5854 | Test Recall: 0.6676\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6800 | Val Loss: 0.6642 | Accuracy: 0.5970 | Precision: 0.5759 | Recall: 0.6403\n",
      "Epoch 02 | Training Loss: 0.6611 | Val Loss: 0.6658 | Accuracy: 0.6060 | Precision: 0.5728 | Recall: 0.7368\n",
      "Epoch 03 | Training Loss: 0.6554 | Val Loss: 0.6840 | Accuracy: 0.5760 | Precision: 0.5405 | Recall: 0.8366\n",
      "Epoch 04 | Training Loss: 0.6503 | Val Loss: 0.6615 | Accuracy: 0.6056 | Precision: 0.5785 | Recall: 0.6869\n",
      "Epoch 05 | Training Loss: 0.6455 | Val Loss: 0.6597 | Accuracy: 0.6098 | Precision: 0.5896 | Recall: 0.6419\n",
      "Epoch 06 | Training Loss: 0.6395 | Val Loss: 0.6661 | Accuracy: 0.6000 | Precision: 0.5669 | Recall: 0.7409\n",
      "Epoch 07 | Training Loss: 0.6339 | Val Loss: 0.6679 | Accuracy: 0.5966 | Precision: 0.5688 | Recall: 0.6939\n",
      "Epoch 08 | Training Loss: 0.6273 | Val Loss: 0.6860 | Accuracy: 0.5814 | Precision: 0.5477 | Recall: 0.7847\n",
      "Epoch 09 | Training Loss: 0.6201 | Val Loss: 0.6669 | Accuracy: 0.6014 | Precision: 0.5906 | Recall: 0.5796\n",
      "Epoch 10 | Training Loss: 0.6117 | Val Loss: 0.6850 | Accuracy: 0.5902 | Precision: 0.5611 | Recall: 0.7108\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6786 | Test Accuracy: 0.5978 | Test Precision: 0.5803 | Test Recall: 0.7064\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6779 | Val Loss: 0.6666 | Accuracy: 0.5968 | Precision: 0.5660 | Recall: 0.7219\n",
      "Epoch 02 | Training Loss: 0.6634 | Val Loss: 0.6647 | Accuracy: 0.5970 | Precision: 0.5945 | Recall: 0.5305\n",
      "Epoch 03 | Training Loss: 0.6582 | Val Loss: 0.6624 | Accuracy: 0.6014 | Precision: 0.5742 | Recall: 0.6877\n",
      "Epoch 04 | Training Loss: 0.6520 | Val Loss: 0.6654 | Accuracy: 0.5986 | Precision: 0.5698 | Recall: 0.7026\n",
      "Epoch 05 | Training Loss: 0.6471 | Val Loss: 0.6598 | Accuracy: 0.6014 | Precision: 0.5764 | Recall: 0.6704\n",
      "Epoch 06 | Training Loss: 0.6433 | Val Loss: 0.6784 | Accuracy: 0.5910 | Precision: 0.5538 | Recall: 0.8053\n",
      "Epoch 07 | Training Loss: 0.6377 | Val Loss: 0.6618 | Accuracy: 0.5982 | Precision: 0.5920 | Recall: 0.5507\n",
      "Epoch 08 | Training Loss: 0.6327 | Val Loss: 0.6632 | Accuracy: 0.6028 | Precision: 0.5880 | Recall: 0.6040\n",
      "Epoch 09 | Training Loss: 0.6250 | Val Loss: 0.6756 | Accuracy: 0.5954 | Precision: 0.5626 | Recall: 0.7430\n",
      "Epoch 10 | Training Loss: 0.6177 | Val Loss: 0.6820 | Accuracy: 0.5934 | Precision: 0.5904 | Recall: 0.5268\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7194 | Test Accuracy: 0.5973 | Test Precision: 0.6108 | Test Recall: 0.5362\n",
      "\n",
      "Training for parameter combination:  54, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6776 | Val Loss: 0.6786 | Accuracy: 0.5792 | Precision: 0.5446 | Recall: 0.8057\n",
      "Epoch 02 | Training Loss: 0.6655 | Val Loss: 0.6652 | Accuracy: 0.6052 | Precision: 0.5958 | Recall: 0.5771\n",
      "Epoch 03 | Training Loss: 0.6625 | Val Loss: 0.6648 | Accuracy: 0.6052 | Precision: 0.5777 | Recall: 0.6898\n",
      "Epoch 04 | Training Loss: 0.6609 | Val Loss: 0.6684 | Accuracy: 0.5946 | Precision: 0.5615 | Recall: 0.7475\n",
      "Epoch 05 | Training Loss: 0.6595 | Val Loss: 0.6623 | Accuracy: 0.6074 | Precision: 0.5896 | Recall: 0.6258\n",
      "Epoch 06 | Training Loss: 0.6581 | Val Loss: 0.6627 | Accuracy: 0.6076 | Precision: 0.5796 | Recall: 0.6939\n",
      "Epoch 07 | Training Loss: 0.6572 | Val Loss: 0.6680 | Accuracy: 0.5942 | Precision: 0.5609 | Recall: 0.7500\n",
      "Epoch 08 | Training Loss: 0.6569 | Val Loss: 0.6620 | Accuracy: 0.6096 | Precision: 0.5987 | Recall: 0.5908\n",
      "Epoch 09 | Training Loss: 0.6558 | Val Loss: 0.6648 | Accuracy: 0.5982 | Precision: 0.5685 | Recall: 0.7104\n",
      "Epoch 10 | Training Loss: 0.6547 | Val Loss: 0.6660 | Accuracy: 0.6016 | Precision: 0.5688 | Recall: 0.7364\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6758 | Test Accuracy: 0.6026 | Test Precision: 0.5805 | Test Recall: 0.7402\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6783 | Val Loss: 0.6658 | Accuracy: 0.6006 | Precision: 0.5748 | Recall: 0.6766\n",
      "Epoch 02 | Training Loss: 0.6637 | Val Loss: 0.6658 | Accuracy: 0.6048 | Precision: 0.5722 | Recall: 0.7323\n",
      "Epoch 03 | Training Loss: 0.6607 | Val Loss: 0.6620 | Accuracy: 0.6052 | Precision: 0.5919 | Recall: 0.5978\n",
      "Epoch 04 | Training Loss: 0.6599 | Val Loss: 0.6716 | Accuracy: 0.5920 | Precision: 0.5575 | Recall: 0.7686\n",
      "Epoch 05 | Training Loss: 0.6584 | Val Loss: 0.6700 | Accuracy: 0.5972 | Precision: 0.5617 | Recall: 0.7698\n",
      "Epoch 06 | Training Loss: 0.6578 | Val Loss: 0.6614 | Accuracy: 0.6078 | Precision: 0.5853 | Recall: 0.6555\n",
      "Epoch 07 | Training Loss: 0.6570 | Val Loss: 0.6609 | Accuracy: 0.6052 | Precision: 0.5828 | Recall: 0.6535\n",
      "Epoch 08 | Training Loss: 0.6560 | Val Loss: 0.6629 | Accuracy: 0.6018 | Precision: 0.6024 | Recall: 0.5256\n",
      "Epoch 09 | Training Loss: 0.6545 | Val Loss: 0.6640 | Accuracy: 0.6036 | Precision: 0.5713 | Recall: 0.7306\n",
      "Epoch 10 | Training Loss: 0.6538 | Val Loss: 0.6637 | Accuracy: 0.6016 | Precision: 0.6113 | Recall: 0.4893\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6998 | Test Accuracy: 0.5996 | Test Precision: 0.6268 | Test Recall: 0.4921\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6796 | Val Loss: 0.6744 | Accuracy: 0.5870 | Precision: 0.5517 | Recall: 0.7904\n",
      "Epoch 02 | Training Loss: 0.6643 | Val Loss: 0.6714 | Accuracy: 0.5946 | Precision: 0.5582 | Recall: 0.7855\n",
      "Epoch 03 | Training Loss: 0.6620 | Val Loss: 0.6612 | Accuracy: 0.6064 | Precision: 0.5862 | Recall: 0.6399\n",
      "Epoch 04 | Training Loss: 0.6604 | Val Loss: 0.6616 | Accuracy: 0.6064 | Precision: 0.5793 | Recall: 0.6873\n",
      "Epoch 05 | Training Loss: 0.6594 | Val Loss: 0.6616 | Accuracy: 0.6088 | Precision: 0.5826 | Recall: 0.6807\n",
      "Epoch 06 | Training Loss: 0.6582 | Val Loss: 0.6611 | Accuracy: 0.6064 | Precision: 0.5918 | Recall: 0.6064\n",
      "Epoch 07 | Training Loss: 0.6570 | Val Loss: 0.6602 | Accuracy: 0.6100 | Precision: 0.5896 | Recall: 0.6432\n",
      "Epoch 08 | Training Loss: 0.6559 | Val Loss: 0.6633 | Accuracy: 0.6054 | Precision: 0.6229 | Recall: 0.4715\n",
      "Epoch 09 | Training Loss: 0.6551 | Val Loss: 0.6646 | Accuracy: 0.6018 | Precision: 0.6265 | Recall: 0.4422\n",
      "Epoch 10 | Training Loss: 0.6541 | Val Loss: 0.6603 | Accuracy: 0.6104 | Precision: 0.5988 | Recall: 0.5953\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7079 | Test Accuracy: 0.6065 | Test Precision: 0.6101 | Test Recall: 0.5904\n",
      "\n",
      "Training for parameter combination:  55, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7006 | Val Loss: 0.6737 | Accuracy: 0.5828 | Precision: 0.6136 | Recall: 0.3767\n",
      "Epoch 02 | Training Loss: 0.6652 | Val Loss: 0.6651 | Accuracy: 0.5980 | Precision: 0.5701 | Recall: 0.6947\n",
      "Epoch 03 | Training Loss: 0.6601 | Val Loss: 0.6623 | Accuracy: 0.6066 | Precision: 0.5901 | Recall: 0.6176\n",
      "Epoch 04 | Training Loss: 0.6568 | Val Loss: 0.6624 | Accuracy: 0.6064 | Precision: 0.5892 | Recall: 0.6213\n",
      "Epoch 05 | Training Loss: 0.6551 | Val Loss: 0.6633 | Accuracy: 0.6006 | Precision: 0.5712 | Recall: 0.7063\n",
      "Epoch 06 | Training Loss: 0.6512 | Val Loss: 0.6611 | Accuracy: 0.6024 | Precision: 0.5816 | Recall: 0.6411\n",
      "Epoch 07 | Training Loss: 0.6490 | Val Loss: 0.6608 | Accuracy: 0.6016 | Precision: 0.5786 | Recall: 0.6559\n",
      "Epoch 08 | Training Loss: 0.6468 | Val Loss: 0.6611 | Accuracy: 0.6050 | Precision: 0.5796 | Recall: 0.6741\n",
      "Epoch 09 | Training Loss: 0.6448 | Val Loss: 0.6605 | Accuracy: 0.6026 | Precision: 0.5796 | Recall: 0.6564\n",
      "Epoch 10 | Training Loss: 0.6445 | Val Loss: 0.6609 | Accuracy: 0.6072 | Precision: 0.5818 | Recall: 0.6749\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6357 | Test Accuracy: 0.6072 | Test Precision: 0.5939 | Test Recall: 0.6783\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6823 | Val Loss: 0.6690 | Accuracy: 0.5964 | Precision: 0.5749 | Recall: 0.6427\n",
      "Epoch 02 | Training Loss: 0.6627 | Val Loss: 0.6643 | Accuracy: 0.6086 | Precision: 0.5970 | Recall: 0.5928\n",
      "Epoch 03 | Training Loss: 0.6578 | Val Loss: 0.6617 | Accuracy: 0.6112 | Precision: 0.5982 | Recall: 0.6031\n",
      "Epoch 04 | Training Loss: 0.6553 | Val Loss: 0.6681 | Accuracy: 0.5956 | Precision: 0.5628 | Recall: 0.7434\n",
      "Epoch 05 | Training Loss: 0.6533 | Val Loss: 0.6755 | Accuracy: 0.5858 | Precision: 0.5496 | Recall: 0.8065\n",
      "Epoch 06 | Training Loss: 0.6505 | Val Loss: 0.6606 | Accuracy: 0.6138 | Precision: 0.5985 | Recall: 0.6180\n",
      "Epoch 07 | Training Loss: 0.6481 | Val Loss: 0.6615 | Accuracy: 0.6082 | Precision: 0.6102 | Recall: 0.5309\n",
      "Epoch 08 | Training Loss: 0.6457 | Val Loss: 0.6621 | Accuracy: 0.6060 | Precision: 0.5779 | Recall: 0.6947\n",
      "Epoch 09 | Training Loss: 0.6437 | Val Loss: 0.6593 | Accuracy: 0.6138 | Precision: 0.6003 | Recall: 0.6085\n",
      "Epoch 10 | Training Loss: 0.6422 | Val Loss: 0.6607 | Accuracy: 0.6090 | Precision: 0.6129 | Recall: 0.5252\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6442 | Test Accuracy: 0.6008 | Test Precision: 0.6193 | Test Recall: 0.5234\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6909 | Val Loss: 0.6721 | Accuracy: 0.5818 | Precision: 0.5641 | Recall: 0.6048\n",
      "Epoch 02 | Training Loss: 0.6672 | Val Loss: 0.6709 | Accuracy: 0.5906 | Precision: 0.6054 | Recall: 0.4468\n",
      "Epoch 03 | Training Loss: 0.6639 | Val Loss: 0.6650 | Accuracy: 0.6020 | Precision: 0.5766 | Recall: 0.6741\n",
      "Epoch 04 | Training Loss: 0.6581 | Val Loss: 0.6634 | Accuracy: 0.6010 | Precision: 0.5841 | Recall: 0.6147\n",
      "Epoch 05 | Training Loss: 0.6578 | Val Loss: 0.6665 | Accuracy: 0.6030 | Precision: 0.5715 | Recall: 0.7236\n",
      "Epoch 06 | Training Loss: 0.6561 | Val Loss: 0.6642 | Accuracy: 0.6030 | Precision: 0.5760 | Recall: 0.6861\n",
      "Epoch 07 | Training Loss: 0.6528 | Val Loss: 0.6624 | Accuracy: 0.6020 | Precision: 0.5811 | Recall: 0.6415\n",
      "Epoch 08 | Training Loss: 0.6514 | Val Loss: 0.6624 | Accuracy: 0.6082 | Precision: 0.5882 | Recall: 0.6394\n",
      "Epoch 09 | Training Loss: 0.6491 | Val Loss: 0.6634 | Accuracy: 0.6046 | Precision: 0.5805 | Recall: 0.6650\n",
      "Epoch 10 | Training Loss: 0.6472 | Val Loss: 0.6624 | Accuracy: 0.6044 | Precision: 0.5828 | Recall: 0.6477\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6428 | Test Accuracy: 0.6070 | Test Precision: 0.5991 | Test Recall: 0.6469\n",
      "\n",
      "Training for parameter combination:  56, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6736 | Val Loss: 0.6645 | Accuracy: 0.6074 | Precision: 0.5848 | Recall: 0.6559\n",
      "Epoch 02 | Training Loss: 0.6633 | Val Loss: 0.6778 | Accuracy: 0.5842 | Precision: 0.5489 | Recall: 0.7987\n",
      "Epoch 03 | Training Loss: 0.6605 | Val Loss: 0.6629 | Accuracy: 0.6034 | Precision: 0.6002 | Recall: 0.5450\n",
      "Epoch 04 | Training Loss: 0.6584 | Val Loss: 0.6621 | Accuracy: 0.6010 | Precision: 0.5789 | Recall: 0.6489\n",
      "Epoch 05 | Training Loss: 0.6571 | Val Loss: 0.6618 | Accuracy: 0.5978 | Precision: 0.5736 | Recall: 0.6642\n",
      "Epoch 06 | Training Loss: 0.6540 | Val Loss: 0.6616 | Accuracy: 0.6044 | Precision: 0.5826 | Recall: 0.6489\n",
      "Epoch 07 | Training Loss: 0.6507 | Val Loss: 0.6602 | Accuracy: 0.6052 | Precision: 0.5960 | Recall: 0.5763\n",
      "Epoch 08 | Training Loss: 0.6491 | Val Loss: 0.6630 | Accuracy: 0.5988 | Precision: 0.5739 | Recall: 0.6700\n",
      "Epoch 09 | Training Loss: 0.6476 | Val Loss: 0.6628 | Accuracy: 0.6018 | Precision: 0.5731 | Recall: 0.7005\n",
      "Epoch 10 | Training Loss: 0.6439 | Val Loss: 0.6611 | Accuracy: 0.6058 | Precision: 0.5779 | Recall: 0.6931\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6418 | Test Accuracy: 0.6065 | Test Precision: 0.5904 | Test Recall: 0.6960\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6726 | Val Loss: 0.6638 | Accuracy: 0.6046 | Precision: 0.5889 | Recall: 0.6106\n",
      "Epoch 02 | Training Loss: 0.6637 | Val Loss: 0.6637 | Accuracy: 0.5998 | Precision: 0.5712 | Recall: 0.7001\n",
      "Epoch 03 | Training Loss: 0.6608 | Val Loss: 0.6618 | Accuracy: 0.6006 | Precision: 0.5719 | Recall: 0.7009\n",
      "Epoch 04 | Training Loss: 0.6569 | Val Loss: 0.6620 | Accuracy: 0.6066 | Precision: 0.5779 | Recall: 0.6997\n",
      "Epoch 05 | Training Loss: 0.6552 | Val Loss: 0.6628 | Accuracy: 0.6010 | Precision: 0.5699 | Recall: 0.7211\n",
      "Epoch 06 | Training Loss: 0.6519 | Val Loss: 0.6596 | Accuracy: 0.6088 | Precision: 0.5871 | Recall: 0.6506\n",
      "Epoch 07 | Training Loss: 0.6503 | Val Loss: 0.6602 | Accuracy: 0.6082 | Precision: 0.6081 | Recall: 0.5396\n",
      "Epoch 08 | Training Loss: 0.6464 | Val Loss: 0.6649 | Accuracy: 0.6068 | Precision: 0.5814 | Recall: 0.6745\n",
      "Epoch 09 | Training Loss: 0.6434 | Val Loss: 0.6660 | Accuracy: 0.6010 | Precision: 0.5661 | Recall: 0.7574\n",
      "Epoch 10 | Training Loss: 0.6420 | Val Loss: 0.6576 | Accuracy: 0.6066 | Precision: 0.5956 | Recall: 0.5870\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6288 | Test Accuracy: 0.6038 | Test Precision: 0.6081 | Test Recall: 0.5842\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6755 | Val Loss: 0.6673 | Accuracy: 0.5906 | Precision: 0.6172 | Recall: 0.4097\n",
      "Epoch 02 | Training Loss: 0.6642 | Val Loss: 0.6720 | Accuracy: 0.5942 | Precision: 0.5599 | Recall: 0.7620\n",
      "Epoch 03 | Training Loss: 0.6616 | Val Loss: 0.6634 | Accuracy: 0.5968 | Precision: 0.5674 | Recall: 0.7087\n",
      "Epoch 04 | Training Loss: 0.6568 | Val Loss: 0.6615 | Accuracy: 0.6008 | Precision: 0.5961 | Recall: 0.5474\n",
      "Epoch 05 | Training Loss: 0.6553 | Val Loss: 0.6647 | Accuracy: 0.6030 | Precision: 0.6050 | Recall: 0.5219\n",
      "Epoch 06 | Training Loss: 0.6538 | Val Loss: 0.6641 | Accuracy: 0.6008 | Precision: 0.6158 | Recall: 0.4695\n",
      "Epoch 07 | Training Loss: 0.6513 | Val Loss: 0.6687 | Accuracy: 0.6030 | Precision: 0.5664 | Recall: 0.7727\n",
      "Epoch 08 | Training Loss: 0.6478 | Val Loss: 0.6606 | Accuracy: 0.6018 | Precision: 0.5736 | Recall: 0.6964\n",
      "Epoch 09 | Training Loss: 0.6449 | Val Loss: 0.6579 | Accuracy: 0.6054 | Precision: 0.6024 | Recall: 0.5474\n",
      "Epoch 10 | Training Loss: 0.6422 | Val Loss: 0.6580 | Accuracy: 0.6034 | Precision: 0.5947 | Recall: 0.5714\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6323 | Test Accuracy: 0.6057 | Test Precision: 0.6119 | Test Recall: 0.5780\n",
      "\n",
      "Training for parameter combination:  57, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7571 | Val Loss: 0.6893 | Accuracy: 0.5668 | Precision: 0.5410 | Recall: 0.7017\n",
      "Epoch 02 | Training Loss: 0.6890 | Val Loss: 0.6847 | Accuracy: 0.5848 | Precision: 0.5792 | Recall: 0.5248\n",
      "Epoch 03 | Training Loss: 0.6765 | Val Loss: 0.6778 | Accuracy: 0.5820 | Precision: 0.5540 | Recall: 0.7063\n",
      "Epoch 04 | Training Loss: 0.6693 | Val Loss: 0.6845 | Accuracy: 0.5800 | Precision: 0.5605 | Recall: 0.6192\n",
      "Epoch 05 | Training Loss: 0.6639 | Val Loss: 0.6681 | Accuracy: 0.5970 | Precision: 0.5697 | Recall: 0.6898\n",
      "Epoch 06 | Training Loss: 0.6585 | Val Loss: 0.6708 | Accuracy: 0.6014 | Precision: 0.5726 | Recall: 0.7009\n",
      "Epoch 07 | Training Loss: 0.6543 | Val Loss: 0.6716 | Accuracy: 0.6056 | Precision: 0.5852 | Recall: 0.6407\n",
      "Epoch 08 | Training Loss: 0.6483 | Val Loss: 0.6706 | Accuracy: 0.5886 | Precision: 0.6009 | Recall: 0.4509\n",
      "Epoch 09 | Training Loss: 0.6446 | Val Loss: 0.6747 | Accuracy: 0.5904 | Precision: 0.5998 | Recall: 0.4662\n",
      "Epoch 10 | Training Loss: 0.6424 | Val Loss: 0.6736 | Accuracy: 0.5990 | Precision: 0.5789 | Recall: 0.6341\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6785 | Test Accuracy: 0.6023 | Test Precision: 0.5958 | Test Recall: 0.6362\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7375 | Val Loss: 0.7278 | Accuracy: 0.5504 | Precision: 0.6137 | Recall: 0.1960\n",
      "Epoch 02 | Training Loss: 0.6875 | Val Loss: 0.6711 | Accuracy: 0.5908 | Precision: 0.5720 | Recall: 0.6192\n",
      "Epoch 03 | Training Loss: 0.6750 | Val Loss: 0.7215 | Accuracy: 0.5740 | Precision: 0.5382 | Recall: 0.8544\n",
      "Epoch 04 | Training Loss: 0.6668 | Val Loss: 0.6919 | Accuracy: 0.5840 | Precision: 0.6162 | Recall: 0.3762\n",
      "Epoch 05 | Training Loss: 0.6604 | Val Loss: 0.6688 | Accuracy: 0.6000 | Precision: 0.5872 | Recall: 0.5887\n",
      "Epoch 06 | Training Loss: 0.6562 | Val Loss: 0.6691 | Accuracy: 0.6028 | Precision: 0.5910 | Recall: 0.5866\n",
      "Epoch 07 | Training Loss: 0.6521 | Val Loss: 0.6752 | Accuracy: 0.5856 | Precision: 0.5898 | Recall: 0.4769\n",
      "Epoch 08 | Training Loss: 0.6471 | Val Loss: 0.6717 | Accuracy: 0.5910 | Precision: 0.5823 | Recall: 0.5532\n",
      "Epoch 09 | Training Loss: 0.6431 | Val Loss: 0.6771 | Accuracy: 0.5928 | Precision: 0.5732 | Recall: 0.6267\n",
      "Epoch 10 | Training Loss: 0.6411 | Val Loss: 0.6753 | Accuracy: 0.5904 | Precision: 0.5663 | Recall: 0.6621\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6655 | Test Accuracy: 0.6022 | Test Precision: 0.5892 | Test Recall: 0.6750\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7489 | Val Loss: 0.6791 | Accuracy: 0.5834 | Precision: 0.5681 | Recall: 0.5866\n",
      "Epoch 02 | Training Loss: 0.6854 | Val Loss: 0.6997 | Accuracy: 0.5600 | Precision: 0.5756 | Recall: 0.3519\n",
      "Epoch 03 | Training Loss: 0.6737 | Val Loss: 0.7082 | Accuracy: 0.5668 | Precision: 0.6013 | Recall: 0.3160\n",
      "Epoch 04 | Training Loss: 0.6654 | Val Loss: 0.6721 | Accuracy: 0.5922 | Precision: 0.5628 | Recall: 0.7120\n",
      "Epoch 05 | Training Loss: 0.6591 | Val Loss: 0.6690 | Accuracy: 0.6014 | Precision: 0.5749 | Recall: 0.6828\n",
      "Epoch 06 | Training Loss: 0.6548 | Val Loss: 0.6642 | Accuracy: 0.5948 | Precision: 0.5726 | Recall: 0.6477\n",
      "Epoch 07 | Training Loss: 0.6501 | Val Loss: 0.6886 | Accuracy: 0.5858 | Precision: 0.5507 | Recall: 0.7908\n",
      "Epoch 08 | Training Loss: 0.6463 | Val Loss: 0.6696 | Accuracy: 0.5996 | Precision: 0.5676 | Recall: 0.7306\n",
      "Epoch 09 | Training Loss: 0.6429 | Val Loss: 0.6687 | Accuracy: 0.5884 | Precision: 0.5986 | Recall: 0.4583\n",
      "Epoch 10 | Training Loss: 0.6390 | Val Loss: 0.6720 | Accuracy: 0.5870 | Precision: 0.5574 | Recall: 0.7186\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6508 | Test Accuracy: 0.5852 | Test Precision: 0.5676 | Test Recall: 0.7158\n",
      "\n",
      "Training for parameter combination:  58, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7249 | Val Loss: 0.7097 | Accuracy: 0.4866 | Precision: 0.4705 | Recall: 0.4711\n",
      "Epoch 02 | Training Loss: 0.7091 | Val Loss: 0.7040 | Accuracy: 0.4912 | Precision: 0.4747 | Recall: 0.4645\n",
      "Epoch 03 | Training Loss: 0.7040 | Val Loss: 0.7002 | Accuracy: 0.5020 | Precision: 0.4872 | Recall: 0.5202\n",
      "Epoch 04 | Training Loss: 0.7000 | Val Loss: 0.6969 | Accuracy: 0.5110 | Precision: 0.4960 | Recall: 0.5380\n",
      "Epoch 05 | Training Loss: 0.6968 | Val Loss: 0.6943 | Accuracy: 0.5214 | Precision: 0.5058 | Recall: 0.5553\n",
      "Epoch 06 | Training Loss: 0.6940 | Val Loss: 0.6914 | Accuracy: 0.5310 | Precision: 0.5169 | Recall: 0.4975\n",
      "Epoch 07 | Training Loss: 0.6918 | Val Loss: 0.6900 | Accuracy: 0.5358 | Precision: 0.5193 | Recall: 0.5718\n",
      "Epoch 08 | Training Loss: 0.6898 | Val Loss: 0.6883 | Accuracy: 0.5424 | Precision: 0.5259 | Recall: 0.5693\n",
      "Epoch 09 | Training Loss: 0.6879 | Val Loss: 0.6875 | Accuracy: 0.5436 | Precision: 0.5242 | Recall: 0.6341\n",
      "Epoch 10 | Training Loss: 0.6864 | Val Loss: 0.6856 | Accuracy: 0.5546 | Precision: 0.5367 | Recall: 0.5945\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6735 | Test Accuracy: 0.5512 | Test Precision: 0.5470 | Test Recall: 0.5958\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7012 | Val Loss: 0.6997 | Accuracy: 0.4828 | Precision: 0.4701 | Recall: 0.5252\n",
      "Epoch 02 | Training Loss: 0.6977 | Val Loss: 0.6969 | Accuracy: 0.4968 | Precision: 0.4843 | Recall: 0.5862\n",
      "Epoch 03 | Training Loss: 0.6946 | Val Loss: 0.6935 | Accuracy: 0.5030 | Precision: 0.4882 | Recall: 0.5227\n",
      "Epoch 04 | Training Loss: 0.6920 | Val Loss: 0.6917 | Accuracy: 0.5186 | Precision: 0.5029 | Recall: 0.6134\n",
      "Epoch 05 | Training Loss: 0.6897 | Val Loss: 0.6889 | Accuracy: 0.5348 | Precision: 0.5195 | Recall: 0.5380\n",
      "Epoch 06 | Training Loss: 0.6876 | Val Loss: 0.6872 | Accuracy: 0.5454 | Precision: 0.5287 | Recall: 0.5738\n",
      "Epoch 07 | Training Loss: 0.6858 | Val Loss: 0.6856 | Accuracy: 0.5528 | Precision: 0.5352 | Recall: 0.5895\n",
      "Epoch 08 | Training Loss: 0.6841 | Val Loss: 0.6847 | Accuracy: 0.5564 | Precision: 0.5344 | Recall: 0.6609\n",
      "Epoch 09 | Training Loss: 0.6826 | Val Loss: 0.6829 | Accuracy: 0.5646 | Precision: 0.5451 | Recall: 0.6155\n",
      "Epoch 10 | Training Loss: 0.6812 | Val Loss: 0.6816 | Accuracy: 0.5678 | Precision: 0.5483 | Recall: 0.6155\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6901 | Test Accuracy: 0.5682 | Test Precision: 0.5621 | Test Recall: 0.6172\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7045 | Val Loss: 0.7020 | Accuracy: 0.4886 | Precision: 0.4732 | Recall: 0.4839\n",
      "Epoch 02 | Training Loss: 0.6998 | Val Loss: 0.6991 | Accuracy: 0.4918 | Precision: 0.4768 | Recall: 0.4955\n",
      "Epoch 03 | Training Loss: 0.6967 | Val Loss: 0.6963 | Accuracy: 0.5024 | Precision: 0.4866 | Recall: 0.4777\n",
      "Epoch 04 | Training Loss: 0.6939 | Val Loss: 0.6956 | Accuracy: 0.5058 | Precision: 0.4926 | Recall: 0.6444\n",
      "Epoch 05 | Training Loss: 0.6918 | Val Loss: 0.6922 | Accuracy: 0.5190 | Precision: 0.5036 | Recall: 0.5421\n",
      "Epoch 06 | Training Loss: 0.6897 | Val Loss: 0.6907 | Accuracy: 0.5226 | Precision: 0.5068 | Recall: 0.5718\n",
      "Epoch 07 | Training Loss: 0.6878 | Val Loss: 0.6885 | Accuracy: 0.5346 | Precision: 0.5213 | Recall: 0.4889\n",
      "Epoch 08 | Training Loss: 0.6861 | Val Loss: 0.6872 | Accuracy: 0.5444 | Precision: 0.5297 | Recall: 0.5375\n",
      "Epoch 09 | Training Loss: 0.6846 | Val Loss: 0.6868 | Accuracy: 0.5560 | Precision: 0.5334 | Recall: 0.6724\n",
      "Epoch 10 | Training Loss: 0.6833 | Val Loss: 0.6856 | Accuracy: 0.5646 | Precision: 0.5405 | Recall: 0.6803\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6838 | Test Accuracy: 0.5643 | Test Precision: 0.5529 | Test Recall: 0.6727\n",
      "\n",
      "Training for parameter combination:  59, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7464 | Val Loss: 0.7093 | Accuracy: 0.4980 | Precision: 0.4904 | Recall: 0.9092\n",
      "Epoch 02 | Training Loss: 0.6987 | Val Loss: 0.6956 | Accuracy: 0.5188 | Precision: 0.5028 | Recall: 0.6691\n",
      "Epoch 03 | Training Loss: 0.6949 | Val Loss: 0.6934 | Accuracy: 0.5202 | Precision: 0.5045 | Recall: 0.5780\n",
      "Epoch 04 | Training Loss: 0.6940 | Val Loss: 0.6925 | Accuracy: 0.5216 | Precision: 0.5060 | Recall: 0.5602\n",
      "Epoch 05 | Training Loss: 0.6933 | Val Loss: 0.6917 | Accuracy: 0.5228 | Precision: 0.5072 | Recall: 0.5549\n",
      "Epoch 06 | Training Loss: 0.6927 | Val Loss: 0.6912 | Accuracy: 0.5282 | Precision: 0.5120 | Recall: 0.5710\n",
      "Epoch 07 | Training Loss: 0.6920 | Val Loss: 0.6907 | Accuracy: 0.5324 | Precision: 0.5157 | Recall: 0.5837\n",
      "Epoch 08 | Training Loss: 0.6914 | Val Loss: 0.6901 | Accuracy: 0.5340 | Precision: 0.5170 | Recall: 0.5891\n",
      "Epoch 09 | Training Loss: 0.6907 | Val Loss: 0.6895 | Accuracy: 0.5366 | Precision: 0.5195 | Recall: 0.5870\n",
      "Epoch 10 | Training Loss: 0.6901 | Val Loss: 0.6889 | Accuracy: 0.5378 | Precision: 0.5208 | Recall: 0.5837\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6845 | Test Accuracy: 0.5406 | Test Precision: 0.5376 | Test Recall: 0.5795\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7062 | Val Loss: 0.6971 | Accuracy: 0.5082 | Precision: 0.4890 | Recall: 0.3205\n",
      "Epoch 02 | Training Loss: 0.6974 | Val Loss: 0.6962 | Accuracy: 0.5070 | Precision: 0.4908 | Recall: 0.4526\n",
      "Epoch 03 | Training Loss: 0.6960 | Val Loss: 0.6956 | Accuracy: 0.5092 | Precision: 0.4939 | Recall: 0.4992\n",
      "Epoch 04 | Training Loss: 0.6951 | Val Loss: 0.6948 | Accuracy: 0.5150 | Precision: 0.4998 | Recall: 0.5161\n",
      "Epoch 05 | Training Loss: 0.6942 | Val Loss: 0.6940 | Accuracy: 0.5224 | Precision: 0.5072 | Recall: 0.5223\n",
      "Epoch 06 | Training Loss: 0.6934 | Val Loss: 0.6934 | Accuracy: 0.5248 | Precision: 0.5091 | Recall: 0.5540\n",
      "Epoch 07 | Training Loss: 0.6926 | Val Loss: 0.6927 | Accuracy: 0.5252 | Precision: 0.5095 | Recall: 0.5516\n",
      "Epoch 08 | Training Loss: 0.6919 | Val Loss: 0.6918 | Accuracy: 0.5266 | Precision: 0.5111 | Recall: 0.5400\n",
      "Epoch 09 | Training Loss: 0.6912 | Val Loss: 0.6912 | Accuracy: 0.5302 | Precision: 0.5143 | Recall: 0.5557\n",
      "Epoch 10 | Training Loss: 0.6905 | Val Loss: 0.6906 | Accuracy: 0.5356 | Precision: 0.5191 | Recall: 0.5718\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6973 | Test Accuracy: 0.5333 | Test Precision: 0.5306 | Test Recall: 0.5783\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7148 | Val Loss: 0.7045 | Accuracy: 0.4982 | Precision: 0.4797 | Recall: 0.4138\n",
      "Epoch 02 | Training Loss: 0.7034 | Val Loss: 0.7034 | Accuracy: 0.4926 | Precision: 0.4788 | Recall: 0.5256\n",
      "Epoch 03 | Training Loss: 0.7016 | Val Loss: 0.7023 | Accuracy: 0.4962 | Precision: 0.4831 | Recall: 0.5590\n",
      "Epoch 04 | Training Loss: 0.7002 | Val Loss: 0.7011 | Accuracy: 0.5006 | Precision: 0.4872 | Recall: 0.5751\n",
      "Epoch 05 | Training Loss: 0.6989 | Val Loss: 0.6996 | Accuracy: 0.5070 | Precision: 0.4925 | Recall: 0.5586\n",
      "Epoch 06 | Training Loss: 0.6977 | Val Loss: 0.6985 | Accuracy: 0.5092 | Precision: 0.4947 | Recall: 0.5747\n",
      "Epoch 07 | Training Loss: 0.6966 | Val Loss: 0.6972 | Accuracy: 0.5138 | Precision: 0.4987 | Recall: 0.5689\n",
      "Epoch 08 | Training Loss: 0.6955 | Val Loss: 0.6962 | Accuracy: 0.5170 | Precision: 0.5016 | Recall: 0.5751\n",
      "Epoch 09 | Training Loss: 0.6944 | Val Loss: 0.6953 | Accuracy: 0.5198 | Precision: 0.5040 | Recall: 0.5916\n",
      "Epoch 10 | Training Loss: 0.6935 | Val Loss: 0.6943 | Accuracy: 0.5232 | Precision: 0.5071 | Recall: 0.5912\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6877 | Test Accuracy: 0.5277 | Test Precision: 0.5250 | Test Recall: 0.5803\n",
      "\n",
      "Training for parameter combination:  60, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6994 | Val Loss: 0.7030 | Accuracy: 0.5566 | Precision: 0.5297 | Recall: 0.7620\n",
      "Epoch 02 | Training Loss: 0.6733 | Val Loss: 0.6804 | Accuracy: 0.5860 | Precision: 0.5508 | Recall: 0.7913\n",
      "Epoch 03 | Training Loss: 0.6687 | Val Loss: 0.6654 | Accuracy: 0.5978 | Precision: 0.5884 | Recall: 0.5668\n",
      "Epoch 04 | Training Loss: 0.6654 | Val Loss: 0.6661 | Accuracy: 0.6012 | Precision: 0.5694 | Recall: 0.7273\n",
      "Epoch 05 | Training Loss: 0.6628 | Val Loss: 0.6823 | Accuracy: 0.5672 | Precision: 0.5337 | Recall: 0.8502\n",
      "Epoch 06 | Training Loss: 0.6613 | Val Loss: 0.6696 | Accuracy: 0.5898 | Precision: 0.5549 | Recall: 0.7776\n",
      "Epoch 07 | Training Loss: 0.6585 | Val Loss: 0.6741 | Accuracy: 0.5714 | Precision: 0.6166 | Recall: 0.3065\n",
      "Epoch 08 | Training Loss: 0.6582 | Val Loss: 0.6804 | Accuracy: 0.5828 | Precision: 0.5481 | Recall: 0.7946\n",
      "Epoch 09 | Training Loss: 0.6556 | Val Loss: 0.6637 | Accuracy: 0.6058 | Precision: 0.5836 | Recall: 0.6522\n",
      "Epoch 10 | Training Loss: 0.6544 | Val Loss: 0.6586 | Accuracy: 0.6108 | Precision: 0.5856 | Recall: 0.6745\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6326 | Test Accuracy: 0.6085 | Test Precision: 0.5956 | Test Recall: 0.6761\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.7039 | Val Loss: 0.6923 | Accuracy: 0.5670 | Precision: 0.6172 | Recall: 0.2814\n",
      "Epoch 02 | Training Loss: 0.6736 | Val Loss: 0.6694 | Accuracy: 0.5936 | Precision: 0.5855 | Recall: 0.5536\n",
      "Epoch 03 | Training Loss: 0.6691 | Val Loss: 0.6721 | Accuracy: 0.5866 | Precision: 0.6155 | Recall: 0.3923\n",
      "Epoch 04 | Training Loss: 0.6657 | Val Loss: 0.6754 | Accuracy: 0.5896 | Precision: 0.6158 | Recall: 0.4080\n",
      "Epoch 05 | Training Loss: 0.6625 | Val Loss: 0.6729 | Accuracy: 0.5972 | Precision: 0.5708 | Recall: 0.6815\n",
      "Epoch 06 | Training Loss: 0.6601 | Val Loss: 0.6707 | Accuracy: 0.5950 | Precision: 0.5596 | Recall: 0.7727\n",
      "Epoch 07 | Training Loss: 0.6580 | Val Loss: 0.6622 | Accuracy: 0.6054 | Precision: 0.5863 | Recall: 0.6320\n",
      "Epoch 08 | Training Loss: 0.6561 | Val Loss: 0.6673 | Accuracy: 0.5980 | Precision: 0.5629 | Recall: 0.7640\n",
      "Epoch 09 | Training Loss: 0.6541 | Val Loss: 0.6655 | Accuracy: 0.6002 | Precision: 0.6063 | Recall: 0.5000\n",
      "Epoch 10 | Training Loss: 0.6528 | Val Loss: 0.6715 | Accuracy: 0.5964 | Precision: 0.5681 | Recall: 0.6988\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6382 | Test Accuracy: 0.6066 | Test Precision: 0.5872 | Test Recall: 0.7180\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6997 | Val Loss: 0.6737 | Accuracy: 0.5888 | Precision: 0.5602 | Recall: 0.7059\n",
      "Epoch 02 | Training Loss: 0.6727 | Val Loss: 0.6689 | Accuracy: 0.5940 | Precision: 0.6180 | Recall: 0.4257\n",
      "Epoch 03 | Training Loss: 0.6673 | Val Loss: 0.6778 | Accuracy: 0.5786 | Precision: 0.5440 | Recall: 0.8082\n",
      "Epoch 04 | Training Loss: 0.6653 | Val Loss: 0.6820 | Accuracy: 0.5694 | Precision: 0.5361 | Recall: 0.8292\n",
      "Epoch 05 | Training Loss: 0.6616 | Val Loss: 0.6853 | Accuracy: 0.5874 | Precision: 0.5509 | Recall: 0.8065\n",
      "Epoch 06 | Training Loss: 0.6595 | Val Loss: 0.6651 | Accuracy: 0.6022 | Precision: 0.5775 | Recall: 0.6687\n",
      "Epoch 07 | Training Loss: 0.6576 | Val Loss: 0.6642 | Accuracy: 0.5940 | Precision: 0.5826 | Recall: 0.5730\n",
      "Epoch 08 | Training Loss: 0.6566 | Val Loss: 0.6626 | Accuracy: 0.6042 | Precision: 0.5734 | Recall: 0.7174\n",
      "Epoch 09 | Training Loss: 0.6541 | Val Loss: 0.6630 | Accuracy: 0.6084 | Precision: 0.5918 | Recall: 0.6196\n",
      "Epoch 10 | Training Loss: 0.6538 | Val Loss: 0.6617 | Accuracy: 0.6054 | Precision: 0.5879 | Recall: 0.6221\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6563 | Test Accuracy: 0.6038 | Test Precision: 0.5984 | Test Recall: 0.6314\n",
      "\n",
      "Training for parameter combination:  61, \n",
      "\n",
      "trial 1 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6778 | Val Loss: 0.6754 | Accuracy: 0.5846 | Precision: 0.5511 | Recall: 0.7723\n",
      "Epoch 02 | Training Loss: 0.6658 | Val Loss: 0.6686 | Accuracy: 0.6020 | Precision: 0.6084 | Recall: 0.5025\n",
      "Epoch 03 | Training Loss: 0.6610 | Val Loss: 0.6660 | Accuracy: 0.5998 | Precision: 0.5791 | Recall: 0.6390\n",
      "Epoch 04 | Training Loss: 0.6565 | Val Loss: 0.6622 | Accuracy: 0.6042 | Precision: 0.5812 | Recall: 0.6572\n",
      "Epoch 05 | Training Loss: 0.6543 | Val Loss: 0.6646 | Accuracy: 0.5998 | Precision: 0.5704 | Recall: 0.7067\n",
      "Epoch 06 | Training Loss: 0.6505 | Val Loss: 0.6604 | Accuracy: 0.6020 | Precision: 0.6014 | Recall: 0.5309\n",
      "Epoch 07 | Training Loss: 0.6482 | Val Loss: 0.6651 | Accuracy: 0.6038 | Precision: 0.5957 | Recall: 0.5689\n",
      "Epoch 08 | Training Loss: 0.6457 | Val Loss: 0.6607 | Accuracy: 0.6116 | Precision: 0.5965 | Recall: 0.6147\n",
      "Epoch 09 | Training Loss: 0.6435 | Val Loss: 0.6631 | Accuracy: 0.6066 | Precision: 0.5764 | Recall: 0.7112\n",
      "Epoch 10 | Training Loss: 0.6423 | Val Loss: 0.6631 | Accuracy: 0.6090 | Precision: 0.5918 | Recall: 0.6238\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6656 | Test Accuracy: 0.6100 | Test Precision: 0.6066 | Test Recall: 0.6260\n",
      "trial 2 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6757 | Val Loss: 0.6707 | Accuracy: 0.5948 | Precision: 0.5600 | Recall: 0.7657\n",
      "Epoch 02 | Training Loss: 0.6645 | Val Loss: 0.6626 | Accuracy: 0.6018 | Precision: 0.5853 | Recall: 0.6126\n",
      "Epoch 03 | Training Loss: 0.6607 | Val Loss: 0.6683 | Accuracy: 0.5976 | Precision: 0.5656 | Recall: 0.7323\n",
      "Epoch 04 | Training Loss: 0.6568 | Val Loss: 0.6600 | Accuracy: 0.6040 | Precision: 0.5772 | Recall: 0.6848\n",
      "Epoch 05 | Training Loss: 0.6530 | Val Loss: 0.6629 | Accuracy: 0.6060 | Precision: 0.6102 | Recall: 0.5186\n",
      "Epoch 06 | Training Loss: 0.6513 | Val Loss: 0.6612 | Accuracy: 0.6080 | Precision: 0.5759 | Recall: 0.7265\n",
      "Epoch 07 | Training Loss: 0.6492 | Val Loss: 0.6601 | Accuracy: 0.6024 | Precision: 0.5858 | Recall: 0.6139\n",
      "Epoch 08 | Training Loss: 0.6467 | Val Loss: 0.6586 | Accuracy: 0.6074 | Precision: 0.5864 | Recall: 0.6456\n",
      "Epoch 09 | Training Loss: 0.6449 | Val Loss: 0.6696 | Accuracy: 0.5964 | Precision: 0.5622 | Recall: 0.7570\n",
      "Epoch 10 | Training Loss: 0.6421 | Val Loss: 0.6624 | Accuracy: 0.6066 | Precision: 0.5858 | Recall: 0.6436\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6366 | Test Accuracy: 0.6052 | Test Precision: 0.5983 | Test Recall: 0.6402\n",
      "trial 3 for current parameter setting...\n",
      "Epoch 01 | Training Loss: 0.6744 | Val Loss: 0.6647 | Accuracy: 0.6018 | Precision: 0.6086 | Recall: 0.5004\n",
      "Epoch 02 | Training Loss: 0.6647 | Val Loss: 0.6625 | Accuracy: 0.6070 | Precision: 0.5837 | Recall: 0.6605\n",
      "Epoch 03 | Training Loss: 0.6608 | Val Loss: 0.6674 | Accuracy: 0.5972 | Precision: 0.5656 | Recall: 0.7294\n",
      "Epoch 04 | Training Loss: 0.6573 | Val Loss: 0.6591 | Accuracy: 0.6084 | Precision: 0.5973 | Recall: 0.5899\n",
      "Epoch 05 | Training Loss: 0.6539 | Val Loss: 0.6657 | Accuracy: 0.5996 | Precision: 0.5679 | Recall: 0.7281\n",
      "Epoch 06 | Training Loss: 0.6515 | Val Loss: 0.6591 | Accuracy: 0.6102 | Precision: 0.5842 | Recall: 0.6795\n",
      "Epoch 07 | Training Loss: 0.6485 | Val Loss: 0.6633 | Accuracy: 0.6034 | Precision: 0.6070 | Recall: 0.5161\n",
      "Epoch 08 | Training Loss: 0.6470 | Val Loss: 0.6660 | Accuracy: 0.6004 | Precision: 0.5713 | Recall: 0.7042\n",
      "Epoch 09 | Training Loss: 0.6450 | Val Loss: 0.6557 | Accuracy: 0.6128 | Precision: 0.6042 | Recall: 0.5837\n",
      "Epoch 10 | Training Loss: 0.6418 | Val Loss: 0.6687 | Accuracy: 0.6082 | Precision: 0.6200 | Recall: 0.4955\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6673 | Test Accuracy: 0.6002 | Test Precision: 0.6300 | Test Recall: 0.4857\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 367\u001b[0m\n\u001b[1;32m    363\u001b[0m     metric_log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mround\u001b[39m(best_recall, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    364\u001b[0m     trials \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 367\u001b[0m tokenization_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenization_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m tokenization_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar_tokenization_details.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenization details:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.12/site-packages/pandas/core/internals/construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "tokenization_table = {'model':[], 'method': [], 'vocab_size':[], 'sequence_len':[]}\n",
    "\n",
    "metric_log = {'model':[], 'seed': [], 'layers':[], 'activation': [], 'optimizer': [], 'learning_rate': [], 'test_accuracy': [], 'test_loss': [], 'precision': [], 'recall': []}\n",
    "\n",
    "visited = []\n",
    "\n",
    "def set_new_seed(trial_number):\n",
    "    \"\"\"set new seed for every trial\n",
    "\n",
    "    Args:\n",
    "        trial_number (int): trial number\n",
    "\n",
    "    Returns:\n",
    "        [None]: None\n",
    "    \"\"\"\n",
    "    random_seed = random.randint(0, 2**32-1)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    return random_seed\n",
    "\n",
    "# -------------------------------\n",
    "# Original MLP Class Definition\n",
    "# -------------------------------\n",
    "class MLP(object):\n",
    "    def __init__(self, layers, activation, device=None):\n",
    "        \"\"\"\n",
    "        layers: list containing dimensions of all layers\n",
    "        activation: str, indicating choice of activation function\n",
    "        device: str or None, either 'cpu' or 'gpu' or None.\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.device = device\n",
    "        # list of all weights and biases\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        # Initialize weights and biases for each layer\n",
    "        for l in range(len(self.layers)):\n",
    "            if l == 0:\n",
    "                continue\n",
    "            W = tf.Variable(tf.random.normal([\n",
    "                            self.layers[l-1], self.layers[l]], \n",
    "                            stddev=0.1))\n",
    "            self.W.append(W)\n",
    "            b = tf.Variable(tf.zeros([1, self.layers[l]]))\n",
    "            self.b.append(b)\n",
    "        \n",
    "        # List of variables to update during backpropagation\n",
    "        self.variables = self.W + self.b\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        X: Tensor, inputs.\n",
    "        \"\"\"\n",
    "        if self.device is not None:\n",
    "            # use '/GPU:0' instead of 'gpu:0' for using gpu on mac\n",
    "            with tf.device('/GPU:0' if self.device == 'gpu' else 'cpu'):\n",
    "                self.y = self.compute_output(X)\n",
    "        else:\n",
    "            self.y = self.compute_output(X)\n",
    "        return self.y\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Computes the loss between predicted and true outputs.\n",
    "        y_pred: Tensor of shape (batch_size, size_output)\n",
    "        y_true: Tensor of shape (batch_size, size_output)\n",
    "        \"\"\"\n",
    "        y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
    "        y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        loss_x = cce(y_true_tf, y_pred_tf)\n",
    "        return loss_x\n",
    "\n",
    "    def backward(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients of the loss with respect to the variables.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            predicted = self.forward(X_train)\n",
    "            current_loss = self.loss(predicted, y_train)\n",
    "        grads = tape.gradient(current_loss, self.variables)\n",
    "        return grads\n",
    "\n",
    "    def compute_output(self, X):\n",
    "        \"\"\"\n",
    "        Custom method to compute the output tensor during the forward pass.\n",
    "        \"\"\"\n",
    "        # Cast X to float32\n",
    "        z = tf.cast(X, dtype=tf.float32)\n",
    "        for l in range(len(self.W)-1):\n",
    "            h = tf.matmul(z, self.W[l]) + self.b[l]\n",
    "            # activation function\n",
    "            if activation == 'ReLU':\n",
    "                z = tf.nn.relu(h)\n",
    "            elif activation == 'Tanh':\n",
    "                z = tf.nn.tanh(h)\n",
    "            elif activation == 'LeakyReLU':\n",
    "                z = tf.nn.leaky_relu(h)\n",
    "        \n",
    "        # Output layer (logits)\n",
    "        output = tf.matmul(z, self.W[-1]) + self.b[-1]\n",
    "        return output\n",
    "\n",
    "# -------------------------------\n",
    "# Character-Level Tokenizer and Preprocessing Functions\n",
    "# -------------------------------\n",
    "def char_level_tokenizer(texts, char_level, num_words=None):\n",
    "    \"\"\"\n",
    "    Create and fit a character-level tokenizer.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): List of texts.\n",
    "        num_words (int or None): Maximum number of tokens to keep.\n",
    "\n",
    "    Returns:\n",
    "        tokenizer: A fitted Tokenizer instance.\n",
    "    \"\"\"\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, char_level=char_level, lower=True)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer\n",
    "\n",
    "def texts_to_bow(tokenizer, texts):\n",
    "    \"\"\"\n",
    "    Convert texts to a bag-of-characters representation.\n",
    "\n",
    "    Args:\n",
    "        tokenizer: A fitted character-level Tokenizer.\n",
    "        texts (list of str): List of texts.\n",
    "\n",
    "    Returns:\n",
    "        Numpy array representing the binary bag-of-characters for each text.\n",
    "    \"\"\"\n",
    "    # texts_to_matrix with mode 'binary' produces a fixed-length binary vector per text.\n",
    "    matrix = tokenizer.texts_to_matrix(texts, mode='binary')\n",
    "    return matrix\n",
    "\n",
    "def one_hot_encode(labels, num_classes=2):\n",
    "    \"\"\"\n",
    "    Convert numeric labels to one-hot encoded vectors.\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "# -------------------------------\n",
    "# Load and Prepare the IMDB Dataset\n",
    "# -------------------------------\n",
    "print(\"Loading IMDB dataset...\")\n",
    "# Load the IMDB reviews dataset with the 'as_supervised' flag so that we get (text, label) pairs.\n",
    "(ds_train, ds_test), ds_info = tfds.load('imdb_reviews',\n",
    "                                           split=['train', 'test'],\n",
    "                                           as_supervised=True,\n",
    "                                           with_info=True)\n",
    "\n",
    "# Convert training dataset to lists.\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for text, label in tfds.as_numpy(ds_train):\n",
    "    # Decode byte strings to utf-8 strings.\n",
    "    train_texts.append(text.decode('utf-8'))\n",
    "    train_labels.append(label)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Create a validation set from the training data (20% for validation).\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert test dataset to lists.\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "for text, label in tfds.as_numpy(ds_test):\n",
    "    test_texts.append(text.decode('utf-8'))\n",
    "    test_labels.append(label)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(f\"Train samples: {len(train_texts)}, Validation samples: {len(val_texts)}, Test samples: {len(test_texts)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Preprocessing: Tokenization and Vectorization\n",
    "# -------------------------------\n",
    "# Build the character-level tokenizer on the training texts.\n",
    "tokenizer = char_level_tokenizer(train_texts, char_level=True)\n",
    "print(\"Tokenizer vocabulary size:\", len(tokenizer.word_index) + 1)\n",
    "\n",
    "# Convert texts to bag-of-characters representation.\n",
    "X_train = texts_to_bow(tokenizer, train_texts)\n",
    "X_val   = texts_to_bow(tokenizer, val_texts)\n",
    "X_test  = texts_to_bow(tokenizer, test_texts)\n",
    "\n",
    "# record tokenization details\n",
    "tokenization_table['model'] = 'mlp'\n",
    "tokenization_table['method'] = 'character'\n",
    "tokenization_table['vocab_size'] = len(tokenizer.word_index) + 1\n",
    "tokenization_table['sequence_len'] = len(X_train[0])\n",
    "\n",
    "\n",
    "# Convert labels to one-hot encoding.\n",
    "y_train = one_hot_encode(train_labels)\n",
    "y_val   = one_hot_encode(val_labels)\n",
    "y_test  = one_hot_encode(test_labels)\n",
    "\n",
    "# -------------------------------\n",
    "# Model Setup\n",
    "# -------------------------------\n",
    "# List of dimensions in all the layers of the network\n",
    "# The input size is determined by the dimension of the bag-of-characters vector.\n",
    "hidden_layers = [1, 2, 3]\n",
    "hidden_sizes = [128, 256, 512]\n",
    "output_size = 2\n",
    "\n",
    "# activation\n",
    "activations = ['ReLU', 'Tanh', 'LeakyReLU']\n",
    "\n",
    "# learning rate\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "\n",
    "# batch size\n",
    "batch_sizes = [32, 64, 128]\n",
    "# optimizer\n",
    "optims = ['SGD', 'Adam', 'RMSProp']\n",
    "\n",
    "# -------------------------------\n",
    "# Training Parameters and Loop\n",
    "# -------------------------------\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "def generate_params():\n",
    "    while True:\n",
    "        n_hidden = random.choice(hidden_layers)\n",
    "        activation = random.choice(activations)\n",
    "        lr = random.choice(learning_rates)\n",
    "        optim = random.choice(optims)\n",
    "        batch_size = random.choice(batch_sizes)\n",
    "        parameters = [n_hidden, activation, lr, optim, batch_size]\n",
    "        if not parameters in visited:\n",
    "            visited.append(parameters)\n",
    "            return parameters\n",
    "\n",
    "trials = 60\n",
    "\n",
    "while trials >=0:\n",
    "    print(f\"\\nTraining for parameter combination:  {60-trials+1}, \\n\")\n",
    "    random_seed = set_new_seed(trials)\n",
    "\n",
    "    parameters = generate_params()\n",
    "    nn_layers = [X_train.shape[1]] + hidden_sizes[:parameters[0]] + [2]\n",
    "    activation = parameters[1]\n",
    "    lr = parameters[2]\n",
    "    optim = parameters[3]\n",
    "    batch_size = parameters[-1]\n",
    "    \n",
    "    best_test_acc = -100\n",
    "    best_precision = None\n",
    "    best_recall = None\n",
    "    best_loss = None\n",
    "    for i in range(3):\n",
    "        print(f\"trial {i+1} for current parameter setting...\")\n",
    "        # Initialize the optimizer\n",
    "        if optim == 'Adam':\n",
    "            optimizer = tf.optimizers.Adam(learning_rate=lr)\n",
    "        elif optim == 'SGD':\n",
    "            optimizer = tf.optimizers.SGD(learning_rate=lr)\n",
    "        elif optim == 'RMSProp':\n",
    "            optimizer = tf.optimizers.RMSprop(learning_rate=lr)\n",
    "            \n",
    "        # Instantiate the MLP model.\n",
    "        model = MLP(nn_layers, activation, device='gpu')\n",
    "\n",
    "        num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
    "\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle training data at the start of each epoch.\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            X_train = X_train[indices]\n",
    "            y_train = y_train[indices]\n",
    "\n",
    "            epoch_loss = 0\n",
    "            for i in range(num_batches):\n",
    "                start = i * batch_size\n",
    "                end = min((i+1) * batch_size, X_train.shape[0])\n",
    "                X_batch = X_train[start:end]\n",
    "                y_batch = y_train[start:end]\n",
    "\n",
    "                # Compute gradients and update weights.\n",
    "                # with tf.GradientTape() as tape:\n",
    "                #     predictions = model.forward(X_batch)\n",
    "                #     loss_value = model.loss(predictions, y_batch)\n",
    "                # grads = tape.gradient(loss_value, model.variables)\n",
    "                predictions = model.forward(X_batch)\n",
    "                loss_value = model.loss(predictions, y_batch)\n",
    "                grads = model.backward(X_batch, y_batch)\n",
    "                optimizer.apply_gradients(zip(grads, model.variables))\n",
    "                epoch_loss += loss_value.numpy() * (end - start)\n",
    "\n",
    "            epoch_loss /= X_train.shape[0]\n",
    "\n",
    "            # Evaluate on validation set.\n",
    "            val_logits = model.forward(X_val)\n",
    "            val_loss = model.loss(val_logits, y_val).numpy()\n",
    "            val_preds = np.argmax(val_logits.numpy(), axis=1)\n",
    "            true_val = np.argmax(y_val, axis=1)\n",
    "            accuracy = np.mean(val_preds == true_val)\n",
    "            precision = precision_score(true_val, val_preds)\n",
    "            recall = recall_score(true_val, val_preds)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:02d} | Training Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "                f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "\n",
    "\n",
    "        # -------------------------------\n",
    "        # Final Evaluation on Test Set\n",
    "        # -------------------------------\n",
    "        num_batches = int(np.ceil(X_test.shape[0] / batch_size))\n",
    "        test_precision = 0.0\n",
    "        test_recall = 0.0\n",
    "        test_accuracy = 0.0\n",
    "        true_test = []\n",
    "        test_preds = []\n",
    "        print(\"\\nEvaluating on test set...\")\n",
    "        for b in range(num_batches):\n",
    "            start = b*batch_size\n",
    "            end = min((b+1)*batch_size, X_test.shape[0])\n",
    "            X_batch = X_test[start: end]\n",
    "            test_output = tf.nn.softmax(model.forward(X_batch), axis=1)\n",
    "            y_batch = y_test[start: end]\n",
    "            test_loss = model.loss(test_output, y_batch).numpy()\n",
    "            predictions = np.argmax(test_output.numpy(), axis=1)\n",
    "            test_preds.extend(predictions)\n",
    "            labels = np.argmax(y_batch, axis=1)\n",
    "            true_test.extend(labels)\n",
    "\n",
    "        test_accuracy = np.mean(np.array(test_preds) == np.array(true_test))\n",
    "        test_precision = precision_score(true_test, test_preds)\n",
    "        test_recall = recall_score(true_test, test_preds)\n",
    "        if test_accuracy > best_test_acc:\n",
    "            best_test_acc = test_accuracy\n",
    "            best_precision = test_precision\n",
    "            best_recall = test_recall\n",
    "            best_loss = test_loss\n",
    "\n",
    "        print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f} | \"\n",
    "            f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "    metric_log['model'].append('mlp_char_tokens')\n",
    "    metric_log['seed'].append(random_seed)\n",
    "    metric_log['layers'].append(parameters[0])\n",
    "    metric_log['activation'].append(activation)\n",
    "    metric_log['optimizer'].append(optim)\n",
    "    metric_log['learning_rate'].append(lr)\n",
    "    metric_log['test_accuracy'].append(round(best_test_acc, 4))\n",
    "    metric_log['test_loss'].append(round(best_loss, 4))\n",
    "    metric_log['precision'].append(round(best_precision, 4))\n",
    "    metric_log['recall'].append(round(best_recall, 4))\n",
    "    trials -= 1\n",
    "\n",
    "\n",
    "tokenization_df = pd.DataFrame(tokenization_table)\n",
    "tokenization_df.to_csv('char_tokenization_details.csv', index=False)\n",
    "\n",
    "print(\"tokenization details:\")\n",
    "print(tokenization_df.head())\n",
    "\n",
    "exp_df = pd.DataFrame(metric_log)\n",
    "exp_df.to_csv('char_token_experiments_log.csv', index=False)\n",
    "print(\"experiments details:\")\n",
    "print(exp_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments details:\n",
      "             model        seed  layers activation optimizer  learning_rate  \\\n",
      "0  mlp_char_tokens  2429128311       1  LeakyReLU       SGD         0.0001   \n",
      "1  mlp_char_tokens   754412604       1  LeakyReLU   RMSProp         0.0001   \n",
      "2  mlp_char_tokens  2932924231       3  LeakyReLU      Adam         0.0010   \n",
      "3  mlp_char_tokens  3966537639       3  LeakyReLU      Adam         0.0010   \n",
      "4  mlp_char_tokens  2735389703       2  LeakyReLU       SGD         0.0010   \n",
      "\n",
      "   test_accuracy  test_loss  precision  recall  \n",
      "0         0.5567     0.6891     0.5585  0.5407  \n",
      "1         0.6080     0.6465     0.5950  0.6770  \n",
      "2         0.6096     0.6890     0.5883  0.7299  \n",
      "3         0.6066     0.6267     0.5988  0.6459  \n",
      "4         0.5755     0.6688     0.5682  0.6292  \n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(tokenization_table, open('char_tokenization_details.pkl', 'wb'))\n",
    "exp_df = pd.DataFrame(metric_log)\n",
    "exp_df.to_csv('char_token_experiments_log.csv', index=False)\n",
    "print(\"experiments details:\")\n",
    "print(exp_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'mlp', 'method': 'character', 'vocab_size': 134, 'sequence_len': 134}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "char_tokenization = pkl.load(open('char_tokenization_details.pkl', 'rb'))\n",
    "char_tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word level tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740002961.967110    4318 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13512 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-02-19 17:09:22.340963: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-02-19 17:09:24.234048: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-02-19 17:09:26.157170: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 20000, Validation samples: 5000, Test samples: 25000\n",
      "Tokenizer vocabulary size: 80169\n",
      "\n",
      "Training for parameter combination: 1, \n",
      "\n",
      "parameters: [1, 'LeakyReLU', 0.0001, 'Adam', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 1...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6575 | Val Loss: 0.4417 | Accuracy: 0.8120 | Precision: 0.8182 | Recall: 0.7871\n",
      "Epoch 02 | Training Loss: 0.2619 | Val Loss: 0.3617 | Accuracy: 0.8494 | Precision: 0.8389 | Recall: 0.8531\n",
      "Epoch 03 | Training Loss: 0.1560 | Val Loss: 0.3374 | Accuracy: 0.8626 | Precision: 0.8651 | Recall: 0.8490\n",
      "Epoch 04 | Training Loss: 0.1032 | Val Loss: 0.3274 | Accuracy: 0.8704 | Precision: 0.8541 | Recall: 0.8837\n",
      "Epoch 05 | Training Loss: 0.0705 | Val Loss: 0.3265 | Accuracy: 0.8754 | Precision: 0.8738 | Recall: 0.8684\n",
      "Epoch 06 | Training Loss: 0.0494 | Val Loss: 0.3284 | Accuracy: 0.8762 | Precision: 0.8641 | Recall: 0.8837\n",
      "Epoch 07 | Training Loss: 0.0353 | Val Loss: 0.3343 | Accuracy: 0.8784 | Precision: 0.8697 | Recall: 0.8812\n",
      "Epoch 08 | Training Loss: 0.0255 | Val Loss: 0.3434 | Accuracy: 0.8750 | Precision: 0.8562 | Recall: 0.8919\n",
      "Epoch 09 | Training Loss: 0.0189 | Val Loss: 0.3511 | Accuracy: 0.8754 | Precision: 0.8581 | Recall: 0.8903\n",
      "Epoch 10 | Training Loss: 0.0141 | Val Loss: 0.3582 | Accuracy: 0.8790 | Precision: 0.8690 | Recall: 0.8837\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3706 | Test Accuracy: 0.8669 | Test Precision: 0.8723 | Test Recall: 0.8598\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 1...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6232 | Val Loss: 0.4349 | Accuracy: 0.8104 | Precision: 0.8045 | Recall: 0.8045\n",
      "Epoch 02 | Training Loss: 0.2577 | Val Loss: 0.3615 | Accuracy: 0.8518 | Precision: 0.8223 | Recall: 0.8857\n",
      "Epoch 03 | Training Loss: 0.1556 | Val Loss: 0.3326 | Accuracy: 0.8676 | Precision: 0.8550 | Recall: 0.8754\n",
      "Epoch 04 | Training Loss: 0.1025 | Val Loss: 0.3227 | Accuracy: 0.8726 | Precision: 0.8601 | Recall: 0.8804\n",
      "Epoch 05 | Training Loss: 0.0705 | Val Loss: 0.3233 | Accuracy: 0.8766 | Precision: 0.8567 | Recall: 0.8952\n",
      "Epoch 06 | Training Loss: 0.0497 | Val Loss: 0.3226 | Accuracy: 0.8806 | Precision: 0.8676 | Recall: 0.8894\n",
      "Epoch 07 | Training Loss: 0.0357 | Val Loss: 0.3285 | Accuracy: 0.8808 | Precision: 0.8627 | Recall: 0.8969\n",
      "Epoch 08 | Training Loss: 0.0260 | Val Loss: 0.3352 | Accuracy: 0.8822 | Precision: 0.8669 | Recall: 0.8944\n",
      "Epoch 09 | Training Loss: 0.0191 | Val Loss: 0.3420 | Accuracy: 0.8834 | Precision: 0.8756 | Recall: 0.8853\n",
      "Epoch 10 | Training Loss: 0.0143 | Val Loss: 0.3508 | Accuracy: 0.8846 | Precision: 0.8716 | Recall: 0.8936\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4387 | Test Accuracy: 0.8681 | Test Precision: 0.8697 | Test Recall: 0.8660\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 1...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6018 | Val Loss: 0.4105 | Accuracy: 0.8212 | Precision: 0.8283 | Recall: 0.7962\n",
      "Epoch 02 | Training Loss: 0.2500 | Val Loss: 0.3463 | Accuracy: 0.8568 | Precision: 0.8411 | Recall: 0.8688\n",
      "Epoch 03 | Training Loss: 0.1500 | Val Loss: 0.3232 | Accuracy: 0.8672 | Precision: 0.8658 | Recall: 0.8593\n",
      "Epoch 04 | Training Loss: 0.0989 | Val Loss: 0.3152 | Accuracy: 0.8744 | Precision: 0.8745 | Recall: 0.8651\n",
      "Epoch 05 | Training Loss: 0.0673 | Val Loss: 0.3137 | Accuracy: 0.8760 | Precision: 0.8790 | Recall: 0.8630\n",
      "Epoch 06 | Training Loss: 0.0470 | Val Loss: 0.3158 | Accuracy: 0.8804 | Precision: 0.8751 | Recall: 0.8787\n",
      "Epoch 07 | Training Loss: 0.0335 | Val Loss: 0.3204 | Accuracy: 0.8814 | Precision: 0.8778 | Recall: 0.8775\n",
      "Epoch 08 | Training Loss: 0.0244 | Val Loss: 0.3273 | Accuracy: 0.8822 | Precision: 0.8725 | Recall: 0.8866\n",
      "Epoch 09 | Training Loss: 0.0181 | Val Loss: 0.3364 | Accuracy: 0.8820 | Precision: 0.8686 | Recall: 0.8915\n",
      "Epoch 10 | Training Loss: 0.0135 | Val Loss: 0.3432 | Accuracy: 0.8818 | Precision: 0.8742 | Recall: 0.8833\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4035 | Test Accuracy: 0.8674 | Test Precision: 0.8722 | Test Recall: 0.8609\n",
      "\n",
      "Training for parameter combination: 2, \n",
      "\n",
      "parameters: [3, 'LeakyReLU', 0.0001, 'SGD', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 2...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0807 | Val Loss: 0.9959 | Accuracy: 0.4820 | Precision: 0.4705 | Recall: 0.5462\n",
      "Epoch 02 | Training Loss: 0.9921 | Val Loss: 0.9641 | Accuracy: 0.4926 | Precision: 0.4774 | Recall: 0.4926\n",
      "Epoch 03 | Training Loss: 0.9713 | Val Loss: 0.9465 | Accuracy: 0.4968 | Precision: 0.4811 | Recall: 0.4823\n",
      "Epoch 04 | Training Loss: 0.9548 | Val Loss: 0.9312 | Accuracy: 0.4992 | Precision: 0.4834 | Recall: 0.4806\n",
      "Epoch 05 | Training Loss: 0.9395 | Val Loss: 0.9170 | Accuracy: 0.5034 | Precision: 0.4878 | Recall: 0.4851\n",
      "Epoch 06 | Training Loss: 0.9252 | Val Loss: 0.9042 | Accuracy: 0.5050 | Precision: 0.4895 | Recall: 0.4889\n",
      "Epoch 07 | Training Loss: 0.9118 | Val Loss: 0.8917 | Accuracy: 0.5084 | Precision: 0.4929 | Recall: 0.4864\n",
      "Epoch 08 | Training Loss: 0.8993 | Val Loss: 0.8802 | Accuracy: 0.5122 | Precision: 0.4969 | Recall: 0.4893\n",
      "Epoch 09 | Training Loss: 0.8876 | Val Loss: 0.8695 | Accuracy: 0.5142 | Precision: 0.4990 | Recall: 0.4930\n",
      "Epoch 10 | Training Loss: 0.8765 | Val Loss: 0.8600 | Accuracy: 0.5178 | Precision: 0.5027 | Recall: 0.5066\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7141 | Test Accuracy: 0.5160 | Test Precision: 0.5166 | Test Recall: 0.4994\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 2...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.1635 | Val Loss: 0.9636 | Accuracy: 0.4826 | Precision: 0.4777 | Recall: 0.7207\n",
      "Epoch 02 | Training Loss: 0.9008 | Val Loss: 0.8848 | Accuracy: 0.4944 | Precision: 0.4816 | Recall: 0.5602\n",
      "Epoch 03 | Training Loss: 0.8704 | Val Loss: 0.8691 | Accuracy: 0.4986 | Precision: 0.4840 | Recall: 0.5177\n",
      "Epoch 04 | Training Loss: 0.8598 | Val Loss: 0.8600 | Accuracy: 0.5016 | Precision: 0.4867 | Recall: 0.5153\n",
      "Epoch 05 | Training Loss: 0.8508 | Val Loss: 0.8514 | Accuracy: 0.5056 | Precision: 0.4905 | Recall: 0.5103\n",
      "Epoch 06 | Training Loss: 0.8424 | Val Loss: 0.8437 | Accuracy: 0.5074 | Precision: 0.4923 | Recall: 0.5140\n",
      "Epoch 07 | Training Loss: 0.8344 | Val Loss: 0.8364 | Accuracy: 0.5094 | Precision: 0.4943 | Recall: 0.5169\n",
      "Epoch 08 | Training Loss: 0.8268 | Val Loss: 0.8296 | Accuracy: 0.5130 | Precision: 0.4978 | Recall: 0.5248\n",
      "Epoch 09 | Training Loss: 0.8197 | Val Loss: 0.8230 | Accuracy: 0.5148 | Precision: 0.4996 | Recall: 0.5252\n",
      "Epoch 10 | Training Loss: 0.8129 | Val Loss: 0.8166 | Accuracy: 0.5164 | Precision: 0.5012 | Recall: 0.5243\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7137 | Test Accuracy: 0.5187 | Test Precision: 0.5186 | Test Recall: 0.5225\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 2...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9538 | Val Loss: 0.9248 | Accuracy: 0.5212 | Precision: 0.5068 | Recall: 0.4600\n",
      "Epoch 02 | Training Loss: 0.8981 | Val Loss: 0.9116 | Accuracy: 0.5210 | Precision: 0.5060 | Recall: 0.5033\n",
      "Epoch 03 | Training Loss: 0.8844 | Val Loss: 0.9003 | Accuracy: 0.5206 | Precision: 0.5055 | Recall: 0.5128\n",
      "Epoch 04 | Training Loss: 0.8725 | Val Loss: 0.8888 | Accuracy: 0.5250 | Precision: 0.5101 | Recall: 0.5103\n",
      "Epoch 05 | Training Loss: 0.8615 | Val Loss: 0.8785 | Accuracy: 0.5310 | Precision: 0.5162 | Recall: 0.5198\n",
      "Epoch 06 | Training Loss: 0.8511 | Val Loss: 0.8686 | Accuracy: 0.5334 | Precision: 0.5186 | Recall: 0.5223\n",
      "Epoch 07 | Training Loss: 0.8413 | Val Loss: 0.8595 | Accuracy: 0.5334 | Precision: 0.5186 | Recall: 0.5239\n",
      "Epoch 08 | Training Loss: 0.8321 | Val Loss: 0.8506 | Accuracy: 0.5354 | Precision: 0.5207 | Recall: 0.5248\n",
      "Epoch 09 | Training Loss: 0.8235 | Val Loss: 0.8426 | Accuracy: 0.5384 | Precision: 0.5236 | Recall: 0.5318\n",
      "Epoch 10 | Training Loss: 0.8153 | Val Loss: 0.8346 | Accuracy: 0.5404 | Precision: 0.5256 | Recall: 0.5334\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7148 | Test Accuracy: 0.5450 | Test Precision: 0.5453 | Test Recall: 0.5425\n",
      "\n",
      "Training for parameter combination: 3, \n",
      "\n",
      "parameters: [2, 'ReLU', 0.0001, 'SGD', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 3...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.1185 | Val Loss: 1.0721 | Accuracy: 0.4762 | Precision: 0.4569 | Recall: 0.4266\n",
      "Epoch 02 | Training Loss: 1.0333 | Val Loss: 1.0584 | Accuracy: 0.4756 | Precision: 0.4601 | Recall: 0.4715\n",
      "Epoch 03 | Training Loss: 1.0190 | Val Loss: 1.0465 | Accuracy: 0.4768 | Precision: 0.4618 | Recall: 0.4790\n",
      "Epoch 04 | Training Loss: 1.0067 | Val Loss: 1.0345 | Accuracy: 0.4814 | Precision: 0.4665 | Recall: 0.4860\n",
      "Epoch 05 | Training Loss: 0.9948 | Val Loss: 1.0230 | Accuracy: 0.4840 | Precision: 0.4692 | Recall: 0.4909\n",
      "Epoch 06 | Training Loss: 0.9835 | Val Loss: 1.0115 | Accuracy: 0.4866 | Precision: 0.4717 | Recall: 0.4917\n",
      "Epoch 07 | Training Loss: 0.9725 | Val Loss: 1.0011 | Accuracy: 0.4880 | Precision: 0.4732 | Recall: 0.4963\n",
      "Epoch 08 | Training Loss: 0.9620 | Val Loss: 0.9913 | Accuracy: 0.4908 | Precision: 0.4763 | Recall: 0.5054\n",
      "Epoch 09 | Training Loss: 0.9520 | Val Loss: 0.9809 | Accuracy: 0.4934 | Precision: 0.4787 | Recall: 0.5041\n",
      "Epoch 10 | Training Loss: 0.9422 | Val Loss: 0.9704 | Accuracy: 0.4948 | Precision: 0.4797 | Recall: 0.4983\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7141 | Test Accuracy: 0.5151 | Test Precision: 0.5151 | Test Recall: 0.5142\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 3...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.5689 | Val Loss: 1.1228 | Accuracy: 0.5026 | Precision: 0.4905 | Recall: 0.6696\n",
      "Epoch 02 | Training Loss: 1.0904 | Val Loss: 1.0460 | Accuracy: 0.5086 | Precision: 0.4938 | Recall: 0.5413\n",
      "Epoch 03 | Training Loss: 1.0632 | Val Loss: 1.0302 | Accuracy: 0.5118 | Precision: 0.4967 | Recall: 0.5256\n",
      "Epoch 04 | Training Loss: 1.0488 | Val Loss: 1.0181 | Accuracy: 0.5142 | Precision: 0.4990 | Recall: 0.5281\n",
      "Epoch 05 | Training Loss: 1.0352 | Val Loss: 1.0059 | Accuracy: 0.5162 | Precision: 0.5010 | Recall: 0.5252\n",
      "Epoch 06 | Training Loss: 1.0223 | Val Loss: 0.9950 | Accuracy: 0.5194 | Precision: 0.5041 | Recall: 0.5314\n",
      "Epoch 07 | Training Loss: 1.0099 | Val Loss: 0.9843 | Accuracy: 0.5218 | Precision: 0.5065 | Recall: 0.5338\n",
      "Epoch 08 | Training Loss: 0.9979 | Val Loss: 0.9737 | Accuracy: 0.5248 | Precision: 0.5095 | Recall: 0.5326\n",
      "Epoch 09 | Training Loss: 0.9867 | Val Loss: 0.9642 | Accuracy: 0.5268 | Precision: 0.5114 | Recall: 0.5375\n",
      "Epoch 10 | Training Loss: 0.9757 | Val Loss: 0.9548 | Accuracy: 0.5294 | Precision: 0.5140 | Recall: 0.5392\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7138 | Test Accuracy: 0.5155 | Test Precision: 0.5151 | Test Recall: 0.5301\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 3...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0966 | Val Loss: 1.0401 | Accuracy: 0.5116 | Precision: 0.4959 | Recall: 0.4472\n",
      "Epoch 02 | Training Loss: 1.0326 | Val Loss: 1.0259 | Accuracy: 0.5112 | Precision: 0.4958 | Recall: 0.4909\n",
      "Epoch 03 | Training Loss: 1.0193 | Val Loss: 1.0145 | Accuracy: 0.5142 | Precision: 0.4990 | Recall: 0.4975\n",
      "Epoch 04 | Training Loss: 1.0076 | Val Loss: 1.0034 | Accuracy: 0.5184 | Precision: 0.5033 | Recall: 0.5021\n",
      "Epoch 05 | Training Loss: 0.9965 | Val Loss: 0.9928 | Accuracy: 0.5210 | Precision: 0.5060 | Recall: 0.5083\n",
      "Epoch 06 | Training Loss: 0.9858 | Val Loss: 0.9828 | Accuracy: 0.5236 | Precision: 0.5085 | Recall: 0.5161\n",
      "Epoch 07 | Training Loss: 0.9755 | Val Loss: 0.9727 | Accuracy: 0.5266 | Precision: 0.5116 | Recall: 0.5165\n",
      "Epoch 08 | Training Loss: 0.9656 | Val Loss: 0.9632 | Accuracy: 0.5288 | Precision: 0.5139 | Recall: 0.5173\n",
      "Epoch 09 | Training Loss: 0.9560 | Val Loss: 0.9541 | Accuracy: 0.5316 | Precision: 0.5167 | Recall: 0.5239\n",
      "Epoch 10 | Training Loss: 0.9468 | Val Loss: 0.9454 | Accuracy: 0.5344 | Precision: 0.5195 | Recall: 0.5281\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7519 | Test Accuracy: 0.5384 | Test Precision: 0.5391 | Test Recall: 0.5296\n",
      "\n",
      "Training for parameter combination: 4, \n",
      "\n",
      "parameters: [1, 'Tanh', 0.001, 'SGD', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 4...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9891 | Val Loss: 0.9497 | Accuracy: 0.5340 | Precision: 0.5188 | Recall: 0.5359\n",
      "Epoch 02 | Training Loss: 0.8822 | Val Loss: 0.8622 | Accuracy: 0.5724 | Precision: 0.5567 | Recall: 0.5792\n",
      "Epoch 03 | Training Loss: 0.8048 | Val Loss: 0.7973 | Accuracy: 0.5982 | Precision: 0.5821 | Recall: 0.6068\n",
      "Epoch 04 | Training Loss: 0.7468 | Val Loss: 0.7465 | Accuracy: 0.6242 | Precision: 0.6095 | Recall: 0.6258\n",
      "Epoch 05 | Training Loss: 0.7018 | Val Loss: 0.7080 | Accuracy: 0.6430 | Precision: 0.6259 | Recall: 0.6551\n",
      "Epoch 06 | Training Loss: 0.6657 | Val Loss: 0.6748 | Accuracy: 0.6606 | Precision: 0.6468 | Recall: 0.6609\n",
      "Epoch 07 | Training Loss: 0.6365 | Val Loss: 0.6494 | Accuracy: 0.6750 | Precision: 0.6576 | Recall: 0.6877\n",
      "Epoch 08 | Training Loss: 0.6122 | Val Loss: 0.6276 | Accuracy: 0.6888 | Precision: 0.6693 | Recall: 0.7079\n",
      "Epoch 09 | Training Loss: 0.5913 | Val Loss: 0.6074 | Accuracy: 0.6998 | Precision: 0.6895 | Recall: 0.6927\n",
      "Epoch 10 | Training Loss: 0.5738 | Val Loss: 0.5927 | Accuracy: 0.7126 | Precision: 0.6932 | Recall: 0.7306\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6253 | Test Accuracy: 0.7136 | Test Precision: 0.7086 | Test Recall: 0.7257\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 4...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9657 | Val Loss: 0.9189 | Accuracy: 0.5544 | Precision: 0.5411 | Recall: 0.5326\n",
      "Epoch 02 | Training Loss: 0.8575 | Val Loss: 0.8459 | Accuracy: 0.5834 | Precision: 0.5707 | Recall: 0.5677\n",
      "Epoch 03 | Training Loss: 0.7913 | Val Loss: 0.7893 | Accuracy: 0.6096 | Precision: 0.5992 | Recall: 0.5879\n",
      "Epoch 04 | Training Loss: 0.7399 | Val Loss: 0.7445 | Accuracy: 0.6314 | Precision: 0.6216 | Recall: 0.6126\n",
      "Epoch 05 | Training Loss: 0.6984 | Val Loss: 0.7081 | Accuracy: 0.6472 | Precision: 0.6367 | Recall: 0.6341\n",
      "Epoch 06 | Training Loss: 0.6644 | Val Loss: 0.6781 | Accuracy: 0.6620 | Precision: 0.6533 | Recall: 0.6452\n",
      "Epoch 07 | Training Loss: 0.6361 | Val Loss: 0.6529 | Accuracy: 0.6740 | Precision: 0.6643 | Recall: 0.6621\n",
      "Epoch 08 | Training Loss: 0.6122 | Val Loss: 0.6315 | Accuracy: 0.6872 | Precision: 0.6795 | Recall: 0.6716\n",
      "Epoch 09 | Training Loss: 0.5916 | Val Loss: 0.6132 | Accuracy: 0.6998 | Precision: 0.6874 | Recall: 0.6984\n",
      "Epoch 10 | Training Loss: 0.5738 | Val Loss: 0.5971 | Accuracy: 0.7112 | Precision: 0.7054 | Recall: 0.6943\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6537 | Test Accuracy: 0.7059 | Test Precision: 0.7120 | Test Recall: 0.6916\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 4...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9179 | Val Loss: 0.8627 | Accuracy: 0.5680 | Precision: 0.5573 | Recall: 0.5297\n",
      "Epoch 02 | Training Loss: 0.8272 | Val Loss: 0.7907 | Accuracy: 0.6036 | Precision: 0.5941 | Recall: 0.5755\n",
      "Epoch 03 | Training Loss: 0.7615 | Val Loss: 0.7373 | Accuracy: 0.6318 | Precision: 0.6209 | Recall: 0.6176\n",
      "Epoch 04 | Training Loss: 0.7113 | Val Loss: 0.6961 | Accuracy: 0.6560 | Precision: 0.6438 | Recall: 0.6502\n",
      "Epoch 05 | Training Loss: 0.6717 | Val Loss: 0.6632 | Accuracy: 0.6760 | Precision: 0.6642 | Recall: 0.6708\n",
      "Epoch 06 | Training Loss: 0.6397 | Val Loss: 0.6366 | Accuracy: 0.6880 | Precision: 0.6763 | Recall: 0.6836\n",
      "Epoch 07 | Training Loss: 0.6133 | Val Loss: 0.6145 | Accuracy: 0.6990 | Precision: 0.6881 | Recall: 0.6935\n",
      "Epoch 08 | Training Loss: 0.5913 | Val Loss: 0.5960 | Accuracy: 0.7086 | Precision: 0.6963 | Recall: 0.7075\n",
      "Epoch 09 | Training Loss: 0.5723 | Val Loss: 0.5811 | Accuracy: 0.7190 | Precision: 0.6999 | Recall: 0.7360\n",
      "Epoch 10 | Training Loss: 0.5562 | Val Loss: 0.5666 | Accuracy: 0.7282 | Precision: 0.7133 | Recall: 0.7347\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5457 | Test Accuracy: 0.7218 | Test Precision: 0.7244 | Test Recall: 0.7160\n",
      "\n",
      "Training for parameter combination: 5, \n",
      "\n",
      "parameters: [1, 'ReLU', 0.0005, 'RMSProp', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 5...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4490 | Val Loss: 0.3416 | Accuracy: 0.8630 | Precision: 0.8883 | Recall: 0.8205\n",
      "Epoch 02 | Training Loss: 0.1559 | Val Loss: 0.3254 | Accuracy: 0.8738 | Precision: 0.8634 | Recall: 0.8787\n",
      "Epoch 03 | Training Loss: 0.0735 | Val Loss: 0.3508 | Accuracy: 0.8732 | Precision: 0.8723 | Recall: 0.8651\n",
      "Epoch 04 | Training Loss: 0.0315 | Val Loss: 0.3858 | Accuracy: 0.8724 | Precision: 0.8651 | Recall: 0.8729\n",
      "Epoch 05 | Training Loss: 0.0126 | Val Loss: 0.4363 | Accuracy: 0.8706 | Precision: 0.8464 | Recall: 0.8956\n",
      "Epoch 06 | Training Loss: 0.0046 | Val Loss: 0.4930 | Accuracy: 0.8730 | Precision: 0.8841 | Recall: 0.8494\n",
      "Epoch 07 | Training Loss: 0.0017 | Val Loss: 0.5403 | Accuracy: 0.8744 | Precision: 0.8612 | Recall: 0.8833\n",
      "Epoch 08 | Training Loss: 0.0008 | Val Loss: 0.5790 | Accuracy: 0.8748 | Precision: 0.8608 | Recall: 0.8849\n",
      "Epoch 09 | Training Loss: 0.0005 | Val Loss: 0.6102 | Accuracy: 0.8734 | Precision: 0.8589 | Recall: 0.8841\n",
      "Epoch 10 | Training Loss: 0.0003 | Val Loss: 0.6288 | Accuracy: 0.8754 | Precision: 0.8668 | Recall: 0.8779\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4125 | Test Accuracy: 0.8700 | Test Precision: 0.8755 | Test Recall: 0.8627\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 5...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4386 | Val Loss: 0.3289 | Accuracy: 0.8722 | Precision: 0.8526 | Recall: 0.8903\n",
      "Epoch 02 | Training Loss: 0.1536 | Val Loss: 0.3247 | Accuracy: 0.8776 | Precision: 0.8865 | Recall: 0.8573\n",
      "Epoch 03 | Training Loss: 0.0704 | Val Loss: 0.3494 | Accuracy: 0.8776 | Precision: 0.8528 | Recall: 0.9035\n",
      "Epoch 04 | Training Loss: 0.0298 | Val Loss: 0.3824 | Accuracy: 0.8772 | Precision: 0.8617 | Recall: 0.8894\n",
      "Epoch 05 | Training Loss: 0.0115 | Val Loss: 0.4255 | Accuracy: 0.8790 | Precision: 0.8634 | Recall: 0.8915\n",
      "Epoch 06 | Training Loss: 0.0041 | Val Loss: 0.4834 | Accuracy: 0.8774 | Precision: 0.8691 | Recall: 0.8795\n",
      "Epoch 07 | Training Loss: 0.0017 | Val Loss: 0.5337 | Accuracy: 0.8772 | Precision: 0.8637 | Recall: 0.8866\n",
      "Epoch 08 | Training Loss: 0.0008 | Val Loss: 0.5737 | Accuracy: 0.8772 | Precision: 0.8664 | Recall: 0.8828\n",
      "Epoch 09 | Training Loss: 0.0005 | Val Loss: 0.5988 | Accuracy: 0.8780 | Precision: 0.8708 | Recall: 0.8787\n",
      "Epoch 10 | Training Loss: 0.0003 | Val Loss: 0.6210 | Accuracy: 0.8784 | Precision: 0.8703 | Recall: 0.8804\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4146 | Test Accuracy: 0.8704 | Test Precision: 0.8734 | Test Recall: 0.8662\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 5...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4514 | Val Loss: 0.3275 | Accuracy: 0.8658 | Precision: 0.8488 | Recall: 0.8800\n",
      "Epoch 02 | Training Loss: 0.1568 | Val Loss: 0.3257 | Accuracy: 0.8758 | Precision: 0.8705 | Recall: 0.8738\n",
      "Epoch 03 | Training Loss: 0.0724 | Val Loss: 0.4279 | Accuracy: 0.8560 | Precision: 0.9277 | Recall: 0.7624\n",
      "Epoch 04 | Training Loss: 0.0302 | Val Loss: 0.3833 | Accuracy: 0.8748 | Precision: 0.8771 | Recall: 0.8626\n",
      "Epoch 05 | Training Loss: 0.0111 | Val Loss: 0.4305 | Accuracy: 0.8774 | Precision: 0.8728 | Recall: 0.8746\n",
      "Epoch 06 | Training Loss: 0.0041 | Val Loss: 0.4890 | Accuracy: 0.8778 | Precision: 0.8565 | Recall: 0.8985\n",
      "Epoch 07 | Training Loss: 0.0016 | Val Loss: 0.5364 | Accuracy: 0.8790 | Precision: 0.8660 | Recall: 0.8878\n",
      "Epoch 08 | Training Loss: 0.0008 | Val Loss: 0.5770 | Accuracy: 0.8794 | Precision: 0.8632 | Recall: 0.8927\n",
      "Epoch 09 | Training Loss: 0.0005 | Val Loss: 0.5996 | Accuracy: 0.8780 | Precision: 0.8726 | Recall: 0.8762\n",
      "Epoch 10 | Training Loss: 0.0003 | Val Loss: 0.6203 | Accuracy: 0.8774 | Precision: 0.8688 | Recall: 0.8800\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4028 | Test Accuracy: 0.8702 | Test Precision: 0.8724 | Test Recall: 0.8672\n",
      "\n",
      "Training for parameter combination: 6, \n",
      "\n",
      "parameters: [1, 'ReLU', 0.0001, 'RMSProp', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 6...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6715 | Val Loss: 0.4769 | Accuracy: 0.7874 | Precision: 0.7682 | Recall: 0.8040\n",
      "Epoch 02 | Training Loss: 0.3476 | Val Loss: 0.3887 | Accuracy: 0.8314 | Precision: 0.8374 | Recall: 0.8094\n",
      "Epoch 03 | Training Loss: 0.2471 | Val Loss: 0.3612 | Accuracy: 0.8508 | Precision: 0.8237 | Recall: 0.8808\n",
      "Epoch 04 | Training Loss: 0.1902 | Val Loss: 0.3432 | Accuracy: 0.8604 | Precision: 0.8433 | Recall: 0.8746\n",
      "Epoch 05 | Training Loss: 0.1520 | Val Loss: 0.3358 | Accuracy: 0.8668 | Precision: 0.8614 | Recall: 0.8643\n",
      "Epoch 06 | Training Loss: 0.1236 | Val Loss: 0.3340 | Accuracy: 0.8672 | Precision: 0.8534 | Recall: 0.8767\n",
      "Epoch 07 | Training Loss: 0.1017 | Val Loss: 0.3339 | Accuracy: 0.8706 | Precision: 0.8599 | Recall: 0.8758\n",
      "Epoch 08 | Training Loss: 0.0833 | Val Loss: 0.3381 | Accuracy: 0.8696 | Precision: 0.8527 | Recall: 0.8837\n",
      "Epoch 09 | Training Loss: 0.0686 | Val Loss: 0.3416 | Accuracy: 0.8696 | Precision: 0.8544 | Recall: 0.8812\n",
      "Epoch 10 | Training Loss: 0.0561 | Val Loss: 0.3462 | Accuracy: 0.8716 | Precision: 0.8637 | Recall: 0.8729\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4139 | Test Accuracy: 0.8636 | Test Precision: 0.8685 | Test Recall: 0.8570\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 6...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6743 | Val Loss: 0.4724 | Accuracy: 0.7856 | Precision: 0.7689 | Recall: 0.7974\n",
      "Epoch 02 | Training Loss: 0.3407 | Val Loss: 0.3854 | Accuracy: 0.8366 | Precision: 0.8236 | Recall: 0.8436\n",
      "Epoch 03 | Training Loss: 0.2416 | Val Loss: 0.3609 | Accuracy: 0.8532 | Precision: 0.8633 | Recall: 0.8284\n",
      "Epoch 04 | Training Loss: 0.1864 | Val Loss: 0.3510 | Accuracy: 0.8580 | Precision: 0.8271 | Recall: 0.8940\n",
      "Epoch 05 | Training Loss: 0.1489 | Val Loss: 0.3403 | Accuracy: 0.8688 | Precision: 0.8559 | Recall: 0.8771\n",
      "Epoch 06 | Training Loss: 0.1203 | Val Loss: 0.3421 | Accuracy: 0.8668 | Precision: 0.8431 | Recall: 0.8911\n",
      "Epoch 07 | Training Loss: 0.0983 | Val Loss: 0.3397 | Accuracy: 0.8688 | Precision: 0.8644 | Recall: 0.8651\n",
      "Epoch 08 | Training Loss: 0.0806 | Val Loss: 0.3427 | Accuracy: 0.8684 | Precision: 0.8634 | Recall: 0.8655\n",
      "Epoch 09 | Training Loss: 0.0659 | Val Loss: 0.3482 | Accuracy: 0.8702 | Precision: 0.8569 | Recall: 0.8791\n",
      "Epoch 10 | Training Loss: 0.0543 | Val Loss: 0.3530 | Accuracy: 0.8706 | Precision: 0.8599 | Recall: 0.8758\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4226 | Test Accuracy: 0.8640 | Test Precision: 0.8674 | Test Recall: 0.8594\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 6...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6384 | Val Loss: 0.4750 | Accuracy: 0.7870 | Precision: 0.7657 | Recall: 0.8078\n",
      "Epoch 02 | Training Loss: 0.3415 | Val Loss: 0.3886 | Accuracy: 0.8388 | Precision: 0.8215 | Recall: 0.8527\n",
      "Epoch 03 | Training Loss: 0.2459 | Val Loss: 0.3603 | Accuracy: 0.8500 | Precision: 0.8327 | Recall: 0.8643\n",
      "Epoch 04 | Training Loss: 0.1922 | Val Loss: 0.3557 | Accuracy: 0.8572 | Precision: 0.8236 | Recall: 0.8977\n",
      "Epoch 05 | Training Loss: 0.1543 | Val Loss: 0.3412 | Accuracy: 0.8644 | Precision: 0.8665 | Recall: 0.8515\n",
      "Epoch 06 | Training Loss: 0.1264 | Val Loss: 0.3383 | Accuracy: 0.8674 | Precision: 0.8560 | Recall: 0.8733\n",
      "Epoch 07 | Training Loss: 0.1037 | Val Loss: 0.3423 | Accuracy: 0.8662 | Precision: 0.8729 | Recall: 0.8474\n",
      "Epoch 08 | Training Loss: 0.0857 | Val Loss: 0.3426 | Accuracy: 0.8714 | Precision: 0.8592 | Recall: 0.8787\n",
      "Epoch 09 | Training Loss: 0.0707 | Val Loss: 0.3470 | Accuracy: 0.8708 | Precision: 0.8596 | Recall: 0.8767\n",
      "Epoch 10 | Training Loss: 0.0584 | Val Loss: 0.3536 | Accuracy: 0.8702 | Precision: 0.8537 | Recall: 0.8837\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4332 | Test Accuracy: 0.8645 | Test Precision: 0.8611 | Test Recall: 0.8692\n",
      "\n",
      "Training for parameter combination: 7, \n",
      "\n",
      "parameters: [1, 'ReLU', 0.001, 'RMSProp', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 7...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3987 | Val Loss: 0.3439 | Accuracy: 0.8662 | Precision: 0.9034 | Recall: 0.8106\n",
      "Epoch 02 | Training Loss: 0.1028 | Val Loss: 0.3429 | Accuracy: 0.8810 | Precision: 0.8698 | Recall: 0.8874\n",
      "Epoch 03 | Training Loss: 0.0201 | Val Loss: 0.4408 | Accuracy: 0.8834 | Precision: 0.8815 | Recall: 0.8775\n",
      "Epoch 04 | Training Loss: 0.0021 | Val Loss: 0.5699 | Accuracy: 0.8844 | Precision: 0.8731 | Recall: 0.8911\n",
      "Epoch 05 | Training Loss: 0.0003 | Val Loss: 0.6399 | Accuracy: 0.8846 | Precision: 0.8690 | Recall: 0.8973\n",
      "Epoch 06 | Training Loss: 0.0001 | Val Loss: 0.6789 | Accuracy: 0.8858 | Precision: 0.8737 | Recall: 0.8936\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.7102 | Accuracy: 0.8848 | Precision: 0.8675 | Recall: 0.8998\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.7251 | Accuracy: 0.8860 | Precision: 0.8723 | Recall: 0.8960\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.7412 | Accuracy: 0.8862 | Precision: 0.8711 | Recall: 0.8981\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.7535 | Accuracy: 0.8860 | Precision: 0.8708 | Recall: 0.8981\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3134 | Test Accuracy: 0.8781 | Test Precision: 0.8780 | Test Recall: 0.8783\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 7...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3955 | Val Loss: 0.3087 | Accuracy: 0.8784 | Precision: 0.8620 | Recall: 0.8919\n",
      "Epoch 02 | Training Loss: 0.1027 | Val Loss: 0.3537 | Accuracy: 0.8724 | Precision: 0.8459 | Recall: 0.9010\n",
      "Epoch 03 | Training Loss: 0.0206 | Val Loss: 0.4551 | Accuracy: 0.8762 | Precision: 0.8912 | Recall: 0.8482\n",
      "Epoch 04 | Training Loss: 0.0021 | Val Loss: 0.5706 | Accuracy: 0.8746 | Precision: 0.8587 | Recall: 0.8874\n",
      "Epoch 05 | Training Loss: 0.0003 | Val Loss: 0.6441 | Accuracy: 0.8800 | Precision: 0.8756 | Recall: 0.8771\n",
      "Epoch 06 | Training Loss: 0.0001 | Val Loss: 0.6844 | Accuracy: 0.8806 | Precision: 0.8694 | Recall: 0.8870\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.7088 | Accuracy: 0.8810 | Precision: 0.8731 | Recall: 0.8828\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.7285 | Accuracy: 0.8810 | Precision: 0.8695 | Recall: 0.8878\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.7427 | Accuracy: 0.8810 | Precision: 0.8707 | Recall: 0.8861\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.7546 | Accuracy: 0.8818 | Precision: 0.8724 | Recall: 0.8857\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3133 | Test Accuracy: 0.8758 | Test Precision: 0.8774 | Test Recall: 0.8738\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 7...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4030 | Val Loss: 0.3105 | Accuracy: 0.8738 | Precision: 0.8608 | Recall: 0.8824\n",
      "Epoch 02 | Training Loss: 0.1065 | Val Loss: 0.3734 | Accuracy: 0.8692 | Precision: 0.9030 | Recall: 0.8181\n",
      "Epoch 03 | Training Loss: 0.0217 | Val Loss: 0.4494 | Accuracy: 0.8780 | Precision: 0.8622 | Recall: 0.8907\n",
      "Epoch 04 | Training Loss: 0.0022 | Val Loss: 0.5824 | Accuracy: 0.8786 | Precision: 0.8778 | Recall: 0.8709\n",
      "Epoch 05 | Training Loss: 0.0003 | Val Loss: 0.6623 | Accuracy: 0.8802 | Precision: 0.8617 | Recall: 0.8969\n",
      "Epoch 06 | Training Loss: 0.0001 | Val Loss: 0.6975 | Accuracy: 0.8824 | Precision: 0.8693 | Recall: 0.8915\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.7280 | Accuracy: 0.8818 | Precision: 0.8647 | Recall: 0.8965\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.7468 | Accuracy: 0.8822 | Precision: 0.8660 | Recall: 0.8956\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.7585 | Accuracy: 0.8820 | Precision: 0.8692 | Recall: 0.8907\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.7732 | Accuracy: 0.8818 | Precision: 0.8667 | Recall: 0.8936\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3134 | Test Accuracy: 0.8767 | Test Precision: 0.8740 | Test Recall: 0.8802\n",
      "\n",
      "Training for parameter combination: 8, \n",
      "\n",
      "parameters: [2, 'LeakyReLU', 0.0005, 'Adam', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 8...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4577 | Val Loss: 0.3263 | Accuracy: 0.8626 | Precision: 0.8975 | Recall: 0.8090\n",
      "Epoch 02 | Training Loss: 0.0868 | Val Loss: 0.3169 | Accuracy: 0.8764 | Precision: 0.8713 | Recall: 0.8742\n",
      "Epoch 03 | Training Loss: 0.0233 | Val Loss: 0.3615 | Accuracy: 0.8780 | Precision: 0.8543 | Recall: 0.9022\n",
      "Epoch 04 | Training Loss: 0.0070 | Val Loss: 0.3951 | Accuracy: 0.8792 | Precision: 0.8637 | Recall: 0.8915\n",
      "Epoch 05 | Training Loss: 0.0029 | Val Loss: 0.4297 | Accuracy: 0.8796 | Precision: 0.8673 | Recall: 0.8874\n",
      "Epoch 06 | Training Loss: 0.0016 | Val Loss: 0.4569 | Accuracy: 0.8810 | Precision: 0.8698 | Recall: 0.8874\n",
      "Epoch 07 | Training Loss: 0.0010 | Val Loss: 0.4807 | Accuracy: 0.8796 | Precision: 0.8647 | Recall: 0.8911\n",
      "Epoch 08 | Training Loss: 0.0007 | Val Loss: 0.5026 | Accuracy: 0.8788 | Precision: 0.8619 | Recall: 0.8932\n",
      "Epoch 09 | Training Loss: 0.0005 | Val Loss: 0.5192 | Accuracy: 0.8782 | Precision: 0.8634 | Recall: 0.8894\n",
      "Epoch 10 | Training Loss: 0.0004 | Val Loss: 0.5357 | Accuracy: 0.8788 | Precision: 0.8636 | Recall: 0.8907\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4112 | Test Accuracy: 0.8668 | Test Precision: 0.8684 | Test Recall: 0.8645\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 8...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4689 | Val Loss: 0.3270 | Accuracy: 0.8624 | Precision: 0.8401 | Recall: 0.8845\n",
      "Epoch 02 | Training Loss: 0.0882 | Val Loss: 0.3387 | Accuracy: 0.8762 | Precision: 0.8858 | Recall: 0.8548\n",
      "Epoch 03 | Training Loss: 0.0237 | Val Loss: 0.3693 | Accuracy: 0.8784 | Precision: 0.8734 | Recall: 0.8762\n",
      "Epoch 04 | Training Loss: 0.0072 | Val Loss: 0.4109 | Accuracy: 0.8786 | Precision: 0.8674 | Recall: 0.8849\n",
      "Epoch 05 | Training Loss: 0.0031 | Val Loss: 0.4451 | Accuracy: 0.8800 | Precision: 0.8639 | Recall: 0.8932\n",
      "Epoch 06 | Training Loss: 0.0018 | Val Loss: 0.4720 | Accuracy: 0.8810 | Precision: 0.8657 | Recall: 0.8932\n",
      "Epoch 07 | Training Loss: 0.0011 | Val Loss: 0.4945 | Accuracy: 0.8798 | Precision: 0.8674 | Recall: 0.8878\n",
      "Epoch 08 | Training Loss: 0.0008 | Val Loss: 0.5145 | Accuracy: 0.8800 | Precision: 0.8686 | Recall: 0.8866\n",
      "Epoch 09 | Training Loss: 0.0005 | Val Loss: 0.5326 | Accuracy: 0.8806 | Precision: 0.8679 | Recall: 0.8890\n",
      "Epoch 10 | Training Loss: 0.0004 | Val Loss: 0.5487 | Accuracy: 0.8804 | Precision: 0.8681 | Recall: 0.8882\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4312 | Test Accuracy: 0.8651 | Test Precision: 0.8682 | Test Recall: 0.8608\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 8...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4444 | Val Loss: 0.3255 | Accuracy: 0.8686 | Precision: 0.8330 | Recall: 0.9117\n",
      "Epoch 02 | Training Loss: 0.0837 | Val Loss: 0.3246 | Accuracy: 0.8794 | Precision: 0.8609 | Recall: 0.8960\n",
      "Epoch 03 | Training Loss: 0.0223 | Val Loss: 0.3652 | Accuracy: 0.8808 | Precision: 0.8740 | Recall: 0.8812\n",
      "Epoch 04 | Training Loss: 0.0065 | Val Loss: 0.4080 | Accuracy: 0.8804 | Precision: 0.8823 | Recall: 0.8692\n",
      "Epoch 05 | Training Loss: 0.0028 | Val Loss: 0.4399 | Accuracy: 0.8826 | Precision: 0.8766 | Recall: 0.8820\n",
      "Epoch 06 | Training Loss: 0.0015 | Val Loss: 0.4693 | Accuracy: 0.8836 | Precision: 0.8702 | Recall: 0.8932\n",
      "Epoch 07 | Training Loss: 0.0010 | Val Loss: 0.4920 | Accuracy: 0.8842 | Precision: 0.8712 | Recall: 0.8932\n",
      "Epoch 08 | Training Loss: 0.0007 | Val Loss: 0.5108 | Accuracy: 0.8828 | Precision: 0.8748 | Recall: 0.8849\n",
      "Epoch 09 | Training Loss: 0.0005 | Val Loss: 0.5287 | Accuracy: 0.8818 | Precision: 0.8718 | Recall: 0.8866\n",
      "Epoch 10 | Training Loss: 0.0004 | Val Loss: 0.5460 | Accuracy: 0.8824 | Precision: 0.8699 | Recall: 0.8907\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4242 | Test Accuracy: 0.8630 | Test Precision: 0.8652 | Test Recall: 0.8599\n",
      "\n",
      "Training for parameter combination: 9, \n",
      "\n",
      "parameters: [3, 'Tanh', 0.001, 'SGD', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 9...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7657 | Val Loss: 0.7255 | Accuracy: 0.5600 | Precision: 0.5454 | Recall: 0.5553\n",
      "Epoch 02 | Training Loss: 0.7147 | Val Loss: 0.6863 | Accuracy: 0.5944 | Precision: 0.5820 | Recall: 0.5796\n",
      "Epoch 03 | Training Loss: 0.6800 | Val Loss: 0.6593 | Accuracy: 0.6214 | Precision: 0.6096 | Recall: 0.6093\n",
      "Epoch 04 | Training Loss: 0.6547 | Val Loss: 0.6391 | Accuracy: 0.6394 | Precision: 0.6273 | Recall: 0.6312\n",
      "Epoch 05 | Training Loss: 0.6349 | Val Loss: 0.6234 | Accuracy: 0.6534 | Precision: 0.6404 | Recall: 0.6502\n",
      "Epoch 06 | Training Loss: 0.6189 | Val Loss: 0.6099 | Accuracy: 0.6638 | Precision: 0.6541 | Recall: 0.6506\n",
      "Epoch 07 | Training Loss: 0.6053 | Val Loss: 0.5988 | Accuracy: 0.6738 | Precision: 0.6635 | Recall: 0.6638\n",
      "Epoch 08 | Training Loss: 0.5933 | Val Loss: 0.5887 | Accuracy: 0.6826 | Precision: 0.6786 | Recall: 0.6559\n",
      "Epoch 09 | Training Loss: 0.5828 | Val Loss: 0.5803 | Accuracy: 0.6926 | Precision: 0.6838 | Recall: 0.6807\n",
      "Epoch 10 | Training Loss: 0.5731 | Val Loss: 0.5723 | Accuracy: 0.7006 | Precision: 0.6919 | Recall: 0.6894\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6076 | Test Accuracy: 0.6900 | Test Precision: 0.6902 | Test Recall: 0.6896\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 9...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7778 | Val Loss: 0.7484 | Accuracy: 0.5238 | Precision: 0.5085 | Recall: 0.5309\n",
      "Epoch 02 | Training Loss: 0.7320 | Val Loss: 0.7140 | Accuracy: 0.5550 | Precision: 0.5397 | Recall: 0.5578\n",
      "Epoch 03 | Training Loss: 0.7011 | Val Loss: 0.6901 | Accuracy: 0.5776 | Precision: 0.5613 | Recall: 0.5895\n",
      "Epoch 04 | Training Loss: 0.6786 | Val Loss: 0.6715 | Accuracy: 0.5950 | Precision: 0.5796 | Recall: 0.5990\n",
      "Epoch 05 | Training Loss: 0.6611 | Val Loss: 0.6576 | Accuracy: 0.6162 | Precision: 0.5977 | Recall: 0.6374\n",
      "Epoch 06 | Training Loss: 0.6470 | Val Loss: 0.6453 | Accuracy: 0.6294 | Precision: 0.6121 | Recall: 0.6432\n",
      "Epoch 07 | Training Loss: 0.6348 | Val Loss: 0.6344 | Accuracy: 0.6440 | Precision: 0.6308 | Recall: 0.6407\n",
      "Epoch 08 | Training Loss: 0.6242 | Val Loss: 0.6253 | Accuracy: 0.6558 | Precision: 0.6413 | Recall: 0.6580\n",
      "Epoch 09 | Training Loss: 0.6147 | Val Loss: 0.6168 | Accuracy: 0.6684 | Precision: 0.6559 | Recall: 0.6646\n",
      "Epoch 10 | Training Loss: 0.6059 | Val Loss: 0.6093 | Accuracy: 0.6770 | Precision: 0.6616 | Recall: 0.6832\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6520 | Test Accuracy: 0.6652 | Test Precision: 0.6624 | Test Recall: 0.6736\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 9...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7784 | Val Loss: 0.7482 | Accuracy: 0.5386 | Precision: 0.5237 | Recall: 0.5330\n",
      "Epoch 02 | Training Loss: 0.7298 | Val Loss: 0.7126 | Accuracy: 0.5670 | Precision: 0.5524 | Recall: 0.5635\n",
      "Epoch 03 | Training Loss: 0.6965 | Val Loss: 0.6878 | Accuracy: 0.5930 | Precision: 0.5764 | Recall: 0.6052\n",
      "Epoch 04 | Training Loss: 0.6720 | Val Loss: 0.6677 | Accuracy: 0.6100 | Precision: 0.5968 | Recall: 0.6027\n",
      "Epoch 05 | Training Loss: 0.6528 | Val Loss: 0.6525 | Accuracy: 0.6280 | Precision: 0.6135 | Recall: 0.6287\n",
      "Epoch 06 | Training Loss: 0.6370 | Val Loss: 0.6398 | Accuracy: 0.6430 | Precision: 0.6284 | Recall: 0.6452\n",
      "Epoch 07 | Training Loss: 0.6237 | Val Loss: 0.6289 | Accuracy: 0.6522 | Precision: 0.6373 | Recall: 0.6559\n",
      "Epoch 08 | Training Loss: 0.6120 | Val Loss: 0.6190 | Accuracy: 0.6594 | Precision: 0.6466 | Recall: 0.6559\n",
      "Epoch 09 | Training Loss: 0.6015 | Val Loss: 0.6104 | Accuracy: 0.6684 | Precision: 0.6542 | Recall: 0.6704\n",
      "Epoch 10 | Training Loss: 0.5918 | Val Loss: 0.6024 | Accuracy: 0.6782 | Precision: 0.6636 | Recall: 0.6819\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6338 | Test Accuracy: 0.6730 | Test Precision: 0.6706 | Test Recall: 0.6799\n",
      "\n",
      "Training for parameter combination: 10, \n",
      "\n",
      "parameters: [3, 'Tanh', 0.0001, 'RMSProp', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 10...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5844 | Val Loss: 0.4820 | Accuracy: 0.7732 | Precision: 0.7701 | Recall: 0.7587\n",
      "Epoch 02 | Training Loss: 0.3840 | Val Loss: 0.3997 | Accuracy: 0.8258 | Precision: 0.8080 | Recall: 0.8403\n",
      "Epoch 03 | Training Loss: 0.2895 | Val Loss: 0.3732 | Accuracy: 0.8418 | Precision: 0.8144 | Recall: 0.8725\n",
      "Epoch 04 | Training Loss: 0.2262 | Val Loss: 0.3649 | Accuracy: 0.8516 | Precision: 0.8217 | Recall: 0.8861\n",
      "Epoch 05 | Training Loss: 0.1775 | Val Loss: 0.3557 | Accuracy: 0.8554 | Precision: 0.8473 | Recall: 0.8560\n",
      "Epoch 06 | Training Loss: 0.1373 | Val Loss: 0.3653 | Accuracy: 0.8582 | Precision: 0.8401 | Recall: 0.8738\n",
      "Epoch 07 | Training Loss: 0.1039 | Val Loss: 0.3793 | Accuracy: 0.8592 | Precision: 0.8432 | Recall: 0.8717\n",
      "Epoch 08 | Training Loss: 0.0757 | Val Loss: 0.4052 | Accuracy: 0.8600 | Precision: 0.8394 | Recall: 0.8795\n",
      "Epoch 09 | Training Loss: 0.0533 | Val Loss: 0.4276 | Accuracy: 0.8600 | Precision: 0.8513 | Recall: 0.8618\n",
      "Epoch 10 | Training Loss: 0.0357 | Val Loss: 0.4636 | Accuracy: 0.8584 | Precision: 0.8578 | Recall: 0.8486\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3903 | Test Accuracy: 0.8529 | Test Precision: 0.8670 | Test Recall: 0.8337\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 10...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6020 | Val Loss: 0.4899 | Accuracy: 0.7612 | Precision: 0.7266 | Recall: 0.8135\n",
      "Epoch 02 | Training Loss: 0.3926 | Val Loss: 0.4020 | Accuracy: 0.8098 | Precision: 0.8010 | Recall: 0.8086\n",
      "Epoch 03 | Training Loss: 0.2934 | Val Loss: 0.3672 | Accuracy: 0.8322 | Precision: 0.8149 | Recall: 0.8461\n",
      "Epoch 04 | Training Loss: 0.2277 | Val Loss: 0.3551 | Accuracy: 0.8440 | Precision: 0.8179 | Recall: 0.8725\n",
      "Epoch 05 | Training Loss: 0.1779 | Val Loss: 0.3538 | Accuracy: 0.8522 | Precision: 0.8224 | Recall: 0.8866\n",
      "Epoch 06 | Training Loss: 0.1375 | Val Loss: 0.3503 | Accuracy: 0.8584 | Precision: 0.8474 | Recall: 0.8634\n",
      "Epoch 07 | Training Loss: 0.1042 | Val Loss: 0.3629 | Accuracy: 0.8594 | Precision: 0.8376 | Recall: 0.8808\n",
      "Epoch 08 | Training Loss: 0.0771 | Val Loss: 0.3783 | Accuracy: 0.8610 | Precision: 0.8410 | Recall: 0.8795\n",
      "Epoch 09 | Training Loss: 0.0546 | Val Loss: 0.3952 | Accuracy: 0.8592 | Precision: 0.8604 | Recall: 0.8469\n",
      "Epoch 10 | Training Loss: 0.0375 | Val Loss: 0.4327 | Accuracy: 0.8596 | Precision: 0.8374 | Recall: 0.8816\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4282 | Test Accuracy: 0.8570 | Test Precision: 0.8462 | Test Recall: 0.8726\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 10...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5888 | Val Loss: 0.4755 | Accuracy: 0.7722 | Precision: 0.7714 | Recall: 0.7533\n",
      "Epoch 02 | Training Loss: 0.3792 | Val Loss: 0.4009 | Accuracy: 0.8198 | Precision: 0.8368 | Recall: 0.7805\n",
      "Epoch 03 | Training Loss: 0.2812 | Val Loss: 0.3651 | Accuracy: 0.8434 | Precision: 0.8237 | Recall: 0.8614\n",
      "Epoch 04 | Training Loss: 0.2167 | Val Loss: 0.3607 | Accuracy: 0.8498 | Precision: 0.8163 | Recall: 0.8907\n",
      "Epoch 05 | Training Loss: 0.1680 | Val Loss: 0.3536 | Accuracy: 0.8542 | Precision: 0.8478 | Recall: 0.8523\n",
      "Epoch 06 | Training Loss: 0.1287 | Val Loss: 0.3605 | Accuracy: 0.8586 | Precision: 0.8486 | Recall: 0.8622\n",
      "Epoch 07 | Training Loss: 0.0972 | Val Loss: 0.3744 | Accuracy: 0.8592 | Precision: 0.8397 | Recall: 0.8771\n",
      "Epoch 08 | Training Loss: 0.0705 | Val Loss: 0.3947 | Accuracy: 0.8608 | Precision: 0.8388 | Recall: 0.8824\n",
      "Epoch 09 | Training Loss: 0.0496 | Val Loss: 0.4378 | Accuracy: 0.8554 | Precision: 0.8179 | Recall: 0.9026\n",
      "Epoch 10 | Training Loss: 0.0339 | Val Loss: 0.4466 | Accuracy: 0.8616 | Precision: 0.8412 | Recall: 0.8808\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4676 | Test Accuracy: 0.8524 | Test Precision: 0.8446 | Test Recall: 0.8637\n",
      "\n",
      "Training for parameter combination: 11, \n",
      "\n",
      "parameters: [1, 'Tanh', 0.0005, 'Adam', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 11...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3758 | Val Loss: 0.2879 | Accuracy: 0.8858 | Precision: 0.8743 | Recall: 0.8927\n",
      "Epoch 02 | Training Loss: 0.0596 | Val Loss: 0.3107 | Accuracy: 0.8872 | Precision: 0.8673 | Recall: 0.9059\n",
      "Epoch 03 | Training Loss: 0.0150 | Val Loss: 0.3398 | Accuracy: 0.8870 | Precision: 0.8684 | Recall: 0.9039\n",
      "Epoch 04 | Training Loss: 0.0044 | Val Loss: 0.3684 | Accuracy: 0.8876 | Precision: 0.8668 | Recall: 0.9076\n",
      "Epoch 05 | Training Loss: 0.0019 | Val Loss: 0.3873 | Accuracy: 0.8874 | Precision: 0.8766 | Recall: 0.8936\n",
      "Epoch 06 | Training Loss: 0.0010 | Val Loss: 0.4078 | Accuracy: 0.8874 | Precision: 0.8760 | Recall: 0.8944\n",
      "Epoch 07 | Training Loss: 0.0006 | Val Loss: 0.4259 | Accuracy: 0.8880 | Precision: 0.8817 | Recall: 0.8882\n",
      "Epoch 08 | Training Loss: 0.0004 | Val Loss: 0.4467 | Accuracy: 0.8874 | Precision: 0.8763 | Recall: 0.8940\n",
      "Epoch 09 | Training Loss: 0.0003 | Val Loss: 0.4652 | Accuracy: 0.8880 | Precision: 0.8792 | Recall: 0.8915\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.4841 | Accuracy: 0.8872 | Precision: 0.8793 | Recall: 0.8894\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3160 | Test Accuracy: 0.8651 | Test Precision: 0.8721 | Test Recall: 0.8558\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 11...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3719 | Val Loss: 0.3062 | Accuracy: 0.8764 | Precision: 0.8538 | Recall: 0.8989\n",
      "Epoch 02 | Training Loss: 0.0562 | Val Loss: 0.3747 | Accuracy: 0.8660 | Precision: 0.8161 | Recall: 0.9340\n",
      "Epoch 03 | Training Loss: 0.0144 | Val Loss: 0.3568 | Accuracy: 0.8814 | Precision: 0.8723 | Recall: 0.8849\n",
      "Epoch 04 | Training Loss: 0.0044 | Val Loss: 0.3874 | Accuracy: 0.8798 | Precision: 0.8677 | Recall: 0.8874\n",
      "Epoch 05 | Training Loss: 0.0018 | Val Loss: 0.4109 | Accuracy: 0.8822 | Precision: 0.8802 | Recall: 0.8762\n",
      "Epoch 06 | Training Loss: 0.0010 | Val Loss: 0.4329 | Accuracy: 0.8798 | Precision: 0.8671 | Recall: 0.8882\n",
      "Epoch 07 | Training Loss: 0.0006 | Val Loss: 0.4544 | Accuracy: 0.8788 | Precision: 0.8639 | Recall: 0.8903\n",
      "Epoch 08 | Training Loss: 0.0004 | Val Loss: 0.4752 | Accuracy: 0.8786 | Precision: 0.8618 | Recall: 0.8927\n",
      "Epoch 09 | Training Loss: 0.0003 | Val Loss: 0.4921 | Accuracy: 0.8814 | Precision: 0.8711 | Recall: 0.8866\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.5117 | Accuracy: 0.8814 | Precision: 0.8693 | Recall: 0.8890\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3182 | Test Accuracy: 0.8655 | Test Precision: 0.8708 | Test Recall: 0.8582\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 11...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3751 | Val Loss: 0.3016 | Accuracy: 0.8756 | Precision: 0.9059 | Recall: 0.8296\n",
      "Epoch 02 | Training Loss: 0.0589 | Val Loss: 0.3151 | Accuracy: 0.8778 | Precision: 0.8593 | Recall: 0.8944\n",
      "Epoch 03 | Training Loss: 0.0145 | Val Loss: 0.3508 | Accuracy: 0.8792 | Precision: 0.8563 | Recall: 0.9022\n",
      "Epoch 04 | Training Loss: 0.0045 | Val Loss: 0.3712 | Accuracy: 0.8834 | Precision: 0.8753 | Recall: 0.8857\n",
      "Epoch 05 | Training Loss: 0.0019 | Val Loss: 0.3949 | Accuracy: 0.8812 | Precision: 0.8690 | Recall: 0.8890\n",
      "Epoch 06 | Training Loss: 0.0010 | Val Loss: 0.4153 | Accuracy: 0.8822 | Precision: 0.8713 | Recall: 0.8882\n",
      "Epoch 07 | Training Loss: 0.0006 | Val Loss: 0.4347 | Accuracy: 0.8816 | Precision: 0.8754 | Recall: 0.8812\n",
      "Epoch 08 | Training Loss: 0.0004 | Val Loss: 0.4564 | Accuracy: 0.8808 | Precision: 0.8677 | Recall: 0.8899\n",
      "Epoch 09 | Training Loss: 0.0003 | Val Loss: 0.4724 | Accuracy: 0.8808 | Precision: 0.8734 | Recall: 0.8820\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.4916 | Accuracy: 0.8806 | Precision: 0.8715 | Recall: 0.8841\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3146 | Test Accuracy: 0.8654 | Test Precision: 0.8741 | Test Recall: 0.8537\n",
      "\n",
      "Training for parameter combination: 12, \n",
      "\n",
      "parameters: [2, 'LeakyReLU', 0.0001, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 12...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.1607 | Val Loss: 1.1165 | Accuracy: 0.5020 | Precision: 0.4873 | Recall: 0.5239\n",
      "Epoch 02 | Training Loss: 1.0600 | Val Loss: 1.0554 | Accuracy: 0.5158 | Precision: 0.5006 | Recall: 0.5371\n",
      "Epoch 03 | Training Loss: 1.0030 | Val Loss: 1.0042 | Accuracy: 0.5288 | Precision: 0.5131 | Recall: 0.5474\n",
      "Epoch 04 | Training Loss: 0.9553 | Val Loss: 0.9608 | Accuracy: 0.5384 | Precision: 0.5228 | Recall: 0.5495\n",
      "Epoch 05 | Training Loss: 0.9148 | Val Loss: 0.9244 | Accuracy: 0.5478 | Precision: 0.5315 | Recall: 0.5681\n",
      "Epoch 06 | Training Loss: 0.8801 | Val Loss: 0.8919 | Accuracy: 0.5554 | Precision: 0.5393 | Recall: 0.5685\n",
      "Epoch 07 | Training Loss: 0.8502 | Val Loss: 0.8636 | Accuracy: 0.5632 | Precision: 0.5480 | Recall: 0.5648\n",
      "Epoch 08 | Training Loss: 0.8242 | Val Loss: 0.8400 | Accuracy: 0.5746 | Precision: 0.5584 | Recall: 0.5858\n",
      "Epoch 09 | Training Loss: 0.8014 | Val Loss: 0.8182 | Accuracy: 0.5824 | Precision: 0.5674 | Recall: 0.5833\n",
      "Epoch 10 | Training Loss: 0.7810 | Val Loss: 0.7996 | Accuracy: 0.5876 | Precision: 0.5717 | Recall: 0.5957\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6711 | Test Accuracy: 0.6045 | Test Precision: 0.6010 | Test Recall: 0.6222\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 12...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.1405 | Val Loss: 1.0880 | Accuracy: 0.5044 | Precision: 0.4894 | Recall: 0.5136\n",
      "Epoch 02 | Training Loss: 1.0659 | Val Loss: 1.0219 | Accuracy: 0.5238 | Precision: 0.5085 | Recall: 0.5289\n",
      "Epoch 03 | Training Loss: 1.0043 | Val Loss: 0.9666 | Accuracy: 0.5406 | Precision: 0.5257 | Recall: 0.5367\n",
      "Epoch 04 | Training Loss: 0.9527 | Val Loss: 0.9230 | Accuracy: 0.5510 | Precision: 0.5350 | Recall: 0.5639\n",
      "Epoch 05 | Training Loss: 0.9095 | Val Loss: 0.8830 | Accuracy: 0.5618 | Precision: 0.5472 | Recall: 0.5573\n",
      "Epoch 06 | Training Loss: 0.8725 | Val Loss: 0.8500 | Accuracy: 0.5742 | Precision: 0.5610 | Recall: 0.5594\n",
      "Epoch 07 | Training Loss: 0.8411 | Val Loss: 0.8224 | Accuracy: 0.5846 | Precision: 0.5701 | Recall: 0.5821\n",
      "Epoch 08 | Training Loss: 0.8138 | Val Loss: 0.7993 | Accuracy: 0.5910 | Precision: 0.5745 | Recall: 0.6027\n",
      "Epoch 09 | Training Loss: 0.7901 | Val Loss: 0.7776 | Accuracy: 0.5980 | Precision: 0.5830 | Recall: 0.5998\n",
      "Epoch 10 | Training Loss: 0.7694 | Val Loss: 0.7603 | Accuracy: 0.6064 | Precision: 0.5895 | Recall: 0.6196\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.8230 | Test Accuracy: 0.6072 | Test Precision: 0.6057 | Test Recall: 0.6140\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 12...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.1313 | Val Loss: 1.0727 | Accuracy: 0.5102 | Precision: 0.4948 | Recall: 0.4955\n",
      "Epoch 02 | Training Loss: 1.0451 | Val Loss: 1.0200 | Accuracy: 0.5226 | Precision: 0.5077 | Recall: 0.5025\n",
      "Epoch 03 | Training Loss: 0.9954 | Val Loss: 0.9750 | Accuracy: 0.5340 | Precision: 0.5196 | Recall: 0.5128\n",
      "Epoch 04 | Training Loss: 0.9527 | Val Loss: 0.9365 | Accuracy: 0.5470 | Precision: 0.5325 | Recall: 0.5371\n",
      "Epoch 05 | Training Loss: 0.9156 | Val Loss: 0.9026 | Accuracy: 0.5560 | Precision: 0.5419 | Recall: 0.5441\n",
      "Epoch 06 | Training Loss: 0.8832 | Val Loss: 0.8729 | Accuracy: 0.5660 | Precision: 0.5525 | Recall: 0.5512\n",
      "Epoch 07 | Training Loss: 0.8548 | Val Loss: 0.8475 | Accuracy: 0.5738 | Precision: 0.5594 | Recall: 0.5689\n",
      "Epoch 08 | Training Loss: 0.8296 | Val Loss: 0.8238 | Accuracy: 0.5860 | Precision: 0.5744 | Recall: 0.5635\n",
      "Epoch 09 | Training Loss: 0.8075 | Val Loss: 0.8035 | Accuracy: 0.5922 | Precision: 0.5804 | Recall: 0.5730\n",
      "Epoch 10 | Training Loss: 0.7877 | Val Loss: 0.7851 | Accuracy: 0.6006 | Precision: 0.5895 | Recall: 0.5800\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6596 | Test Accuracy: 0.6047 | Test Precision: 0.6069 | Test Recall: 0.5942\n",
      "\n",
      "Training for parameter combination: 13, \n",
      "\n",
      "parameters: [2, 'LeakyReLU', 0.001, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 13...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9090 | Val Loss: 0.7787 | Accuracy: 0.6116 | Precision: 0.6075 | Recall: 0.5619\n",
      "Epoch 02 | Training Loss: 0.7015 | Val Loss: 0.6858 | Accuracy: 0.6492 | Precision: 0.6209 | Recall: 0.7100\n",
      "Epoch 03 | Training Loss: 0.6247 | Val Loss: 0.6290 | Accuracy: 0.6800 | Precision: 0.6776 | Recall: 0.6485\n",
      "Epoch 04 | Training Loss: 0.5834 | Val Loss: 0.6028 | Accuracy: 0.6982 | Precision: 0.6748 | Recall: 0.7285\n",
      "Epoch 05 | Training Loss: 0.5567 | Val Loss: 0.5825 | Accuracy: 0.7110 | Precision: 0.6898 | Recall: 0.7339\n",
      "Epoch 06 | Training Loss: 0.5372 | Val Loss: 0.5665 | Accuracy: 0.7234 | Precision: 0.7060 | Recall: 0.7360\n",
      "Epoch 07 | Training Loss: 0.5216 | Val Loss: 0.5570 | Accuracy: 0.7304 | Precision: 0.7058 | Recall: 0.7611\n",
      "Epoch 08 | Training Loss: 0.5082 | Val Loss: 0.5445 | Accuracy: 0.7348 | Precision: 0.7256 | Recall: 0.7285\n",
      "Epoch 09 | Training Loss: 0.4973 | Val Loss: 0.5372 | Accuracy: 0.7424 | Precision: 0.7207 | Recall: 0.7653\n",
      "Epoch 10 | Training Loss: 0.4870 | Val Loss: 0.5301 | Accuracy: 0.7468 | Precision: 0.7237 | Recall: 0.7727\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5006 | Test Accuracy: 0.7470 | Test Precision: 0.7367 | Test Recall: 0.7688\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 13...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8842 | Val Loss: 0.7439 | Accuracy: 0.6136 | Precision: 0.6009 | Recall: 0.6044\n",
      "Epoch 02 | Training Loss: 0.6885 | Val Loss: 0.6474 | Accuracy: 0.6628 | Precision: 0.6574 | Recall: 0.6357\n",
      "Epoch 03 | Training Loss: 0.6161 | Val Loss: 0.6040 | Accuracy: 0.6872 | Precision: 0.6871 | Recall: 0.6514\n",
      "Epoch 04 | Training Loss: 0.5776 | Val Loss: 0.5847 | Accuracy: 0.7020 | Precision: 0.6711 | Recall: 0.7558\n",
      "Epoch 05 | Training Loss: 0.5521 | Val Loss: 0.5599 | Accuracy: 0.7134 | Precision: 0.6975 | Recall: 0.7219\n",
      "Epoch 06 | Training Loss: 0.5336 | Val Loss: 0.5459 | Accuracy: 0.7246 | Precision: 0.7093 | Recall: 0.7318\n",
      "Epoch 07 | Training Loss: 0.5183 | Val Loss: 0.5363 | Accuracy: 0.7286 | Precision: 0.7374 | Recall: 0.6836\n",
      "Epoch 08 | Training Loss: 0.5058 | Val Loss: 0.5250 | Accuracy: 0.7384 | Precision: 0.7352 | Recall: 0.7195\n",
      "Epoch 09 | Training Loss: 0.4943 | Val Loss: 0.5167 | Accuracy: 0.7460 | Precision: 0.7408 | Recall: 0.7323\n",
      "Epoch 10 | Training Loss: 0.4844 | Val Loss: 0.5096 | Accuracy: 0.7526 | Precision: 0.7369 | Recall: 0.7616\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5752 | Test Accuracy: 0.7500 | Test Precision: 0.7533 | Test Recall: 0.7434\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 13...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8767 | Val Loss: 0.7481 | Accuracy: 0.6184 | Precision: 0.6053 | Recall: 0.6118\n",
      "Epoch 02 | Training Loss: 0.6821 | Val Loss: 0.6507 | Accuracy: 0.6624 | Precision: 0.6438 | Recall: 0.6799\n",
      "Epoch 03 | Training Loss: 0.6104 | Val Loss: 0.6025 | Accuracy: 0.6892 | Precision: 0.6793 | Recall: 0.6799\n",
      "Epoch 04 | Training Loss: 0.5713 | Val Loss: 0.5747 | Accuracy: 0.7068 | Precision: 0.7001 | Recall: 0.6914\n",
      "Epoch 05 | Training Loss: 0.5456 | Val Loss: 0.5568 | Accuracy: 0.7196 | Precision: 0.7028 | Recall: 0.7306\n",
      "Epoch 06 | Training Loss: 0.5262 | Val Loss: 0.5417 | Accuracy: 0.7300 | Precision: 0.7183 | Recall: 0.7290\n",
      "Epoch 07 | Training Loss: 0.5109 | Val Loss: 0.5299 | Accuracy: 0.7392 | Precision: 0.7385 | Recall: 0.7153\n",
      "Epoch 08 | Training Loss: 0.4978 | Val Loss: 0.5212 | Accuracy: 0.7430 | Precision: 0.7294 | Recall: 0.7471\n",
      "Epoch 09 | Training Loss: 0.4869 | Val Loss: 0.5129 | Accuracy: 0.7486 | Precision: 0.7359 | Recall: 0.7508\n",
      "Epoch 10 | Training Loss: 0.4769 | Val Loss: 0.5053 | Accuracy: 0.7538 | Precision: 0.7550 | Recall: 0.7285\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5147 | Test Accuracy: 0.7579 | Test Precision: 0.7722 | Test Recall: 0.7317\n",
      "\n",
      "Training for parameter combination: 14, \n",
      "\n",
      "parameters: [1, 'LeakyReLU', 0.0001, 'RMSProp', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 14...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7331 | Val Loss: 0.5309 | Accuracy: 0.7566 | Precision: 0.7524 | Recall: 0.7422\n",
      "Epoch 02 | Training Loss: 0.3944 | Val Loss: 0.4115 | Accuracy: 0.8192 | Precision: 0.8146 | Recall: 0.8119\n",
      "Epoch 03 | Training Loss: 0.2922 | Val Loss: 0.3704 | Accuracy: 0.8416 | Precision: 0.8288 | Recall: 0.8486\n",
      "Epoch 04 | Training Loss: 0.2377 | Val Loss: 0.3515 | Accuracy: 0.8518 | Precision: 0.8320 | Recall: 0.8700\n",
      "Epoch 05 | Training Loss: 0.2011 | Val Loss: 0.3416 | Accuracy: 0.8548 | Precision: 0.8546 | Recall: 0.8441\n",
      "Epoch 06 | Training Loss: 0.1742 | Val Loss: 0.3341 | Accuracy: 0.8608 | Precision: 0.8481 | Recall: 0.8684\n",
      "Epoch 07 | Training Loss: 0.1527 | Val Loss: 0.3336 | Accuracy: 0.8642 | Precision: 0.8412 | Recall: 0.8874\n",
      "Epoch 08 | Training Loss: 0.1354 | Val Loss: 0.3317 | Accuracy: 0.8616 | Precision: 0.8552 | Recall: 0.8601\n",
      "Epoch 09 | Training Loss: 0.1206 | Val Loss: 0.3314 | Accuracy: 0.8654 | Precision: 0.8546 | Recall: 0.8705\n",
      "Epoch 10 | Training Loss: 0.1074 | Val Loss: 0.3331 | Accuracy: 0.8654 | Precision: 0.8515 | Recall: 0.8750\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4095 | Test Accuracy: 0.8662 | Test Precision: 0.8634 | Test Recall: 0.8699\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 14...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7076 | Val Loss: 0.5190 | Accuracy: 0.7628 | Precision: 0.7339 | Recall: 0.8012\n",
      "Epoch 02 | Training Loss: 0.3967 | Val Loss: 0.4194 | Accuracy: 0.8208 | Precision: 0.8485 | Recall: 0.7673\n",
      "Epoch 03 | Training Loss: 0.2957 | Val Loss: 0.3715 | Accuracy: 0.8424 | Precision: 0.8350 | Recall: 0.8412\n",
      "Epoch 04 | Training Loss: 0.2406 | Val Loss: 0.3565 | Accuracy: 0.8536 | Precision: 0.8318 | Recall: 0.8750\n",
      "Epoch 05 | Training Loss: 0.2044 | Val Loss: 0.3456 | Accuracy: 0.8570 | Precision: 0.8384 | Recall: 0.8733\n",
      "Epoch 06 | Training Loss: 0.1775 | Val Loss: 0.3381 | Accuracy: 0.8614 | Precision: 0.8503 | Recall: 0.8667\n",
      "Epoch 07 | Training Loss: 0.1557 | Val Loss: 0.3381 | Accuracy: 0.8642 | Precision: 0.8695 | Recall: 0.8469\n",
      "Epoch 08 | Training Loss: 0.1377 | Val Loss: 0.3381 | Accuracy: 0.8646 | Precision: 0.8424 | Recall: 0.8866\n",
      "Epoch 09 | Training Loss: 0.1225 | Val Loss: 0.3356 | Accuracy: 0.8674 | Precision: 0.8507 | Recall: 0.8812\n",
      "Epoch 10 | Training Loss: 0.1091 | Val Loss: 0.3417 | Accuracy: 0.8668 | Precision: 0.8428 | Recall: 0.8915\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4017 | Test Accuracy: 0.8634 | Test Precision: 0.8492 | Test Recall: 0.8838\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 14...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6968 | Val Loss: 0.5161 | Accuracy: 0.7618 | Precision: 0.7493 | Recall: 0.7644\n",
      "Epoch 02 | Training Loss: 0.3860 | Val Loss: 0.4086 | Accuracy: 0.8224 | Precision: 0.8235 | Recall: 0.8065\n",
      "Epoch 03 | Training Loss: 0.2874 | Val Loss: 0.3682 | Accuracy: 0.8466 | Precision: 0.8356 | Recall: 0.8511\n",
      "Epoch 04 | Training Loss: 0.2347 | Val Loss: 0.3507 | Accuracy: 0.8526 | Precision: 0.8576 | Recall: 0.8346\n",
      "Epoch 05 | Training Loss: 0.1998 | Val Loss: 0.3407 | Accuracy: 0.8614 | Precision: 0.8657 | Recall: 0.8453\n",
      "Epoch 06 | Training Loss: 0.1735 | Val Loss: 0.3350 | Accuracy: 0.8650 | Precision: 0.8704 | Recall: 0.8478\n",
      "Epoch 07 | Training Loss: 0.1522 | Val Loss: 0.3383 | Accuracy: 0.8646 | Precision: 0.8340 | Recall: 0.8998\n",
      "Epoch 08 | Training Loss: 0.1348 | Val Loss: 0.3389 | Accuracy: 0.8650 | Precision: 0.8316 | Recall: 0.9047\n",
      "Epoch 09 | Training Loss: 0.1200 | Val Loss: 0.3317 | Accuracy: 0.8680 | Precision: 0.8618 | Recall: 0.8667\n",
      "Epoch 10 | Training Loss: 0.1075 | Val Loss: 0.3364 | Accuracy: 0.8714 | Precision: 0.8466 | Recall: 0.8973\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4160 | Test Accuracy: 0.8616 | Test Precision: 0.8513 | Test Recall: 0.8764\n",
      "\n",
      "Training for parameter combination: 15, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.001, 'RMSProp', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 15...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4316 | Val Loss: 0.3274 | Accuracy: 0.8634 | Precision: 0.8157 | Recall: 0.9278\n",
      "Epoch 02 | Training Loss: 0.1506 | Val Loss: 0.3941 | Accuracy: 0.8644 | Precision: 0.8152 | Recall: 0.9315\n",
      "Epoch 03 | Training Loss: 0.0394 | Val Loss: 0.5500 | Accuracy: 0.8716 | Precision: 0.8719 | Recall: 0.8618\n",
      "Epoch 04 | Training Loss: 0.0059 | Val Loss: 1.0612 | Accuracy: 0.8722 | Precision: 0.8540 | Recall: 0.8882\n",
      "Epoch 05 | Training Loss: 0.0027 | Val Loss: 1.3000 | Accuracy: 0.8736 | Precision: 0.8684 | Recall: 0.8713\n",
      "Epoch 06 | Training Loss: 0.0006 | Val Loss: 1.4892 | Accuracy: 0.8760 | Precision: 0.8496 | Recall: 0.9043\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 1.5618 | Accuracy: 0.8752 | Precision: 0.8620 | Recall: 0.8841\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 1.5890 | Accuracy: 0.8754 | Precision: 0.8641 | Recall: 0.8816\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 1.6153 | Accuracy: 0.8756 | Precision: 0.8633 | Recall: 0.8833\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.6302 | Accuracy: 0.8758 | Precision: 0.8645 | Recall: 0.8820\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4495 | Test Accuracy: 0.8696 | Test Precision: 0.8713 | Test Recall: 0.8674\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 15...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4241 | Val Loss: 0.4037 | Accuracy: 0.8320 | Precision: 0.7566 | Recall: 0.9633\n",
      "Epoch 02 | Training Loss: 0.1502 | Val Loss: 0.4626 | Accuracy: 0.8436 | Precision: 0.9376 | Recall: 0.7257\n",
      "Epoch 03 | Training Loss: 0.0422 | Val Loss: 0.5642 | Accuracy: 0.8752 | Precision: 0.8612 | Recall: 0.8853\n",
      "Epoch 04 | Training Loss: 0.0096 | Val Loss: 0.8983 | Accuracy: 0.8736 | Precision: 0.8875 | Recall: 0.8465\n",
      "Epoch 05 | Training Loss: 0.0020 | Val Loss: 1.2684 | Accuracy: 0.8754 | Precision: 0.8633 | Recall: 0.8828\n",
      "Epoch 06 | Training Loss: 0.0012 | Val Loss: 1.3849 | Accuracy: 0.8690 | Precision: 0.8678 | Recall: 0.8610\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 1.5141 | Accuracy: 0.8730 | Precision: 0.8677 | Recall: 0.8709\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 1.5555 | Accuracy: 0.8726 | Precision: 0.8669 | Recall: 0.8709\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 1.5846 | Accuracy: 0.8724 | Precision: 0.8666 | Recall: 0.8709\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.6077 | Accuracy: 0.8726 | Precision: 0.8666 | Recall: 0.8713\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3797 | Test Accuracy: 0.8676 | Test Precision: 0.8708 | Test Recall: 0.8634\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 15...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4322 | Val Loss: 0.3263 | Accuracy: 0.8592 | Precision: 0.8094 | Recall: 0.9282\n",
      "Epoch 02 | Training Loss: 0.1509 | Val Loss: 0.3444 | Accuracy: 0.8706 | Precision: 0.8544 | Recall: 0.8837\n",
      "Epoch 03 | Training Loss: 0.0423 | Val Loss: 0.5615 | Accuracy: 0.8666 | Precision: 0.9010 | Recall: 0.8144\n",
      "Epoch 04 | Training Loss: 0.0091 | Val Loss: 0.8782 | Accuracy: 0.8736 | Precision: 0.8787 | Recall: 0.8577\n",
      "Epoch 05 | Training Loss: 0.0038 | Val Loss: 1.2471 | Accuracy: 0.8692 | Precision: 0.8669 | Recall: 0.8626\n",
      "Epoch 06 | Training Loss: 0.0005 | Val Loss: 1.3568 | Accuracy: 0.8716 | Precision: 0.8722 | Recall: 0.8614\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 1.4827 | Accuracy: 0.8714 | Precision: 0.8648 | Recall: 0.8709\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 1.5248 | Accuracy: 0.8708 | Precision: 0.8605 | Recall: 0.8754\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 1.5534 | Accuracy: 0.8712 | Precision: 0.8606 | Recall: 0.8762\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.5766 | Accuracy: 0.8712 | Precision: 0.8600 | Recall: 0.8771\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3537 | Test Accuracy: 0.8690 | Test Precision: 0.8669 | Test Recall: 0.8719\n",
      "\n",
      "Training for parameter combination: 16, \n",
      "\n",
      "parameters: [1, 'Tanh', 0.001, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 16...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9248 | Val Loss: 0.8409 | Accuracy: 0.5730 | Precision: 0.5575 | Recall: 0.5776\n",
      "Epoch 02 | Training Loss: 0.7800 | Val Loss: 0.7373 | Accuracy: 0.6254 | Precision: 0.6149 | Recall: 0.6081\n",
      "Epoch 03 | Training Loss: 0.6913 | Val Loss: 0.6713 | Accuracy: 0.6592 | Precision: 0.6493 | Recall: 0.6460\n",
      "Epoch 04 | Training Loss: 0.6318 | Val Loss: 0.6264 | Accuracy: 0.6822 | Precision: 0.6675 | Recall: 0.6865\n",
      "Epoch 05 | Training Loss: 0.5895 | Val Loss: 0.5929 | Accuracy: 0.7054 | Precision: 0.6901 | Recall: 0.7120\n",
      "Epoch 06 | Training Loss: 0.5576 | Val Loss: 0.5674 | Accuracy: 0.7200 | Precision: 0.7068 | Recall: 0.7219\n",
      "Epoch 07 | Training Loss: 0.5327 | Val Loss: 0.5481 | Accuracy: 0.7314 | Precision: 0.7156 | Recall: 0.7401\n",
      "Epoch 08 | Training Loss: 0.5126 | Val Loss: 0.5332 | Accuracy: 0.7470 | Precision: 0.7270 | Recall: 0.7657\n",
      "Epoch 09 | Training Loss: 0.4960 | Val Loss: 0.5184 | Accuracy: 0.7510 | Precision: 0.7411 | Recall: 0.7475\n",
      "Epoch 10 | Training Loss: 0.4820 | Val Loss: 0.5081 | Accuracy: 0.7590 | Precision: 0.7435 | Recall: 0.7677\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4702 | Test Accuracy: 0.7592 | Test Precision: 0.7568 | Test Recall: 0.7637\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 16...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9008 | Val Loss: 0.8119 | Accuracy: 0.5840 | Precision: 0.5742 | Recall: 0.5491\n",
      "Epoch 02 | Training Loss: 0.7592 | Val Loss: 0.7144 | Accuracy: 0.6306 | Precision: 0.6194 | Recall: 0.6176\n",
      "Epoch 03 | Training Loss: 0.6769 | Val Loss: 0.6539 | Accuracy: 0.6696 | Precision: 0.6516 | Recall: 0.6844\n",
      "Epoch 04 | Training Loss: 0.6229 | Val Loss: 0.6107 | Accuracy: 0.6930 | Precision: 0.6847 | Recall: 0.6799\n",
      "Epoch 05 | Training Loss: 0.5843 | Val Loss: 0.5797 | Accuracy: 0.7126 | Precision: 0.7050 | Recall: 0.7001\n",
      "Epoch 06 | Training Loss: 0.5552 | Val Loss: 0.5559 | Accuracy: 0.7286 | Precision: 0.7193 | Recall: 0.7219\n",
      "Epoch 07 | Training Loss: 0.5323 | Val Loss: 0.5371 | Accuracy: 0.7394 | Precision: 0.7306 | Recall: 0.7327\n",
      "Epoch 08 | Training Loss: 0.5138 | Val Loss: 0.5221 | Accuracy: 0.7482 | Precision: 0.7329 | Recall: 0.7562\n",
      "Epoch 09 | Training Loss: 0.4984 | Val Loss: 0.5096 | Accuracy: 0.7564 | Precision: 0.7397 | Recall: 0.7677\n",
      "Epoch 10 | Training Loss: 0.4853 | Val Loss: 0.4985 | Accuracy: 0.7612 | Precision: 0.7490 | Recall: 0.7632\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5374 | Test Accuracy: 0.7616 | Test Precision: 0.7646 | Test Recall: 0.7558\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 16...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9019 | Val Loss: 0.8183 | Accuracy: 0.5856 | Precision: 0.5706 | Recall: 0.5870\n",
      "Epoch 02 | Training Loss: 0.7617 | Val Loss: 0.7175 | Accuracy: 0.6386 | Precision: 0.6282 | Recall: 0.6238\n",
      "Epoch 03 | Training Loss: 0.6774 | Val Loss: 0.6547 | Accuracy: 0.6742 | Precision: 0.6563 | Recall: 0.6885\n",
      "Epoch 04 | Training Loss: 0.6212 | Val Loss: 0.6101 | Accuracy: 0.6956 | Precision: 0.6811 | Recall: 0.6997\n",
      "Epoch 05 | Training Loss: 0.5813 | Val Loss: 0.5783 | Accuracy: 0.7146 | Precision: 0.6962 | Recall: 0.7298\n",
      "Epoch 06 | Training Loss: 0.5511 | Val Loss: 0.5539 | Accuracy: 0.7278 | Precision: 0.7092 | Recall: 0.7434\n",
      "Epoch 07 | Training Loss: 0.5272 | Val Loss: 0.5342 | Accuracy: 0.7370 | Precision: 0.7237 | Recall: 0.7401\n",
      "Epoch 08 | Training Loss: 0.5082 | Val Loss: 0.5197 | Accuracy: 0.7464 | Precision: 0.7251 | Recall: 0.7682\n",
      "Epoch 09 | Training Loss: 0.4925 | Val Loss: 0.5078 | Accuracy: 0.7574 | Precision: 0.7328 | Recall: 0.7863\n",
      "Epoch 10 | Training Loss: 0.4790 | Val Loss: 0.4953 | Accuracy: 0.7628 | Precision: 0.7429 | Recall: 0.7809\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5579 | Test Accuracy: 0.7603 | Test Precision: 0.7571 | Test Recall: 0.7666\n",
      "\n",
      "Training for parameter combination: 17, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.0001, 'SGD', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 17...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8594 | Val Loss: 0.8345 | Accuracy: 0.5340 | Precision: 0.5189 | Recall: 0.5322\n",
      "Epoch 02 | Training Loss: 0.8382 | Val Loss: 0.8197 | Accuracy: 0.5370 | Precision: 0.5219 | Recall: 0.5347\n",
      "Epoch 03 | Training Loss: 0.8233 | Val Loss: 0.8062 | Accuracy: 0.5436 | Precision: 0.5291 | Recall: 0.5330\n",
      "Epoch 04 | Training Loss: 0.8100 | Val Loss: 0.7943 | Accuracy: 0.5456 | Precision: 0.5316 | Recall: 0.5272\n",
      "Epoch 05 | Training Loss: 0.7982 | Val Loss: 0.7844 | Accuracy: 0.5488 | Precision: 0.5341 | Recall: 0.5433\n",
      "Epoch 06 | Training Loss: 0.7874 | Val Loss: 0.7753 | Accuracy: 0.5522 | Precision: 0.5369 | Recall: 0.5553\n",
      "Epoch 07 | Training Loss: 0.7775 | Val Loss: 0.7672 | Accuracy: 0.5562 | Precision: 0.5404 | Recall: 0.5660\n",
      "Epoch 08 | Training Loss: 0.7686 | Val Loss: 0.7585 | Accuracy: 0.5604 | Precision: 0.5458 | Recall: 0.5553\n",
      "Epoch 09 | Training Loss: 0.7605 | Val Loss: 0.7514 | Accuracy: 0.5638 | Precision: 0.5490 | Recall: 0.5615\n",
      "Epoch 10 | Training Loss: 0.7531 | Val Loss: 0.7453 | Accuracy: 0.5676 | Precision: 0.5519 | Recall: 0.5743\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7136 | Test Accuracy: 0.5538 | Test Precision: 0.5525 | Test Recall: 0.5654\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 17...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.2270 | Val Loss: 0.8801 | Accuracy: 0.5108 | Precision: 0.4959 | Recall: 0.5429\n",
      "Epoch 02 | Training Loss: 0.8851 | Val Loss: 0.8547 | Accuracy: 0.5218 | Precision: 0.5067 | Recall: 0.5169\n",
      "Epoch 03 | Training Loss: 0.8630 | Val Loss: 0.8371 | Accuracy: 0.5248 | Precision: 0.5093 | Recall: 0.5396\n",
      "Epoch 04 | Training Loss: 0.8441 | Val Loss: 0.8200 | Accuracy: 0.5300 | Precision: 0.5147 | Recall: 0.5351\n",
      "Epoch 05 | Training Loss: 0.8274 | Val Loss: 0.8057 | Accuracy: 0.5360 | Precision: 0.5206 | Recall: 0.5425\n",
      "Epoch 06 | Training Loss: 0.8127 | Val Loss: 0.7929 | Accuracy: 0.5414 | Precision: 0.5261 | Recall: 0.5450\n",
      "Epoch 07 | Training Loss: 0.7997 | Val Loss: 0.7818 | Accuracy: 0.5462 | Precision: 0.5307 | Recall: 0.5532\n",
      "Epoch 08 | Training Loss: 0.7881 | Val Loss: 0.7717 | Accuracy: 0.5496 | Precision: 0.5345 | Recall: 0.5495\n",
      "Epoch 09 | Training Loss: 0.7778 | Val Loss: 0.7630 | Accuracy: 0.5542 | Precision: 0.5388 | Recall: 0.5590\n",
      "Epoch 10 | Training Loss: 0.7683 | Val Loss: 0.7549 | Accuracy: 0.5550 | Precision: 0.5398 | Recall: 0.5565\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7161 | Test Accuracy: 0.5424 | Test Precision: 0.5420 | Test Recall: 0.5473\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 17...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9669 | Val Loss: 0.8390 | Accuracy: 0.5048 | Precision: 0.4890 | Recall: 0.4781\n",
      "Epoch 02 | Training Loss: 0.8257 | Val Loss: 0.8276 | Accuracy: 0.5100 | Precision: 0.4950 | Recall: 0.5334\n",
      "Epoch 03 | Training Loss: 0.8128 | Val Loss: 0.8153 | Accuracy: 0.5144 | Precision: 0.4992 | Recall: 0.5202\n",
      "Epoch 04 | Training Loss: 0.8011 | Val Loss: 0.8053 | Accuracy: 0.5170 | Precision: 0.5018 | Recall: 0.5268\n",
      "Epoch 05 | Training Loss: 0.7906 | Val Loss: 0.7956 | Accuracy: 0.5206 | Precision: 0.5054 | Recall: 0.5235\n",
      "Epoch 06 | Training Loss: 0.7810 | Val Loss: 0.7873 | Accuracy: 0.5234 | Precision: 0.5081 | Recall: 0.5318\n",
      "Epoch 07 | Training Loss: 0.7722 | Val Loss: 0.7802 | Accuracy: 0.5282 | Precision: 0.5125 | Recall: 0.5483\n",
      "Epoch 08 | Training Loss: 0.7641 | Val Loss: 0.7725 | Accuracy: 0.5330 | Precision: 0.5177 | Recall: 0.5375\n",
      "Epoch 09 | Training Loss: 0.7567 | Val Loss: 0.7666 | Accuracy: 0.5342 | Precision: 0.5183 | Recall: 0.5557\n",
      "Epoch 10 | Training Loss: 0.7499 | Val Loss: 0.7603 | Accuracy: 0.5390 | Precision: 0.5234 | Recall: 0.5487\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6895 | Test Accuracy: 0.5530 | Test Precision: 0.5534 | Test Recall: 0.5497\n",
      "\n",
      "Training for parameter combination: 18, \n",
      "\n",
      "parameters: [1, 'LeakyReLU', 0.0001, 'Adam', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 18...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5863 | Val Loss: 0.3796 | Accuracy: 0.8392 | Precision: 0.8282 | Recall: 0.8432\n",
      "Epoch 02 | Training Loss: 0.2121 | Val Loss: 0.3288 | Accuracy: 0.8618 | Precision: 0.8664 | Recall: 0.8453\n",
      "Epoch 03 | Training Loss: 0.1154 | Val Loss: 0.3118 | Accuracy: 0.8772 | Precision: 0.8667 | Recall: 0.8824\n",
      "Epoch 04 | Training Loss: 0.0679 | Val Loss: 0.3127 | Accuracy: 0.8798 | Precision: 0.8777 | Recall: 0.8738\n",
      "Epoch 05 | Training Loss: 0.0409 | Val Loss: 0.3195 | Accuracy: 0.8796 | Precision: 0.8606 | Recall: 0.8969\n",
      "Epoch 06 | Training Loss: 0.0250 | Val Loss: 0.3319 | Accuracy: 0.8810 | Precision: 0.8605 | Recall: 0.9006\n",
      "Epoch 07 | Training Loss: 0.0156 | Val Loss: 0.3483 | Accuracy: 0.8808 | Precision: 0.8598 | Recall: 0.9010\n",
      "Epoch 08 | Training Loss: 0.0099 | Val Loss: 0.3614 | Accuracy: 0.8840 | Precision: 0.8736 | Recall: 0.8894\n",
      "Epoch 09 | Training Loss: 0.0064 | Val Loss: 0.3768 | Accuracy: 0.8842 | Precision: 0.8730 | Recall: 0.8907\n",
      "Epoch 10 | Training Loss: 0.0041 | Val Loss: 0.3980 | Accuracy: 0.8794 | Precision: 0.8615 | Recall: 0.8952\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3157 | Test Accuracy: 0.8678 | Test Precision: 0.8665 | Test Recall: 0.8694\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 18...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5290 | Val Loss: 0.3571 | Accuracy: 0.8516 | Precision: 0.8361 | Recall: 0.8630\n",
      "Epoch 02 | Training Loss: 0.2052 | Val Loss: 0.3162 | Accuracy: 0.8714 | Precision: 0.8494 | Recall: 0.8932\n",
      "Epoch 03 | Training Loss: 0.1135 | Val Loss: 0.3003 | Accuracy: 0.8838 | Precision: 0.8809 | Recall: 0.8791\n",
      "Epoch 04 | Training Loss: 0.0676 | Val Loss: 0.3025 | Accuracy: 0.8838 | Precision: 0.8667 | Recall: 0.8985\n",
      "Epoch 05 | Training Loss: 0.0406 | Val Loss: 0.3112 | Accuracy: 0.8870 | Precision: 0.8702 | Recall: 0.9014\n",
      "Epoch 06 | Training Loss: 0.0249 | Val Loss: 0.3230 | Accuracy: 0.8856 | Precision: 0.8698 | Recall: 0.8985\n",
      "Epoch 07 | Training Loss: 0.0154 | Val Loss: 0.3383 | Accuracy: 0.8858 | Precision: 0.8824 | Recall: 0.8820\n",
      "Epoch 08 | Training Loss: 0.0097 | Val Loss: 0.3542 | Accuracy: 0.8836 | Precision: 0.8693 | Recall: 0.8944\n",
      "Epoch 09 | Training Loss: 0.0062 | Val Loss: 0.3722 | Accuracy: 0.8840 | Precision: 0.8682 | Recall: 0.8969\n",
      "Epoch 10 | Training Loss: 0.0041 | Val Loss: 0.3925 | Accuracy: 0.8840 | Precision: 0.8667 | Recall: 0.8989\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3192 | Test Accuracy: 0.8670 | Test Precision: 0.8673 | Test Recall: 0.8666\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 18...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5340 | Val Loss: 0.3574 | Accuracy: 0.8492 | Precision: 0.8212 | Recall: 0.8808\n",
      "Epoch 02 | Training Loss: 0.2054 | Val Loss: 0.3147 | Accuracy: 0.8694 | Precision: 0.8691 | Recall: 0.8601\n",
      "Epoch 03 | Training Loss: 0.1133 | Val Loss: 0.3067 | Accuracy: 0.8796 | Precision: 0.8656 | Recall: 0.8899\n",
      "Epoch 04 | Training Loss: 0.0673 | Val Loss: 0.3088 | Accuracy: 0.8812 | Precision: 0.8775 | Recall: 0.8775\n",
      "Epoch 05 | Training Loss: 0.0407 | Val Loss: 0.3179 | Accuracy: 0.8806 | Precision: 0.8767 | Recall: 0.8771\n",
      "Epoch 06 | Training Loss: 0.0251 | Val Loss: 0.3304 | Accuracy: 0.8824 | Precision: 0.8681 | Recall: 0.8932\n",
      "Epoch 07 | Training Loss: 0.0156 | Val Loss: 0.3461 | Accuracy: 0.8820 | Precision: 0.8716 | Recall: 0.8874\n",
      "Epoch 08 | Training Loss: 0.0098 | Val Loss: 0.3620 | Accuracy: 0.8824 | Precision: 0.8699 | Recall: 0.8907\n",
      "Epoch 09 | Training Loss: 0.0063 | Val Loss: 0.3815 | Accuracy: 0.8816 | Precision: 0.8721 | Recall: 0.8857\n",
      "Epoch 10 | Training Loss: 0.0041 | Val Loss: 0.3996 | Accuracy: 0.8826 | Precision: 0.8687 | Recall: 0.8927\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3232 | Test Accuracy: 0.8684 | Test Precision: 0.8711 | Test Recall: 0.8647\n",
      "\n",
      "Training for parameter combination: 19, \n",
      "\n",
      "parameters: [3, 'Tanh', 0.0005, 'Adam', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 19...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4040 | Val Loss: 0.3006 | Accuracy: 0.8690 | Precision: 0.8411 | Recall: 0.8998\n",
      "Epoch 02 | Training Loss: 0.0720 | Val Loss: 0.3222 | Accuracy: 0.8752 | Precision: 0.8566 | Recall: 0.8919\n",
      "Epoch 03 | Training Loss: 0.0117 | Val Loss: 0.3877 | Accuracy: 0.8774 | Precision: 0.8522 | Recall: 0.9039\n",
      "Epoch 04 | Training Loss: 0.0026 | Val Loss: 0.4224 | Accuracy: 0.8790 | Precision: 0.8699 | Recall: 0.8824\n",
      "Epoch 05 | Training Loss: 0.0009 | Val Loss: 0.4517 | Accuracy: 0.8780 | Precision: 0.8648 | Recall: 0.8870\n",
      "Epoch 06 | Training Loss: 0.0005 | Val Loss: 0.4742 | Accuracy: 0.8786 | Precision: 0.8641 | Recall: 0.8894\n",
      "Epoch 07 | Training Loss: 0.0004 | Val Loss: 0.4917 | Accuracy: 0.8788 | Precision: 0.8677 | Recall: 0.8849\n",
      "Epoch 08 | Training Loss: 0.0003 | Val Loss: 0.5077 | Accuracy: 0.8788 | Precision: 0.8683 | Recall: 0.8841\n",
      "Epoch 09 | Training Loss: 0.0002 | Val Loss: 0.5227 | Accuracy: 0.8798 | Precision: 0.8674 | Recall: 0.8878\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.5349 | Accuracy: 0.8794 | Precision: 0.8688 | Recall: 0.8849\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4145 | Test Accuracy: 0.8658 | Test Precision: 0.8718 | Test Recall: 0.8577\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 19...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3878 | Val Loss: 0.2994 | Accuracy: 0.8756 | Precision: 0.8428 | Recall: 0.9138\n",
      "Epoch 02 | Training Loss: 0.0729 | Val Loss: 0.3262 | Accuracy: 0.8774 | Precision: 0.8728 | Recall: 0.8746\n",
      "Epoch 03 | Training Loss: 0.0114 | Val Loss: 0.3863 | Accuracy: 0.8818 | Precision: 0.8659 | Recall: 0.8948\n",
      "Epoch 04 | Training Loss: 0.0020 | Val Loss: 0.4302 | Accuracy: 0.8824 | Precision: 0.8652 | Recall: 0.8973\n",
      "Epoch 05 | Training Loss: 0.0008 | Val Loss: 0.4580 | Accuracy: 0.8820 | Precision: 0.8665 | Recall: 0.8944\n",
      "Epoch 06 | Training Loss: 0.0005 | Val Loss: 0.4796 | Accuracy: 0.8830 | Precision: 0.8688 | Recall: 0.8936\n",
      "Epoch 07 | Training Loss: 0.0003 | Val Loss: 0.4986 | Accuracy: 0.8830 | Precision: 0.8679 | Recall: 0.8948\n",
      "Epoch 08 | Training Loss: 0.0002 | Val Loss: 0.5147 | Accuracy: 0.8834 | Precision: 0.8686 | Recall: 0.8948\n",
      "Epoch 09 | Training Loss: 0.0002 | Val Loss: 0.5287 | Accuracy: 0.8832 | Precision: 0.8689 | Recall: 0.8940\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.5423 | Accuracy: 0.8838 | Precision: 0.8682 | Recall: 0.8965\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4140 | Test Accuracy: 0.8689 | Test Precision: 0.8720 | Test Recall: 0.8647\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 19...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3991 | Val Loss: 0.2926 | Accuracy: 0.8784 | Precision: 0.8921 | Recall: 0.8523\n",
      "Epoch 02 | Training Loss: 0.0749 | Val Loss: 0.3116 | Accuracy: 0.8790 | Precision: 0.8826 | Recall: 0.8655\n",
      "Epoch 03 | Training Loss: 0.0125 | Val Loss: 0.3808 | Accuracy: 0.8776 | Precision: 0.8722 | Recall: 0.8758\n",
      "Epoch 04 | Training Loss: 0.0023 | Val Loss: 0.4218 | Accuracy: 0.8798 | Precision: 0.8695 | Recall: 0.8849\n",
      "Epoch 05 | Training Loss: 0.0009 | Val Loss: 0.4513 | Accuracy: 0.8794 | Precision: 0.8673 | Recall: 0.8870\n",
      "Epoch 06 | Training Loss: 0.0005 | Val Loss: 0.4728 | Accuracy: 0.8796 | Precision: 0.8691 | Recall: 0.8849\n",
      "Epoch 07 | Training Loss: 0.0003 | Val Loss: 0.4928 | Accuracy: 0.8798 | Precision: 0.8671 | Recall: 0.8882\n",
      "Epoch 08 | Training Loss: 0.0002 | Val Loss: 0.5081 | Accuracy: 0.8792 | Precision: 0.8675 | Recall: 0.8861\n",
      "Epoch 09 | Training Loss: 0.0002 | Val Loss: 0.5219 | Accuracy: 0.8800 | Precision: 0.8692 | Recall: 0.8857\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.5350 | Accuracy: 0.8800 | Precision: 0.8680 | Recall: 0.8874\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4052 | Test Accuracy: 0.8670 | Test Precision: 0.8724 | Test Recall: 0.8597\n",
      "\n",
      "Training for parameter combination: 20, \n",
      "\n",
      "parameters: [2, 'ReLU', 0.001, 'RMSProp', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 20...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4595 | Val Loss: 0.3176 | Accuracy: 0.8676 | Precision: 0.8898 | Recall: 0.8296\n",
      "Epoch 02 | Training Loss: 0.1241 | Val Loss: 0.3452 | Accuracy: 0.8766 | Precision: 0.8704 | Recall: 0.8758\n",
      "Epoch 03 | Training Loss: 0.0273 | Val Loss: 0.5067 | Accuracy: 0.8700 | Precision: 0.8465 | Recall: 0.8940\n",
      "Epoch 04 | Training Loss: 0.0028 | Val Loss: 0.7170 | Accuracy: 0.8738 | Precision: 0.8565 | Recall: 0.8886\n",
      "Epoch 05 | Training Loss: 0.0002 | Val Loss: 0.8486 | Accuracy: 0.8778 | Precision: 0.8556 | Recall: 0.8998\n",
      "Epoch 06 | Training Loss: 0.0000 | Val Loss: 0.9278 | Accuracy: 0.8766 | Precision: 0.8575 | Recall: 0.8940\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 0.9662 | Accuracy: 0.8758 | Precision: 0.8602 | Recall: 0.8882\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.9980 | Accuracy: 0.8766 | Precision: 0.8598 | Recall: 0.8907\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 1.0215 | Accuracy: 0.8762 | Precision: 0.8594 | Recall: 0.8903\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.0410 | Accuracy: 0.8758 | Precision: 0.8590 | Recall: 0.8899\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4391 | Test Accuracy: 0.8740 | Test Precision: 0.8725 | Test Recall: 0.8762\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 20...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4674 | Val Loss: 0.3184 | Accuracy: 0.8652 | Precision: 0.8818 | Recall: 0.8337\n",
      "Epoch 02 | Training Loss: 0.1301 | Val Loss: 0.4186 | Accuracy: 0.8482 | Precision: 0.9160 | Recall: 0.7562\n",
      "Epoch 03 | Training Loss: 0.0266 | Val Loss: 0.5089 | Accuracy: 0.8678 | Precision: 0.8439 | Recall: 0.8923\n",
      "Epoch 04 | Training Loss: 0.0032 | Val Loss: 0.7480 | Accuracy: 0.8704 | Precision: 0.8569 | Recall: 0.8795\n",
      "Epoch 05 | Training Loss: 0.0003 | Val Loss: 0.8661 | Accuracy: 0.8720 | Precision: 0.8789 | Recall: 0.8535\n",
      "Epoch 06 | Training Loss: 0.0000 | Val Loss: 0.9347 | Accuracy: 0.8722 | Precision: 0.8586 | Recall: 0.8816\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 0.9713 | Accuracy: 0.8728 | Precision: 0.8631 | Recall: 0.8767\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 1.0019 | Accuracy: 0.8736 | Precision: 0.8613 | Recall: 0.8812\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 1.0241 | Accuracy: 0.8736 | Precision: 0.8616 | Recall: 0.8808\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.0432 | Accuracy: 0.8734 | Precision: 0.8612 | Recall: 0.8808\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4118 | Test Accuracy: 0.8710 | Test Precision: 0.8706 | Test Recall: 0.8715\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 20...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4418 | Val Loss: 0.3659 | Accuracy: 0.8542 | Precision: 0.7929 | Recall: 0.9464\n",
      "Epoch 02 | Training Loss: 0.1230 | Val Loss: 0.3665 | Accuracy: 0.8740 | Precision: 0.8416 | Recall: 0.9117\n",
      "Epoch 03 | Training Loss: 0.0247 | Val Loss: 0.4953 | Accuracy: 0.8762 | Precision: 0.8664 | Recall: 0.8804\n",
      "Epoch 04 | Training Loss: 0.0028 | Val Loss: 0.7374 | Accuracy: 0.8776 | Precision: 0.8653 | Recall: 0.8853\n",
      "Epoch 05 | Training Loss: 0.0002 | Val Loss: 0.8650 | Accuracy: 0.8784 | Precision: 0.8673 | Recall: 0.8845\n",
      "Epoch 06 | Training Loss: 0.0000 | Val Loss: 0.9294 | Accuracy: 0.8794 | Precision: 0.8676 | Recall: 0.8866\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 0.9702 | Accuracy: 0.8780 | Precision: 0.8634 | Recall: 0.8890\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.9956 | Accuracy: 0.8792 | Precision: 0.8672 | Recall: 0.8866\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 1.0167 | Accuracy: 0.8790 | Precision: 0.8672 | Recall: 0.8861\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.0365 | Accuracy: 0.8792 | Precision: 0.8649 | Recall: 0.8899\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3904 | Test Accuracy: 0.8724 | Test Precision: 0.8729 | Test Recall: 0.8717\n",
      "\n",
      "Training for parameter combination: 21, \n",
      "\n",
      "parameters: [1, 'LeakyReLU', 0.001, 'SGD', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 21...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0137 | Val Loss: 0.9626 | Accuracy: 0.5450 | Precision: 0.5306 | Recall: 0.5330\n",
      "Epoch 02 | Training Loss: 0.9470 | Val Loss: 0.9106 | Accuracy: 0.5636 | Precision: 0.5490 | Recall: 0.5594\n",
      "Epoch 03 | Training Loss: 0.8957 | Val Loss: 0.8660 | Accuracy: 0.5796 | Precision: 0.5661 | Recall: 0.5689\n",
      "Epoch 04 | Training Loss: 0.8529 | Val Loss: 0.8296 | Accuracy: 0.5956 | Precision: 0.5820 | Recall: 0.5887\n",
      "Epoch 05 | Training Loss: 0.8166 | Val Loss: 0.7994 | Accuracy: 0.6054 | Precision: 0.5908 | Recall: 0.6052\n",
      "Epoch 06 | Training Loss: 0.7853 | Val Loss: 0.7715 | Accuracy: 0.6186 | Precision: 0.6051 | Recall: 0.6139\n",
      "Epoch 07 | Training Loss: 0.7580 | Val Loss: 0.7486 | Accuracy: 0.6296 | Precision: 0.6155 | Recall: 0.6287\n",
      "Epoch 08 | Training Loss: 0.7342 | Val Loss: 0.7284 | Accuracy: 0.6390 | Precision: 0.6243 | Recall: 0.6411\n",
      "Epoch 09 | Training Loss: 0.7131 | Val Loss: 0.7108 | Accuracy: 0.6494 | Precision: 0.6336 | Recall: 0.6564\n",
      "Epoch 10 | Training Loss: 0.6942 | Val Loss: 0.6934 | Accuracy: 0.6602 | Precision: 0.6483 | Recall: 0.6539\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6240 | Test Accuracy: 0.6598 | Test Precision: 0.6630 | Test Recall: 0.6502\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 21...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0578 | Val Loss: 1.0468 | Accuracy: 0.5290 | Precision: 0.5143 | Recall: 0.5128\n",
      "Epoch 02 | Training Loss: 0.9827 | Val Loss: 0.9823 | Accuracy: 0.5494 | Precision: 0.5341 | Recall: 0.5520\n",
      "Epoch 03 | Training Loss: 0.9214 | Val Loss: 0.9272 | Accuracy: 0.5698 | Precision: 0.5559 | Recall: 0.5598\n",
      "Epoch 04 | Training Loss: 0.8706 | Val Loss: 0.8833 | Accuracy: 0.5848 | Precision: 0.5693 | Recall: 0.5895\n",
      "Epoch 05 | Training Loss: 0.8283 | Val Loss: 0.8441 | Accuracy: 0.6054 | Precision: 0.5966 | Recall: 0.5747\n",
      "Epoch 06 | Training Loss: 0.7921 | Val Loss: 0.8126 | Accuracy: 0.6186 | Precision: 0.6033 | Recall: 0.6229\n",
      "Epoch 07 | Training Loss: 0.7611 | Val Loss: 0.7842 | Accuracy: 0.6324 | Precision: 0.6168 | Recall: 0.6382\n",
      "Epoch 08 | Training Loss: 0.7341 | Val Loss: 0.7589 | Accuracy: 0.6424 | Precision: 0.6284 | Recall: 0.6419\n",
      "Epoch 09 | Training Loss: 0.7105 | Val Loss: 0.7379 | Accuracy: 0.6510 | Precision: 0.6339 | Recall: 0.6630\n",
      "Epoch 10 | Training Loss: 0.6896 | Val Loss: 0.7180 | Accuracy: 0.6606 | Precision: 0.6452 | Recall: 0.6663\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6590 | Test Accuracy: 0.6626 | Test Precision: 0.6629 | Test Recall: 0.6618\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 21...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.1113 | Val Loss: 1.0614 | Accuracy: 0.5040 | Precision: 0.4888 | Recall: 0.5029\n",
      "Epoch 02 | Training Loss: 1.0199 | Val Loss: 0.9942 | Accuracy: 0.5244 | Precision: 0.5089 | Recall: 0.5433\n",
      "Epoch 03 | Training Loss: 0.9573 | Val Loss: 0.9385 | Accuracy: 0.5396 | Precision: 0.5231 | Recall: 0.5693\n",
      "Epoch 04 | Training Loss: 0.9057 | Val Loss: 0.8886 | Accuracy: 0.5600 | Precision: 0.5446 | Recall: 0.5648\n",
      "Epoch 05 | Training Loss: 0.8621 | Val Loss: 0.8489 | Accuracy: 0.5766 | Precision: 0.5609 | Recall: 0.5833\n",
      "Epoch 06 | Training Loss: 0.8251 | Val Loss: 0.8149 | Accuracy: 0.5936 | Precision: 0.5776 | Recall: 0.6019\n",
      "Epoch 07 | Training Loss: 0.7931 | Val Loss: 0.7854 | Accuracy: 0.6078 | Precision: 0.5926 | Recall: 0.6110\n",
      "Epoch 08 | Training Loss: 0.7652 | Val Loss: 0.7595 | Accuracy: 0.6200 | Precision: 0.6062 | Recall: 0.6167\n",
      "Epoch 09 | Training Loss: 0.7405 | Val Loss: 0.7376 | Accuracy: 0.6326 | Precision: 0.6172 | Recall: 0.6378\n",
      "Epoch 10 | Training Loss: 0.7191 | Val Loss: 0.7175 | Accuracy: 0.6430 | Precision: 0.6282 | Recall: 0.6460\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6311 | Test Accuracy: 0.6444 | Test Precision: 0.6450 | Test Recall: 0.6423\n",
      "\n",
      "Training for parameter combination: 22, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.0001, 'Adam', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 22...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5833 | Val Loss: 0.4169 | Accuracy: 0.8082 | Precision: 0.7823 | Recall: 0.8375\n",
      "Epoch 02 | Training Loss: 0.2315 | Val Loss: 0.3584 | Accuracy: 0.8474 | Precision: 0.8600 | Recall: 0.8185\n",
      "Epoch 03 | Training Loss: 0.0945 | Val Loss: 0.3757 | Accuracy: 0.8546 | Precision: 0.8220 | Recall: 0.8936\n",
      "Epoch 04 | Training Loss: 0.0346 | Val Loss: 0.4185 | Accuracy: 0.8606 | Precision: 0.8277 | Recall: 0.8998\n",
      "Epoch 05 | Training Loss: 0.0114 | Val Loss: 0.4696 | Accuracy: 0.8654 | Precision: 0.8552 | Recall: 0.8696\n",
      "Epoch 06 | Training Loss: 0.0039 | Val Loss: 0.5266 | Accuracy: 0.8668 | Precision: 0.8597 | Recall: 0.8667\n",
      "Epoch 07 | Training Loss: 0.0016 | Val Loss: 0.5797 | Accuracy: 0.8696 | Precision: 0.8643 | Recall: 0.8672\n",
      "Epoch 08 | Training Loss: 0.0008 | Val Loss: 0.6272 | Accuracy: 0.8694 | Precision: 0.8552 | Recall: 0.8795\n",
      "Epoch 09 | Training Loss: 0.0004 | Val Loss: 0.6686 | Accuracy: 0.8696 | Precision: 0.8558 | Recall: 0.8791\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.7077 | Accuracy: 0.8694 | Precision: 0.8569 | Recall: 0.8771\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3271 | Test Accuracy: 0.8509 | Test Precision: 0.8480 | Test Recall: 0.8551\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 22...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5591 | Val Loss: 0.4282 | Accuracy: 0.8100 | Precision: 0.7686 | Recall: 0.8700\n",
      "Epoch 02 | Training Loss: 0.2237 | Val Loss: 0.3778 | Accuracy: 0.8422 | Precision: 0.8603 | Recall: 0.8053\n",
      "Epoch 03 | Training Loss: 0.0934 | Val Loss: 0.3774 | Accuracy: 0.8548 | Precision: 0.8601 | Recall: 0.8366\n",
      "Epoch 04 | Training Loss: 0.0342 | Val Loss: 0.4234 | Accuracy: 0.8578 | Precision: 0.8395 | Recall: 0.8738\n",
      "Epoch 05 | Training Loss: 0.0114 | Val Loss: 0.4763 | Accuracy: 0.8596 | Precision: 0.8540 | Recall: 0.8568\n",
      "Epoch 06 | Training Loss: 0.0040 | Val Loss: 0.5307 | Accuracy: 0.8616 | Precision: 0.8523 | Recall: 0.8643\n",
      "Epoch 07 | Training Loss: 0.0017 | Val Loss: 0.5816 | Accuracy: 0.8632 | Precision: 0.8502 | Recall: 0.8713\n",
      "Epoch 08 | Training Loss: 0.0008 | Val Loss: 0.6225 | Accuracy: 0.8632 | Precision: 0.8542 | Recall: 0.8655\n",
      "Epoch 09 | Training Loss: 0.0004 | Val Loss: 0.6623 | Accuracy: 0.8640 | Precision: 0.8530 | Recall: 0.8692\n",
      "Epoch 10 | Training Loss: 0.0003 | Val Loss: 0.6980 | Accuracy: 0.8646 | Precision: 0.8532 | Recall: 0.8705\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3139 | Test Accuracy: 0.8538 | Test Precision: 0.8532 | Test Recall: 0.8547\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 22...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5507 | Val Loss: 0.4181 | Accuracy: 0.8108 | Precision: 0.7851 | Recall: 0.8395\n",
      "Epoch 02 | Training Loss: 0.2267 | Val Loss: 0.3770 | Accuracy: 0.8378 | Precision: 0.8094 | Recall: 0.8705\n",
      "Epoch 03 | Training Loss: 0.0941 | Val Loss: 0.3896 | Accuracy: 0.8440 | Precision: 0.8442 | Recall: 0.8317\n",
      "Epoch 04 | Training Loss: 0.0332 | Val Loss: 0.4556 | Accuracy: 0.8492 | Precision: 0.8247 | Recall: 0.8750\n",
      "Epoch 05 | Training Loss: 0.0102 | Val Loss: 0.5251 | Accuracy: 0.8542 | Precision: 0.8498 | Recall: 0.8494\n",
      "Epoch 06 | Training Loss: 0.0033 | Val Loss: 0.5964 | Accuracy: 0.8546 | Precision: 0.8437 | Recall: 0.8593\n",
      "Epoch 07 | Training Loss: 0.0013 | Val Loss: 0.6536 | Accuracy: 0.8556 | Precision: 0.8423 | Recall: 0.8639\n",
      "Epoch 08 | Training Loss: 0.0007 | Val Loss: 0.7005 | Accuracy: 0.8576 | Precision: 0.8474 | Recall: 0.8614\n",
      "Epoch 09 | Training Loss: 0.0004 | Val Loss: 0.7434 | Accuracy: 0.8578 | Precision: 0.8449 | Recall: 0.8655\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.7822 | Accuracy: 0.8580 | Precision: 0.8453 | Recall: 0.8655\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3880 | Test Accuracy: 0.8510 | Test Precision: 0.8476 | Test Recall: 0.8559\n",
      "\n",
      "Training for parameter combination: 23, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.001, 'Adam', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 23...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4268 | Val Loss: 0.3097 | Accuracy: 0.8726 | Precision: 0.8391 | Recall: 0.9121\n",
      "Epoch 02 | Training Loss: 0.0599 | Val Loss: 0.3680 | Accuracy: 0.8712 | Precision: 0.8338 | Recall: 0.9171\n",
      "Epoch 03 | Training Loss: 0.0061 | Val Loss: 0.4725 | Accuracy: 0.8738 | Precision: 0.8843 | Recall: 0.8511\n",
      "Epoch 04 | Training Loss: 0.0006 | Val Loss: 0.5355 | Accuracy: 0.8772 | Precision: 0.8691 | Recall: 0.8791\n",
      "Epoch 05 | Training Loss: 0.0002 | Val Loss: 0.5774 | Accuracy: 0.8756 | Precision: 0.8660 | Recall: 0.8795\n",
      "Epoch 06 | Training Loss: 0.0001 | Val Loss: 0.6076 | Accuracy: 0.8758 | Precision: 0.8666 | Recall: 0.8791\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.6318 | Accuracy: 0.8756 | Precision: 0.8684 | Recall: 0.8762\n",
      "Epoch 08 | Training Loss: 0.0001 | Val Loss: 0.6546 | Accuracy: 0.8762 | Precision: 0.8670 | Recall: 0.8795\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.6731 | Accuracy: 0.8758 | Precision: 0.8678 | Recall: 0.8775\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.6903 | Accuracy: 0.8760 | Precision: 0.8682 | Recall: 0.8775\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3802 | Test Accuracy: 0.8670 | Test Precision: 0.8709 | Test Recall: 0.8618\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 23...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4277 | Val Loss: 0.2817 | Accuracy: 0.8840 | Precision: 0.8633 | Recall: 0.9039\n",
      "Epoch 02 | Training Loss: 0.0601 | Val Loss: 0.3452 | Accuracy: 0.8706 | Precision: 0.9112 | Recall: 0.8123\n",
      "Epoch 03 | Training Loss: 0.0057 | Val Loss: 0.4617 | Accuracy: 0.8802 | Precision: 0.8608 | Recall: 0.8981\n",
      "Epoch 04 | Training Loss: 0.0006 | Val Loss: 0.5193 | Accuracy: 0.8804 | Precision: 0.8664 | Recall: 0.8907\n",
      "Epoch 05 | Training Loss: 0.0002 | Val Loss: 0.5583 | Accuracy: 0.8808 | Precision: 0.8659 | Recall: 0.8923\n",
      "Epoch 06 | Training Loss: 0.0001 | Val Loss: 0.5866 | Accuracy: 0.8804 | Precision: 0.8655 | Recall: 0.8919\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.6104 | Accuracy: 0.8790 | Precision: 0.8639 | Recall: 0.8907\n",
      "Epoch 08 | Training Loss: 0.0001 | Val Loss: 0.6313 | Accuracy: 0.8788 | Precision: 0.8633 | Recall: 0.8911\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.6471 | Accuracy: 0.8796 | Precision: 0.8665 | Recall: 0.8886\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.6645 | Accuracy: 0.8790 | Precision: 0.8648 | Recall: 0.8894\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3411 | Test Accuracy: 0.8704 | Test Precision: 0.8712 | Test Recall: 0.8693\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 23...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3981 | Val Loss: 0.2905 | Accuracy: 0.8800 | Precision: 0.8894 | Recall: 0.8593\n",
      "Epoch 02 | Training Loss: 0.0537 | Val Loss: 0.3494 | Accuracy: 0.8790 | Precision: 0.8622 | Recall: 0.8932\n",
      "Epoch 03 | Training Loss: 0.0048 | Val Loss: 0.4967 | Accuracy: 0.8804 | Precision: 0.8586 | Recall: 0.9018\n",
      "Epoch 04 | Training Loss: 0.0004 | Val Loss: 0.5501 | Accuracy: 0.8836 | Precision: 0.8753 | Recall: 0.8861\n",
      "Epoch 05 | Training Loss: 0.0002 | Val Loss: 0.5934 | Accuracy: 0.8826 | Precision: 0.8729 | Recall: 0.8870\n",
      "Epoch 06 | Training Loss: 0.0001 | Val Loss: 0.6268 | Accuracy: 0.8820 | Precision: 0.8734 | Recall: 0.8849\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.6560 | Accuracy: 0.8830 | Precision: 0.8742 | Recall: 0.8861\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.6844 | Accuracy: 0.8828 | Precision: 0.8721 | Recall: 0.8886\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.7059 | Accuracy: 0.8830 | Precision: 0.8733 | Recall: 0.8874\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.7302 | Accuracy: 0.8828 | Precision: 0.8712 | Recall: 0.8899\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4316 | Test Accuracy: 0.8660 | Test Precision: 0.8706 | Test Recall: 0.8598\n",
      "\n",
      "Training for parameter combination: 24, \n",
      "\n",
      "parameters: [3, 'LeakyReLU', 0.0001, 'Adam', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 24...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6734 | Val Loss: 0.4926 | Accuracy: 0.7698 | Precision: 0.7781 | Recall: 0.7347\n",
      "Epoch 02 | Training Loss: 0.3344 | Val Loss: 0.4112 | Accuracy: 0.8234 | Precision: 0.8277 | Recall: 0.8028\n",
      "Epoch 03 | Training Loss: 0.1999 | Val Loss: 0.3815 | Accuracy: 0.8460 | Precision: 0.8406 | Recall: 0.8420\n",
      "Epoch 04 | Training Loss: 0.1209 | Val Loss: 0.3791 | Accuracy: 0.8522 | Precision: 0.8518 | Recall: 0.8416\n",
      "Epoch 05 | Training Loss: 0.0720 | Val Loss: 0.3914 | Accuracy: 0.8594 | Precision: 0.8525 | Recall: 0.8585\n",
      "Epoch 06 | Training Loss: 0.0415 | Val Loss: 0.4137 | Accuracy: 0.8600 | Precision: 0.8539 | Recall: 0.8581\n",
      "Epoch 07 | Training Loss: 0.0241 | Val Loss: 0.4460 | Accuracy: 0.8612 | Precision: 0.8422 | Recall: 0.8783\n",
      "Epoch 08 | Training Loss: 0.0142 | Val Loss: 0.4725 | Accuracy: 0.8636 | Precision: 0.8532 | Recall: 0.8680\n",
      "Epoch 09 | Training Loss: 0.0086 | Val Loss: 0.5050 | Accuracy: 0.8630 | Precision: 0.8441 | Recall: 0.8800\n",
      "Epoch 10 | Training Loss: 0.0056 | Val Loss: 0.5307 | Accuracy: 0.8642 | Precision: 0.8491 | Recall: 0.8754\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4426 | Test Accuracy: 0.8515 | Test Precision: 0.8529 | Test Recall: 0.8494\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 24...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6197 | Val Loss: 0.4641 | Accuracy: 0.7850 | Precision: 0.7682 | Recall: 0.7970\n",
      "Epoch 02 | Training Loss: 0.3269 | Val Loss: 0.3858 | Accuracy: 0.8358 | Precision: 0.8152 | Recall: 0.8552\n",
      "Epoch 03 | Training Loss: 0.1994 | Val Loss: 0.3584 | Accuracy: 0.8534 | Precision: 0.8450 | Recall: 0.8544\n",
      "Epoch 04 | Training Loss: 0.1220 | Val Loss: 0.3620 | Accuracy: 0.8570 | Precision: 0.8293 | Recall: 0.8878\n",
      "Epoch 05 | Training Loss: 0.0722 | Val Loss: 0.3710 | Accuracy: 0.8592 | Precision: 0.8344 | Recall: 0.8853\n",
      "Epoch 06 | Training Loss: 0.0421 | Val Loss: 0.3872 | Accuracy: 0.8660 | Precision: 0.8591 | Recall: 0.8655\n",
      "Epoch 07 | Training Loss: 0.0243 | Val Loss: 0.4157 | Accuracy: 0.8644 | Precision: 0.8429 | Recall: 0.8853\n",
      "Epoch 08 | Training Loss: 0.0140 | Val Loss: 0.4440 | Accuracy: 0.8654 | Precision: 0.8459 | Recall: 0.8833\n",
      "Epoch 09 | Training Loss: 0.0086 | Val Loss: 0.4686 | Accuracy: 0.8662 | Precision: 0.8526 | Recall: 0.8754\n",
      "Epoch 10 | Training Loss: 0.0054 | Val Loss: 0.4930 | Accuracy: 0.8672 | Precision: 0.8601 | Recall: 0.8672\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3972 | Test Accuracy: 0.8515 | Test Precision: 0.8619 | Test Recall: 0.8371\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 24...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6394 | Val Loss: 0.4852 | Accuracy: 0.7696 | Precision: 0.7690 | Recall: 0.7500\n",
      "Epoch 02 | Training Loss: 0.3341 | Val Loss: 0.3972 | Accuracy: 0.8264 | Precision: 0.8044 | Recall: 0.8482\n",
      "Epoch 03 | Training Loss: 0.2033 | Val Loss: 0.3658 | Accuracy: 0.8460 | Precision: 0.8507 | Recall: 0.8276\n",
      "Epoch 04 | Training Loss: 0.1234 | Val Loss: 0.3614 | Accuracy: 0.8538 | Precision: 0.8355 | Recall: 0.8696\n",
      "Epoch 05 | Training Loss: 0.0729 | Val Loss: 0.3747 | Accuracy: 0.8608 | Precision: 0.8518 | Recall: 0.8630\n",
      "Epoch 06 | Training Loss: 0.0418 | Val Loss: 0.4041 | Accuracy: 0.8598 | Precision: 0.8385 | Recall: 0.8804\n",
      "Epoch 07 | Training Loss: 0.0238 | Val Loss: 0.4314 | Accuracy: 0.8634 | Precision: 0.8566 | Recall: 0.8626\n",
      "Epoch 08 | Training Loss: 0.0137 | Val Loss: 0.4664 | Accuracy: 0.8636 | Precision: 0.8608 | Recall: 0.8573\n",
      "Epoch 09 | Training Loss: 0.0081 | Val Loss: 0.4962 | Accuracy: 0.8642 | Precision: 0.8574 | Recall: 0.8634\n",
      "Epoch 10 | Training Loss: 0.0050 | Val Loss: 0.5279 | Accuracy: 0.8656 | Precision: 0.8484 | Recall: 0.8800\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4455 | Test Accuracy: 0.8543 | Test Precision: 0.8496 | Test Recall: 0.8610\n",
      "\n",
      "Training for parameter combination: 25, \n",
      "\n",
      "parameters: [3, 'LeakyReLU', 0.001, 'RMSProp', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 25...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4183 | Val Loss: 0.3276 | Accuracy: 0.8598 | Precision: 0.9116 | Recall: 0.7871\n",
      "Epoch 02 | Training Loss: 0.1548 | Val Loss: 0.3666 | Accuracy: 0.8730 | Precision: 0.8534 | Recall: 0.8911\n",
      "Epoch 03 | Training Loss: 0.0548 | Val Loss: 0.4588 | Accuracy: 0.8722 | Precision: 0.8702 | Recall: 0.8655\n",
      "Epoch 04 | Training Loss: 0.0222 | Val Loss: 0.6258 | Accuracy: 0.8752 | Precision: 0.8667 | Recall: 0.8775\n",
      "Epoch 05 | Training Loss: 0.0092 | Val Loss: 1.0906 | Accuracy: 0.8644 | Precision: 0.8125 | Recall: 0.9365\n",
      "Epoch 06 | Training Loss: 0.0048 | Val Loss: 1.1144 | Accuracy: 0.8696 | Precision: 0.8910 | Recall: 0.8329\n",
      "Epoch 07 | Training Loss: 0.0044 | Val Loss: 1.0919 | Accuracy: 0.8732 | Precision: 0.8864 | Recall: 0.8469\n",
      "Epoch 08 | Training Loss: 0.0020 | Val Loss: 1.2654 | Accuracy: 0.8744 | Precision: 0.8723 | Recall: 0.8680\n",
      "Epoch 09 | Training Loss: 0.0055 | Val Loss: 1.1763 | Accuracy: 0.8726 | Precision: 0.8593 | Recall: 0.8816\n",
      "Epoch 10 | Training Loss: 0.0032 | Val Loss: 1.1751 | Accuracy: 0.8750 | Precision: 0.8800 | Recall: 0.8593\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4284 | Test Accuracy: 0.8648 | Test Precision: 0.8835 | Test Recall: 0.8404\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 25...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4268 | Val Loss: 0.3031 | Accuracy: 0.8756 | Precision: 0.8403 | Recall: 0.9179\n",
      "Epoch 02 | Training Loss: 0.1530 | Val Loss: 0.3311 | Accuracy: 0.8764 | Precision: 0.8849 | Recall: 0.8564\n",
      "Epoch 03 | Training Loss: 0.0539 | Val Loss: 0.5861 | Accuracy: 0.8662 | Precision: 0.8164 | Recall: 0.9340\n",
      "Epoch 04 | Training Loss: 0.0207 | Val Loss: 0.9245 | Accuracy: 0.8408 | Precision: 0.7690 | Recall: 0.9600\n",
      "Epoch 05 | Training Loss: 0.0082 | Val Loss: 0.8350 | Accuracy: 0.8742 | Precision: 0.8840 | Recall: 0.8523\n",
      "Epoch 06 | Training Loss: 0.0049 | Val Loss: 1.0034 | Accuracy: 0.8754 | Precision: 0.8785 | Recall: 0.8622\n",
      "Epoch 07 | Training Loss: 0.0054 | Val Loss: 1.0512 | Accuracy: 0.8704 | Precision: 0.8943 | Recall: 0.8309\n",
      "Epoch 08 | Training Loss: 0.0057 | Val Loss: 1.1341 | Accuracy: 0.8576 | Precision: 0.9065 | Recall: 0.7875\n",
      "Epoch 09 | Training Loss: 0.0011 | Val Loss: 1.2894 | Accuracy: 0.8728 | Precision: 0.8492 | Recall: 0.8969\n",
      "Epoch 10 | Training Loss: 0.0030 | Val Loss: 1.3740 | Accuracy: 0.8652 | Precision: 0.8177 | Recall: 0.9290\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4392 | Test Accuracy: 0.8595 | Test Precision: 0.8234 | Test Recall: 0.9153\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 25...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4377 | Val Loss: 0.5255 | Accuracy: 0.7954 | Precision: 0.7084 | Recall: 0.9823\n",
      "Epoch 02 | Training Loss: 0.1487 | Val Loss: 0.3861 | Accuracy: 0.8596 | Precision: 0.8032 | Recall: 0.9410\n",
      "Epoch 03 | Training Loss: 0.0481 | Val Loss: 0.4910 | Accuracy: 0.8730 | Precision: 0.8506 | Recall: 0.8952\n",
      "Epoch 04 | Training Loss: 0.0167 | Val Loss: 0.7364 | Accuracy: 0.8650 | Precision: 0.8197 | Recall: 0.9249\n",
      "Epoch 05 | Training Loss: 0.0093 | Val Loss: 0.8580 | Accuracy: 0.8708 | Precision: 0.8430 | Recall: 0.9014\n",
      "Epoch 06 | Training Loss: 0.0071 | Val Loss: 0.9605 | Accuracy: 0.8746 | Precision: 0.8806 | Recall: 0.8577\n",
      "Epoch 07 | Training Loss: 0.0046 | Val Loss: 1.0318 | Accuracy: 0.8696 | Precision: 0.8605 | Recall: 0.8725\n",
      "Epoch 08 | Training Loss: 0.0028 | Val Loss: 1.1126 | Accuracy: 0.8774 | Precision: 0.8606 | Recall: 0.8915\n",
      "Epoch 09 | Training Loss: 0.0053 | Val Loss: 1.1197 | Accuracy: 0.8764 | Precision: 0.8603 | Recall: 0.8894\n",
      "Epoch 10 | Training Loss: 0.0032 | Val Loss: 1.2319 | Accuracy: 0.8686 | Precision: 0.8953 | Recall: 0.8255\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3821 | Test Accuracy: 0.8553 | Test Precision: 0.9004 | Test Recall: 0.7990\n",
      "\n",
      "Training for parameter combination: 26, \n",
      "\n",
      "parameters: [1, 'LeakyReLU', 0.001, 'Adam', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 26...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4194 | Val Loss: 0.3100 | Accuracy: 0.8794 | Precision: 0.8525 | Recall: 0.9084\n",
      "Epoch 02 | Training Loss: 0.0619 | Val Loss: 0.3193 | Accuracy: 0.8860 | Precision: 0.8824 | Recall: 0.8824\n",
      "Epoch 03 | Training Loss: 0.0165 | Val Loss: 0.3501 | Accuracy: 0.8868 | Precision: 0.8666 | Recall: 0.9059\n",
      "Epoch 04 | Training Loss: 0.0064 | Val Loss: 0.3689 | Accuracy: 0.8886 | Precision: 0.8834 | Recall: 0.8874\n",
      "Epoch 05 | Training Loss: 0.0033 | Val Loss: 0.3914 | Accuracy: 0.8870 | Precision: 0.8705 | Recall: 0.9010\n",
      "Epoch 06 | Training Loss: 0.0021 | Val Loss: 0.4071 | Accuracy: 0.8866 | Precision: 0.8727 | Recall: 0.8969\n",
      "Epoch 07 | Training Loss: 0.0014 | Val Loss: 0.4242 | Accuracy: 0.8860 | Precision: 0.8684 | Recall: 0.9014\n",
      "Epoch 08 | Training Loss: 0.0010 | Val Loss: 0.4389 | Accuracy: 0.8862 | Precision: 0.8688 | Recall: 0.9014\n",
      "Epoch 09 | Training Loss: 0.0008 | Val Loss: 0.4482 | Accuracy: 0.8860 | Precision: 0.8741 | Recall: 0.8936\n",
      "Epoch 10 | Training Loss: 0.0006 | Val Loss: 0.4625 | Accuracy: 0.8856 | Precision: 0.8692 | Recall: 0.8993\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4531 | Test Accuracy: 0.8693 | Test Precision: 0.8722 | Test Recall: 0.8654\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 26...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4415 | Val Loss: 0.3054 | Accuracy: 0.8786 | Precision: 0.8578 | Recall: 0.8985\n",
      "Epoch 02 | Training Loss: 0.0639 | Val Loss: 0.3291 | Accuracy: 0.8780 | Precision: 0.8516 | Recall: 0.9064\n",
      "Epoch 03 | Training Loss: 0.0187 | Val Loss: 0.3445 | Accuracy: 0.8844 | Precision: 0.8755 | Recall: 0.8878\n",
      "Epoch 04 | Training Loss: 0.0071 | Val Loss: 0.3700 | Accuracy: 0.8808 | Precision: 0.8639 | Recall: 0.8952\n",
      "Epoch 05 | Training Loss: 0.0037 | Val Loss: 0.3895 | Accuracy: 0.8830 | Precision: 0.8679 | Recall: 0.8948\n",
      "Epoch 06 | Training Loss: 0.0023 | Val Loss: 0.4072 | Accuracy: 0.8832 | Precision: 0.8677 | Recall: 0.8956\n",
      "Epoch 07 | Training Loss: 0.0016 | Val Loss: 0.4217 | Accuracy: 0.8826 | Precision: 0.8705 | Recall: 0.8903\n",
      "Epoch 08 | Training Loss: 0.0011 | Val Loss: 0.4387 | Accuracy: 0.8836 | Precision: 0.8666 | Recall: 0.8981\n",
      "Epoch 09 | Training Loss: 0.0008 | Val Loss: 0.4511 | Accuracy: 0.8842 | Precision: 0.8683 | Recall: 0.8973\n",
      "Epoch 10 | Training Loss: 0.0006 | Val Loss: 0.4627 | Accuracy: 0.8838 | Precision: 0.8685 | Recall: 0.8960\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4063 | Test Accuracy: 0.8659 | Test Precision: 0.8690 | Test Recall: 0.8618\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 26...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4217 | Val Loss: 0.3110 | Accuracy: 0.8790 | Precision: 0.8625 | Recall: 0.8927\n",
      "Epoch 02 | Training Loss: 0.0610 | Val Loss: 0.3255 | Accuracy: 0.8828 | Precision: 0.8664 | Recall: 0.8965\n",
      "Epoch 03 | Training Loss: 0.0171 | Val Loss: 0.3580 | Accuracy: 0.8820 | Precision: 0.8869 | Recall: 0.8672\n",
      "Epoch 04 | Training Loss: 0.0065 | Val Loss: 0.3797 | Accuracy: 0.8848 | Precision: 0.8765 | Recall: 0.8874\n",
      "Epoch 05 | Training Loss: 0.0033 | Val Loss: 0.4022 | Accuracy: 0.8852 | Precision: 0.8819 | Recall: 0.8812\n",
      "Epoch 06 | Training Loss: 0.0020 | Val Loss: 0.4225 | Accuracy: 0.8864 | Precision: 0.8739 | Recall: 0.8948\n",
      "Epoch 07 | Training Loss: 0.0014 | Val Loss: 0.4379 | Accuracy: 0.8856 | Precision: 0.8777 | Recall: 0.8878\n",
      "Epoch 08 | Training Loss: 0.0010 | Val Loss: 0.4532 | Accuracy: 0.8854 | Precision: 0.8782 | Recall: 0.8866\n",
      "Epoch 09 | Training Loss: 0.0007 | Val Loss: 0.4676 | Accuracy: 0.8866 | Precision: 0.8761 | Recall: 0.8923\n",
      "Epoch 10 | Training Loss: 0.0006 | Val Loss: 0.4805 | Accuracy: 0.8866 | Precision: 0.8748 | Recall: 0.8940\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4196 | Test Accuracy: 0.8671 | Test Precision: 0.8700 | Test Recall: 0.8631\n",
      "\n",
      "Training for parameter combination: 27, \n",
      "\n",
      "parameters: [2, 'Tanh', 0.001, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 27...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8478 | Val Loss: 0.7721 | Accuracy: 0.5636 | Precision: 0.5470 | Recall: 0.5804\n",
      "Epoch 02 | Training Loss: 0.7076 | Val Loss: 0.6813 | Accuracy: 0.6238 | Precision: 0.6115 | Recall: 0.6143\n",
      "Epoch 03 | Training Loss: 0.6378 | Val Loss: 0.6329 | Accuracy: 0.6636 | Precision: 0.6442 | Recall: 0.6836\n",
      "Epoch 04 | Training Loss: 0.5952 | Val Loss: 0.6008 | Accuracy: 0.6896 | Precision: 0.6690 | Recall: 0.7120\n",
      "Epoch 05 | Training Loss: 0.5654 | Val Loss: 0.5800 | Accuracy: 0.7062 | Precision: 0.6776 | Recall: 0.7517\n",
      "Epoch 06 | Training Loss: 0.5433 | Val Loss: 0.5601 | Accuracy: 0.7196 | Precision: 0.6981 | Recall: 0.7430\n",
      "Epoch 07 | Training Loss: 0.5252 | Val Loss: 0.5450 | Accuracy: 0.7298 | Precision: 0.7111 | Recall: 0.7455\n",
      "Epoch 08 | Training Loss: 0.5100 | Val Loss: 0.5333 | Accuracy: 0.7370 | Precision: 0.7148 | Recall: 0.7611\n",
      "Epoch 09 | Training Loss: 0.4969 | Val Loss: 0.5220 | Accuracy: 0.7432 | Precision: 0.7267 | Recall: 0.7537\n",
      "Epoch 10 | Training Loss: 0.4851 | Val Loss: 0.5135 | Accuracy: 0.7502 | Precision: 0.7303 | Recall: 0.7686\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4447 | Test Accuracy: 0.7543 | Test Precision: 0.7527 | Test Recall: 0.7575\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 27...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8279 | Val Loss: 0.7539 | Accuracy: 0.5776 | Precision: 0.5640 | Recall: 0.5668\n",
      "Epoch 02 | Training Loss: 0.7014 | Val Loss: 0.6745 | Accuracy: 0.6252 | Precision: 0.6078 | Recall: 0.6394\n",
      "Epoch 03 | Training Loss: 0.6363 | Val Loss: 0.6271 | Accuracy: 0.6648 | Precision: 0.6612 | Recall: 0.6328\n",
      "Epoch 04 | Training Loss: 0.5964 | Val Loss: 0.5968 | Accuracy: 0.6848 | Precision: 0.6715 | Recall: 0.6848\n",
      "Epoch 05 | Training Loss: 0.5681 | Val Loss: 0.5756 | Accuracy: 0.7046 | Precision: 0.6859 | Recall: 0.7207\n",
      "Epoch 06 | Training Loss: 0.5468 | Val Loss: 0.5591 | Accuracy: 0.7198 | Precision: 0.6971 | Recall: 0.7463\n",
      "Epoch 07 | Training Loss: 0.5294 | Val Loss: 0.5444 | Accuracy: 0.7328 | Precision: 0.7138 | Recall: 0.7492\n",
      "Epoch 08 | Training Loss: 0.5149 | Val Loss: 0.5321 | Accuracy: 0.7418 | Precision: 0.7278 | Recall: 0.7467\n",
      "Epoch 09 | Training Loss: 0.5022 | Val Loss: 0.5228 | Accuracy: 0.7476 | Precision: 0.7295 | Recall: 0.7620\n",
      "Epoch 10 | Training Loss: 0.4911 | Val Loss: 0.5137 | Accuracy: 0.7508 | Precision: 0.7365 | Recall: 0.7566\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5942 | Test Accuracy: 0.7464 | Test Precision: 0.7485 | Test Recall: 0.7421\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 27...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8372 | Val Loss: 0.7492 | Accuracy: 0.5806 | Precision: 0.5639 | Recall: 0.5953\n",
      "Epoch 02 | Training Loss: 0.7103 | Val Loss: 0.6666 | Accuracy: 0.6344 | Precision: 0.6194 | Recall: 0.6378\n",
      "Epoch 03 | Training Loss: 0.6434 | Val Loss: 0.6186 | Accuracy: 0.6678 | Precision: 0.6582 | Recall: 0.6547\n",
      "Epoch 04 | Training Loss: 0.6022 | Val Loss: 0.5881 | Accuracy: 0.6946 | Precision: 0.6783 | Recall: 0.7038\n",
      "Epoch 05 | Training Loss: 0.5731 | Val Loss: 0.5682 | Accuracy: 0.7080 | Precision: 0.6815 | Recall: 0.7467\n",
      "Epoch 06 | Training Loss: 0.5514 | Val Loss: 0.5482 | Accuracy: 0.7254 | Precision: 0.7130 | Recall: 0.7257\n",
      "Epoch 07 | Training Loss: 0.5338 | Val Loss: 0.5346 | Accuracy: 0.7334 | Precision: 0.7174 | Recall: 0.7426\n",
      "Epoch 08 | Training Loss: 0.5190 | Val Loss: 0.5263 | Accuracy: 0.7416 | Precision: 0.7131 | Recall: 0.7814\n",
      "Epoch 09 | Training Loss: 0.5064 | Val Loss: 0.5127 | Accuracy: 0.7504 | Precision: 0.7361 | Recall: 0.7562\n",
      "Epoch 10 | Training Loss: 0.4950 | Val Loss: 0.5051 | Accuracy: 0.7582 | Precision: 0.7383 | Recall: 0.7764\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5881 | Test Accuracy: 0.7422 | Test Precision: 0.7382 | Test Recall: 0.7506\n",
      "\n",
      "Training for parameter combination: 28, \n",
      "\n",
      "parameters: [2, 'LeakyReLU', 0.0001, 'RMSProp', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 28...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6840 | Val Loss: 0.4996 | Accuracy: 0.7696 | Precision: 0.7552 | Recall: 0.7764\n",
      "Epoch 02 | Training Loss: 0.3795 | Val Loss: 0.4317 | Accuracy: 0.8128 | Precision: 0.7739 | Recall: 0.8672\n",
      "Epoch 03 | Training Loss: 0.2770 | Val Loss: 0.3895 | Accuracy: 0.8370 | Precision: 0.8245 | Recall: 0.8432\n",
      "Epoch 04 | Training Loss: 0.2146 | Val Loss: 0.3886 | Accuracy: 0.8420 | Precision: 0.8618 | Recall: 0.8028\n",
      "Epoch 05 | Training Loss: 0.1701 | Val Loss: 0.3759 | Accuracy: 0.8518 | Precision: 0.8359 | Recall: 0.8639\n",
      "Epoch 06 | Training Loss: 0.1365 | Val Loss: 0.3792 | Accuracy: 0.8576 | Precision: 0.8432 | Recall: 0.8676\n",
      "Epoch 07 | Training Loss: 0.1100 | Val Loss: 0.3899 | Accuracy: 0.8588 | Precision: 0.8374 | Recall: 0.8795\n",
      "Epoch 08 | Training Loss: 0.0879 | Val Loss: 0.4080 | Accuracy: 0.8572 | Precision: 0.8276 | Recall: 0.8911\n",
      "Epoch 09 | Training Loss: 0.0700 | Val Loss: 0.4153 | Accuracy: 0.8574 | Precision: 0.8664 | Recall: 0.8346\n",
      "Epoch 10 | Training Loss: 0.0553 | Val Loss: 0.4508 | Accuracy: 0.8556 | Precision: 0.8180 | Recall: 0.9031\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4831 | Test Accuracy: 0.8517 | Test Precision: 0.8237 | Test Recall: 0.8950\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 28...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6852 | Val Loss: 0.5127 | Accuracy: 0.7628 | Precision: 0.7732 | Recall: 0.7228\n",
      "Epoch 02 | Training Loss: 0.3809 | Val Loss: 0.4270 | Accuracy: 0.8172 | Precision: 0.7975 | Recall: 0.8350\n",
      "Epoch 03 | Training Loss: 0.2816 | Val Loss: 0.3947 | Accuracy: 0.8392 | Precision: 0.8282 | Recall: 0.8432\n",
      "Epoch 04 | Training Loss: 0.2202 | Val Loss: 0.3872 | Accuracy: 0.8468 | Precision: 0.8174 | Recall: 0.8808\n",
      "Epoch 05 | Training Loss: 0.1777 | Val Loss: 0.3849 | Accuracy: 0.8526 | Precision: 0.8216 | Recall: 0.8890\n",
      "Epoch 06 | Training Loss: 0.1433 | Val Loss: 0.3803 | Accuracy: 0.8590 | Precision: 0.8512 | Recall: 0.8593\n",
      "Epoch 07 | Training Loss: 0.1171 | Val Loss: 0.3920 | Accuracy: 0.8608 | Precision: 0.8315 | Recall: 0.8940\n",
      "Epoch 08 | Training Loss: 0.0946 | Val Loss: 0.4002 | Accuracy: 0.8602 | Precision: 0.8622 | Recall: 0.8469\n",
      "Epoch 09 | Training Loss: 0.0759 | Val Loss: 0.4166 | Accuracy: 0.8624 | Precision: 0.8349 | Recall: 0.8927\n",
      "Epoch 10 | Training Loss: 0.0607 | Val Loss: 0.4269 | Accuracy: 0.8642 | Precision: 0.8475 | Recall: 0.8779\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4466 | Test Accuracy: 0.8509 | Test Precision: 0.8493 | Test Recall: 0.8532\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 28...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7388 | Val Loss: 0.5478 | Accuracy: 0.7450 | Precision: 0.8003 | Recall: 0.6316\n",
      "Epoch 02 | Training Loss: 0.3832 | Val Loss: 0.4245 | Accuracy: 0.8128 | Precision: 0.8229 | Recall: 0.7822\n",
      "Epoch 03 | Training Loss: 0.2767 | Val Loss: 0.3904 | Accuracy: 0.8332 | Precision: 0.8089 | Recall: 0.8589\n",
      "Epoch 04 | Training Loss: 0.2139 | Val Loss: 0.3913 | Accuracy: 0.8392 | Precision: 0.8757 | Recall: 0.7789\n",
      "Epoch 05 | Training Loss: 0.1694 | Val Loss: 0.3737 | Accuracy: 0.8504 | Precision: 0.8647 | Recall: 0.8197\n",
      "Epoch 06 | Training Loss: 0.1349 | Val Loss: 0.3731 | Accuracy: 0.8554 | Precision: 0.8311 | Recall: 0.8808\n",
      "Epoch 07 | Training Loss: 0.1078 | Val Loss: 0.3784 | Accuracy: 0.8598 | Precision: 0.8680 | Recall: 0.8383\n",
      "Epoch 08 | Training Loss: 0.0857 | Val Loss: 0.4088 | Accuracy: 0.8546 | Precision: 0.8148 | Recall: 0.9059\n",
      "Epoch 09 | Training Loss: 0.0679 | Val Loss: 0.3979 | Accuracy: 0.8606 | Precision: 0.8500 | Recall: 0.8651\n",
      "Epoch 10 | Training Loss: 0.0532 | Val Loss: 0.4165 | Accuracy: 0.8596 | Precision: 0.8441 | Recall: 0.8713\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4326 | Test Accuracy: 0.8555 | Test Precision: 0.8496 | Test Recall: 0.8638\n",
      "\n",
      "Training for parameter combination: 29, \n",
      "\n",
      "parameters: [3, 'Tanh', 0.0001, 'RMSProp', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 29...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4931 | Val Loss: 0.3936 | Accuracy: 0.8216 | Precision: 0.8469 | Recall: 0.7715\n",
      "Epoch 02 | Training Loss: 0.2566 | Val Loss: 0.3402 | Accuracy: 0.8556 | Precision: 0.8399 | Recall: 0.8676\n",
      "Epoch 03 | Training Loss: 0.1638 | Val Loss: 0.3377 | Accuracy: 0.8688 | Precision: 0.8647 | Recall: 0.8647\n",
      "Epoch 04 | Training Loss: 0.1059 | Val Loss: 0.3550 | Accuracy: 0.8644 | Precision: 0.8371 | Recall: 0.8944\n",
      "Epoch 05 | Training Loss: 0.0650 | Val Loss: 0.3784 | Accuracy: 0.8628 | Precision: 0.8421 | Recall: 0.8824\n",
      "Epoch 06 | Training Loss: 0.0372 | Val Loss: 0.4234 | Accuracy: 0.8626 | Precision: 0.8581 | Recall: 0.8585\n",
      "Epoch 07 | Training Loss: 0.0190 | Val Loss: 0.4873 | Accuracy: 0.8608 | Precision: 0.8331 | Recall: 0.8915\n",
      "Epoch 08 | Training Loss: 0.0087 | Val Loss: 0.5546 | Accuracy: 0.8610 | Precision: 0.8410 | Recall: 0.8795\n",
      "Epoch 09 | Training Loss: 0.0036 | Val Loss: 0.6287 | Accuracy: 0.8604 | Precision: 0.8422 | Recall: 0.8762\n",
      "Epoch 10 | Training Loss: 0.0012 | Val Loss: 0.7019 | Accuracy: 0.8612 | Precision: 0.8536 | Recall: 0.8614\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3150 | Test Accuracy: 0.8563 | Test Precision: 0.8632 | Test Recall: 0.8467\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 29...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4922 | Val Loss: 0.3773 | Accuracy: 0.8330 | Precision: 0.8323 | Recall: 0.8210\n",
      "Epoch 02 | Training Loss: 0.2623 | Val Loss: 0.3333 | Accuracy: 0.8618 | Precision: 0.8443 | Recall: 0.8767\n",
      "Epoch 03 | Training Loss: 0.1722 | Val Loss: 0.3301 | Accuracy: 0.8686 | Precision: 0.8558 | Recall: 0.8767\n",
      "Epoch 04 | Training Loss: 0.1134 | Val Loss: 0.3527 | Accuracy: 0.8678 | Precision: 0.8821 | Recall: 0.8395\n",
      "Epoch 05 | Training Loss: 0.0717 | Val Loss: 0.3723 | Accuracy: 0.8704 | Precision: 0.8538 | Recall: 0.8841\n",
      "Epoch 06 | Training Loss: 0.0427 | Val Loss: 0.4050 | Accuracy: 0.8710 | Precision: 0.8620 | Recall: 0.8738\n",
      "Epoch 07 | Training Loss: 0.0235 | Val Loss: 0.4542 | Accuracy: 0.8692 | Precision: 0.8694 | Recall: 0.8593\n",
      "Epoch 08 | Training Loss: 0.0117 | Val Loss: 0.5162 | Accuracy: 0.8662 | Precision: 0.8509 | Recall: 0.8779\n",
      "Epoch 09 | Training Loss: 0.0054 | Val Loss: 0.5850 | Accuracy: 0.8682 | Precision: 0.8642 | Recall: 0.8639\n",
      "Epoch 10 | Training Loss: 0.0022 | Val Loss: 0.6534 | Accuracy: 0.8662 | Precision: 0.8548 | Recall: 0.8721\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4034 | Test Accuracy: 0.8583 | Test Precision: 0.8568 | Test Recall: 0.8604\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 29...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4832 | Val Loss: 0.3757 | Accuracy: 0.8344 | Precision: 0.8046 | Recall: 0.8696\n",
      "Epoch 02 | Training Loss: 0.2586 | Val Loss: 0.3321 | Accuracy: 0.8610 | Precision: 0.8397 | Recall: 0.8816\n",
      "Epoch 03 | Training Loss: 0.1703 | Val Loss: 0.3438 | Accuracy: 0.8618 | Precision: 0.8242 | Recall: 0.9088\n",
      "Epoch 04 | Training Loss: 0.1122 | Val Loss: 0.3452 | Accuracy: 0.8670 | Precision: 0.8642 | Recall: 0.8610\n",
      "Epoch 05 | Training Loss: 0.0715 | Val Loss: 0.3720 | Accuracy: 0.8690 | Precision: 0.8615 | Recall: 0.8696\n",
      "Epoch 06 | Training Loss: 0.0428 | Val Loss: 0.4150 | Accuracy: 0.8680 | Precision: 0.8462 | Recall: 0.8894\n",
      "Epoch 07 | Training Loss: 0.0236 | Val Loss: 0.4602 | Accuracy: 0.8674 | Precision: 0.8549 | Recall: 0.8750\n",
      "Epoch 08 | Training Loss: 0.0113 | Val Loss: 0.5271 | Accuracy: 0.8640 | Precision: 0.8568 | Recall: 0.8639\n",
      "Epoch 09 | Training Loss: 0.0051 | Val Loss: 0.6053 | Accuracy: 0.8634 | Precision: 0.8431 | Recall: 0.8824\n",
      "Epoch 10 | Training Loss: 0.0019 | Val Loss: 0.6728 | Accuracy: 0.8636 | Precision: 0.8512 | Recall: 0.8709\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4060 | Test Accuracy: 0.8554 | Test Precision: 0.8567 | Test Recall: 0.8536\n",
      "\n",
      "Training for parameter combination: 30, \n",
      "\n",
      "parameters: [1, 'ReLU', 0.001, 'RMSProp', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 30...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4239 | Val Loss: 0.3297 | Accuracy: 0.8662 | Precision: 0.8972 | Recall: 0.8177\n",
      "Epoch 02 | Training Loss: 0.1166 | Val Loss: 0.3282 | Accuracy: 0.8790 | Precision: 0.8804 | Recall: 0.8684\n",
      "Epoch 03 | Training Loss: 0.0310 | Val Loss: 0.3885 | Accuracy: 0.8824 | Precision: 0.8732 | Recall: 0.8861\n",
      "Epoch 04 | Training Loss: 0.0060 | Val Loss: 0.4655 | Accuracy: 0.8788 | Precision: 0.8750 | Recall: 0.8750\n",
      "Epoch 05 | Training Loss: 0.0010 | Val Loss: 0.5531 | Accuracy: 0.8804 | Precision: 0.8742 | Recall: 0.8800\n",
      "Epoch 06 | Training Loss: 0.0003 | Val Loss: 0.6060 | Accuracy: 0.8820 | Precision: 0.8636 | Recall: 0.8985\n",
      "Epoch 07 | Training Loss: 0.0002 | Val Loss: 0.6292 | Accuracy: 0.8814 | Precision: 0.8714 | Recall: 0.8861\n",
      "Epoch 08 | Training Loss: 0.0001 | Val Loss: 0.6509 | Accuracy: 0.8814 | Precision: 0.8690 | Recall: 0.8894\n",
      "Epoch 09 | Training Loss: 0.0001 | Val Loss: 0.6654 | Accuracy: 0.8820 | Precision: 0.8731 | Recall: 0.8853\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.6793 | Accuracy: 0.8816 | Precision: 0.8697 | Recall: 0.8890\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4215 | Test Accuracy: 0.8739 | Test Precision: 0.8717 | Test Recall: 0.8768\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 30...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4335 | Val Loss: 0.3219 | Accuracy: 0.8724 | Precision: 0.8305 | Recall: 0.9257\n",
      "Epoch 02 | Training Loss: 0.1124 | Val Loss: 0.4623 | Accuracy: 0.8402 | Precision: 0.7681 | Recall: 0.9604\n",
      "Epoch 03 | Training Loss: 0.0307 | Val Loss: 0.3759 | Accuracy: 0.8816 | Precision: 0.8804 | Recall: 0.8746\n",
      "Epoch 04 | Training Loss: 0.0054 | Val Loss: 0.4664 | Accuracy: 0.8846 | Precision: 0.8771 | Recall: 0.8861\n",
      "Epoch 05 | Training Loss: 0.0009 | Val Loss: 0.5410 | Accuracy: 0.8834 | Precision: 0.8749 | Recall: 0.8861\n",
      "Epoch 06 | Training Loss: 0.0003 | Val Loss: 0.5849 | Accuracy: 0.8842 | Precision: 0.8767 | Recall: 0.8857\n",
      "Epoch 07 | Training Loss: 0.0002 | Val Loss: 0.6150 | Accuracy: 0.8824 | Precision: 0.8690 | Recall: 0.8919\n",
      "Epoch 08 | Training Loss: 0.0001 | Val Loss: 0.6329 | Accuracy: 0.8822 | Precision: 0.8704 | Recall: 0.8894\n",
      "Epoch 09 | Training Loss: 0.0001 | Val Loss: 0.6470 | Accuracy: 0.8838 | Precision: 0.8741 | Recall: 0.8882\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.6599 | Accuracy: 0.8826 | Precision: 0.8708 | Recall: 0.8899\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4314 | Test Accuracy: 0.8753 | Test Precision: 0.8749 | Test Recall: 0.8758\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 30...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4271 | Val Loss: 0.3391 | Accuracy: 0.8630 | Precision: 0.9005 | Recall: 0.8065\n",
      "Epoch 02 | Training Loss: 0.1123 | Val Loss: 0.3485 | Accuracy: 0.8754 | Precision: 0.8569 | Recall: 0.8919\n",
      "Epoch 03 | Training Loss: 0.0299 | Val Loss: 0.4119 | Accuracy: 0.8772 | Precision: 0.8712 | Recall: 0.8762\n",
      "Epoch 04 | Training Loss: 0.0057 | Val Loss: 0.6376 | Accuracy: 0.8580 | Precision: 0.7999 | Recall: 0.9431\n",
      "Epoch 05 | Training Loss: 0.0010 | Val Loss: 0.5876 | Accuracy: 0.8780 | Precision: 0.8625 | Recall: 0.8903\n",
      "Epoch 06 | Training Loss: 0.0003 | Val Loss: 0.6341 | Accuracy: 0.8782 | Precision: 0.8649 | Recall: 0.8874\n",
      "Epoch 07 | Training Loss: 0.0002 | Val Loss: 0.6651 | Accuracy: 0.8780 | Precision: 0.8625 | Recall: 0.8903\n",
      "Epoch 08 | Training Loss: 0.0001 | Val Loss: 0.6870 | Accuracy: 0.8776 | Precision: 0.8624 | Recall: 0.8894\n",
      "Epoch 09 | Training Loss: 0.0001 | Val Loss: 0.7003 | Accuracy: 0.8794 | Precision: 0.8676 | Recall: 0.8866\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.7136 | Accuracy: 0.8796 | Precision: 0.8679 | Recall: 0.8866\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4245 | Test Accuracy: 0.8736 | Test Precision: 0.8741 | Test Recall: 0.8730\n",
      "\n",
      "Training for parameter combination: 31, \n",
      "\n",
      "parameters: [2, 'Tanh', 0.0005, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 31...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8312 | Val Loss: 0.7812 | Accuracy: 0.5690 | Precision: 0.5529 | Recall: 0.5796\n",
      "Epoch 02 | Training Loss: 0.7569 | Val Loss: 0.7277 | Accuracy: 0.6004 | Precision: 0.5866 | Recall: 0.5953\n",
      "Epoch 03 | Training Loss: 0.7085 | Val Loss: 0.6900 | Accuracy: 0.6234 | Precision: 0.6094 | Recall: 0.6217\n",
      "Epoch 04 | Training Loss: 0.6726 | Val Loss: 0.6614 | Accuracy: 0.6412 | Precision: 0.6293 | Recall: 0.6324\n",
      "Epoch 05 | Training Loss: 0.6447 | Val Loss: 0.6402 | Accuracy: 0.6506 | Precision: 0.6323 | Recall: 0.6675\n",
      "Epoch 06 | Training Loss: 0.6228 | Val Loss: 0.6212 | Accuracy: 0.6692 | Precision: 0.6574 | Recall: 0.6634\n",
      "Epoch 07 | Training Loss: 0.6045 | Val Loss: 0.6063 | Accuracy: 0.6802 | Precision: 0.6690 | Recall: 0.6737\n",
      "Epoch 08 | Training Loss: 0.5893 | Val Loss: 0.5940 | Accuracy: 0.6906 | Precision: 0.6770 | Recall: 0.6918\n",
      "Epoch 09 | Training Loss: 0.5761 | Val Loss: 0.5834 | Accuracy: 0.7010 | Precision: 0.6856 | Recall: 0.7079\n",
      "Epoch 10 | Training Loss: 0.5646 | Val Loss: 0.5735 | Accuracy: 0.7050 | Precision: 0.6939 | Recall: 0.7005\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6247 | Test Accuracy: 0.7096 | Test Precision: 0.7111 | Test Recall: 0.7062\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 31...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8540 | Val Loss: 0.8025 | Accuracy: 0.5568 | Precision: 0.5422 | Recall: 0.5516\n",
      "Epoch 02 | Training Loss: 0.7699 | Val Loss: 0.7402 | Accuracy: 0.5910 | Precision: 0.5780 | Recall: 0.5792\n",
      "Epoch 03 | Training Loss: 0.7152 | Val Loss: 0.6965 | Accuracy: 0.6156 | Precision: 0.6038 | Recall: 0.6023\n",
      "Epoch 04 | Training Loss: 0.6755 | Val Loss: 0.6645 | Accuracy: 0.6396 | Precision: 0.6269 | Recall: 0.6337\n",
      "Epoch 05 | Training Loss: 0.6454 | Val Loss: 0.6402 | Accuracy: 0.6564 | Precision: 0.6410 | Recall: 0.6621\n",
      "Epoch 06 | Training Loss: 0.6218 | Val Loss: 0.6205 | Accuracy: 0.6702 | Precision: 0.6551 | Recall: 0.6753\n",
      "Epoch 07 | Training Loss: 0.6025 | Val Loss: 0.6041 | Accuracy: 0.6832 | Precision: 0.6695 | Recall: 0.6844\n",
      "Epoch 08 | Training Loss: 0.5863 | Val Loss: 0.5917 | Accuracy: 0.6934 | Precision: 0.6719 | Recall: 0.7182\n",
      "Epoch 09 | Training Loss: 0.5725 | Val Loss: 0.5791 | Accuracy: 0.7040 | Precision: 0.6930 | Recall: 0.6993\n",
      "Epoch 10 | Training Loss: 0.5605 | Val Loss: 0.5695 | Accuracy: 0.7094 | Precision: 0.6918 | Recall: 0.7224\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5848 | Test Accuracy: 0.7083 | Test Precision: 0.7085 | Test Recall: 0.7079\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 31...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8864 | Val Loss: 0.8218 | Accuracy: 0.5404 | Precision: 0.5263 | Recall: 0.5206\n",
      "Epoch 02 | Training Loss: 0.7854 | Val Loss: 0.7512 | Accuracy: 0.5774 | Precision: 0.5642 | Recall: 0.5639\n",
      "Epoch 03 | Training Loss: 0.7236 | Val Loss: 0.7034 | Accuracy: 0.6058 | Precision: 0.5920 | Recall: 0.6015\n",
      "Epoch 04 | Training Loss: 0.6802 | Val Loss: 0.6707 | Accuracy: 0.6276 | Precision: 0.6082 | Recall: 0.6518\n",
      "Epoch 05 | Training Loss: 0.6483 | Val Loss: 0.6440 | Accuracy: 0.6490 | Precision: 0.6308 | Recall: 0.6654\n",
      "Epoch 06 | Training Loss: 0.6237 | Val Loss: 0.6228 | Accuracy: 0.6660 | Precision: 0.6518 | Recall: 0.6679\n",
      "Epoch 07 | Training Loss: 0.6040 | Val Loss: 0.6063 | Accuracy: 0.6788 | Precision: 0.6649 | Recall: 0.6803\n",
      "Epoch 08 | Training Loss: 0.5877 | Val Loss: 0.5933 | Accuracy: 0.6904 | Precision: 0.6726 | Recall: 0.7042\n",
      "Epoch 09 | Training Loss: 0.5738 | Val Loss: 0.5810 | Accuracy: 0.6984 | Precision: 0.6859 | Recall: 0.6972\n",
      "Epoch 10 | Training Loss: 0.5620 | Val Loss: 0.5711 | Accuracy: 0.7054 | Precision: 0.6917 | Recall: 0.7079\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6119 | Test Accuracy: 0.7058 | Test Precision: 0.7102 | Test Recall: 0.6955\n",
      "\n",
      "Training for parameter combination: 32, \n",
      "\n",
      "parameters: [2, 'Tanh', 0.0005, 'RMSProp', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 32...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4445 | Val Loss: 0.3692 | Accuracy: 0.8400 | Precision: 0.7792 | Recall: 0.9348\n",
      "Epoch 02 | Training Loss: 0.1743 | Val Loss: 0.3385 | Accuracy: 0.8642 | Precision: 0.8262 | Recall: 0.9117\n",
      "Epoch 03 | Training Loss: 0.0839 | Val Loss: 0.3424 | Accuracy: 0.8696 | Precision: 0.8550 | Recall: 0.8804\n",
      "Epoch 04 | Training Loss: 0.0360 | Val Loss: 0.4648 | Accuracy: 0.8524 | Precision: 0.9149 | Recall: 0.7669\n",
      "Epoch 05 | Training Loss: 0.0159 | Val Loss: 0.4521 | Accuracy: 0.8752 | Precision: 0.8686 | Recall: 0.8750\n",
      "Epoch 06 | Training Loss: 0.0058 | Val Loss: 0.5096 | Accuracy: 0.8744 | Precision: 0.8677 | Recall: 0.8742\n",
      "Epoch 07 | Training Loss: 0.0017 | Val Loss: 0.5783 | Accuracy: 0.8710 | Precision: 0.8542 | Recall: 0.8849\n",
      "Epoch 08 | Training Loss: 0.0006 | Val Loss: 0.6297 | Accuracy: 0.8720 | Precision: 0.8545 | Recall: 0.8870\n",
      "Epoch 09 | Training Loss: 0.0003 | Val Loss: 0.6611 | Accuracy: 0.8742 | Precision: 0.8609 | Recall: 0.8833\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.6864 | Accuracy: 0.8740 | Precision: 0.8611 | Recall: 0.8824\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4289 | Test Accuracy: 0.8652 | Test Precision: 0.8678 | Test Recall: 0.8618\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 32...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4364 | Val Loss: 0.3761 | Accuracy: 0.8428 | Precision: 0.7814 | Recall: 0.9381\n",
      "Epoch 02 | Training Loss: 0.1778 | Val Loss: 0.3196 | Accuracy: 0.8660 | Precision: 0.8588 | Recall: 0.8659\n",
      "Epoch 03 | Training Loss: 0.0903 | Val Loss: 0.3559 | Accuracy: 0.8660 | Precision: 0.8912 | Recall: 0.8243\n",
      "Epoch 04 | Training Loss: 0.0410 | Val Loss: 0.4174 | Accuracy: 0.8684 | Precision: 0.8317 | Recall: 0.9134\n",
      "Epoch 05 | Training Loss: 0.0174 | Val Loss: 0.4966 | Accuracy: 0.8658 | Precision: 0.8255 | Recall: 0.9171\n",
      "Epoch 06 | Training Loss: 0.0055 | Val Loss: 0.5393 | Accuracy: 0.8682 | Precision: 0.8725 | Recall: 0.8527\n",
      "Epoch 07 | Training Loss: 0.0016 | Val Loss: 0.6406 | Accuracy: 0.8680 | Precision: 0.8356 | Recall: 0.9059\n",
      "Epoch 08 | Training Loss: 0.0006 | Val Loss: 0.6660 | Accuracy: 0.8686 | Precision: 0.8590 | Recall: 0.8721\n",
      "Epoch 09 | Training Loss: 0.0003 | Val Loss: 0.7011 | Accuracy: 0.8682 | Precision: 0.8586 | Recall: 0.8717\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.7267 | Accuracy: 0.8690 | Precision: 0.8582 | Recall: 0.8742\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4357 | Test Accuracy: 0.8658 | Test Precision: 0.8640 | Test Recall: 0.8683\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 32...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4424 | Val Loss: 0.3664 | Accuracy: 0.8374 | Precision: 0.9025 | Recall: 0.7450\n",
      "Epoch 02 | Training Loss: 0.1754 | Val Loss: 0.3595 | Accuracy: 0.8630 | Precision: 0.8104 | Recall: 0.9365\n",
      "Epoch 03 | Training Loss: 0.0878 | Val Loss: 0.3485 | Accuracy: 0.8708 | Precision: 0.8511 | Recall: 0.8890\n",
      "Epoch 04 | Training Loss: 0.0390 | Val Loss: 0.3967 | Accuracy: 0.8708 | Precision: 0.8539 | Recall: 0.8849\n",
      "Epoch 05 | Training Loss: 0.0162 | Val Loss: 0.4886 | Accuracy: 0.8696 | Precision: 0.8359 | Recall: 0.9097\n",
      "Epoch 06 | Training Loss: 0.0057 | Val Loss: 0.5378 | Accuracy: 0.8754 | Precision: 0.8638 | Recall: 0.8820\n",
      "Epoch 07 | Training Loss: 0.0015 | Val Loss: 0.6088 | Accuracy: 0.8770 | Precision: 0.8696 | Recall: 0.8779\n",
      "Epoch 08 | Training Loss: 0.0005 | Val Loss: 0.6637 | Accuracy: 0.8768 | Precision: 0.8642 | Recall: 0.8849\n",
      "Epoch 09 | Training Loss: 0.0003 | Val Loss: 0.6977 | Accuracy: 0.8768 | Precision: 0.8654 | Recall: 0.8833\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.7238 | Accuracy: 0.8770 | Precision: 0.8646 | Recall: 0.8849\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3703 | Test Accuracy: 0.8648 | Test Precision: 0.8653 | Test Recall: 0.8641\n",
      "\n",
      "Training for parameter combination: 33, \n",
      "\n",
      "parameters: [3, 'Tanh', 0.0001, 'Adam', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 33...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5710 | Val Loss: 0.4480 | Accuracy: 0.7948 | Precision: 0.7754 | Recall: 0.8119\n",
      "Epoch 02 | Training Loss: 0.2940 | Val Loss: 0.3612 | Accuracy: 0.8352 | Precision: 0.8187 | Recall: 0.8478\n",
      "Epoch 03 | Training Loss: 0.1648 | Val Loss: 0.3373 | Accuracy: 0.8532 | Precision: 0.8460 | Recall: 0.8523\n",
      "Epoch 04 | Training Loss: 0.0915 | Val Loss: 0.3369 | Accuracy: 0.8614 | Precision: 0.8599 | Recall: 0.8531\n",
      "Epoch 05 | Training Loss: 0.0497 | Val Loss: 0.3504 | Accuracy: 0.8626 | Precision: 0.8626 | Recall: 0.8523\n",
      "Epoch 06 | Training Loss: 0.0266 | Val Loss: 0.3685 | Accuracy: 0.8636 | Precision: 0.8492 | Recall: 0.8738\n",
      "Epoch 07 | Training Loss: 0.0146 | Val Loss: 0.3868 | Accuracy: 0.8658 | Precision: 0.8617 | Recall: 0.8614\n",
      "Epoch 08 | Training Loss: 0.0086 | Val Loss: 0.4062 | Accuracy: 0.8642 | Precision: 0.8505 | Recall: 0.8733\n",
      "Epoch 09 | Training Loss: 0.0055 | Val Loss: 0.4227 | Accuracy: 0.8660 | Precision: 0.8553 | Recall: 0.8709\n",
      "Epoch 10 | Training Loss: 0.0038 | Val Loss: 0.4386 | Accuracy: 0.8662 | Precision: 0.8528 | Recall: 0.8750\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4166 | Test Accuracy: 0.8565 | Test Precision: 0.8557 | Test Recall: 0.8575\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 33...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5611 | Val Loss: 0.4447 | Accuracy: 0.8022 | Precision: 0.7806 | Recall: 0.8234\n",
      "Epoch 02 | Training Loss: 0.2935 | Val Loss: 0.3662 | Accuracy: 0.8420 | Precision: 0.8181 | Recall: 0.8667\n",
      "Epoch 03 | Training Loss: 0.1675 | Val Loss: 0.3416 | Accuracy: 0.8540 | Precision: 0.8391 | Recall: 0.8647\n",
      "Epoch 04 | Training Loss: 0.0947 | Val Loss: 0.3447 | Accuracy: 0.8590 | Precision: 0.8377 | Recall: 0.8795\n",
      "Epoch 05 | Training Loss: 0.0518 | Val Loss: 0.3607 | Accuracy: 0.8604 | Precision: 0.8390 | Recall: 0.8812\n",
      "Epoch 06 | Training Loss: 0.0281 | Val Loss: 0.3747 | Accuracy: 0.8618 | Precision: 0.8510 | Recall: 0.8667\n",
      "Epoch 07 | Training Loss: 0.0154 | Val Loss: 0.3948 | Accuracy: 0.8632 | Precision: 0.8494 | Recall: 0.8725\n",
      "Epoch 08 | Training Loss: 0.0090 | Val Loss: 0.4122 | Accuracy: 0.8648 | Precision: 0.8550 | Recall: 0.8684\n",
      "Epoch 09 | Training Loss: 0.0056 | Val Loss: 0.4306 | Accuracy: 0.8650 | Precision: 0.8522 | Recall: 0.8729\n",
      "Epoch 10 | Training Loss: 0.0038 | Val Loss: 0.4482 | Accuracy: 0.8678 | Precision: 0.8513 | Recall: 0.8812\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3830 | Test Accuracy: 0.8574 | Test Precision: 0.8547 | Test Recall: 0.8614\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 33...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5737 | Val Loss: 0.4526 | Accuracy: 0.7904 | Precision: 0.7700 | Recall: 0.8094\n",
      "Epoch 02 | Training Loss: 0.3044 | Val Loss: 0.3683 | Accuracy: 0.8378 | Precision: 0.8293 | Recall: 0.8379\n",
      "Epoch 03 | Training Loss: 0.1750 | Val Loss: 0.3446 | Accuracy: 0.8550 | Precision: 0.8432 | Recall: 0.8610\n",
      "Epoch 04 | Training Loss: 0.0985 | Val Loss: 0.3473 | Accuracy: 0.8594 | Precision: 0.8599 | Recall: 0.8482\n",
      "Epoch 05 | Training Loss: 0.0533 | Val Loss: 0.3638 | Accuracy: 0.8618 | Precision: 0.8661 | Recall: 0.8457\n",
      "Epoch 06 | Training Loss: 0.0285 | Val Loss: 0.3848 | Accuracy: 0.8682 | Precision: 0.8526 | Recall: 0.8804\n",
      "Epoch 07 | Training Loss: 0.0156 | Val Loss: 0.4067 | Accuracy: 0.8684 | Precision: 0.8555 | Recall: 0.8767\n",
      "Epoch 08 | Training Loss: 0.0090 | Val Loss: 0.4266 | Accuracy: 0.8684 | Precision: 0.8578 | Recall: 0.8733\n",
      "Epoch 09 | Training Loss: 0.0057 | Val Loss: 0.4464 | Accuracy: 0.8690 | Precision: 0.8568 | Recall: 0.8762\n",
      "Epoch 10 | Training Loss: 0.0037 | Val Loss: 0.4630 | Accuracy: 0.8688 | Precision: 0.8579 | Recall: 0.8742\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3702 | Test Accuracy: 0.8610 | Test Precision: 0.8614 | Test Recall: 0.8605\n",
      "\n",
      "Training for parameter combination: 34, \n",
      "\n",
      "parameters: [1, 'Tanh', 0.0005, 'RMSProp', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 34...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4486 | Val Loss: 0.3319 | Accuracy: 0.8616 | Precision: 0.8179 | Recall: 0.9191\n",
      "Epoch 02 | Training Loss: 0.1915 | Val Loss: 0.3529 | Accuracy: 0.8592 | Precision: 0.8024 | Recall: 0.9414\n",
      "Epoch 03 | Training Loss: 0.1205 | Val Loss: 0.3079 | Accuracy: 0.8784 | Precision: 0.8718 | Recall: 0.8783\n",
      "Epoch 04 | Training Loss: 0.0799 | Val Loss: 0.3568 | Accuracy: 0.8680 | Precision: 0.9153 | Recall: 0.8020\n",
      "Epoch 05 | Training Loss: 0.0510 | Val Loss: 0.3480 | Accuracy: 0.8806 | Precision: 0.8573 | Recall: 0.9043\n",
      "Epoch 06 | Training Loss: 0.0334 | Val Loss: 0.4051 | Accuracy: 0.8706 | Precision: 0.9119 | Recall: 0.8115\n",
      "Epoch 07 | Training Loss: 0.0216 | Val Loss: 0.4334 | Accuracy: 0.8732 | Precision: 0.8303 | Recall: 0.9282\n",
      "Epoch 08 | Training Loss: 0.0138 | Val Loss: 0.4603 | Accuracy: 0.8710 | Precision: 0.8328 | Recall: 0.9183\n",
      "Epoch 09 | Training Loss: 0.0080 | Val Loss: 0.4546 | Accuracy: 0.8766 | Precision: 0.8747 | Recall: 0.8700\n",
      "Epoch 10 | Training Loss: 0.0049 | Val Loss: 0.4876 | Accuracy: 0.8746 | Precision: 0.8622 | Recall: 0.8824\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4577 | Test Accuracy: 0.8642 | Test Precision: 0.8659 | Test Recall: 0.8618\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 34...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4470 | Val Loss: 0.3099 | Accuracy: 0.8726 | Precision: 0.8584 | Recall: 0.8828\n",
      "Epoch 02 | Training Loss: 0.1921 | Val Loss: 0.2991 | Accuracy: 0.8770 | Precision: 0.8724 | Recall: 0.8742\n",
      "Epoch 03 | Training Loss: 0.1227 | Val Loss: 0.3232 | Accuracy: 0.8748 | Precision: 0.8375 | Recall: 0.9204\n",
      "Epoch 04 | Training Loss: 0.0809 | Val Loss: 0.3907 | Accuracy: 0.8592 | Precision: 0.8003 | Recall: 0.9455\n",
      "Epoch 05 | Training Loss: 0.0541 | Val Loss: 0.3557 | Accuracy: 0.8754 | Precision: 0.8972 | Recall: 0.8391\n",
      "Epoch 06 | Training Loss: 0.0348 | Val Loss: 0.3703 | Accuracy: 0.8802 | Precision: 0.8687 | Recall: 0.8870\n",
      "Epoch 07 | Training Loss: 0.0218 | Val Loss: 0.4137 | Accuracy: 0.8730 | Precision: 0.8397 | Recall: 0.9121\n",
      "Epoch 08 | Training Loss: 0.0138 | Val Loss: 0.4454 | Accuracy: 0.8724 | Precision: 0.9019 | Recall: 0.8267\n",
      "Epoch 09 | Training Loss: 0.0085 | Val Loss: 0.4527 | Accuracy: 0.8798 | Precision: 0.8746 | Recall: 0.8779\n",
      "Epoch 10 | Training Loss: 0.0052 | Val Loss: 0.4828 | Accuracy: 0.8792 | Precision: 0.8739 | Recall: 0.8775\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4151 | Test Accuracy: 0.8674 | Test Precision: 0.8702 | Test Recall: 0.8637\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 34...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4550 | Val Loss: 0.3606 | Accuracy: 0.8490 | Precision: 0.7911 | Recall: 0.9356\n",
      "Epoch 02 | Training Loss: 0.1929 | Val Loss: 0.3049 | Accuracy: 0.8684 | Precision: 0.8546 | Recall: 0.8779\n",
      "Epoch 03 | Training Loss: 0.1213 | Val Loss: 0.3183 | Accuracy: 0.8710 | Precision: 0.8402 | Recall: 0.9064\n",
      "Epoch 04 | Training Loss: 0.0781 | Val Loss: 0.3345 | Accuracy: 0.8716 | Precision: 0.8827 | Recall: 0.8478\n",
      "Epoch 05 | Training Loss: 0.0520 | Val Loss: 0.3492 | Accuracy: 0.8754 | Precision: 0.8677 | Recall: 0.8767\n",
      "Epoch 06 | Training Loss: 0.0330 | Val Loss: 0.3830 | Accuracy: 0.8690 | Precision: 0.8465 | Recall: 0.8915\n",
      "Epoch 07 | Training Loss: 0.0214 | Val Loss: 0.4032 | Accuracy: 0.8730 | Precision: 0.8701 | Recall: 0.8676\n",
      "Epoch 08 | Training Loss: 0.0132 | Val Loss: 0.4465 | Accuracy: 0.8702 | Precision: 0.8874 | Recall: 0.8387\n",
      "Epoch 09 | Training Loss: 0.0082 | Val Loss: 0.4753 | Accuracy: 0.8678 | Precision: 0.8381 | Recall: 0.9014\n",
      "Epoch 10 | Training Loss: 0.0049 | Val Loss: 0.4915 | Accuracy: 0.8724 | Precision: 0.8607 | Recall: 0.8791\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4217 | Test Accuracy: 0.8647 | Test Precision: 0.8666 | Test Recall: 0.8620\n",
      "\n",
      "Training for parameter combination: 35, \n",
      "\n",
      "parameters: [1, 'Tanh', 0.0005, 'SGD', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 35...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9744 | Val Loss: 0.9531 | Accuracy: 0.5212 | Precision: 0.5060 | Recall: 0.5256\n",
      "Epoch 02 | Training Loss: 0.9164 | Val Loss: 0.9044 | Accuracy: 0.5356 | Precision: 0.5201 | Recall: 0.5446\n",
      "Epoch 03 | Training Loss: 0.8698 | Val Loss: 0.8628 | Accuracy: 0.5552 | Precision: 0.5391 | Recall: 0.5693\n",
      "Epoch 04 | Training Loss: 0.8299 | Val Loss: 0.8257 | Accuracy: 0.5728 | Precision: 0.5573 | Recall: 0.5776\n",
      "Epoch 05 | Training Loss: 0.7953 | Val Loss: 0.7940 | Accuracy: 0.5864 | Precision: 0.5705 | Recall: 0.5941\n",
      "Epoch 06 | Training Loss: 0.7652 | Val Loss: 0.7660 | Accuracy: 0.6044 | Precision: 0.5885 | Recall: 0.6118\n",
      "Epoch 07 | Training Loss: 0.7385 | Val Loss: 0.7414 | Accuracy: 0.6174 | Precision: 0.6019 | Recall: 0.6225\n",
      "Epoch 08 | Training Loss: 0.7153 | Val Loss: 0.7193 | Accuracy: 0.6304 | Precision: 0.6152 | Recall: 0.6345\n",
      "Epoch 09 | Training Loss: 0.6944 | Val Loss: 0.7010 | Accuracy: 0.6398 | Precision: 0.6213 | Recall: 0.6580\n",
      "Epoch 10 | Training Loss: 0.6758 | Val Loss: 0.6826 | Accuracy: 0.6484 | Precision: 0.6319 | Recall: 0.6580\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6691 | Test Accuracy: 0.6472 | Test Precision: 0.6438 | Test Recall: 0.6590\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 35...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9459 | Val Loss: 0.9138 | Accuracy: 0.5478 | Precision: 0.5329 | Recall: 0.5446\n",
      "Epoch 02 | Training Loss: 0.8934 | Val Loss: 0.8713 | Accuracy: 0.5608 | Precision: 0.5446 | Recall: 0.5743\n",
      "Epoch 03 | Training Loss: 0.8495 | Val Loss: 0.8334 | Accuracy: 0.5812 | Precision: 0.5648 | Recall: 0.5936\n",
      "Epoch 04 | Training Loss: 0.8118 | Val Loss: 0.7995 | Accuracy: 0.5928 | Precision: 0.5775 | Recall: 0.5961\n",
      "Epoch 05 | Training Loss: 0.7791 | Val Loss: 0.7707 | Accuracy: 0.6076 | Precision: 0.5931 | Recall: 0.6073\n",
      "Epoch 06 | Training Loss: 0.7506 | Val Loss: 0.7464 | Accuracy: 0.6222 | Precision: 0.6063 | Recall: 0.6295\n",
      "Epoch 07 | Training Loss: 0.7254 | Val Loss: 0.7248 | Accuracy: 0.6330 | Precision: 0.6160 | Recall: 0.6452\n",
      "Epoch 08 | Training Loss: 0.7033 | Val Loss: 0.7040 | Accuracy: 0.6414 | Precision: 0.6272 | Recall: 0.6419\n",
      "Epoch 09 | Training Loss: 0.6835 | Val Loss: 0.6868 | Accuracy: 0.6502 | Precision: 0.6343 | Recall: 0.6576\n",
      "Epoch 10 | Training Loss: 0.6657 | Val Loss: 0.6713 | Accuracy: 0.6598 | Precision: 0.6429 | Recall: 0.6708\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6187 | Test Accuracy: 0.6592 | Test Precision: 0.6592 | Test Recall: 0.6593\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 35...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9486 | Val Loss: 0.9059 | Accuracy: 0.5466 | Precision: 0.5308 | Recall: 0.5586\n",
      "Epoch 02 | Training Loss: 0.8894 | Val Loss: 0.8626 | Accuracy: 0.5610 | Precision: 0.5440 | Recall: 0.5846\n",
      "Epoch 03 | Training Loss: 0.8451 | Val Loss: 0.8249 | Accuracy: 0.5744 | Precision: 0.5562 | Recall: 0.6044\n",
      "Epoch 04 | Training Loss: 0.8072 | Val Loss: 0.7906 | Accuracy: 0.5902 | Precision: 0.5733 | Recall: 0.6052\n",
      "Epoch 05 | Training Loss: 0.7745 | Val Loss: 0.7618 | Accuracy: 0.6072 | Precision: 0.5913 | Recall: 0.6143\n",
      "Epoch 06 | Training Loss: 0.7461 | Val Loss: 0.7381 | Accuracy: 0.6204 | Precision: 0.6026 | Recall: 0.6374\n",
      "Epoch 07 | Training Loss: 0.7212 | Val Loss: 0.7156 | Accuracy: 0.6344 | Precision: 0.6183 | Recall: 0.6423\n",
      "Epoch 08 | Training Loss: 0.6993 | Val Loss: 0.6969 | Accuracy: 0.6432 | Precision: 0.6256 | Recall: 0.6576\n",
      "Epoch 09 | Training Loss: 0.6797 | Val Loss: 0.6798 | Accuracy: 0.6516 | Precision: 0.6337 | Recall: 0.6667\n",
      "Epoch 10 | Training Loss: 0.6623 | Val Loss: 0.6648 | Accuracy: 0.6598 | Precision: 0.6407 | Recall: 0.6790\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5871 | Test Accuracy: 0.6596 | Test Precision: 0.6594 | Test Recall: 0.6604\n",
      "\n",
      "Training for parameter combination: 36, \n",
      "\n",
      "parameters: [1, 'ReLU', 0.0001, 'Adam', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 36...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7358 | Val Loss: 0.5369 | Accuracy: 0.7530 | Precision: 0.7450 | Recall: 0.7459\n",
      "Epoch 02 | Training Loss: 0.3583 | Val Loss: 0.4297 | Accuracy: 0.8110 | Precision: 0.7876 | Recall: 0.8354\n",
      "Epoch 03 | Training Loss: 0.2303 | Val Loss: 0.3827 | Accuracy: 0.8324 | Precision: 0.8147 | Recall: 0.8469\n",
      "Epoch 04 | Training Loss: 0.1607 | Val Loss: 0.3580 | Accuracy: 0.8472 | Precision: 0.8304 | Recall: 0.8606\n",
      "Epoch 05 | Training Loss: 0.1174 | Val Loss: 0.3437 | Accuracy: 0.8534 | Precision: 0.8346 | Recall: 0.8700\n",
      "Epoch 06 | Training Loss: 0.0882 | Val Loss: 0.3360 | Accuracy: 0.8578 | Precision: 0.8400 | Recall: 0.8729\n",
      "Epoch 07 | Training Loss: 0.0676 | Val Loss: 0.3319 | Accuracy: 0.8618 | Precision: 0.8426 | Recall: 0.8791\n",
      "Epoch 08 | Training Loss: 0.0526 | Val Loss: 0.3272 | Accuracy: 0.8660 | Precision: 0.8542 | Recall: 0.8725\n",
      "Epoch 09 | Training Loss: 0.0415 | Val Loss: 0.3275 | Accuracy: 0.8676 | Precision: 0.8499 | Recall: 0.8828\n",
      "Epoch 10 | Training Loss: 0.0331 | Val Loss: 0.3278 | Accuracy: 0.8688 | Precision: 0.8528 | Recall: 0.8816\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4265 | Test Accuracy: 0.8620 | Test Precision: 0.8626 | Test Recall: 0.8612\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 36...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7330 | Val Loss: 0.5109 | Accuracy: 0.7640 | Precision: 0.7723 | Recall: 0.7277\n",
      "Epoch 02 | Training Loss: 0.3611 | Val Loss: 0.4095 | Accuracy: 0.8292 | Precision: 0.8123 | Recall: 0.8424\n",
      "Epoch 03 | Training Loss: 0.2319 | Val Loss: 0.3674 | Accuracy: 0.8454 | Precision: 0.8365 | Recall: 0.8465\n",
      "Epoch 04 | Training Loss: 0.1616 | Val Loss: 0.3460 | Accuracy: 0.8574 | Precision: 0.8534 | Recall: 0.8523\n",
      "Epoch 05 | Training Loss: 0.1176 | Val Loss: 0.3345 | Accuracy: 0.8650 | Precision: 0.8645 | Recall: 0.8556\n",
      "Epoch 06 | Training Loss: 0.0877 | Val Loss: 0.3269 | Accuracy: 0.8684 | Precision: 0.8631 | Recall: 0.8659\n",
      "Epoch 07 | Training Loss: 0.0667 | Val Loss: 0.3260 | Accuracy: 0.8726 | Precision: 0.8522 | Recall: 0.8919\n",
      "Epoch 08 | Training Loss: 0.0515 | Val Loss: 0.3232 | Accuracy: 0.8750 | Precision: 0.8623 | Recall: 0.8833\n",
      "Epoch 09 | Training Loss: 0.0405 | Val Loss: 0.3236 | Accuracy: 0.8764 | Precision: 0.8644 | Recall: 0.8837\n",
      "Epoch 10 | Training Loss: 0.0322 | Val Loss: 0.3251 | Accuracy: 0.8782 | Precision: 0.8664 | Recall: 0.8853\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4317 | Test Accuracy: 0.8644 | Test Precision: 0.8658 | Test Recall: 0.8626\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 36...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7360 | Val Loss: 0.5422 | Accuracy: 0.7500 | Precision: 0.7161 | Recall: 0.8024\n",
      "Epoch 02 | Training Loss: 0.3565 | Val Loss: 0.4278 | Accuracy: 0.8168 | Precision: 0.8098 | Recall: 0.8131\n",
      "Epoch 03 | Training Loss: 0.2266 | Val Loss: 0.3849 | Accuracy: 0.8412 | Precision: 0.8335 | Recall: 0.8403\n",
      "Epoch 04 | Training Loss: 0.1581 | Val Loss: 0.3645 | Accuracy: 0.8516 | Precision: 0.8359 | Recall: 0.8634\n",
      "Epoch 05 | Training Loss: 0.1155 | Val Loss: 0.3523 | Accuracy: 0.8588 | Precision: 0.8409 | Recall: 0.8742\n",
      "Epoch 06 | Training Loss: 0.0869 | Val Loss: 0.3449 | Accuracy: 0.8630 | Precision: 0.8536 | Recall: 0.8659\n",
      "Epoch 07 | Training Loss: 0.0664 | Val Loss: 0.3417 | Accuracy: 0.8660 | Precision: 0.8486 | Recall: 0.8808\n",
      "Epoch 08 | Training Loss: 0.0517 | Val Loss: 0.3403 | Accuracy: 0.8698 | Precision: 0.8533 | Recall: 0.8833\n",
      "Epoch 09 | Training Loss: 0.0408 | Val Loss: 0.3412 | Accuracy: 0.8698 | Precision: 0.8494 | Recall: 0.8890\n",
      "Epoch 10 | Training Loss: 0.0325 | Val Loss: 0.3414 | Accuracy: 0.8736 | Precision: 0.8573 | Recall: 0.8870\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4028 | Test Accuracy: 0.8592 | Test Precision: 0.8572 | Test Recall: 0.8622\n",
      "\n",
      "Training for parameter combination: 37, \n",
      "\n",
      "parameters: [3, 'Tanh', 0.0005, 'Adam', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 37...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3572 | Val Loss: 0.2810 | Accuracy: 0.8786 | Precision: 0.8955 | Recall: 0.8486\n",
      "Epoch 02 | Training Loss: 0.0506 | Val Loss: 0.3239 | Accuracy: 0.8742 | Precision: 0.8779 | Recall: 0.8601\n",
      "Epoch 03 | Training Loss: 0.0060 | Val Loss: 0.4296 | Accuracy: 0.8814 | Precision: 0.8714 | Recall: 0.8861\n",
      "Epoch 04 | Training Loss: 0.0006 | Val Loss: 0.4831 | Accuracy: 0.8796 | Precision: 0.8682 | Recall: 0.8861\n",
      "Epoch 05 | Training Loss: 0.0002 | Val Loss: 0.5189 | Accuracy: 0.8796 | Precision: 0.8670 | Recall: 0.8878\n",
      "Epoch 06 | Training Loss: 0.0001 | Val Loss: 0.5471 | Accuracy: 0.8800 | Precision: 0.8704 | Recall: 0.8841\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.5740 | Accuracy: 0.8808 | Precision: 0.8715 | Recall: 0.8845\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.5995 | Accuracy: 0.8810 | Precision: 0.8698 | Recall: 0.8874\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.6237 | Accuracy: 0.8820 | Precision: 0.8710 | Recall: 0.8882\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.6476 | Accuracy: 0.8822 | Precision: 0.8701 | Recall: 0.8899\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3134 | Test Accuracy: 0.8679 | Test Precision: 0.8693 | Test Recall: 0.8659\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 37...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3538 | Val Loss: 0.2925 | Accuracy: 0.8758 | Precision: 0.8385 | Recall: 0.9212\n",
      "Epoch 02 | Training Loss: 0.0518 | Val Loss: 0.3525 | Accuracy: 0.8736 | Precision: 0.8819 | Recall: 0.8535\n",
      "Epoch 03 | Training Loss: 0.0061 | Val Loss: 0.4671 | Accuracy: 0.8766 | Precision: 0.8863 | Recall: 0.8552\n",
      "Epoch 04 | Training Loss: 0.0006 | Val Loss: 0.5190 | Accuracy: 0.8812 | Precision: 0.8669 | Recall: 0.8919\n",
      "Epoch 05 | Training Loss: 0.0002 | Val Loss: 0.5531 | Accuracy: 0.8834 | Precision: 0.8701 | Recall: 0.8927\n",
      "Epoch 06 | Training Loss: 0.0001 | Val Loss: 0.5822 | Accuracy: 0.8828 | Precision: 0.8709 | Recall: 0.8903\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.6096 | Accuracy: 0.8832 | Precision: 0.8704 | Recall: 0.8919\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.6359 | Accuracy: 0.8824 | Precision: 0.8681 | Recall: 0.8932\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.6593 | Accuracy: 0.8828 | Precision: 0.8706 | Recall: 0.8907\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.6833 | Accuracy: 0.8824 | Precision: 0.8699 | Recall: 0.8907\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3135 | Test Accuracy: 0.8657 | Test Precision: 0.8672 | Test Recall: 0.8636\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 37...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3489 | Val Loss: 0.2751 | Accuracy: 0.8828 | Precision: 0.9066 | Recall: 0.8453\n",
      "Epoch 02 | Training Loss: 0.0516 | Val Loss: 0.3509 | Accuracy: 0.8816 | Precision: 0.8601 | Recall: 0.9026\n",
      "Epoch 03 | Training Loss: 0.0059 | Val Loss: 0.4477 | Accuracy: 0.8822 | Precision: 0.8631 | Recall: 0.8998\n",
      "Epoch 04 | Training Loss: 0.0006 | Val Loss: 0.5096 | Accuracy: 0.8818 | Precision: 0.8682 | Recall: 0.8915\n",
      "Epoch 05 | Training Loss: 0.0002 | Val Loss: 0.5424 | Accuracy: 0.8808 | Precision: 0.8662 | Recall: 0.8919\n",
      "Epoch 06 | Training Loss: 0.0001 | Val Loss: 0.5707 | Accuracy: 0.8812 | Precision: 0.8657 | Recall: 0.8936\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.5959 | Accuracy: 0.8814 | Precision: 0.8652 | Recall: 0.8948\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.6192 | Accuracy: 0.8810 | Precision: 0.8654 | Recall: 0.8936\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.6420 | Accuracy: 0.8810 | Precision: 0.8657 | Recall: 0.8932\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.6648 | Accuracy: 0.8812 | Precision: 0.8651 | Recall: 0.8944\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3165 | Test Accuracy: 0.8648 | Test Precision: 0.8658 | Test Recall: 0.8633\n",
      "\n",
      "Training for parameter combination: 38, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.0001, 'Adam', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 38...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5961 | Val Loss: 0.4762 | Accuracy: 0.7724 | Precision: 0.7546 | Recall: 0.7863\n",
      "Epoch 02 | Training Loss: 0.2894 | Val Loss: 0.4070 | Accuracy: 0.8148 | Precision: 0.8052 | Recall: 0.8152\n",
      "Epoch 03 | Training Loss: 0.1492 | Val Loss: 0.3942 | Accuracy: 0.8368 | Precision: 0.8255 | Recall: 0.8412\n",
      "Epoch 04 | Training Loss: 0.0723 | Val Loss: 0.4161 | Accuracy: 0.8434 | Precision: 0.8219 | Recall: 0.8643\n",
      "Epoch 05 | Training Loss: 0.0329 | Val Loss: 0.4529 | Accuracy: 0.8452 | Precision: 0.8354 | Recall: 0.8478\n",
      "Epoch 06 | Training Loss: 0.0144 | Val Loss: 0.5021 | Accuracy: 0.8482 | Precision: 0.8444 | Recall: 0.8420\n",
      "Epoch 07 | Training Loss: 0.0066 | Val Loss: 0.5513 | Accuracy: 0.8480 | Precision: 0.8382 | Recall: 0.8507\n",
      "Epoch 08 | Training Loss: 0.0034 | Val Loss: 0.5945 | Accuracy: 0.8486 | Precision: 0.8311 | Recall: 0.8630\n",
      "Epoch 09 | Training Loss: 0.0020 | Val Loss: 0.6305 | Accuracy: 0.8498 | Precision: 0.8369 | Recall: 0.8573\n",
      "Epoch 10 | Training Loss: 0.0012 | Val Loss: 0.6627 | Accuracy: 0.8502 | Precision: 0.8378 | Recall: 0.8568\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3913 | Test Accuracy: 0.8456 | Test Precision: 0.8446 | Test Recall: 0.8470\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 38...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5956 | Val Loss: 0.4692 | Accuracy: 0.7798 | Precision: 0.7499 | Recall: 0.8189\n",
      "Epoch 02 | Training Loss: 0.2906 | Val Loss: 0.3949 | Accuracy: 0.8276 | Precision: 0.8039 | Recall: 0.8523\n",
      "Epoch 03 | Training Loss: 0.1488 | Val Loss: 0.3825 | Accuracy: 0.8396 | Precision: 0.8405 | Recall: 0.8259\n",
      "Epoch 04 | Training Loss: 0.0726 | Val Loss: 0.4032 | Accuracy: 0.8452 | Precision: 0.8373 | Recall: 0.8449\n",
      "Epoch 05 | Training Loss: 0.0326 | Val Loss: 0.4432 | Accuracy: 0.8474 | Precision: 0.8380 | Recall: 0.8494\n",
      "Epoch 06 | Training Loss: 0.0142 | Val Loss: 0.4905 | Accuracy: 0.8496 | Precision: 0.8366 | Recall: 0.8573\n",
      "Epoch 07 | Training Loss: 0.0065 | Val Loss: 0.5442 | Accuracy: 0.8500 | Precision: 0.8335 | Recall: 0.8630\n",
      "Epoch 08 | Training Loss: 0.0032 | Val Loss: 0.5895 | Accuracy: 0.8522 | Precision: 0.8393 | Recall: 0.8597\n",
      "Epoch 09 | Training Loss: 0.0018 | Val Loss: 0.6263 | Accuracy: 0.8534 | Precision: 0.8452 | Recall: 0.8540\n",
      "Epoch 10 | Training Loss: 0.0011 | Val Loss: 0.6612 | Accuracy: 0.8532 | Precision: 0.8410 | Recall: 0.8597\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4776 | Test Accuracy: 0.8537 | Test Precision: 0.8493 | Test Recall: 0.8600\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 38...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6149 | Val Loss: 0.4843 | Accuracy: 0.7710 | Precision: 0.7485 | Recall: 0.7946\n",
      "Epoch 02 | Training Loss: 0.2932 | Val Loss: 0.4035 | Accuracy: 0.8234 | Precision: 0.8088 | Recall: 0.8325\n",
      "Epoch 03 | Training Loss: 0.1500 | Val Loss: 0.3972 | Accuracy: 0.8382 | Precision: 0.8035 | Recall: 0.8820\n",
      "Epoch 04 | Training Loss: 0.0732 | Val Loss: 0.4022 | Accuracy: 0.8496 | Precision: 0.8576 | Recall: 0.8271\n",
      "Epoch 05 | Training Loss: 0.0335 | Val Loss: 0.4353 | Accuracy: 0.8516 | Precision: 0.8490 | Recall: 0.8441\n",
      "Epoch 06 | Training Loss: 0.0154 | Val Loss: 0.4746 | Accuracy: 0.8548 | Precision: 0.8502 | Recall: 0.8502\n",
      "Epoch 07 | Training Loss: 0.0074 | Val Loss: 0.5273 | Accuracy: 0.8580 | Precision: 0.8353 | Recall: 0.8808\n",
      "Epoch 08 | Training Loss: 0.0039 | Val Loss: 0.5548 | Accuracy: 0.8602 | Precision: 0.8522 | Recall: 0.8610\n",
      "Epoch 09 | Training Loss: 0.0022 | Val Loss: 0.5931 | Accuracy: 0.8598 | Precision: 0.8447 | Recall: 0.8709\n",
      "Epoch 10 | Training Loss: 0.0014 | Val Loss: 0.6232 | Accuracy: 0.8606 | Precision: 0.8480 | Recall: 0.8680\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4328 | Test Accuracy: 0.8457 | Test Precision: 0.8484 | Test Recall: 0.8419\n",
      "\n",
      "Training for parameter combination: 39, \n",
      "\n",
      "parameters: [1, 'ReLU', 0.0005, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 39...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0032 | Val Loss: 0.9515 | Accuracy: 0.5442 | Precision: 0.5304 | Recall: 0.5210\n",
      "Epoch 02 | Training Loss: 0.8991 | Val Loss: 0.8706 | Accuracy: 0.5716 | Precision: 0.5560 | Recall: 0.5780\n",
      "Epoch 03 | Training Loss: 0.8250 | Val Loss: 0.8107 | Accuracy: 0.5980 | Precision: 0.5806 | Recall: 0.6151\n",
      "Epoch 04 | Training Loss: 0.7694 | Val Loss: 0.7627 | Accuracy: 0.6204 | Precision: 0.6093 | Recall: 0.6048\n",
      "Epoch 05 | Training Loss: 0.7263 | Val Loss: 0.7269 | Accuracy: 0.6374 | Precision: 0.6215 | Recall: 0.6448\n",
      "Epoch 06 | Training Loss: 0.6915 | Val Loss: 0.6990 | Accuracy: 0.6510 | Precision: 0.6293 | Recall: 0.6815\n",
      "Epoch 07 | Training Loss: 0.6631 | Val Loss: 0.6726 | Accuracy: 0.6674 | Precision: 0.6514 | Recall: 0.6753\n",
      "Epoch 08 | Training Loss: 0.6391 | Val Loss: 0.6520 | Accuracy: 0.6762 | Precision: 0.6609 | Recall: 0.6819\n",
      "Epoch 09 | Training Loss: 0.6189 | Val Loss: 0.6356 | Accuracy: 0.6860 | Precision: 0.6647 | Recall: 0.7108\n",
      "Epoch 10 | Training Loss: 0.6013 | Val Loss: 0.6195 | Accuracy: 0.6912 | Precision: 0.6720 | Recall: 0.7092\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5664 | Test Accuracy: 0.6957 | Test Precision: 0.6928 | Test Recall: 0.7032\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 39...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0324 | Val Loss: 0.9641 | Accuracy: 0.5368 | Precision: 0.5213 | Recall: 0.5441\n",
      "Epoch 02 | Training Loss: 0.9135 | Val Loss: 0.8727 | Accuracy: 0.5672 | Precision: 0.5531 | Recall: 0.5582\n",
      "Epoch 03 | Training Loss: 0.8329 | Val Loss: 0.8083 | Accuracy: 0.5934 | Precision: 0.5800 | Recall: 0.5846\n",
      "Epoch 04 | Training Loss: 0.7745 | Val Loss: 0.7606 | Accuracy: 0.6144 | Precision: 0.5990 | Recall: 0.6188\n",
      "Epoch 05 | Training Loss: 0.7297 | Val Loss: 0.7234 | Accuracy: 0.6356 | Precision: 0.6194 | Recall: 0.6440\n",
      "Epoch 06 | Training Loss: 0.6941 | Val Loss: 0.6945 | Accuracy: 0.6530 | Precision: 0.6340 | Recall: 0.6724\n",
      "Epoch 07 | Training Loss: 0.6651 | Val Loss: 0.6690 | Accuracy: 0.6678 | Precision: 0.6522 | Recall: 0.6745\n",
      "Epoch 08 | Training Loss: 0.6417 | Val Loss: 0.6481 | Accuracy: 0.6788 | Precision: 0.6643 | Recall: 0.6823\n",
      "Epoch 09 | Training Loss: 0.6214 | Val Loss: 0.6307 | Accuracy: 0.6888 | Precision: 0.6732 | Recall: 0.6960\n",
      "Epoch 10 | Training Loss: 0.6039 | Val Loss: 0.6159 | Accuracy: 0.6960 | Precision: 0.6804 | Recall: 0.7034\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4585 | Test Accuracy: 0.6922 | Test Precision: 0.6919 | Test Recall: 0.6928\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 39...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0486 | Val Loss: 0.9810 | Accuracy: 0.5282 | Precision: 0.5124 | Recall: 0.5540\n",
      "Epoch 02 | Training Loss: 0.9166 | Val Loss: 0.8881 | Accuracy: 0.5598 | Precision: 0.5423 | Recall: 0.5903\n",
      "Epoch 03 | Training Loss: 0.8343 | Val Loss: 0.8177 | Accuracy: 0.6000 | Precision: 0.5839 | Recall: 0.6089\n",
      "Epoch 04 | Training Loss: 0.7735 | Val Loss: 0.7656 | Accuracy: 0.6168 | Precision: 0.6071 | Recall: 0.5941\n",
      "Epoch 05 | Training Loss: 0.7269 | Val Loss: 0.7260 | Accuracy: 0.6334 | Precision: 0.6234 | Recall: 0.6159\n",
      "Epoch 06 | Training Loss: 0.6903 | Val Loss: 0.6949 | Accuracy: 0.6476 | Precision: 0.6330 | Recall: 0.6498\n",
      "Epoch 07 | Training Loss: 0.6603 | Val Loss: 0.6699 | Accuracy: 0.6594 | Precision: 0.6417 | Recall: 0.6737\n",
      "Epoch 08 | Training Loss: 0.6354 | Val Loss: 0.6469 | Accuracy: 0.6700 | Precision: 0.6610 | Recall: 0.6555\n",
      "Epoch 09 | Training Loss: 0.6147 | Val Loss: 0.6287 | Accuracy: 0.6782 | Precision: 0.6713 | Recall: 0.6588\n",
      "Epoch 10 | Training Loss: 0.5968 | Val Loss: 0.6137 | Accuracy: 0.6876 | Precision: 0.6712 | Recall: 0.6972\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5916 | Test Accuracy: 0.6924 | Test Precision: 0.6892 | Test Recall: 0.7009\n",
      "\n",
      "Training for parameter combination: 40, \n",
      "\n",
      "parameters: [3, 'LeakyReLU', 0.0005, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 40...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8231 | Val Loss: 0.7588 | Accuracy: 0.5714 | Precision: 0.5528 | Recall: 0.6064\n",
      "Epoch 02 | Training Loss: 0.7183 | Val Loss: 0.6986 | Accuracy: 0.6004 | Precision: 0.5803 | Recall: 0.6353\n",
      "Epoch 03 | Training Loss: 0.6718 | Val Loss: 0.6655 | Accuracy: 0.6262 | Precision: 0.6075 | Recall: 0.6469\n",
      "Epoch 04 | Training Loss: 0.6443 | Val Loss: 0.6444 | Accuracy: 0.6430 | Precision: 0.6284 | Recall: 0.6452\n",
      "Epoch 05 | Training Loss: 0.6249 | Val Loss: 0.6301 | Accuracy: 0.6526 | Precision: 0.6330 | Recall: 0.6745\n",
      "Epoch 06 | Training Loss: 0.6102 | Val Loss: 0.6191 | Accuracy: 0.6636 | Precision: 0.6395 | Recall: 0.7017\n",
      "Epoch 07 | Training Loss: 0.5977 | Val Loss: 0.6071 | Accuracy: 0.6768 | Precision: 0.6625 | Recall: 0.6795\n",
      "Epoch 08 | Training Loss: 0.5869 | Val Loss: 0.5980 | Accuracy: 0.6836 | Precision: 0.6734 | Recall: 0.6745\n",
      "Epoch 09 | Training Loss: 0.5771 | Val Loss: 0.5917 | Accuracy: 0.6926 | Precision: 0.6679 | Recall: 0.7277\n",
      "Epoch 10 | Training Loss: 0.5681 | Val Loss: 0.5828 | Accuracy: 0.6964 | Precision: 0.6899 | Recall: 0.6790\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7286 | Test Accuracy: 0.6926 | Test Precision: 0.7031 | Test Recall: 0.6667\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 40...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8789 | Val Loss: 0.7861 | Accuracy: 0.5522 | Precision: 0.5358 | Recall: 0.5710\n",
      "Epoch 02 | Training Loss: 0.7494 | Val Loss: 0.7166 | Accuracy: 0.5870 | Precision: 0.5656 | Recall: 0.6382\n",
      "Epoch 03 | Training Loss: 0.6940 | Val Loss: 0.6772 | Accuracy: 0.6168 | Precision: 0.5967 | Recall: 0.6469\n",
      "Epoch 04 | Training Loss: 0.6618 | Val Loss: 0.6540 | Accuracy: 0.6350 | Precision: 0.6137 | Recall: 0.6671\n",
      "Epoch 05 | Training Loss: 0.6400 | Val Loss: 0.6365 | Accuracy: 0.6488 | Precision: 0.6330 | Recall: 0.6559\n",
      "Epoch 06 | Training Loss: 0.6233 | Val Loss: 0.6238 | Accuracy: 0.6582 | Precision: 0.6488 | Recall: 0.6432\n",
      "Epoch 07 | Training Loss: 0.6103 | Val Loss: 0.6134 | Accuracy: 0.6668 | Precision: 0.6508 | Recall: 0.6749\n",
      "Epoch 08 | Training Loss: 0.5988 | Val Loss: 0.6051 | Accuracy: 0.6750 | Precision: 0.6544 | Recall: 0.6984\n",
      "Epoch 09 | Training Loss: 0.5886 | Val Loss: 0.5964 | Accuracy: 0.6830 | Precision: 0.6698 | Recall: 0.6828\n",
      "Epoch 10 | Training Loss: 0.5797 | Val Loss: 0.5896 | Accuracy: 0.6892 | Precision: 0.6713 | Recall: 0.7034\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5876 | Test Accuracy: 0.6797 | Test Precision: 0.6759 | Test Recall: 0.6903\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 40...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8791 | Val Loss: 0.7973 | Accuracy: 0.5604 | Precision: 0.5473 | Recall: 0.5392\n",
      "Epoch 02 | Training Loss: 0.7378 | Val Loss: 0.7183 | Accuracy: 0.5962 | Precision: 0.5752 | Recall: 0.6390\n",
      "Epoch 03 | Training Loss: 0.6788 | Val Loss: 0.6708 | Accuracy: 0.6244 | Precision: 0.6126 | Recall: 0.6126\n",
      "Epoch 04 | Training Loss: 0.6468 | Val Loss: 0.6485 | Accuracy: 0.6420 | Precision: 0.6188 | Recall: 0.6811\n",
      "Epoch 05 | Training Loss: 0.6255 | Val Loss: 0.6276 | Accuracy: 0.6582 | Precision: 0.6435 | Recall: 0.6613\n",
      "Epoch 06 | Training Loss: 0.6094 | Val Loss: 0.6151 | Accuracy: 0.6712 | Precision: 0.6497 | Recall: 0.6984\n",
      "Epoch 07 | Training Loss: 0.5962 | Val Loss: 0.6022 | Accuracy: 0.6782 | Precision: 0.6642 | Recall: 0.6799\n",
      "Epoch 08 | Training Loss: 0.5853 | Val Loss: 0.5952 | Accuracy: 0.6850 | Precision: 0.6583 | Recall: 0.7281\n",
      "Epoch 09 | Training Loss: 0.5753 | Val Loss: 0.5848 | Accuracy: 0.6888 | Precision: 0.6668 | Recall: 0.7158\n",
      "Epoch 10 | Training Loss: 0.5660 | Val Loss: 0.5764 | Accuracy: 0.6978 | Precision: 0.6780 | Recall: 0.7174\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5797 | Test Accuracy: 0.7044 | Test Precision: 0.7008 | Test Recall: 0.7132\n",
      "\n",
      "Training for parameter combination: 41, \n",
      "\n",
      "parameters: [1, 'ReLU', 0.001, 'SGD', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 41...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0280 | Val Loss: 0.9776 | Accuracy: 0.5092 | Precision: 0.4942 | Recall: 0.5285\n",
      "Epoch 02 | Training Loss: 0.9655 | Val Loss: 0.9246 | Accuracy: 0.5302 | Precision: 0.5146 | Recall: 0.5450\n",
      "Epoch 03 | Training Loss: 0.9145 | Val Loss: 0.8795 | Accuracy: 0.5548 | Precision: 0.5424 | Recall: 0.5223\n",
      "Epoch 04 | Training Loss: 0.8717 | Val Loss: 0.8427 | Accuracy: 0.5674 | Precision: 0.5538 | Recall: 0.5540\n",
      "Epoch 05 | Training Loss: 0.8350 | Val Loss: 0.8122 | Accuracy: 0.5798 | Precision: 0.5641 | Recall: 0.5866\n",
      "Epoch 06 | Training Loss: 0.8035 | Val Loss: 0.7849 | Accuracy: 0.5942 | Precision: 0.5797 | Recall: 0.5928\n",
      "Epoch 07 | Training Loss: 0.7762 | Val Loss: 0.7627 | Accuracy: 0.6066 | Precision: 0.5889 | Recall: 0.6246\n",
      "Epoch 08 | Training Loss: 0.7522 | Val Loss: 0.7417 | Accuracy: 0.6184 | Precision: 0.6017 | Recall: 0.6295\n",
      "Epoch 09 | Training Loss: 0.7311 | Val Loss: 0.7225 | Accuracy: 0.6318 | Precision: 0.6187 | Recall: 0.6267\n",
      "Epoch 10 | Training Loss: 0.7120 | Val Loss: 0.7073 | Accuracy: 0.6384 | Precision: 0.6213 | Recall: 0.6510\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6836 | Test Accuracy: 0.6326 | Test Precision: 0.6311 | Test Recall: 0.6382\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 41...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0396 | Val Loss: 0.9648 | Accuracy: 0.5402 | Precision: 0.5244 | Recall: 0.5532\n",
      "Epoch 02 | Training Loss: 0.9645 | Val Loss: 0.9116 | Accuracy: 0.5588 | Precision: 0.5427 | Recall: 0.5714\n",
      "Epoch 03 | Training Loss: 0.9122 | Val Loss: 0.8657 | Accuracy: 0.5796 | Precision: 0.5667 | Recall: 0.5644\n",
      "Epoch 04 | Training Loss: 0.8683 | Val Loss: 0.8296 | Accuracy: 0.5946 | Precision: 0.5808 | Recall: 0.5887\n",
      "Epoch 05 | Training Loss: 0.8312 | Val Loss: 0.7990 | Accuracy: 0.6094 | Precision: 0.5943 | Recall: 0.6122\n",
      "Epoch 06 | Training Loss: 0.7993 | Val Loss: 0.7724 | Accuracy: 0.6256 | Precision: 0.6107 | Recall: 0.6283\n",
      "Epoch 07 | Training Loss: 0.7717 | Val Loss: 0.7487 | Accuracy: 0.6346 | Precision: 0.6219 | Recall: 0.6283\n",
      "Epoch 08 | Training Loss: 0.7477 | Val Loss: 0.7284 | Accuracy: 0.6436 | Precision: 0.6310 | Recall: 0.6378\n",
      "Epoch 09 | Training Loss: 0.7264 | Val Loss: 0.7112 | Accuracy: 0.6498 | Precision: 0.6344 | Recall: 0.6551\n",
      "Epoch 10 | Training Loss: 0.7077 | Val Loss: 0.6960 | Accuracy: 0.6578 | Precision: 0.6413 | Recall: 0.6675\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7503 | Test Accuracy: 0.6489 | Test Precision: 0.6484 | Test Recall: 0.6506\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 41...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0318 | Val Loss: 1.0199 | Accuracy: 0.5016 | Precision: 0.4853 | Recall: 0.4629\n",
      "Epoch 02 | Training Loss: 0.9580 | Val Loss: 0.9651 | Accuracy: 0.5206 | Precision: 0.5057 | Recall: 0.4963\n",
      "Epoch 03 | Training Loss: 0.9070 | Val Loss: 0.9188 | Accuracy: 0.5380 | Precision: 0.5240 | Recall: 0.5136\n",
      "Epoch 04 | Training Loss: 0.8643 | Val Loss: 0.8805 | Accuracy: 0.5528 | Precision: 0.5390 | Recall: 0.5355\n",
      "Epoch 05 | Training Loss: 0.8284 | Val Loss: 0.8469 | Accuracy: 0.5654 | Precision: 0.5534 | Recall: 0.5363\n",
      "Epoch 06 | Training Loss: 0.7978 | Val Loss: 0.8186 | Accuracy: 0.5770 | Precision: 0.5654 | Recall: 0.5512\n",
      "Epoch 07 | Training Loss: 0.7714 | Val Loss: 0.7950 | Accuracy: 0.5876 | Precision: 0.5738 | Recall: 0.5804\n",
      "Epoch 08 | Training Loss: 0.7480 | Val Loss: 0.7733 | Accuracy: 0.5994 | Precision: 0.5862 | Recall: 0.5908\n",
      "Epoch 09 | Training Loss: 0.7277 | Val Loss: 0.7534 | Accuracy: 0.6090 | Precision: 0.5998 | Recall: 0.5813\n",
      "Epoch 10 | Training Loss: 0.7096 | Val Loss: 0.7371 | Accuracy: 0.6186 | Precision: 0.6056 | Recall: 0.6114\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6727 | Test Accuracy: 0.6278 | Test Precision: 0.6276 | Test Recall: 0.6284\n",
      "\n",
      "Training for parameter combination: 42, \n",
      "\n",
      "parameters: [3, 'LeakyReLU', 0.0001, 'RMSProp', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 42...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5263 | Val Loss: 0.4012 | Accuracy: 0.8250 | Precision: 0.8422 | Recall: 0.7863\n",
      "Epoch 02 | Training Loss: 0.2838 | Val Loss: 0.3558 | Accuracy: 0.8528 | Precision: 0.8679 | Recall: 0.8214\n",
      "Epoch 03 | Training Loss: 0.1890 | Val Loss: 0.3640 | Accuracy: 0.8582 | Precision: 0.8168 | Recall: 0.9121\n",
      "Epoch 04 | Training Loss: 0.1293 | Val Loss: 0.3810 | Accuracy: 0.8608 | Precision: 0.8181 | Recall: 0.9167\n",
      "Epoch 05 | Training Loss: 0.0885 | Val Loss: 0.3891 | Accuracy: 0.8720 | Precision: 0.8751 | Recall: 0.8585\n",
      "Epoch 06 | Training Loss: 0.0575 | Val Loss: 0.4256 | Accuracy: 0.8704 | Precision: 0.8529 | Recall: 0.8853\n",
      "Epoch 07 | Training Loss: 0.0368 | Val Loss: 0.4971 | Accuracy: 0.8654 | Precision: 0.8330 | Recall: 0.9035\n",
      "Epoch 08 | Training Loss: 0.0217 | Val Loss: 0.5476 | Accuracy: 0.8676 | Precision: 0.8736 | Recall: 0.8498\n",
      "Epoch 09 | Training Loss: 0.0126 | Val Loss: 0.6262 | Accuracy: 0.8658 | Precision: 0.8362 | Recall: 0.8993\n",
      "Epoch 10 | Training Loss: 0.0067 | Val Loss: 0.7050 | Accuracy: 0.8664 | Precision: 0.8555 | Recall: 0.8717\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3161 | Test Accuracy: 0.8558 | Test Precision: 0.8571 | Test Recall: 0.8541\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 42...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5270 | Val Loss: 0.3976 | Accuracy: 0.8242 | Precision: 0.8016 | Recall: 0.8469\n",
      "Epoch 02 | Training Loss: 0.2800 | Val Loss: 0.3603 | Accuracy: 0.8508 | Precision: 0.8638 | Recall: 0.8218\n",
      "Epoch 03 | Training Loss: 0.1897 | Val Loss: 0.3506 | Accuracy: 0.8590 | Precision: 0.8571 | Recall: 0.8511\n",
      "Epoch 04 | Training Loss: 0.1318 | Val Loss: 0.3745 | Accuracy: 0.8634 | Precision: 0.8638 | Recall: 0.8527\n",
      "Epoch 05 | Training Loss: 0.0912 | Val Loss: 0.3998 | Accuracy: 0.8628 | Precision: 0.8567 | Recall: 0.8610\n",
      "Epoch 06 | Training Loss: 0.0609 | Val Loss: 0.4523 | Accuracy: 0.8612 | Precision: 0.8764 | Recall: 0.8309\n",
      "Epoch 07 | Training Loss: 0.0388 | Val Loss: 0.5288 | Accuracy: 0.8552 | Precision: 0.8815 | Recall: 0.8102\n",
      "Epoch 08 | Training Loss: 0.0234 | Val Loss: 0.5553 | Accuracy: 0.8604 | Precision: 0.8528 | Recall: 0.8606\n",
      "Epoch 09 | Training Loss: 0.0128 | Val Loss: 0.6458 | Accuracy: 0.8592 | Precision: 0.8539 | Recall: 0.8560\n",
      "Epoch 10 | Training Loss: 0.0069 | Val Loss: 0.7455 | Accuracy: 0.8564 | Precision: 0.8342 | Recall: 0.8783\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3319 | Test Accuracy: 0.8552 | Test Precision: 0.8472 | Test Recall: 0.8668\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 42...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5308 | Val Loss: 0.4084 | Accuracy: 0.8240 | Precision: 0.7883 | Recall: 0.8709\n",
      "Epoch 02 | Training Loss: 0.2824 | Val Loss: 0.3602 | Accuracy: 0.8516 | Precision: 0.8383 | Recall: 0.8597\n",
      "Epoch 03 | Training Loss: 0.1894 | Val Loss: 0.3633 | Accuracy: 0.8598 | Precision: 0.8686 | Recall: 0.8375\n",
      "Epoch 04 | Training Loss: 0.1306 | Val Loss: 0.3747 | Accuracy: 0.8600 | Precision: 0.8440 | Recall: 0.8725\n",
      "Epoch 05 | Training Loss: 0.0878 | Val Loss: 0.4077 | Accuracy: 0.8602 | Precision: 0.8574 | Recall: 0.8535\n",
      "Epoch 06 | Training Loss: 0.0564 | Val Loss: 0.4602 | Accuracy: 0.8586 | Precision: 0.8534 | Recall: 0.8552\n",
      "Epoch 07 | Training Loss: 0.0342 | Val Loss: 0.5285 | Accuracy: 0.8616 | Precision: 0.8453 | Recall: 0.8746\n",
      "Epoch 08 | Training Loss: 0.0193 | Val Loss: 0.6098 | Accuracy: 0.8584 | Precision: 0.8462 | Recall: 0.8651\n",
      "Epoch 09 | Training Loss: 0.0098 | Val Loss: 0.7032 | Accuracy: 0.8564 | Precision: 0.8490 | Recall: 0.8560\n",
      "Epoch 10 | Training Loss: 0.0052 | Val Loss: 0.8056 | Accuracy: 0.8590 | Precision: 0.8521 | Recall: 0.8581\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5180 | Test Accuracy: 0.8536 | Test Precision: 0.8517 | Test Recall: 0.8564\n",
      "\n",
      "Training for parameter combination: 43, \n",
      "\n",
      "parameters: [2, 'LeakyReLU', 0.001, 'RMSProp', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 43...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4566 | Val Loss: 0.3049 | Accuracy: 0.8730 | Precision: 0.8841 | Recall: 0.8494\n",
      "Epoch 02 | Training Loss: 0.1445 | Val Loss: 0.3309 | Accuracy: 0.8816 | Precision: 0.8715 | Recall: 0.8866\n",
      "Epoch 03 | Training Loss: 0.0518 | Val Loss: 0.5950 | Accuracy: 0.8550 | Precision: 0.7955 | Recall: 0.9435\n",
      "Epoch 04 | Training Loss: 0.0180 | Val Loss: 0.6258 | Accuracy: 0.8710 | Precision: 0.8323 | Recall: 0.9191\n",
      "Epoch 05 | Training Loss: 0.0070 | Val Loss: 0.8027 | Accuracy: 0.8714 | Precision: 0.8765 | Recall: 0.8552\n",
      "Epoch 06 | Training Loss: 0.0032 | Val Loss: 0.8902 | Accuracy: 0.8704 | Precision: 0.8584 | Recall: 0.8775\n",
      "Epoch 07 | Training Loss: 0.0005 | Val Loss: 1.0138 | Accuracy: 0.8726 | Precision: 0.8492 | Recall: 0.8965\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 1.0527 | Accuracy: 0.8746 | Precision: 0.8624 | Recall: 0.8820\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 1.0875 | Accuracy: 0.8758 | Precision: 0.8631 | Recall: 0.8841\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.1116 | Accuracy: 0.8764 | Precision: 0.8665 | Recall: 0.8808\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3787 | Test Accuracy: 0.8706 | Test Precision: 0.8725 | Test Recall: 0.8681\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 43...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4492 | Val Loss: 0.2939 | Accuracy: 0.8838 | Precision: 0.8778 | Recall: 0.8833\n",
      "Epoch 02 | Training Loss: 0.1454 | Val Loss: 0.3967 | Accuracy: 0.8558 | Precision: 0.7964 | Recall: 0.9439\n",
      "Epoch 03 | Training Loss: 0.0530 | Val Loss: 0.6142 | Accuracy: 0.8514 | Precision: 0.9335 | Recall: 0.7467\n",
      "Epoch 04 | Training Loss: 0.0188 | Val Loss: 0.6183 | Accuracy: 0.8700 | Precision: 0.8261 | Recall: 0.9270\n",
      "Epoch 05 | Training Loss: 0.0056 | Val Loss: 0.8272 | Accuracy: 0.8704 | Precision: 0.9201 | Recall: 0.8024\n",
      "Epoch 06 | Training Loss: 0.0015 | Val Loss: 0.8442 | Accuracy: 0.8788 | Precision: 0.8636 | Recall: 0.8907\n",
      "Epoch 07 | Training Loss: 0.0002 | Val Loss: 0.9335 | Accuracy: 0.8780 | Precision: 0.8637 | Recall: 0.8886\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.9814 | Accuracy: 0.8806 | Precision: 0.8697 | Recall: 0.8866\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 1.0145 | Accuracy: 0.8804 | Precision: 0.8696 | Recall: 0.8861\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.0387 | Accuracy: 0.8802 | Precision: 0.8696 | Recall: 0.8857\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3937 | Test Accuracy: 0.8721 | Test Precision: 0.8698 | Test Recall: 0.8752\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 43...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4762 | Val Loss: 0.3224 | Accuracy: 0.8654 | Precision: 0.8996 | Recall: 0.8131\n",
      "Epoch 02 | Training Loss: 0.1458 | Val Loss: 0.3478 | Accuracy: 0.8744 | Precision: 0.8522 | Recall: 0.8965\n",
      "Epoch 03 | Training Loss: 0.0517 | Val Loss: 0.4572 | Accuracy: 0.8772 | Precision: 0.8649 | Recall: 0.8849\n",
      "Epoch 04 | Training Loss: 0.0160 | Val Loss: 0.6347 | Accuracy: 0.8726 | Precision: 0.8497 | Recall: 0.8956\n",
      "Epoch 05 | Training Loss: 0.0062 | Val Loss: 0.7511 | Accuracy: 0.8736 | Precision: 0.8740 | Recall: 0.8639\n",
      "Epoch 06 | Training Loss: 0.0022 | Val Loss: 0.9307 | Accuracy: 0.8684 | Precision: 0.8974 | Recall: 0.8226\n",
      "Epoch 07 | Training Loss: 0.0018 | Val Loss: 0.9998 | Accuracy: 0.8716 | Precision: 0.8491 | Recall: 0.8940\n",
      "Epoch 08 | Training Loss: 0.0004 | Val Loss: 1.0583 | Accuracy: 0.8754 | Precision: 0.8581 | Recall: 0.8903\n",
      "Epoch 09 | Training Loss: 0.0001 | Val Loss: 1.1041 | Accuracy: 0.8778 | Precision: 0.8651 | Recall: 0.8861\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.1306 | Accuracy: 0.8774 | Precision: 0.8676 | Recall: 0.8816\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4025 | Test Accuracy: 0.8662 | Test Precision: 0.8661 | Test Recall: 0.8665\n",
      "\n",
      "Training for parameter combination: 44, \n",
      "\n",
      "parameters: [2, 'Tanh', 0.0001, 'Adam', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 44...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4985 | Val Loss: 0.3577 | Accuracy: 0.8444 | Precision: 0.8248 | Recall: 0.8622\n",
      "Epoch 02 | Training Loss: 0.1848 | Val Loss: 0.3172 | Accuracy: 0.8658 | Precision: 0.8493 | Recall: 0.8791\n",
      "Epoch 03 | Training Loss: 0.0814 | Val Loss: 0.3145 | Accuracy: 0.8740 | Precision: 0.8540 | Recall: 0.8927\n",
      "Epoch 04 | Training Loss: 0.0349 | Val Loss: 0.3319 | Accuracy: 0.8746 | Precision: 0.8484 | Recall: 0.9026\n",
      "Epoch 05 | Training Loss: 0.0151 | Val Loss: 0.3446 | Accuracy: 0.8770 | Precision: 0.8652 | Recall: 0.8841\n",
      "Epoch 06 | Training Loss: 0.0069 | Val Loss: 0.3667 | Accuracy: 0.8762 | Precision: 0.8655 | Recall: 0.8816\n",
      "Epoch 07 | Training Loss: 0.0035 | Val Loss: 0.3887 | Accuracy: 0.8788 | Precision: 0.8654 | Recall: 0.8882\n",
      "Epoch 08 | Training Loss: 0.0020 | Val Loss: 0.4093 | Accuracy: 0.8776 | Precision: 0.8644 | Recall: 0.8866\n",
      "Epoch 09 | Training Loss: 0.0012 | Val Loss: 0.4305 | Accuracy: 0.8786 | Precision: 0.8641 | Recall: 0.8894\n",
      "Epoch 10 | Training Loss: 0.0007 | Val Loss: 0.4495 | Accuracy: 0.8788 | Precision: 0.8633 | Recall: 0.8911\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3181 | Test Accuracy: 0.8650 | Test Precision: 0.8661 | Test Recall: 0.8634\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 44...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5041 | Val Loss: 0.3646 | Accuracy: 0.8432 | Precision: 0.8171 | Recall: 0.8717\n",
      "Epoch 02 | Training Loss: 0.1771 | Val Loss: 0.3265 | Accuracy: 0.8626 | Precision: 0.8339 | Recall: 0.8948\n",
      "Epoch 03 | Training Loss: 0.0773 | Val Loss: 0.3230 | Accuracy: 0.8722 | Precision: 0.8474 | Recall: 0.8981\n",
      "Epoch 04 | Training Loss: 0.0330 | Val Loss: 0.3380 | Accuracy: 0.8754 | Precision: 0.8541 | Recall: 0.8960\n",
      "Epoch 05 | Training Loss: 0.0146 | Val Loss: 0.3518 | Accuracy: 0.8750 | Precision: 0.8640 | Recall: 0.8808\n",
      "Epoch 06 | Training Loss: 0.0066 | Val Loss: 0.3772 | Accuracy: 0.8714 | Precision: 0.8532 | Recall: 0.8874\n",
      "Epoch 07 | Training Loss: 0.0033 | Val Loss: 0.3972 | Accuracy: 0.8746 | Precision: 0.8598 | Recall: 0.8857\n",
      "Epoch 08 | Training Loss: 0.0019 | Val Loss: 0.4143 | Accuracy: 0.8732 | Precision: 0.8659 | Recall: 0.8738\n",
      "Epoch 09 | Training Loss: 0.0011 | Val Loss: 0.4363 | Accuracy: 0.8736 | Precision: 0.8584 | Recall: 0.8853\n",
      "Epoch 10 | Training Loss: 0.0007 | Val Loss: 0.4551 | Accuracy: 0.8752 | Precision: 0.8623 | Recall: 0.8837\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3218 | Test Accuracy: 0.8627 | Test Precision: 0.8686 | Test Recall: 0.8546\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 44...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4850 | Val Loss: 0.3557 | Accuracy: 0.8440 | Precision: 0.8171 | Recall: 0.8738\n",
      "Epoch 02 | Training Loss: 0.1809 | Val Loss: 0.3195 | Accuracy: 0.8616 | Precision: 0.8265 | Recall: 0.9043\n",
      "Epoch 03 | Training Loss: 0.0798 | Val Loss: 0.3101 | Accuracy: 0.8696 | Precision: 0.8527 | Recall: 0.8837\n",
      "Epoch 04 | Training Loss: 0.0338 | Val Loss: 0.3328 | Accuracy: 0.8734 | Precision: 0.8472 | Recall: 0.9014\n",
      "Epoch 05 | Training Loss: 0.0144 | Val Loss: 0.3475 | Accuracy: 0.8752 | Precision: 0.8659 | Recall: 0.8787\n",
      "Epoch 06 | Training Loss: 0.0064 | Val Loss: 0.3715 | Accuracy: 0.8756 | Precision: 0.8613 | Recall: 0.8861\n",
      "Epoch 07 | Training Loss: 0.0033 | Val Loss: 0.3947 | Accuracy: 0.8766 | Precision: 0.8645 | Recall: 0.8841\n",
      "Epoch 08 | Training Loss: 0.0018 | Val Loss: 0.4186 | Accuracy: 0.8778 | Precision: 0.8613 | Recall: 0.8915\n",
      "Epoch 09 | Training Loss: 0.0011 | Val Loss: 0.4382 | Accuracy: 0.8770 | Precision: 0.8614 | Recall: 0.8894\n",
      "Epoch 10 | Training Loss: 0.0007 | Val Loss: 0.4583 | Accuracy: 0.8768 | Precision: 0.8633 | Recall: 0.8861\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3158 | Test Accuracy: 0.8644 | Test Precision: 0.8688 | Test Recall: 0.8585\n",
      "\n",
      "Training for parameter combination: 45, \n",
      "\n",
      "parameters: [2, 'Tanh', 0.001, 'Adam', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 45...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3655 | Val Loss: 0.2833 | Accuracy: 0.8818 | Precision: 0.8902 | Recall: 0.8626\n",
      "Epoch 02 | Training Loss: 0.0375 | Val Loss: 0.3111 | Accuracy: 0.8882 | Precision: 0.8768 | Recall: 0.8952\n",
      "Epoch 03 | Training Loss: 0.0051 | Val Loss: 0.3633 | Accuracy: 0.8836 | Precision: 0.8623 | Recall: 0.9043\n",
      "Epoch 04 | Training Loss: 0.0015 | Val Loss: 0.3876 | Accuracy: 0.8864 | Precision: 0.8803 | Recall: 0.8861\n",
      "Epoch 05 | Training Loss: 0.0007 | Val Loss: 0.4083 | Accuracy: 0.8850 | Precision: 0.8772 | Recall: 0.8870\n",
      "Epoch 06 | Training Loss: 0.0005 | Val Loss: 0.4271 | Accuracy: 0.8854 | Precision: 0.8724 | Recall: 0.8944\n",
      "Epoch 07 | Training Loss: 0.0003 | Val Loss: 0.4409 | Accuracy: 0.8850 | Precision: 0.8751 | Recall: 0.8899\n",
      "Epoch 08 | Training Loss: 0.0002 | Val Loss: 0.4540 | Accuracy: 0.8846 | Precision: 0.8740 | Recall: 0.8903\n",
      "Epoch 09 | Training Loss: 0.0002 | Val Loss: 0.4664 | Accuracy: 0.8854 | Precision: 0.8736 | Recall: 0.8927\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.4766 | Accuracy: 0.8850 | Precision: 0.8741 | Recall: 0.8911\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3757 | Test Accuracy: 0.8698 | Test Precision: 0.8766 | Test Recall: 0.8609\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 45...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3666 | Val Loss: 0.3046 | Accuracy: 0.8768 | Precision: 0.8361 | Recall: 0.9278\n",
      "Epoch 02 | Training Loss: 0.0376 | Val Loss: 0.3185 | Accuracy: 0.8862 | Precision: 0.8747 | Recall: 0.8932\n",
      "Epoch 03 | Training Loss: 0.0056 | Val Loss: 0.3609 | Accuracy: 0.8886 | Precision: 0.8815 | Recall: 0.8899\n",
      "Epoch 04 | Training Loss: 0.0014 | Val Loss: 0.3934 | Accuracy: 0.8892 | Precision: 0.8798 | Recall: 0.8936\n",
      "Epoch 05 | Training Loss: 0.0007 | Val Loss: 0.4148 | Accuracy: 0.8914 | Precision: 0.8834 | Recall: 0.8940\n",
      "Epoch 06 | Training Loss: 0.0005 | Val Loss: 0.4324 | Accuracy: 0.8916 | Precision: 0.8863 | Recall: 0.8907\n",
      "Epoch 07 | Training Loss: 0.0003 | Val Loss: 0.4482 | Accuracy: 0.8914 | Precision: 0.8822 | Recall: 0.8956\n",
      "Epoch 08 | Training Loss: 0.0002 | Val Loss: 0.4617 | Accuracy: 0.8916 | Precision: 0.8828 | Recall: 0.8952\n",
      "Epoch 09 | Training Loss: 0.0002 | Val Loss: 0.4739 | Accuracy: 0.8910 | Precision: 0.8818 | Recall: 0.8952\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.4851 | Accuracy: 0.8912 | Precision: 0.8815 | Recall: 0.8960\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3897 | Test Accuracy: 0.8717 | Test Precision: 0.8743 | Test Recall: 0.8682\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 45...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3794 | Val Loss: 0.2867 | Accuracy: 0.8804 | Precision: 0.8471 | Recall: 0.9191\n",
      "Epoch 02 | Training Loss: 0.0397 | Val Loss: 0.3206 | Accuracy: 0.8854 | Precision: 0.8861 | Recall: 0.8762\n",
      "Epoch 03 | Training Loss: 0.0059 | Val Loss: 0.3590 | Accuracy: 0.8894 | Precision: 0.8877 | Recall: 0.8837\n",
      "Epoch 04 | Training Loss: 0.0017 | Val Loss: 0.3884 | Accuracy: 0.8900 | Precision: 0.8840 | Recall: 0.8899\n",
      "Epoch 05 | Training Loss: 0.0008 | Val Loss: 0.4105 | Accuracy: 0.8898 | Precision: 0.8843 | Recall: 0.8890\n",
      "Epoch 06 | Training Loss: 0.0005 | Val Loss: 0.4282 | Accuracy: 0.8886 | Precision: 0.8859 | Recall: 0.8841\n",
      "Epoch 07 | Training Loss: 0.0004 | Val Loss: 0.4432 | Accuracy: 0.8882 | Precision: 0.8830 | Recall: 0.8870\n",
      "Epoch 08 | Training Loss: 0.0003 | Val Loss: 0.4570 | Accuracy: 0.8886 | Precision: 0.8831 | Recall: 0.8878\n",
      "Epoch 09 | Training Loss: 0.0002 | Val Loss: 0.4690 | Accuracy: 0.8888 | Precision: 0.8831 | Recall: 0.8882\n",
      "Epoch 10 | Training Loss: 0.0002 | Val Loss: 0.4801 | Accuracy: 0.8874 | Precision: 0.8831 | Recall: 0.8849\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4082 | Test Accuracy: 0.8700 | Test Precision: 0.8748 | Test Recall: 0.8637\n",
      "\n",
      "Training for parameter combination: 46, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.0001, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 46...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8776 | Val Loss: 0.8244 | Accuracy: 0.5272 | Precision: 0.5120 | Recall: 0.5301\n",
      "Epoch 02 | Training Loss: 0.8277 | Val Loss: 0.7991 | Accuracy: 0.5330 | Precision: 0.5178 | Recall: 0.5334\n",
      "Epoch 03 | Training Loss: 0.8025 | Val Loss: 0.7790 | Accuracy: 0.5380 | Precision: 0.5226 | Recall: 0.5429\n",
      "Epoch 04 | Training Loss: 0.7820 | Val Loss: 0.7620 | Accuracy: 0.5462 | Precision: 0.5313 | Recall: 0.5425\n",
      "Epoch 05 | Training Loss: 0.7648 | Val Loss: 0.7491 | Accuracy: 0.5512 | Precision: 0.5345 | Recall: 0.5747\n",
      "Epoch 06 | Training Loss: 0.7508 | Val Loss: 0.7368 | Accuracy: 0.5578 | Precision: 0.5417 | Recall: 0.5705\n",
      "Epoch 07 | Training Loss: 0.7387 | Val Loss: 0.7274 | Accuracy: 0.5626 | Precision: 0.5455 | Recall: 0.5858\n",
      "Epoch 08 | Training Loss: 0.7284 | Val Loss: 0.7180 | Accuracy: 0.5662 | Precision: 0.5509 | Recall: 0.5689\n",
      "Epoch 09 | Training Loss: 0.7194 | Val Loss: 0.7103 | Accuracy: 0.5728 | Precision: 0.5591 | Recall: 0.5619\n",
      "Epoch 10 | Training Loss: 0.7115 | Val Loss: 0.7046 | Accuracy: 0.5774 | Precision: 0.5608 | Recall: 0.5916\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7253 | Test Accuracy: 0.5690 | Test Precision: 0.5661 | Test Recall: 0.5904\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 46...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8551 | Val Loss: 0.8338 | Accuracy: 0.5110 | Precision: 0.4956 | Recall: 0.4847\n",
      "Epoch 02 | Training Loss: 0.8061 | Val Loss: 0.8084 | Accuracy: 0.5214 | Precision: 0.5062 | Recall: 0.5186\n",
      "Epoch 03 | Training Loss: 0.7828 | Val Loss: 0.7868 | Accuracy: 0.5296 | Precision: 0.5158 | Recall: 0.4851\n",
      "Epoch 04 | Training Loss: 0.7647 | Val Loss: 0.7709 | Accuracy: 0.5404 | Precision: 0.5255 | Recall: 0.5363\n",
      "Epoch 05 | Training Loss: 0.7496 | Val Loss: 0.7563 | Accuracy: 0.5494 | Precision: 0.5364 | Recall: 0.5198\n",
      "Epoch 06 | Training Loss: 0.7370 | Val Loss: 0.7455 | Accuracy: 0.5494 | Precision: 0.5345 | Recall: 0.5470\n",
      "Epoch 07 | Training Loss: 0.7262 | Val Loss: 0.7354 | Accuracy: 0.5536 | Precision: 0.5389 | Recall: 0.5487\n",
      "Epoch 08 | Training Loss: 0.7168 | Val Loss: 0.7261 | Accuracy: 0.5600 | Precision: 0.5477 | Recall: 0.5309\n",
      "Epoch 09 | Training Loss: 0.7085 | Val Loss: 0.7188 | Accuracy: 0.5642 | Precision: 0.5501 | Recall: 0.5545\n",
      "Epoch 10 | Training Loss: 0.7011 | Val Loss: 0.7119 | Accuracy: 0.5688 | Precision: 0.5551 | Recall: 0.5573\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6082 | Test Accuracy: 0.5838 | Test Precision: 0.5857 | Test Recall: 0.5730\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 46...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8789 | Val Loss: 0.8091 | Accuracy: 0.5228 | Precision: 0.5078 | Recall: 0.5120\n",
      "Epoch 02 | Training Loss: 0.7948 | Val Loss: 0.7861 | Accuracy: 0.5296 | Precision: 0.5147 | Recall: 0.5190\n",
      "Epoch 03 | Training Loss: 0.7741 | Val Loss: 0.7682 | Accuracy: 0.5336 | Precision: 0.5181 | Recall: 0.5437\n",
      "Epoch 04 | Training Loss: 0.7569 | Val Loss: 0.7522 | Accuracy: 0.5436 | Precision: 0.5295 | Recall: 0.5256\n",
      "Epoch 05 | Training Loss: 0.7431 | Val Loss: 0.7401 | Accuracy: 0.5492 | Precision: 0.5335 | Recall: 0.5582\n",
      "Epoch 06 | Training Loss: 0.7312 | Val Loss: 0.7293 | Accuracy: 0.5558 | Precision: 0.5405 | Recall: 0.5594\n",
      "Epoch 07 | Training Loss: 0.7212 | Val Loss: 0.7203 | Accuracy: 0.5612 | Precision: 0.5456 | Recall: 0.5681\n",
      "Epoch 08 | Training Loss: 0.7126 | Val Loss: 0.7124 | Accuracy: 0.5654 | Precision: 0.5493 | Recall: 0.5767\n",
      "Epoch 09 | Training Loss: 0.7050 | Val Loss: 0.7061 | Accuracy: 0.5730 | Precision: 0.5556 | Recall: 0.5961\n",
      "Epoch 10 | Training Loss: 0.6985 | Val Loss: 0.6991 | Accuracy: 0.5762 | Precision: 0.5608 | Recall: 0.5800\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6560 | Test Accuracy: 0.5742 | Test Precision: 0.5748 | Test Recall: 0.5697\n",
      "\n",
      "Training for parameter combination: 47, \n",
      "\n",
      "parameters: [2, 'Tanh', 0.0001, 'SGD', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 47...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9790 | Val Loss: 0.9490 | Accuracy: 0.5198 | Precision: 0.5077 | Recall: 0.3111\n",
      "Epoch 02 | Training Loss: 0.9335 | Val Loss: 0.9198 | Accuracy: 0.5098 | Precision: 0.4924 | Recall: 0.3606\n",
      "Epoch 03 | Training Loss: 0.9086 | Val Loss: 0.9036 | Accuracy: 0.5140 | Precision: 0.4985 | Recall: 0.4010\n",
      "Epoch 04 | Training Loss: 0.8938 | Val Loss: 0.8934 | Accuracy: 0.5156 | Precision: 0.5005 | Recall: 0.4328\n",
      "Epoch 05 | Training Loss: 0.8836 | Val Loss: 0.8859 | Accuracy: 0.5130 | Precision: 0.4975 | Recall: 0.4526\n",
      "Epoch 06 | Training Loss: 0.8757 | Val Loss: 0.8795 | Accuracy: 0.5138 | Precision: 0.4985 | Recall: 0.4686\n",
      "Epoch 07 | Training Loss: 0.8690 | Val Loss: 0.8738 | Accuracy: 0.5166 | Precision: 0.5015 | Recall: 0.4831\n",
      "Epoch 08 | Training Loss: 0.8628 | Val Loss: 0.8683 | Accuracy: 0.5176 | Precision: 0.5025 | Recall: 0.4905\n",
      "Epoch 09 | Training Loss: 0.8570 | Val Loss: 0.8630 | Accuracy: 0.5192 | Precision: 0.5042 | Recall: 0.4979\n",
      "Epoch 10 | Training Loss: 0.8514 | Val Loss: 0.8579 | Accuracy: 0.5208 | Precision: 0.5058 | Recall: 0.5012\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6910 | Test Accuracy: 0.5289 | Test Precision: 0.5297 | Test Recall: 0.5156\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 47...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9595 | Val Loss: 0.9418 | Accuracy: 0.4972 | Precision: 0.4852 | Recall: 0.6081\n",
      "Epoch 02 | Training Loss: 0.9372 | Val Loss: 0.9232 | Accuracy: 0.5028 | Precision: 0.4891 | Recall: 0.5734\n",
      "Epoch 03 | Training Loss: 0.9238 | Val Loss: 0.9113 | Accuracy: 0.5000 | Precision: 0.4860 | Recall: 0.5425\n",
      "Epoch 04 | Training Loss: 0.9144 | Val Loss: 0.9024 | Accuracy: 0.5026 | Precision: 0.4879 | Recall: 0.5248\n",
      "Epoch 05 | Training Loss: 0.9068 | Val Loss: 0.8951 | Accuracy: 0.5076 | Precision: 0.4925 | Recall: 0.5169\n",
      "Epoch 06 | Training Loss: 0.9001 | Val Loss: 0.8887 | Accuracy: 0.5098 | Precision: 0.4946 | Recall: 0.5124\n",
      "Epoch 07 | Training Loss: 0.8939 | Val Loss: 0.8827 | Accuracy: 0.5134 | Precision: 0.4982 | Recall: 0.5099\n",
      "Epoch 08 | Training Loss: 0.8880 | Val Loss: 0.8771 | Accuracy: 0.5146 | Precision: 0.4994 | Recall: 0.5087\n",
      "Epoch 09 | Training Loss: 0.8822 | Val Loss: 0.8717 | Accuracy: 0.5184 | Precision: 0.5032 | Recall: 0.5111\n",
      "Epoch 10 | Training Loss: 0.8766 | Val Loss: 0.8664 | Accuracy: 0.5212 | Precision: 0.5061 | Recall: 0.5116\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6928 | Test Accuracy: 0.5116 | Test Precision: 0.5117 | Test Recall: 0.5103\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 47...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9502 | Val Loss: 0.9610 | Accuracy: 0.4912 | Precision: 0.4787 | Recall: 0.5569\n",
      "Epoch 02 | Training Loss: 0.9378 | Val Loss: 0.9487 | Accuracy: 0.4940 | Precision: 0.4805 | Recall: 0.5400\n",
      "Epoch 03 | Training Loss: 0.9282 | Val Loss: 0.9390 | Accuracy: 0.4984 | Precision: 0.4841 | Recall: 0.5272\n",
      "Epoch 04 | Training Loss: 0.9200 | Val Loss: 0.9306 | Accuracy: 0.4984 | Precision: 0.4838 | Recall: 0.5169\n",
      "Epoch 05 | Training Loss: 0.9124 | Val Loss: 0.9229 | Accuracy: 0.4994 | Precision: 0.4845 | Recall: 0.5103\n",
      "Epoch 06 | Training Loss: 0.9053 | Val Loss: 0.9158 | Accuracy: 0.5006 | Precision: 0.4856 | Recall: 0.5066\n",
      "Epoch 07 | Training Loss: 0.8985 | Val Loss: 0.9090 | Accuracy: 0.5040 | Precision: 0.4889 | Recall: 0.5070\n",
      "Epoch 08 | Training Loss: 0.8920 | Val Loss: 0.9025 | Accuracy: 0.5072 | Precision: 0.4920 | Recall: 0.5091\n",
      "Epoch 09 | Training Loss: 0.8856 | Val Loss: 0.8962 | Accuracy: 0.5096 | Precision: 0.4944 | Recall: 0.5103\n",
      "Epoch 10 | Training Loss: 0.8793 | Val Loss: 0.8900 | Accuracy: 0.5120 | Precision: 0.4968 | Recall: 0.5091\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7698 | Test Accuracy: 0.5116 | Test Precision: 0.5117 | Test Recall: 0.5094\n",
      "\n",
      "Training for parameter combination: 48, \n",
      "\n",
      "parameters: [2, 'Tanh', 0.0005, 'SGD', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 48...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8609 | Val Loss: 0.8352 | Accuracy: 0.5568 | Precision: 0.5401 | Recall: 0.5784\n",
      "Epoch 02 | Training Loss: 0.8051 | Val Loss: 0.7994 | Accuracy: 0.5692 | Precision: 0.5514 | Recall: 0.5978\n",
      "Epoch 03 | Training Loss: 0.7706 | Val Loss: 0.7685 | Accuracy: 0.5860 | Precision: 0.5684 | Recall: 0.6064\n",
      "Epoch 04 | Training Loss: 0.7415 | Val Loss: 0.7432 | Accuracy: 0.6022 | Precision: 0.5844 | Recall: 0.6213\n",
      "Epoch 05 | Training Loss: 0.7170 | Val Loss: 0.7205 | Accuracy: 0.6152 | Precision: 0.5998 | Recall: 0.6196\n",
      "Epoch 06 | Training Loss: 0.6960 | Val Loss: 0.7021 | Accuracy: 0.6236 | Precision: 0.6069 | Recall: 0.6345\n",
      "Epoch 07 | Training Loss: 0.6777 | Val Loss: 0.6859 | Accuracy: 0.6338 | Precision: 0.6171 | Recall: 0.6448\n",
      "Epoch 08 | Training Loss: 0.6617 | Val Loss: 0.6714 | Accuracy: 0.6434 | Precision: 0.6291 | Recall: 0.6444\n",
      "Epoch 09 | Training Loss: 0.6476 | Val Loss: 0.6589 | Accuracy: 0.6528 | Precision: 0.6383 | Recall: 0.6551\n",
      "Epoch 10 | Training Loss: 0.6350 | Val Loss: 0.6477 | Accuracy: 0.6578 | Precision: 0.6428 | Recall: 0.6621\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6368 | Test Accuracy: 0.6569 | Test Precision: 0.6583 | Test Recall: 0.6525\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 48...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9074 | Val Loss: 0.8783 | Accuracy: 0.5068 | Precision: 0.4914 | Recall: 0.4955\n",
      "Epoch 02 | Training Loss: 0.8492 | Val Loss: 0.8305 | Accuracy: 0.5310 | Precision: 0.5166 | Recall: 0.5058\n",
      "Epoch 03 | Training Loss: 0.8034 | Val Loss: 0.7925 | Accuracy: 0.5486 | Precision: 0.5347 | Recall: 0.5309\n",
      "Epoch 04 | Training Loss: 0.7663 | Val Loss: 0.7615 | Accuracy: 0.5644 | Precision: 0.5507 | Recall: 0.5516\n",
      "Epoch 05 | Training Loss: 0.7357 | Val Loss: 0.7359 | Accuracy: 0.5822 | Precision: 0.5682 | Recall: 0.5759\n",
      "Epoch 06 | Training Loss: 0.7101 | Val Loss: 0.7139 | Accuracy: 0.6002 | Precision: 0.5889 | Recall: 0.5804\n",
      "Epoch 07 | Training Loss: 0.6885 | Val Loss: 0.6956 | Accuracy: 0.6152 | Precision: 0.6026 | Recall: 0.6056\n",
      "Epoch 08 | Training Loss: 0.6698 | Val Loss: 0.6801 | Accuracy: 0.6246 | Precision: 0.6102 | Recall: 0.6246\n",
      "Epoch 09 | Training Loss: 0.6537 | Val Loss: 0.6658 | Accuracy: 0.6356 | Precision: 0.6248 | Recall: 0.6217\n",
      "Epoch 10 | Training Loss: 0.6395 | Val Loss: 0.6537 | Accuracy: 0.6448 | Precision: 0.6331 | Recall: 0.6357\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6526 | Test Accuracy: 0.6441 | Test Precision: 0.6446 | Test Recall: 0.6425\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 48...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9281 | Val Loss: 0.9043 | Accuracy: 0.5090 | Precision: 0.4937 | Recall: 0.4983\n",
      "Epoch 02 | Training Loss: 0.8628 | Val Loss: 0.8501 | Accuracy: 0.5368 | Precision: 0.5220 | Recall: 0.5276\n",
      "Epoch 03 | Training Loss: 0.8124 | Val Loss: 0.8064 | Accuracy: 0.5598 | Precision: 0.5469 | Recall: 0.5367\n",
      "Epoch 04 | Training Loss: 0.7721 | Val Loss: 0.7718 | Accuracy: 0.5800 | Precision: 0.5671 | Recall: 0.5652\n",
      "Epoch 05 | Training Loss: 0.7393 | Val Loss: 0.7433 | Accuracy: 0.5930 | Precision: 0.5799 | Recall: 0.5821\n",
      "Epoch 06 | Training Loss: 0.7120 | Val Loss: 0.7190 | Accuracy: 0.6054 | Precision: 0.5951 | Recall: 0.5821\n",
      "Epoch 07 | Training Loss: 0.6891 | Val Loss: 0.6989 | Accuracy: 0.6144 | Precision: 0.6037 | Recall: 0.5957\n",
      "Epoch 08 | Training Loss: 0.6694 | Val Loss: 0.6818 | Accuracy: 0.6260 | Precision: 0.6142 | Recall: 0.6147\n",
      "Epoch 09 | Training Loss: 0.6525 | Val Loss: 0.6664 | Accuracy: 0.6344 | Precision: 0.6243 | Recall: 0.6176\n",
      "Epoch 10 | Training Loss: 0.6377 | Val Loss: 0.6532 | Accuracy: 0.6462 | Precision: 0.6351 | Recall: 0.6353\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6178 | Test Accuracy: 0.6551 | Test Precision: 0.6581 | Test Recall: 0.6458\n",
      "\n",
      "Training for parameter combination: 49, \n",
      "\n",
      "parameters: [1, 'ReLU', 0.0005, 'RMSProp', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 49...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4232 | Val Loss: 0.3299 | Accuracy: 0.8696 | Precision: 0.8533 | Recall: 0.8828\n",
      "Epoch 02 | Training Loss: 0.1369 | Val Loss: 0.3364 | Accuracy: 0.8766 | Precision: 0.8763 | Recall: 0.8680\n",
      "Epoch 03 | Training Loss: 0.0540 | Val Loss: 0.3907 | Accuracy: 0.8756 | Precision: 0.8457 | Recall: 0.9092\n",
      "Epoch 04 | Training Loss: 0.0176 | Val Loss: 0.4420 | Accuracy: 0.8770 | Precision: 0.8815 | Recall: 0.8622\n",
      "Epoch 05 | Training Loss: 0.0047 | Val Loss: 0.5112 | Accuracy: 0.8748 | Precision: 0.8622 | Recall: 0.8828\n",
      "Epoch 06 | Training Loss: 0.0011 | Val Loss: 0.5932 | Accuracy: 0.8764 | Precision: 0.8618 | Recall: 0.8874\n",
      "Epoch 07 | Training Loss: 0.0004 | Val Loss: 0.6468 | Accuracy: 0.8766 | Precision: 0.8581 | Recall: 0.8932\n",
      "Epoch 08 | Training Loss: 0.0002 | Val Loss: 0.6782 | Accuracy: 0.8774 | Precision: 0.8603 | Recall: 0.8919\n",
      "Epoch 09 | Training Loss: 0.0001 | Val Loss: 0.6983 | Accuracy: 0.8760 | Precision: 0.8631 | Recall: 0.8845\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.7181 | Accuracy: 0.8772 | Precision: 0.8617 | Recall: 0.8894\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3137 | Test Accuracy: 0.8760 | Test Precision: 0.8738 | Test Recall: 0.8790\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 49...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4110 | Val Loss: 0.3211 | Accuracy: 0.8744 | Precision: 0.8984 | Recall: 0.8354\n",
      "Epoch 02 | Training Loss: 0.1378 | Val Loss: 0.3369 | Accuracy: 0.8750 | Precision: 0.8398 | Recall: 0.9171\n",
      "Epoch 03 | Training Loss: 0.0550 | Val Loss: 0.3626 | Accuracy: 0.8788 | Precision: 0.8622 | Recall: 0.8927\n",
      "Epoch 04 | Training Loss: 0.0177 | Val Loss: 0.4233 | Accuracy: 0.8818 | Precision: 0.8820 | Recall: 0.8729\n",
      "Epoch 05 | Training Loss: 0.0045 | Val Loss: 0.5256 | Accuracy: 0.8756 | Precision: 0.8413 | Recall: 0.9163\n",
      "Epoch 06 | Training Loss: 0.0012 | Val Loss: 0.5673 | Accuracy: 0.8826 | Precision: 0.8652 | Recall: 0.8977\n",
      "Epoch 07 | Training Loss: 0.0004 | Val Loss: 0.6137 | Accuracy: 0.8818 | Precision: 0.8670 | Recall: 0.8932\n",
      "Epoch 08 | Training Loss: 0.0002 | Val Loss: 0.6434 | Accuracy: 0.8820 | Precision: 0.8698 | Recall: 0.8899\n",
      "Epoch 09 | Training Loss: 0.0001 | Val Loss: 0.6666 | Accuracy: 0.8826 | Precision: 0.8673 | Recall: 0.8948\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.6846 | Accuracy: 0.8824 | Precision: 0.8654 | Recall: 0.8969\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3365 | Test Accuracy: 0.8724 | Test Precision: 0.8697 | Test Recall: 0.8761\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 49...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4229 | Val Loss: 0.3250 | Accuracy: 0.8718 | Precision: 0.8422 | Recall: 0.9051\n",
      "Epoch 02 | Training Loss: 0.1364 | Val Loss: 0.3375 | Accuracy: 0.8758 | Precision: 0.9001 | Recall: 0.8366\n",
      "Epoch 03 | Training Loss: 0.0538 | Val Loss: 0.3646 | Accuracy: 0.8822 | Precision: 0.8847 | Recall: 0.8705\n",
      "Epoch 04 | Training Loss: 0.0174 | Val Loss: 0.4286 | Accuracy: 0.8800 | Precision: 0.8651 | Recall: 0.8915\n",
      "Epoch 05 | Training Loss: 0.0046 | Val Loss: 0.4914 | Accuracy: 0.8828 | Precision: 0.8724 | Recall: 0.8882\n",
      "Epoch 06 | Training Loss: 0.0012 | Val Loss: 0.5657 | Accuracy: 0.8806 | Precision: 0.8685 | Recall: 0.8882\n",
      "Epoch 07 | Training Loss: 0.0004 | Val Loss: 0.6180 | Accuracy: 0.8810 | Precision: 0.8642 | Recall: 0.8952\n",
      "Epoch 08 | Training Loss: 0.0002 | Val Loss: 0.6418 | Accuracy: 0.8812 | Precision: 0.8707 | Recall: 0.8866\n",
      "Epoch 09 | Training Loss: 0.0001 | Val Loss: 0.6638 | Accuracy: 0.8814 | Precision: 0.8705 | Recall: 0.8874\n",
      "Epoch 10 | Training Loss: 0.0001 | Val Loss: 0.6795 | Accuracy: 0.8814 | Precision: 0.8726 | Recall: 0.8845\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3260 | Test Accuracy: 0.8734 | Test Precision: 0.8775 | Test Recall: 0.8679\n",
      "\n",
      "Training for parameter combination: 50, \n",
      "\n",
      "parameters: [3, 'Tanh', 0.0005, 'RMSProp', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 50...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3765 | Val Loss: 0.2951 | Accuracy: 0.8696 | Precision: 0.8513 | Recall: 0.8857\n",
      "Epoch 02 | Training Loss: 0.1406 | Val Loss: 0.3127 | Accuracy: 0.8724 | Precision: 0.8730 | Recall: 0.8622\n",
      "Epoch 03 | Training Loss: 0.0462 | Val Loss: 0.4391 | Accuracy: 0.8652 | Precision: 0.8838 | Recall: 0.8313\n",
      "Epoch 04 | Training Loss: 0.0113 | Val Loss: 0.6821 | Accuracy: 0.8608 | Precision: 0.8119 | Recall: 0.9278\n",
      "Epoch 05 | Training Loss: 0.0025 | Val Loss: 0.7836 | Accuracy: 0.8678 | Precision: 0.8400 | Recall: 0.8985\n",
      "Epoch 06 | Training Loss: 0.0003 | Val Loss: 0.8840 | Accuracy: 0.8676 | Precision: 0.8605 | Recall: 0.8676\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 0.9388 | Accuracy: 0.8692 | Precision: 0.8577 | Recall: 0.8754\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.9682 | Accuracy: 0.8704 | Precision: 0.8572 | Recall: 0.8791\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.9888 | Accuracy: 0.8702 | Precision: 0.8574 | Recall: 0.8783\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.0049 | Accuracy: 0.8698 | Precision: 0.8576 | Recall: 0.8771\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3133 | Test Accuracy: 0.8702 | Test Precision: 0.8735 | Test Recall: 0.8658\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 50...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3701 | Val Loss: 0.2937 | Accuracy: 0.8752 | Precision: 0.8626 | Recall: 0.8833\n",
      "Epoch 02 | Training Loss: 0.1370 | Val Loss: 0.3177 | Accuracy: 0.8794 | Precision: 0.8629 | Recall: 0.8932\n",
      "Epoch 03 | Training Loss: 0.0466 | Val Loss: 0.4160 | Accuracy: 0.8732 | Precision: 0.8513 | Recall: 0.8948\n",
      "Epoch 04 | Training Loss: 0.0113 | Val Loss: 0.5457 | Accuracy: 0.8724 | Precision: 0.8715 | Recall: 0.8643\n",
      "Epoch 05 | Training Loss: 0.0021 | Val Loss: 0.7531 | Accuracy: 0.8732 | Precision: 0.8612 | Recall: 0.8804\n",
      "Epoch 06 | Training Loss: 0.0004 | Val Loss: 0.8573 | Accuracy: 0.8760 | Precision: 0.8676 | Recall: 0.8783\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 0.8972 | Accuracy: 0.8752 | Precision: 0.8653 | Recall: 0.8795\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.9210 | Accuracy: 0.8754 | Precision: 0.8674 | Recall: 0.8771\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.9395 | Accuracy: 0.8752 | Precision: 0.8659 | Recall: 0.8787\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.9545 | Accuracy: 0.8752 | Precision: 0.8659 | Recall: 0.8787\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4333 | Test Accuracy: 0.8696 | Test Precision: 0.8700 | Test Recall: 0.8690\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 50...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3758 | Val Loss: 0.2919 | Accuracy: 0.8768 | Precision: 0.8628 | Recall: 0.8870\n",
      "Epoch 02 | Training Loss: 0.1412 | Val Loss: 0.3171 | Accuracy: 0.8732 | Precision: 0.8477 | Recall: 0.9002\n",
      "Epoch 03 | Training Loss: 0.0479 | Val Loss: 0.3940 | Accuracy: 0.8756 | Precision: 0.8808 | Recall: 0.8597\n",
      "Epoch 04 | Training Loss: 0.0137 | Val Loss: 0.5470 | Accuracy: 0.8768 | Precision: 0.8669 | Recall: 0.8812\n",
      "Epoch 05 | Training Loss: 0.0023 | Val Loss: 0.7299 | Accuracy: 0.8752 | Precision: 0.8583 | Recall: 0.8894\n",
      "Epoch 06 | Training Loss: 0.0002 | Val Loss: 0.8527 | Accuracy: 0.8758 | Precision: 0.8590 | Recall: 0.8899\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 0.8913 | Accuracy: 0.8768 | Precision: 0.8642 | Recall: 0.8849\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.9179 | Accuracy: 0.8762 | Precision: 0.8646 | Recall: 0.8828\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.9413 | Accuracy: 0.8764 | Precision: 0.8629 | Recall: 0.8857\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.9558 | Accuracy: 0.8760 | Precision: 0.8646 | Recall: 0.8824\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3196 | Test Accuracy: 0.8689 | Test Precision: 0.8661 | Test Recall: 0.8727\n",
      "\n",
      "Training for parameter combination: 51, \n",
      "\n",
      "parameters: [2, 'ReLU', 0.0005, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 51...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9586 | Val Loss: 0.8669 | Accuracy: 0.5544 | Precision: 0.5385 | Recall: 0.5660\n",
      "Epoch 02 | Training Loss: 0.8160 | Val Loss: 0.7730 | Accuracy: 0.5912 | Precision: 0.5823 | Recall: 0.5545\n",
      "Epoch 03 | Training Loss: 0.7414 | Val Loss: 0.7203 | Accuracy: 0.6136 | Precision: 0.6016 | Recall: 0.6011\n",
      "Epoch 04 | Training Loss: 0.6951 | Val Loss: 0.6863 | Accuracy: 0.6328 | Precision: 0.6210 | Recall: 0.6225\n",
      "Epoch 05 | Training Loss: 0.6636 | Val Loss: 0.6622 | Accuracy: 0.6518 | Precision: 0.6412 | Recall: 0.6399\n",
      "Epoch 06 | Training Loss: 0.6404 | Val Loss: 0.6442 | Accuracy: 0.6638 | Precision: 0.6551 | Recall: 0.6473\n",
      "Epoch 07 | Training Loss: 0.6219 | Val Loss: 0.6304 | Accuracy: 0.6730 | Precision: 0.6544 | Recall: 0.6898\n",
      "Epoch 08 | Training Loss: 0.6068 | Val Loss: 0.6187 | Accuracy: 0.6826 | Precision: 0.6629 | Recall: 0.7026\n",
      "Epoch 09 | Training Loss: 0.5942 | Val Loss: 0.6082 | Accuracy: 0.6914 | Precision: 0.6727 | Recall: 0.7079\n",
      "Epoch 10 | Training Loss: 0.5828 | Val Loss: 0.5996 | Accuracy: 0.6912 | Precision: 0.6921 | Recall: 0.6539\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6230 | Test Accuracy: 0.6862 | Test Precision: 0.7019 | Test Recall: 0.6475\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 51...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9208 | Val Loss: 0.8368 | Accuracy: 0.5590 | Precision: 0.5410 | Recall: 0.5957\n",
      "Epoch 02 | Training Loss: 0.7902 | Val Loss: 0.7559 | Accuracy: 0.5900 | Precision: 0.5719 | Recall: 0.6139\n",
      "Epoch 03 | Training Loss: 0.7240 | Val Loss: 0.7076 | Accuracy: 0.6130 | Precision: 0.5968 | Recall: 0.6217\n",
      "Epoch 04 | Training Loss: 0.6823 | Val Loss: 0.6792 | Accuracy: 0.6330 | Precision: 0.6071 | Recall: 0.6889\n",
      "Epoch 05 | Training Loss: 0.6529 | Val Loss: 0.6528 | Accuracy: 0.6486 | Precision: 0.6374 | Recall: 0.6382\n",
      "Epoch 06 | Training Loss: 0.6317 | Val Loss: 0.6352 | Accuracy: 0.6644 | Precision: 0.6503 | Recall: 0.6658\n",
      "Epoch 07 | Training Loss: 0.6146 | Val Loss: 0.6209 | Accuracy: 0.6766 | Precision: 0.6653 | Recall: 0.6700\n",
      "Epoch 08 | Training Loss: 0.6006 | Val Loss: 0.6092 | Accuracy: 0.6830 | Precision: 0.6763 | Recall: 0.6638\n",
      "Epoch 09 | Training Loss: 0.5885 | Val Loss: 0.6010 | Accuracy: 0.6862 | Precision: 0.6608 | Recall: 0.7248\n",
      "Epoch 10 | Training Loss: 0.5782 | Val Loss: 0.5917 | Accuracy: 0.6932 | Precision: 0.6688 | Recall: 0.7273\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5702 | Test Accuracy: 0.6916 | Test Precision: 0.6800 | Test Recall: 0.7237\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 51...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9467 | Val Loss: 0.8459 | Accuracy: 0.5642 | Precision: 0.5495 | Recall: 0.5606\n",
      "Epoch 02 | Training Loss: 0.8103 | Val Loss: 0.7591 | Accuracy: 0.5974 | Precision: 0.5808 | Recall: 0.6093\n",
      "Epoch 03 | Training Loss: 0.7344 | Val Loss: 0.7068 | Accuracy: 0.6206 | Precision: 0.6043 | Recall: 0.6300\n",
      "Epoch 04 | Training Loss: 0.6874 | Val Loss: 0.6734 | Accuracy: 0.6368 | Precision: 0.6193 | Recall: 0.6510\n",
      "Epoch 05 | Training Loss: 0.6553 | Val Loss: 0.6493 | Accuracy: 0.6488 | Precision: 0.6310 | Recall: 0.6638\n",
      "Epoch 06 | Training Loss: 0.6316 | Val Loss: 0.6302 | Accuracy: 0.6604 | Precision: 0.6542 | Recall: 0.6353\n",
      "Epoch 07 | Training Loss: 0.6133 | Val Loss: 0.6171 | Accuracy: 0.6728 | Precision: 0.6530 | Recall: 0.6939\n",
      "Epoch 08 | Training Loss: 0.5982 | Val Loss: 0.6044 | Accuracy: 0.6822 | Precision: 0.6660 | Recall: 0.6910\n",
      "Epoch 09 | Training Loss: 0.5856 | Val Loss: 0.5950 | Accuracy: 0.6888 | Precision: 0.6687 | Recall: 0.7096\n",
      "Epoch 10 | Training Loss: 0.5744 | Val Loss: 0.5863 | Accuracy: 0.6970 | Precision: 0.6765 | Recall: 0.7186\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5035 | Test Accuracy: 0.6969 | Test Precision: 0.6891 | Test Recall: 0.7175\n",
      "\n",
      "Training for parameter combination: 52, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.0001, 'RMSProp', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 52...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6821 | Val Loss: 0.5520 | Accuracy: 0.7268 | Precision: 0.7337 | Recall: 0.6852\n",
      "Epoch 02 | Training Loss: 0.4347 | Val Loss: 0.4756 | Accuracy: 0.7866 | Precision: 0.7398 | Recall: 0.8634\n",
      "Epoch 03 | Training Loss: 0.3117 | Val Loss: 0.4234 | Accuracy: 0.8144 | Precision: 0.7899 | Recall: 0.8408\n",
      "Epoch 04 | Training Loss: 0.2308 | Val Loss: 0.4106 | Accuracy: 0.8300 | Precision: 0.8025 | Recall: 0.8614\n",
      "Epoch 05 | Training Loss: 0.1720 | Val Loss: 0.4013 | Accuracy: 0.8368 | Precision: 0.8266 | Recall: 0.8395\n",
      "Epoch 06 | Training Loss: 0.1269 | Val Loss: 0.4169 | Accuracy: 0.8422 | Precision: 0.8507 | Recall: 0.8181\n",
      "Epoch 07 | Training Loss: 0.0925 | Val Loss: 0.4405 | Accuracy: 0.8450 | Precision: 0.8637 | Recall: 0.8078\n",
      "Epoch 08 | Training Loss: 0.0654 | Val Loss: 0.4513 | Accuracy: 0.8484 | Precision: 0.8372 | Recall: 0.8531\n",
      "Epoch 09 | Training Loss: 0.0441 | Val Loss: 0.4947 | Accuracy: 0.8482 | Precision: 0.8266 | Recall: 0.8692\n",
      "Epoch 10 | Training Loss: 0.0290 | Val Loss: 0.5312 | Accuracy: 0.8504 | Precision: 0.8401 | Recall: 0.8540\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4469 | Test Accuracy: 0.8409 | Test Precision: 0.8433 | Test Recall: 0.8374\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 52...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6536 | Val Loss: 0.5396 | Accuracy: 0.7322 | Precision: 0.7548 | Recall: 0.6630\n",
      "Epoch 02 | Training Loss: 0.4260 | Val Loss: 0.4892 | Accuracy: 0.7770 | Precision: 0.7159 | Recall: 0.8952\n",
      "Epoch 03 | Training Loss: 0.3117 | Val Loss: 0.4225 | Accuracy: 0.8144 | Precision: 0.8489 | Recall: 0.7508\n",
      "Epoch 04 | Training Loss: 0.2360 | Val Loss: 0.3974 | Accuracy: 0.8294 | Precision: 0.8376 | Recall: 0.8040\n",
      "Epoch 05 | Training Loss: 0.1791 | Val Loss: 0.3921 | Accuracy: 0.8394 | Precision: 0.8301 | Recall: 0.8408\n",
      "Epoch 06 | Training Loss: 0.1345 | Val Loss: 0.4022 | Accuracy: 0.8424 | Precision: 0.8185 | Recall: 0.8672\n",
      "Epoch 07 | Training Loss: 0.0987 | Val Loss: 0.4140 | Accuracy: 0.8472 | Precision: 0.8286 | Recall: 0.8634\n",
      "Epoch 08 | Training Loss: 0.0711 | Val Loss: 0.4381 | Accuracy: 0.8482 | Precision: 0.8640 | Recall: 0.8152\n",
      "Epoch 09 | Training Loss: 0.0498 | Val Loss: 0.4616 | Accuracy: 0.8518 | Precision: 0.8482 | Recall: 0.8457\n",
      "Epoch 10 | Training Loss: 0.0334 | Val Loss: 0.5177 | Accuracy: 0.8460 | Precision: 0.8759 | Recall: 0.7950\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4765 | Test Accuracy: 0.8354 | Test Precision: 0.8741 | Test Recall: 0.7836\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 52...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6467 | Val Loss: 0.5211 | Accuracy: 0.7452 | Precision: 0.7195 | Recall: 0.7776\n",
      "Epoch 02 | Training Loss: 0.4183 | Val Loss: 0.4382 | Accuracy: 0.8014 | Precision: 0.7726 | Recall: 0.8366\n",
      "Epoch 03 | Training Loss: 0.3067 | Val Loss: 0.3994 | Accuracy: 0.8236 | Precision: 0.8079 | Recall: 0.8346\n",
      "Epoch 04 | Training Loss: 0.2326 | Val Loss: 0.4361 | Accuracy: 0.8186 | Precision: 0.7581 | Recall: 0.9191\n",
      "Epoch 05 | Training Loss: 0.1771 | Val Loss: 0.3854 | Accuracy: 0.8422 | Precision: 0.8284 | Recall: 0.8507\n",
      "Epoch 06 | Training Loss: 0.1348 | Val Loss: 0.3906 | Accuracy: 0.8470 | Precision: 0.8290 | Recall: 0.8622\n",
      "Epoch 07 | Training Loss: 0.0997 | Val Loss: 0.4043 | Accuracy: 0.8520 | Precision: 0.8426 | Recall: 0.8544\n",
      "Epoch 08 | Training Loss: 0.0725 | Val Loss: 0.4317 | Accuracy: 0.8548 | Precision: 0.8679 | Recall: 0.8263\n",
      "Epoch 09 | Training Loss: 0.0506 | Val Loss: 0.4575 | Accuracy: 0.8526 | Precision: 0.8487 | Recall: 0.8469\n",
      "Epoch 10 | Training Loss: 0.0341 | Val Loss: 0.5432 | Accuracy: 0.8412 | Precision: 0.7940 | Recall: 0.9080\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4761 | Test Accuracy: 0.8394 | Test Precision: 0.8037 | Test Recall: 0.8982\n",
      "\n",
      "Training for parameter combination: 53, \n",
      "\n",
      "parameters: [2, 'LeakyReLU', 0.0001, 'Adam', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 53...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6089 | Val Loss: 0.4129 | Accuracy: 0.8094 | Precision: 0.8134 | Recall: 0.7875\n",
      "Epoch 02 | Training Loss: 0.2519 | Val Loss: 0.3558 | Accuracy: 0.8466 | Precision: 0.8416 | Recall: 0.8420\n",
      "Epoch 03 | Training Loss: 0.1404 | Val Loss: 0.3401 | Accuracy: 0.8614 | Precision: 0.8666 | Recall: 0.8441\n",
      "Epoch 04 | Training Loss: 0.0798 | Val Loss: 0.3431 | Accuracy: 0.8686 | Precision: 0.8477 | Recall: 0.8886\n",
      "Epoch 05 | Training Loss: 0.0447 | Val Loss: 0.3510 | Accuracy: 0.8700 | Precision: 0.8699 | Recall: 0.8606\n",
      "Epoch 06 | Training Loss: 0.0252 | Val Loss: 0.3689 | Accuracy: 0.8748 | Precision: 0.8727 | Recall: 0.8684\n",
      "Epoch 07 | Training Loss: 0.0146 | Val Loss: 0.3909 | Accuracy: 0.8744 | Precision: 0.8552 | Recall: 0.8919\n",
      "Epoch 08 | Training Loss: 0.0088 | Val Loss: 0.4089 | Accuracy: 0.8764 | Precision: 0.8659 | Recall: 0.8816\n",
      "Epoch 09 | Training Loss: 0.0055 | Val Loss: 0.4309 | Accuracy: 0.8778 | Precision: 0.8639 | Recall: 0.8878\n",
      "Epoch 10 | Training Loss: 0.0036 | Val Loss: 0.4523 | Accuracy: 0.8784 | Precision: 0.8632 | Recall: 0.8903\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4264 | Test Accuracy: 0.8596 | Test Precision: 0.8575 | Test Recall: 0.8626\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 53...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.5982 | Val Loss: 0.4369 | Accuracy: 0.8056 | Precision: 0.8339 | Recall: 0.7479\n",
      "Epoch 02 | Training Loss: 0.2584 | Val Loss: 0.3699 | Accuracy: 0.8488 | Precision: 0.8352 | Recall: 0.8573\n",
      "Epoch 03 | Training Loss: 0.1443 | Val Loss: 0.3498 | Accuracy: 0.8626 | Precision: 0.8475 | Recall: 0.8738\n",
      "Epoch 04 | Training Loss: 0.0814 | Val Loss: 0.3519 | Accuracy: 0.8692 | Precision: 0.8557 | Recall: 0.8783\n",
      "Epoch 05 | Training Loss: 0.0459 | Val Loss: 0.3650 | Accuracy: 0.8714 | Precision: 0.8693 | Recall: 0.8647\n",
      "Epoch 06 | Training Loss: 0.0258 | Val Loss: 0.3849 | Accuracy: 0.8728 | Precision: 0.8697 | Recall: 0.8676\n",
      "Epoch 07 | Training Loss: 0.0149 | Val Loss: 0.4075 | Accuracy: 0.8750 | Precision: 0.8571 | Recall: 0.8907\n",
      "Epoch 08 | Training Loss: 0.0089 | Val Loss: 0.4280 | Accuracy: 0.8746 | Precision: 0.8595 | Recall: 0.8861\n",
      "Epoch 09 | Training Loss: 0.0056 | Val Loss: 0.4483 | Accuracy: 0.8748 | Precision: 0.8649 | Recall: 0.8791\n",
      "Epoch 10 | Training Loss: 0.0037 | Val Loss: 0.4707 | Accuracy: 0.8750 | Precision: 0.8602 | Recall: 0.8861\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4215 | Test Accuracy: 0.8572 | Test Precision: 0.8551 | Test Recall: 0.8602\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 53...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6725 | Val Loss: 0.4464 | Accuracy: 0.8030 | Precision: 0.7803 | Recall: 0.8263\n",
      "Epoch 02 | Training Loss: 0.2672 | Val Loss: 0.3801 | Accuracy: 0.8432 | Precision: 0.8218 | Recall: 0.8639\n",
      "Epoch 03 | Training Loss: 0.1461 | Val Loss: 0.3577 | Accuracy: 0.8572 | Precision: 0.8490 | Recall: 0.8581\n",
      "Epoch 04 | Training Loss: 0.0831 | Val Loss: 0.3617 | Accuracy: 0.8634 | Precision: 0.8450 | Recall: 0.8795\n",
      "Epoch 05 | Training Loss: 0.0473 | Val Loss: 0.3725 | Accuracy: 0.8670 | Precision: 0.8517 | Recall: 0.8787\n",
      "Epoch 06 | Training Loss: 0.0269 | Val Loss: 0.4041 | Accuracy: 0.8650 | Precision: 0.8334 | Recall: 0.9018\n",
      "Epoch 07 | Training Loss: 0.0159 | Val Loss: 0.4097 | Accuracy: 0.8714 | Precision: 0.8618 | Recall: 0.8750\n",
      "Epoch 08 | Training Loss: 0.0095 | Val Loss: 0.4315 | Accuracy: 0.8706 | Precision: 0.8649 | Recall: 0.8688\n",
      "Epoch 09 | Training Loss: 0.0061 | Val Loss: 0.4534 | Accuracy: 0.8718 | Precision: 0.8602 | Recall: 0.8783\n",
      "Epoch 10 | Training Loss: 0.0040 | Val Loss: 0.4729 | Accuracy: 0.8708 | Precision: 0.8623 | Recall: 0.8729\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4699 | Test Accuracy: 0.8561 | Test Precision: 0.8617 | Test Recall: 0.8483\n",
      "\n",
      "Training for parameter combination: 54, \n",
      "\n",
      "parameters: [2, 'ReLU', 0.0005, 'Adam', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 54...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4188 | Val Loss: 0.2946 | Accuracy: 0.8780 | Precision: 0.8736 | Recall: 0.8750\n",
      "Epoch 02 | Training Loss: 0.0498 | Val Loss: 0.3227 | Accuracy: 0.8744 | Precision: 0.8742 | Recall: 0.8655\n",
      "Epoch 03 | Training Loss: 0.0063 | Val Loss: 0.3880 | Accuracy: 0.8782 | Precision: 0.8586 | Recall: 0.8965\n",
      "Epoch 04 | Training Loss: 0.0012 | Val Loss: 0.4291 | Accuracy: 0.8814 | Precision: 0.8794 | Recall: 0.8754\n",
      "Epoch 05 | Training Loss: 0.0004 | Val Loss: 0.4643 | Accuracy: 0.8830 | Precision: 0.8773 | Recall: 0.8820\n",
      "Epoch 06 | Training Loss: 0.0002 | Val Loss: 0.4943 | Accuracy: 0.8828 | Precision: 0.8757 | Recall: 0.8837\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.5221 | Accuracy: 0.8830 | Precision: 0.8730 | Recall: 0.8878\n",
      "Epoch 08 | Training Loss: 0.0001 | Val Loss: 0.5482 | Accuracy: 0.8824 | Precision: 0.8708 | Recall: 0.8894\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.5714 | Accuracy: 0.8816 | Precision: 0.8718 | Recall: 0.8861\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.5938 | Accuracy: 0.8838 | Precision: 0.8760 | Recall: 0.8857\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3153 | Test Accuracy: 0.8704 | Test Precision: 0.8732 | Test Recall: 0.8667\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 54...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4123 | Val Loss: 0.3160 | Accuracy: 0.8736 | Precision: 0.8544 | Recall: 0.8911\n",
      "Epoch 02 | Training Loss: 0.0483 | Val Loss: 0.3869 | Accuracy: 0.8678 | Precision: 0.8211 | Recall: 0.9299\n",
      "Epoch 03 | Training Loss: 0.0062 | Val Loss: 0.4083 | Accuracy: 0.8778 | Precision: 0.8827 | Recall: 0.8626\n",
      "Epoch 04 | Training Loss: 0.0012 | Val Loss: 0.4604 | Accuracy: 0.8816 | Precision: 0.8664 | Recall: 0.8936\n",
      "Epoch 05 | Training Loss: 0.0005 | Val Loss: 0.5007 | Accuracy: 0.8828 | Precision: 0.8661 | Recall: 0.8969\n",
      "Epoch 06 | Training Loss: 0.0002 | Val Loss: 0.5364 | Accuracy: 0.8828 | Precision: 0.8644 | Recall: 0.8993\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.5654 | Accuracy: 0.8824 | Precision: 0.8657 | Recall: 0.8965\n",
      "Epoch 08 | Training Loss: 0.0001 | Val Loss: 0.5953 | Accuracy: 0.8830 | Precision: 0.8650 | Recall: 0.8989\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.6219 | Accuracy: 0.8828 | Precision: 0.8667 | Recall: 0.8960\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.6479 | Accuracy: 0.8824 | Precision: 0.8672 | Recall: 0.8944\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3361 | Test Accuracy: 0.8693 | Test Precision: 0.8720 | Test Recall: 0.8658\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 54...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.4112 | Val Loss: 0.2890 | Accuracy: 0.8816 | Precision: 0.8578 | Recall: 0.9059\n",
      "Epoch 02 | Training Loss: 0.0523 | Val Loss: 0.3195 | Accuracy: 0.8788 | Precision: 0.8689 | Recall: 0.8833\n",
      "Epoch 03 | Training Loss: 0.0059 | Val Loss: 0.3906 | Accuracy: 0.8844 | Precision: 0.8583 | Recall: 0.9121\n",
      "Epoch 04 | Training Loss: 0.0010 | Val Loss: 0.4272 | Accuracy: 0.8858 | Precision: 0.8746 | Recall: 0.8923\n",
      "Epoch 05 | Training Loss: 0.0004 | Val Loss: 0.4665 | Accuracy: 0.8862 | Precision: 0.8729 | Recall: 0.8956\n",
      "Epoch 06 | Training Loss: 0.0002 | Val Loss: 0.4993 | Accuracy: 0.8860 | Precision: 0.8753 | Recall: 0.8919\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.5320 | Accuracy: 0.8862 | Precision: 0.8751 | Recall: 0.8927\n",
      "Epoch 08 | Training Loss: 0.0001 | Val Loss: 0.5635 | Accuracy: 0.8862 | Precision: 0.8732 | Recall: 0.8952\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.5930 | Accuracy: 0.8870 | Precision: 0.8734 | Recall: 0.8969\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.6227 | Accuracy: 0.8854 | Precision: 0.8701 | Recall: 0.8977\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3293 | Test Accuracy: 0.8700 | Test Precision: 0.8705 | Test Recall: 0.8694\n",
      "\n",
      "Training for parameter combination: 55, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.0001, 'RMSProp', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 55...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6127 | Val Loss: 0.4882 | Accuracy: 0.7690 | Precision: 0.7462 | Recall: 0.7933\n",
      "Epoch 02 | Training Loss: 0.3619 | Val Loss: 0.4151 | Accuracy: 0.8132 | Precision: 0.7835 | Recall: 0.8494\n",
      "Epoch 03 | Training Loss: 0.2462 | Val Loss: 0.3881 | Accuracy: 0.8340 | Precision: 0.8426 | Recall: 0.8086\n",
      "Epoch 04 | Training Loss: 0.1724 | Val Loss: 0.3803 | Accuracy: 0.8456 | Precision: 0.8408 | Recall: 0.8408\n",
      "Epoch 05 | Training Loss: 0.1192 | Val Loss: 0.3972 | Accuracy: 0.8462 | Precision: 0.8625 | Recall: 0.8123\n",
      "Epoch 06 | Training Loss: 0.0786 | Val Loss: 0.4167 | Accuracy: 0.8554 | Precision: 0.8390 | Recall: 0.8684\n",
      "Epoch 07 | Training Loss: 0.0499 | Val Loss: 0.4489 | Accuracy: 0.8576 | Precision: 0.8488 | Recall: 0.8593\n",
      "Epoch 08 | Training Loss: 0.0301 | Val Loss: 0.5032 | Accuracy: 0.8576 | Precision: 0.8594 | Recall: 0.8445\n",
      "Epoch 09 | Training Loss: 0.0166 | Val Loss: 0.5845 | Accuracy: 0.8544 | Precision: 0.8224 | Recall: 0.8923\n",
      "Epoch 10 | Training Loss: 0.0087 | Val Loss: 0.6755 | Accuracy: 0.8492 | Precision: 0.8090 | Recall: 0.9018\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3746 | Test Accuracy: 0.8472 | Test Precision: 0.8180 | Test Recall: 0.8930\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 55...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6093 | Val Loss: 0.4752 | Accuracy: 0.7760 | Precision: 0.7972 | Recall: 0.7215\n",
      "Epoch 02 | Training Loss: 0.3664 | Val Loss: 0.4043 | Accuracy: 0.8226 | Precision: 0.7824 | Recall: 0.8783\n",
      "Epoch 03 | Training Loss: 0.2521 | Val Loss: 0.3713 | Accuracy: 0.8474 | Precision: 0.8195 | Recall: 0.8787\n",
      "Epoch 04 | Training Loss: 0.1783 | Val Loss: 0.3663 | Accuracy: 0.8546 | Precision: 0.8277 | Recall: 0.8841\n",
      "Epoch 05 | Training Loss: 0.1244 | Val Loss: 0.3768 | Accuracy: 0.8504 | Precision: 0.8666 | Recall: 0.8172\n",
      "Epoch 06 | Training Loss: 0.0836 | Val Loss: 0.3933 | Accuracy: 0.8564 | Precision: 0.8621 | Recall: 0.8379\n",
      "Epoch 07 | Training Loss: 0.0535 | Val Loss: 0.4322 | Accuracy: 0.8584 | Precision: 0.8563 | Recall: 0.8507\n",
      "Epoch 08 | Training Loss: 0.0319 | Val Loss: 0.4783 | Accuracy: 0.8582 | Precision: 0.8482 | Recall: 0.8618\n",
      "Epoch 09 | Training Loss: 0.0177 | Val Loss: 0.5475 | Accuracy: 0.8584 | Precision: 0.8373 | Recall: 0.8787\n",
      "Epoch 10 | Training Loss: 0.0090 | Val Loss: 0.6687 | Accuracy: 0.8512 | Precision: 0.8111 | Recall: 0.9035\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4111 | Test Accuracy: 0.8465 | Test Precision: 0.8166 | Test Recall: 0.8938\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 55...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6116 | Val Loss: 0.4853 | Accuracy: 0.7716 | Precision: 0.7406 | Recall: 0.8139\n",
      "Epoch 02 | Training Loss: 0.3622 | Val Loss: 0.4129 | Accuracy: 0.8178 | Precision: 0.8340 | Recall: 0.7793\n",
      "Epoch 03 | Training Loss: 0.2461 | Val Loss: 0.3893 | Accuracy: 0.8336 | Precision: 0.8076 | Recall: 0.8622\n",
      "Epoch 04 | Training Loss: 0.1717 | Val Loss: 0.3843 | Accuracy: 0.8428 | Precision: 0.8268 | Recall: 0.8548\n",
      "Epoch 05 | Training Loss: 0.1183 | Val Loss: 0.4007 | Accuracy: 0.8506 | Precision: 0.8455 | Recall: 0.8465\n",
      "Epoch 06 | Training Loss: 0.0788 | Val Loss: 0.4639 | Accuracy: 0.8412 | Precision: 0.7953 | Recall: 0.9055\n",
      "Epoch 07 | Training Loss: 0.0501 | Val Loss: 0.4690 | Accuracy: 0.8554 | Precision: 0.8557 | Recall: 0.8441\n",
      "Epoch 08 | Training Loss: 0.0298 | Val Loss: 0.5291 | Accuracy: 0.8510 | Precision: 0.8317 | Recall: 0.8684\n",
      "Epoch 09 | Training Loss: 0.0169 | Val Loss: 0.5865 | Accuracy: 0.8492 | Precision: 0.8247 | Recall: 0.8750\n",
      "Epoch 10 | Training Loss: 0.0089 | Val Loss: 0.6506 | Accuracy: 0.8528 | Precision: 0.8488 | Recall: 0.8474\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4269 | Test Accuracy: 0.8454 | Test Precision: 0.8567 | Test Recall: 0.8296\n",
      "\n",
      "Training for parameter combination: 56, \n",
      "\n",
      "parameters: [2, 'Tanh', 0.001, 'RMSProp', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 56...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3755 | Val Loss: 0.2937 | Accuracy: 0.8694 | Precision: 0.8976 | Recall: 0.8247\n",
      "Epoch 02 | Training Loss: 0.1358 | Val Loss: 0.3150 | Accuracy: 0.8786 | Precision: 0.8653 | Recall: 0.8878\n",
      "Epoch 03 | Training Loss: 0.0468 | Val Loss: 0.4364 | Accuracy: 0.8800 | Precision: 0.8666 | Recall: 0.8894\n",
      "Epoch 04 | Training Loss: 0.0127 | Val Loss: 0.5848 | Accuracy: 0.8770 | Precision: 0.8562 | Recall: 0.8969\n",
      "Epoch 05 | Training Loss: 0.0034 | Val Loss: 0.7930 | Accuracy: 0.8760 | Precision: 0.8507 | Recall: 0.9026\n",
      "Epoch 06 | Training Loss: 0.0003 | Val Loss: 0.9103 | Accuracy: 0.8824 | Precision: 0.8699 | Recall: 0.8907\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 0.9595 | Accuracy: 0.8824 | Precision: 0.8729 | Recall: 0.8866\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.9911 | Accuracy: 0.8828 | Precision: 0.8718 | Recall: 0.8890\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 1.0134 | Accuracy: 0.8830 | Precision: 0.8727 | Recall: 0.8882\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 1.0307 | Accuracy: 0.8828 | Precision: 0.8730 | Recall: 0.8874\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3135 | Test Accuracy: 0.8717 | Test Precision: 0.8744 | Test Recall: 0.8680\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 56...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3789 | Val Loss: 0.3163 | Accuracy: 0.8658 | Precision: 0.8143 | Recall: 0.9369\n",
      "Epoch 02 | Training Loss: 0.1354 | Val Loss: 0.3411 | Accuracy: 0.8754 | Precision: 0.8327 | Recall: 0.9299\n",
      "Epoch 03 | Training Loss: 0.0425 | Val Loss: 0.4337 | Accuracy: 0.8760 | Precision: 0.8419 | Recall: 0.9163\n",
      "Epoch 04 | Training Loss: 0.0118 | Val Loss: 0.5810 | Accuracy: 0.8740 | Precision: 0.8565 | Recall: 0.8890\n",
      "Epoch 05 | Training Loss: 0.0030 | Val Loss: 0.7170 | Accuracy: 0.8788 | Precision: 0.8753 | Recall: 0.8746\n",
      "Epoch 06 | Training Loss: 0.0002 | Val Loss: 0.8668 | Accuracy: 0.8796 | Precision: 0.8612 | Recall: 0.8960\n",
      "Epoch 07 | Training Loss: 0.0000 | Val Loss: 0.8946 | Accuracy: 0.8820 | Precision: 0.8713 | Recall: 0.8878\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.9228 | Accuracy: 0.8814 | Precision: 0.8672 | Recall: 0.8919\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.9419 | Accuracy: 0.8816 | Precision: 0.8682 | Recall: 0.8911\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.9565 | Accuracy: 0.8828 | Precision: 0.8712 | Recall: 0.8899\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3133 | Test Accuracy: 0.8717 | Test Precision: 0.8755 | Test Recall: 0.8666\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 56...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.3805 | Val Loss: 0.2908 | Accuracy: 0.8744 | Precision: 0.8563 | Recall: 0.8903\n",
      "Epoch 02 | Training Loss: 0.1326 | Val Loss: 0.3136 | Accuracy: 0.8816 | Precision: 0.8760 | Recall: 0.8804\n",
      "Epoch 03 | Training Loss: 0.0454 | Val Loss: 0.4130 | Accuracy: 0.8780 | Precision: 0.8470 | Recall: 0.9134\n",
      "Epoch 04 | Training Loss: 0.0131 | Val Loss: 0.5409 | Accuracy: 0.8726 | Precision: 0.8473 | Recall: 0.8993\n",
      "Epoch 05 | Training Loss: 0.0021 | Val Loss: 0.7792 | Accuracy: 0.8738 | Precision: 0.8517 | Recall: 0.8956\n",
      "Epoch 06 | Training Loss: 0.0004 | Val Loss: 0.8423 | Accuracy: 0.8774 | Precision: 0.8694 | Recall: 0.8791\n",
      "Epoch 07 | Training Loss: 0.0001 | Val Loss: 0.9130 | Accuracy: 0.8800 | Precision: 0.8671 | Recall: 0.8886\n",
      "Epoch 08 | Training Loss: 0.0000 | Val Loss: 0.9409 | Accuracy: 0.8784 | Precision: 0.8664 | Recall: 0.8857\n",
      "Epoch 09 | Training Loss: 0.0000 | Val Loss: 0.9653 | Accuracy: 0.8780 | Precision: 0.8640 | Recall: 0.8882\n",
      "Epoch 10 | Training Loss: 0.0000 | Val Loss: 0.9812 | Accuracy: 0.8778 | Precision: 0.8648 | Recall: 0.8866\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3301 | Test Accuracy: 0.8727 | Test Precision: 0.8744 | Test Recall: 0.8703\n",
      "\n",
      "Training for parameter combination: 57, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.001, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 57...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7994 | Val Loss: 0.7086 | Accuracy: 0.5680 | Precision: 0.5553 | Recall: 0.5470\n",
      "Epoch 02 | Training Loss: 0.6862 | Val Loss: 0.6689 | Accuracy: 0.6026 | Precision: 0.5747 | Recall: 0.6935\n",
      "Epoch 03 | Training Loss: 0.6504 | Val Loss: 0.6400 | Accuracy: 0.6284 | Precision: 0.6266 | Recall: 0.5780\n",
      "Epoch 04 | Training Loss: 0.6267 | Val Loss: 0.6239 | Accuracy: 0.6482 | Precision: 0.6237 | Recall: 0.6918\n",
      "Epoch 05 | Training Loss: 0.6073 | Val Loss: 0.6089 | Accuracy: 0.6658 | Precision: 0.6421 | Recall: 0.7017\n",
      "Epoch 06 | Training Loss: 0.5904 | Val Loss: 0.5950 | Accuracy: 0.6816 | Precision: 0.6646 | Recall: 0.6931\n",
      "Epoch 07 | Training Loss: 0.5756 | Val Loss: 0.5894 | Accuracy: 0.6854 | Precision: 0.6485 | Recall: 0.7665\n",
      "Epoch 08 | Training Loss: 0.5621 | Val Loss: 0.5729 | Accuracy: 0.7002 | Precision: 0.7010 | Recall: 0.6654\n",
      "Epoch 09 | Training Loss: 0.5491 | Val Loss: 0.5637 | Accuracy: 0.7096 | Precision: 0.6910 | Recall: 0.7252\n",
      "Epoch 10 | Training Loss: 0.5372 | Val Loss: 0.5542 | Accuracy: 0.7168 | Precision: 0.7147 | Recall: 0.6922\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5277 | Test Accuracy: 0.7112 | Test Precision: 0.7187 | Test Recall: 0.6940\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 57...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8011 | Val Loss: 0.7245 | Accuracy: 0.5606 | Precision: 0.5438 | Recall: 0.5817\n",
      "Epoch 02 | Training Loss: 0.6885 | Val Loss: 0.6735 | Accuracy: 0.6038 | Precision: 0.5859 | Recall: 0.6233\n",
      "Epoch 03 | Training Loss: 0.6526 | Val Loss: 0.6484 | Accuracy: 0.6254 | Precision: 0.6234 | Recall: 0.5743\n",
      "Epoch 04 | Training Loss: 0.6305 | Val Loss: 0.6335 | Accuracy: 0.6458 | Precision: 0.6213 | Recall: 0.6898\n",
      "Epoch 05 | Training Loss: 0.6127 | Val Loss: 0.6169 | Accuracy: 0.6600 | Precision: 0.6550 | Recall: 0.6312\n",
      "Epoch 06 | Training Loss: 0.5973 | Val Loss: 0.6046 | Accuracy: 0.6742 | Precision: 0.6713 | Recall: 0.6427\n",
      "Epoch 07 | Training Loss: 0.5832 | Val Loss: 0.5941 | Accuracy: 0.6844 | Precision: 0.6673 | Recall: 0.6960\n",
      "Epoch 08 | Training Loss: 0.5701 | Val Loss: 0.5835 | Accuracy: 0.6962 | Precision: 0.6951 | Recall: 0.6650\n",
      "Epoch 09 | Training Loss: 0.5582 | Val Loss: 0.5754 | Accuracy: 0.7014 | Precision: 0.6790 | Recall: 0.7285\n",
      "Epoch 10 | Training Loss: 0.5466 | Val Loss: 0.5655 | Accuracy: 0.7102 | Precision: 0.6931 | Recall: 0.7219\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5821 | Test Accuracy: 0.7056 | Test Precision: 0.7032 | Test Recall: 0.7113\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 57...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8031 | Val Loss: 0.7412 | Accuracy: 0.5414 | Precision: 0.5244 | Recall: 0.5817\n",
      "Epoch 02 | Training Loss: 0.6997 | Val Loss: 0.7039 | Accuracy: 0.5712 | Precision: 0.5476 | Recall: 0.6642\n",
      "Epoch 03 | Training Loss: 0.6669 | Val Loss: 0.6762 | Accuracy: 0.5938 | Precision: 0.5805 | Recall: 0.5846\n",
      "Epoch 04 | Training Loss: 0.6457 | Val Loss: 0.6609 | Accuracy: 0.6168 | Precision: 0.6074 | Recall: 0.5928\n",
      "Epoch 05 | Training Loss: 0.6285 | Val Loss: 0.6499 | Accuracy: 0.6304 | Precision: 0.6074 | Recall: 0.6720\n",
      "Epoch 06 | Training Loss: 0.6128 | Val Loss: 0.6392 | Accuracy: 0.6448 | Precision: 0.6185 | Recall: 0.6976\n",
      "Epoch 07 | Training Loss: 0.5986 | Val Loss: 0.6265 | Accuracy: 0.6562 | Precision: 0.6331 | Recall: 0.6918\n",
      "Epoch 08 | Training Loss: 0.5850 | Val Loss: 0.6169 | Accuracy: 0.6670 | Precision: 0.6774 | Recall: 0.5978\n",
      "Epoch 09 | Training Loss: 0.5722 | Val Loss: 0.6048 | Accuracy: 0.6764 | Precision: 0.6621 | Recall: 0.6790\n",
      "Epoch 10 | Training Loss: 0.5600 | Val Loss: 0.5989 | Accuracy: 0.6886 | Precision: 0.6598 | Recall: 0.7384\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5943 | Test Accuracy: 0.6956 | Test Precision: 0.6827 | Test Recall: 0.7310\n",
      "\n",
      "Training for parameter combination: 58, \n",
      "\n",
      "parameters: [2, 'ReLU', 0.001, 'SGD', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 58...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9824 | Val Loss: 0.9040 | Accuracy: 0.5266 | Precision: 0.5113 | Recall: 0.5342\n",
      "Epoch 02 | Training Loss: 0.8678 | Val Loss: 0.8399 | Accuracy: 0.5446 | Precision: 0.5280 | Recall: 0.5714\n",
      "Epoch 03 | Training Loss: 0.8102 | Val Loss: 0.7928 | Accuracy: 0.5650 | Precision: 0.5482 | Recall: 0.5837\n",
      "Epoch 04 | Training Loss: 0.7678 | Val Loss: 0.7583 | Accuracy: 0.5854 | Precision: 0.5735 | Recall: 0.5652\n",
      "Epoch 05 | Training Loss: 0.7356 | Val Loss: 0.7317 | Accuracy: 0.5960 | Precision: 0.5842 | Recall: 0.5784\n",
      "Epoch 06 | Training Loss: 0.7108 | Val Loss: 0.7113 | Accuracy: 0.6096 | Precision: 0.5928 | Recall: 0.6217\n",
      "Epoch 07 | Training Loss: 0.6906 | Val Loss: 0.6942 | Accuracy: 0.6200 | Precision: 0.6048 | Recall: 0.6238\n",
      "Epoch 08 | Training Loss: 0.6738 | Val Loss: 0.6804 | Accuracy: 0.6298 | Precision: 0.6139 | Recall: 0.6370\n",
      "Epoch 09 | Training Loss: 0.6600 | Val Loss: 0.6686 | Accuracy: 0.6378 | Precision: 0.6239 | Recall: 0.6366\n",
      "Epoch 10 | Training Loss: 0.6480 | Val Loss: 0.6590 | Accuracy: 0.6414 | Precision: 0.6247 | Recall: 0.6522\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6138 | Test Accuracy: 0.6468 | Test Precision: 0.6421 | Test Recall: 0.6636\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 58...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9925 | Val Loss: 0.9280 | Accuracy: 0.5370 | Precision: 0.5224 | Recall: 0.5248\n",
      "Epoch 02 | Training Loss: 0.8992 | Val Loss: 0.8655 | Accuracy: 0.5556 | Precision: 0.5443 | Recall: 0.5124\n",
      "Epoch 03 | Training Loss: 0.8415 | Val Loss: 0.8214 | Accuracy: 0.5652 | Precision: 0.5500 | Recall: 0.5672\n",
      "Epoch 04 | Training Loss: 0.7985 | Val Loss: 0.7864 | Accuracy: 0.5788 | Precision: 0.5659 | Recall: 0.5631\n",
      "Epoch 05 | Training Loss: 0.7657 | Val Loss: 0.7626 | Accuracy: 0.5914 | Precision: 0.5738 | Recall: 0.6114\n",
      "Epoch 06 | Training Loss: 0.7397 | Val Loss: 0.7404 | Accuracy: 0.5982 | Precision: 0.5826 | Recall: 0.6040\n",
      "Epoch 07 | Training Loss: 0.7186 | Val Loss: 0.7223 | Accuracy: 0.6084 | Precision: 0.6010 | Recall: 0.5718\n",
      "Epoch 08 | Training Loss: 0.7013 | Val Loss: 0.7086 | Accuracy: 0.6144 | Precision: 0.6005 | Recall: 0.6114\n",
      "Epoch 09 | Training Loss: 0.6865 | Val Loss: 0.6969 | Accuracy: 0.6202 | Precision: 0.6046 | Recall: 0.6258\n",
      "Epoch 10 | Training Loss: 0.6738 | Val Loss: 0.6854 | Accuracy: 0.6260 | Precision: 0.6192 | Recall: 0.5936\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6977 | Test Accuracy: 0.6299 | Test Precision: 0.6362 | Test Recall: 0.6070\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 58...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9531 | Val Loss: 0.8857 | Accuracy: 0.5324 | Precision: 0.5173 | Recall: 0.5314\n",
      "Epoch 02 | Training Loss: 0.8590 | Val Loss: 0.8303 | Accuracy: 0.5504 | Precision: 0.5334 | Recall: 0.5796\n",
      "Epoch 03 | Training Loss: 0.8068 | Val Loss: 0.7921 | Accuracy: 0.5656 | Precision: 0.5458 | Recall: 0.6192\n",
      "Epoch 04 | Training Loss: 0.7686 | Val Loss: 0.7593 | Accuracy: 0.5828 | Precision: 0.5653 | Recall: 0.6035\n",
      "Epoch 05 | Training Loss: 0.7392 | Val Loss: 0.7372 | Accuracy: 0.5900 | Precision: 0.5696 | Recall: 0.6316\n",
      "Epoch 06 | Training Loss: 0.7159 | Val Loss: 0.7172 | Accuracy: 0.6034 | Precision: 0.5848 | Recall: 0.6275\n",
      "Epoch 07 | Training Loss: 0.6971 | Val Loss: 0.7012 | Accuracy: 0.6126 | Precision: 0.5974 | Recall: 0.6159\n",
      "Epoch 08 | Training Loss: 0.6812 | Val Loss: 0.6883 | Accuracy: 0.6198 | Precision: 0.6046 | Recall: 0.6233\n",
      "Epoch 09 | Training Loss: 0.6679 | Val Loss: 0.6806 | Accuracy: 0.6204 | Precision: 0.5956 | Recall: 0.6762\n",
      "Epoch 10 | Training Loss: 0.6564 | Val Loss: 0.6678 | Accuracy: 0.6314 | Precision: 0.6181 | Recall: 0.6271\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6279 | Test Accuracy: 0.6348 | Test Precision: 0.6376 | Test Recall: 0.6248\n",
      "\n",
      "Training for parameter combination: 59, \n",
      "\n",
      "parameters: [1, 'ReLU', 0.0001, 'SGD', 32]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 59...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0306 | Val Loss: 1.0375 | Accuracy: 0.4998 | Precision: 0.4841 | Recall: 0.4839\n",
      "Epoch 02 | Training Loss: 0.9984 | Val Loss: 1.0147 | Accuracy: 0.5080 | Precision: 0.4926 | Recall: 0.4963\n",
      "Epoch 03 | Training Loss: 0.9757 | Val Loss: 0.9935 | Accuracy: 0.5152 | Precision: 0.5000 | Recall: 0.5074\n",
      "Epoch 04 | Training Loss: 0.9545 | Val Loss: 0.9733 | Accuracy: 0.5210 | Precision: 0.5059 | Recall: 0.5132\n",
      "Epoch 05 | Training Loss: 0.9346 | Val Loss: 0.9543 | Accuracy: 0.5294 | Precision: 0.5146 | Recall: 0.5169\n",
      "Epoch 06 | Training Loss: 0.9160 | Val Loss: 0.9369 | Accuracy: 0.5354 | Precision: 0.5205 | Recall: 0.5281\n",
      "Epoch 07 | Training Loss: 0.8985 | Val Loss: 0.9200 | Accuracy: 0.5402 | Precision: 0.5258 | Recall: 0.5264\n",
      "Epoch 08 | Training Loss: 0.8820 | Val Loss: 0.9049 | Accuracy: 0.5474 | Precision: 0.5325 | Recall: 0.5446\n",
      "Epoch 09 | Training Loss: 0.8665 | Val Loss: 0.8894 | Accuracy: 0.5532 | Precision: 0.5392 | Recall: 0.5388\n",
      "Epoch 10 | Training Loss: 0.8519 | Val Loss: 0.8761 | Accuracy: 0.5584 | Precision: 0.5435 | Recall: 0.5569\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7541 | Test Accuracy: 0.5742 | Test Precision: 0.5746 | Test Recall: 0.5721\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 59...\n",
      "\n",
      "Epoch 01 | Training Loss: 1.0341 | Val Loss: 0.9979 | Accuracy: 0.5066 | Precision: 0.4916 | Recall: 0.5206\n",
      "Epoch 02 | Training Loss: 1.0082 | Val Loss: 0.9744 | Accuracy: 0.5154 | Precision: 0.5002 | Recall: 0.5177\n",
      "Epoch 03 | Training Loss: 0.9852 | Val Loss: 0.9534 | Accuracy: 0.5222 | Precision: 0.5071 | Recall: 0.5190\n",
      "Epoch 04 | Training Loss: 0.9639 | Val Loss: 0.9341 | Accuracy: 0.5288 | Precision: 0.5137 | Recall: 0.5264\n",
      "Epoch 05 | Training Loss: 0.9438 | Val Loss: 0.9175 | Accuracy: 0.5346 | Precision: 0.5189 | Recall: 0.5483\n",
      "Epoch 06 | Training Loss: 0.9251 | Val Loss: 0.8991 | Accuracy: 0.5420 | Precision: 0.5271 | Recall: 0.5384\n",
      "Epoch 07 | Training Loss: 0.9076 | Val Loss: 0.8844 | Accuracy: 0.5482 | Precision: 0.5324 | Recall: 0.5590\n",
      "Epoch 08 | Training Loss: 0.8911 | Val Loss: 0.8689 | Accuracy: 0.5538 | Precision: 0.5383 | Recall: 0.5594\n",
      "Epoch 09 | Training Loss: 0.8756 | Val Loss: 0.8550 | Accuracy: 0.5596 | Precision: 0.5441 | Recall: 0.5648\n",
      "Epoch 10 | Training Loss: 0.8608 | Val Loss: 0.8411 | Accuracy: 0.5664 | Precision: 0.5520 | Recall: 0.5606\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.7585 | Test Accuracy: 0.5762 | Test Precision: 0.5775 | Test Recall: 0.5672\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 59...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.9829 | Val Loss: 0.9637 | Accuracy: 0.5276 | Precision: 0.5129 | Recall: 0.5087\n",
      "Epoch 02 | Training Loss: 0.9562 | Val Loss: 0.9453 | Accuracy: 0.5380 | Precision: 0.5238 | Recall: 0.5177\n",
      "Epoch 03 | Training Loss: 0.9377 | Val Loss: 0.9282 | Accuracy: 0.5456 | Precision: 0.5314 | Recall: 0.5314\n",
      "Epoch 04 | Training Loss: 0.9203 | Val Loss: 0.9122 | Accuracy: 0.5518 | Precision: 0.5378 | Recall: 0.5375\n",
      "Epoch 05 | Training Loss: 0.9039 | Val Loss: 0.8976 | Accuracy: 0.5568 | Precision: 0.5420 | Recall: 0.5532\n",
      "Epoch 06 | Training Loss: 0.8884 | Val Loss: 0.8832 | Accuracy: 0.5622 | Precision: 0.5479 | Recall: 0.5549\n",
      "Epoch 07 | Training Loss: 0.8739 | Val Loss: 0.8696 | Accuracy: 0.5696 | Precision: 0.5556 | Recall: 0.5611\n",
      "Epoch 08 | Training Loss: 0.8601 | Val Loss: 0.8571 | Accuracy: 0.5736 | Precision: 0.5593 | Recall: 0.5677\n",
      "Epoch 09 | Training Loss: 0.8471 | Val Loss: 0.8446 | Accuracy: 0.5784 | Precision: 0.5652 | Recall: 0.5648\n",
      "Epoch 10 | Training Loss: 0.8348 | Val Loss: 0.8333 | Accuracy: 0.5836 | Precision: 0.5703 | Recall: 0.5722\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5452 | Test Accuracy: 0.5856 | Test Precision: 0.5859 | Test Recall: 0.5841\n",
      "\n",
      "Training for parameter combination: 60, \n",
      "\n",
      "parameters: [3, 'LeakyReLU', 0.0001, 'RMSProp', 128]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 60...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6178 | Val Loss: 0.4927 | Accuracy: 0.7638 | Precision: 0.7826 | Recall: 0.7100\n",
      "Epoch 02 | Training Loss: 0.3881 | Val Loss: 0.4215 | Accuracy: 0.8122 | Precision: 0.8299 | Recall: 0.7706\n",
      "Epoch 03 | Training Loss: 0.2912 | Val Loss: 0.3943 | Accuracy: 0.8258 | Precision: 0.7888 | Recall: 0.8750\n",
      "Epoch 04 | Training Loss: 0.2276 | Val Loss: 0.3974 | Accuracy: 0.8350 | Precision: 0.7875 | Recall: 0.9035\n",
      "Epoch 05 | Training Loss: 0.1794 | Val Loss: 0.3721 | Accuracy: 0.8484 | Precision: 0.8515 | Recall: 0.8325\n",
      "Epoch 06 | Training Loss: 0.1405 | Val Loss: 0.3820 | Accuracy: 0.8526 | Precision: 0.8597 | Recall: 0.8317\n",
      "Epoch 07 | Training Loss: 0.1098 | Val Loss: 0.3964 | Accuracy: 0.8560 | Precision: 0.8638 | Recall: 0.8346\n",
      "Epoch 08 | Training Loss: 0.0832 | Val Loss: 0.4141 | Accuracy: 0.8552 | Precision: 0.8605 | Recall: 0.8370\n",
      "Epoch 09 | Training Loss: 0.0614 | Val Loss: 0.4502 | Accuracy: 0.8530 | Precision: 0.8267 | Recall: 0.8816\n",
      "Epoch 10 | Training Loss: 0.0443 | Val Loss: 0.4886 | Accuracy: 0.8534 | Precision: 0.8678 | Recall: 0.8230\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4626 | Test Accuracy: 0.8499 | Test Precision: 0.8802 | Test Recall: 0.8100\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 60...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6199 | Val Loss: 0.4856 | Accuracy: 0.7770 | Precision: 0.7692 | Recall: 0.7715\n",
      "Epoch 02 | Training Loss: 0.3815 | Val Loss: 0.4308 | Accuracy: 0.8112 | Precision: 0.8610 | Recall: 0.7281\n",
      "Epoch 03 | Training Loss: 0.2851 | Val Loss: 0.3830 | Accuracy: 0.8456 | Precision: 0.8309 | Recall: 0.8556\n",
      "Epoch 04 | Training Loss: 0.2234 | Val Loss: 0.3728 | Accuracy: 0.8512 | Precision: 0.8457 | Recall: 0.8478\n",
      "Epoch 05 | Training Loss: 0.1778 | Val Loss: 0.3744 | Accuracy: 0.8532 | Precision: 0.8614 | Recall: 0.8309\n",
      "Epoch 06 | Training Loss: 0.1396 | Val Loss: 0.3981 | Accuracy: 0.8488 | Precision: 0.8791 | Recall: 0.7979\n",
      "Epoch 07 | Training Loss: 0.1092 | Val Loss: 0.3964 | Accuracy: 0.8574 | Precision: 0.8572 | Recall: 0.8469\n",
      "Epoch 08 | Training Loss: 0.0838 | Val Loss: 0.4330 | Accuracy: 0.8564 | Precision: 0.8224 | Recall: 0.8977\n",
      "Epoch 09 | Training Loss: 0.0630 | Val Loss: 0.4561 | Accuracy: 0.8586 | Precision: 0.8313 | Recall: 0.8886\n",
      "Epoch 10 | Training Loss: 0.0462 | Val Loss: 0.5008 | Accuracy: 0.8572 | Precision: 0.8207 | Recall: 0.9026\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4419 | Test Accuracy: 0.8502 | Test Precision: 0.8210 | Test Recall: 0.8958\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 60...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6171 | Val Loss: 0.4927 | Accuracy: 0.7668 | Precision: 0.8065 | Recall: 0.6828\n",
      "Epoch 02 | Training Loss: 0.3890 | Val Loss: 0.4090 | Accuracy: 0.8252 | Precision: 0.8463 | Recall: 0.7814\n",
      "Epoch 03 | Training Loss: 0.2928 | Val Loss: 0.3775 | Accuracy: 0.8438 | Precision: 0.8580 | Recall: 0.8123\n",
      "Epoch 04 | Training Loss: 0.2310 | Val Loss: 0.3612 | Accuracy: 0.8492 | Precision: 0.8252 | Recall: 0.8742\n",
      "Epoch 05 | Training Loss: 0.1826 | Val Loss: 0.3584 | Accuracy: 0.8546 | Precision: 0.8371 | Recall: 0.8692\n",
      "Epoch 06 | Training Loss: 0.1444 | Val Loss: 0.3742 | Accuracy: 0.8538 | Precision: 0.8771 | Recall: 0.8123\n",
      "Epoch 07 | Training Loss: 0.1129 | Val Loss: 0.3809 | Accuracy: 0.8572 | Precision: 0.8685 | Recall: 0.8313\n",
      "Epoch 08 | Training Loss: 0.0861 | Val Loss: 0.3977 | Accuracy: 0.8624 | Precision: 0.8483 | Recall: 0.8721\n",
      "Epoch 09 | Training Loss: 0.0645 | Val Loss: 0.4197 | Accuracy: 0.8598 | Precision: 0.8501 | Recall: 0.8630\n",
      "Epoch 10 | Training Loss: 0.0470 | Val Loss: 0.4724 | Accuracy: 0.8556 | Precision: 0.8197 | Recall: 0.9002\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.4690 | Test Accuracy: 0.8478 | Test Precision: 0.8176 | Test Recall: 0.8953\n",
      "\n",
      "Training for parameter combination: 61, \n",
      "\n",
      "parameters: [3, 'ReLU', 0.001, 'SGD', 64]\n",
      "trial 1 for current parameter setting...\n",
      "\n",
      "Training for trial 61...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8112 | Val Loss: 0.7490 | Accuracy: 0.5488 | Precision: 0.5343 | Recall: 0.5396\n",
      "Epoch 02 | Training Loss: 0.7224 | Val Loss: 0.7059 | Accuracy: 0.5796 | Precision: 0.5583 | Recall: 0.6357\n",
      "Epoch 03 | Training Loss: 0.6854 | Val Loss: 0.6789 | Accuracy: 0.5988 | Precision: 0.5836 | Recall: 0.6019\n",
      "Epoch 04 | Training Loss: 0.6639 | Val Loss: 0.6655 | Accuracy: 0.6124 | Precision: 0.5889 | Recall: 0.6642\n",
      "Epoch 05 | Training Loss: 0.6488 | Val Loss: 0.6515 | Accuracy: 0.6248 | Precision: 0.6092 | Recall: 0.6308\n",
      "Epoch 06 | Training Loss: 0.6364 | Val Loss: 0.6428 | Accuracy: 0.6340 | Precision: 0.6140 | Recall: 0.6601\n",
      "Epoch 07 | Training Loss: 0.6261 | Val Loss: 0.6360 | Accuracy: 0.6390 | Precision: 0.6142 | Recall: 0.6865\n",
      "Epoch 08 | Training Loss: 0.6171 | Val Loss: 0.6292 | Accuracy: 0.6444 | Precision: 0.6189 | Recall: 0.6935\n",
      "Epoch 09 | Training Loss: 0.6085 | Val Loss: 0.6205 | Accuracy: 0.6558 | Precision: 0.6397 | Recall: 0.6642\n",
      "Epoch 10 | Training Loss: 0.6006 | Val Loss: 0.6144 | Accuracy: 0.6612 | Precision: 0.6442 | Recall: 0.6729\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6443 | Test Accuracy: 0.6618 | Test Precision: 0.6595 | Test Recall: 0.6690\n",
      "trial 2 for current parameter setting...\n",
      "\n",
      "Training for trial 61...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.8246 | Val Loss: 0.7742 | Accuracy: 0.5412 | Precision: 0.5245 | Recall: 0.5734\n",
      "Epoch 02 | Training Loss: 0.7278 | Val Loss: 0.7172 | Accuracy: 0.5724 | Precision: 0.5576 | Recall: 0.5710\n",
      "Epoch 03 | Training Loss: 0.6868 | Val Loss: 0.6891 | Accuracy: 0.5954 | Precision: 0.5896 | Recall: 0.5441\n",
      "Epoch 04 | Training Loss: 0.6623 | Val Loss: 0.6715 | Accuracy: 0.6128 | Precision: 0.5926 | Recall: 0.6440\n",
      "Epoch 05 | Training Loss: 0.6452 | Val Loss: 0.6589 | Accuracy: 0.6266 | Precision: 0.6026 | Recall: 0.6749\n",
      "Epoch 06 | Training Loss: 0.6309 | Val Loss: 0.6462 | Accuracy: 0.6352 | Precision: 0.6147 | Recall: 0.6634\n",
      "Epoch 07 | Training Loss: 0.6187 | Val Loss: 0.6372 | Accuracy: 0.6428 | Precision: 0.6201 | Recall: 0.6795\n",
      "Epoch 08 | Training Loss: 0.6078 | Val Loss: 0.6285 | Accuracy: 0.6504 | Precision: 0.6273 | Recall: 0.6873\n",
      "Epoch 09 | Training Loss: 0.5976 | Val Loss: 0.6199 | Accuracy: 0.6602 | Precision: 0.6393 | Recall: 0.6865\n",
      "Epoch 10 | Training Loss: 0.5883 | Val Loss: 0.6154 | Accuracy: 0.6638 | Precision: 0.6336 | Recall: 0.7269\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.5918 | Test Accuracy: 0.6821 | Test Precision: 0.6668 | Test Recall: 0.7279\n",
      "trial 3 for current parameter setting...\n",
      "\n",
      "Training for trial 61...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.7926 | Val Loss: 0.7489 | Accuracy: 0.5520 | Precision: 0.5393 | Recall: 0.5210\n",
      "Epoch 02 | Training Loss: 0.7188 | Val Loss: 0.7082 | Accuracy: 0.5872 | Precision: 0.5701 | Recall: 0.6035\n",
      "Epoch 03 | Training Loss: 0.6857 | Val Loss: 0.6862 | Accuracy: 0.6022 | Precision: 0.5851 | Recall: 0.6167\n",
      "Epoch 04 | Training Loss: 0.6655 | Val Loss: 0.6715 | Accuracy: 0.6136 | Precision: 0.6002 | Recall: 0.6077\n",
      "Epoch 05 | Training Loss: 0.6511 | Val Loss: 0.6605 | Accuracy: 0.6274 | Precision: 0.6164 | Recall: 0.6126\n",
      "Epoch 06 | Training Loss: 0.6398 | Val Loss: 0.6523 | Accuracy: 0.6368 | Precision: 0.6177 | Recall: 0.6580\n",
      "Epoch 07 | Training Loss: 0.6296 | Val Loss: 0.6439 | Accuracy: 0.6450 | Precision: 0.6280 | Recall: 0.6568\n",
      "Epoch 08 | Training Loss: 0.6205 | Val Loss: 0.6384 | Accuracy: 0.6472 | Precision: 0.6230 | Recall: 0.6894\n",
      "Epoch 09 | Training Loss: 0.6119 | Val Loss: 0.6300 | Accuracy: 0.6564 | Precision: 0.6394 | Recall: 0.6679\n",
      "Epoch 10 | Training Loss: 0.6040 | Val Loss: 0.6238 | Accuracy: 0.6624 | Precision: 0.6440 | Recall: 0.6790\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6221 | Test Accuracy: 0.6654 | Test Precision: 0.6583 | Test Recall: 0.6876\n",
      "experiments details:\n",
      "             model        seed  layers activation optimizer  learning_rate  \\\n",
      "0  mlp_word_tokens  3984522128       1  LeakyReLU      Adam         0.0001   \n",
      "1  mlp_word_tokens   958425074       3  LeakyReLU       SGD         0.0001   \n",
      "2  mlp_word_tokens  3323213511       2       ReLU       SGD         0.0001   \n",
      "3  mlp_word_tokens  1559482149       1       Tanh       SGD         0.0010   \n",
      "4  mlp_word_tokens  2965523731       1       ReLU   RMSProp         0.0005   \n",
      "\n",
      "   test_accuracy  test_loss  precision  recall  \n",
      "0         0.8681     0.4387     0.8697  0.8660  \n",
      "1         0.5450     0.7148     0.5453  0.5425  \n",
      "2         0.5384     0.7519     0.5391  0.5296  \n",
      "3         0.7218     0.5457     0.7244  0.7160  \n",
      "4         0.8704     0.4146     0.8734  0.8662  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "tokenization_table = {'model':[], 'method': [], 'vocab_size':[], 'sequence_len':[]}\n",
    "\n",
    "metric_log = {'model':[], 'seed': [], 'layers':[], 'activation': [], 'optimizer': [], 'learning_rate': [], 'test_accuracy': [], 'test_loss': [], 'precision': [], 'recall': []}\n",
    "\n",
    "visited = []\n",
    "\n",
    "def set_new_seed(trial_number):\n",
    "    \"\"\"set new seed for every trial\n",
    "\n",
    "    Args:\n",
    "        trial_number (int): trial number\n",
    "\n",
    "    Returns:\n",
    "        [None]: None\n",
    "    \"\"\"\n",
    "    random_seed = random.randint(0, 2**32-1)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    return random_seed\n",
    "\n",
    "# -------------------------------\n",
    "# Original MLP Class Definition\n",
    "# -------------------------------\n",
    "class MLP(object):\n",
    "    def __init__(self, layers, activation, device=None):\n",
    "        \"\"\"\n",
    "        layers: list containing dimensions of all layers\n",
    "        activation: str, indicating choice of activation function\n",
    "        device: str or None, either 'cpu' or 'gpu' or None.\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.device = device\n",
    "        # list of all weights and biases\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "\n",
    "        # Initialize weights and biases for each layer\n",
    "        for l in range(len(self.layers)):\n",
    "            if l == 0:\n",
    "                continue\n",
    "            W = tf.Variable(tf.random.normal([\n",
    "                            self.layers[l-1], self.layers[l]], \n",
    "                            stddev=0.1))\n",
    "            self.W.append(W)\n",
    "            b = tf.Variable(tf.zeros([1, self.layers[l]]))\n",
    "            self.b.append(b)\n",
    "\n",
    "        # List of variables to update during backpropagation\n",
    "        self.variables = self.W + self.b\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        X: Tensor, inputs.\n",
    "        \"\"\"\n",
    "        if self.device is not None:\n",
    "            # use '/GPU:0' instead of 'gpu:0' for using gpu on mac\n",
    "            with tf.device('/GPU:0' if self.device == 'gpu' else 'cpu'):\n",
    "                self.y = self.compute_output(X)\n",
    "        else:\n",
    "            self.y = self.compute_output(X)\n",
    "        return self.y\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Computes the loss between predicted and true outputs.\n",
    "        y_pred: Tensor of shape (batch_size, size_output)\n",
    "        y_true: Tensor of shape (batch_size, size_output)\n",
    "        \"\"\"\n",
    "        y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
    "        y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        loss_x = cce(y_true_tf, y_pred_tf)\n",
    "        return loss_x\n",
    "\n",
    "    def backward(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients of the loss with respect to the variables.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            predicted = self.forward(X_train)\n",
    "            current_loss = self.loss(predicted, y_train)\n",
    "        grads = tape.gradient(current_loss, self.variables)\n",
    "        return grads\n",
    "\n",
    "    def compute_output(self, X):\n",
    "        \"\"\"\n",
    "        Custom method to compute the output tensor during the forward pass.\n",
    "        \"\"\"\n",
    "        # Cast X to float32\n",
    "        z = tf.cast(X, dtype=tf.float32)\n",
    "        for l in range(len(self.W)-1):\n",
    "            h = tf.matmul(z, self.W[l]) + self.b[l]\n",
    "            # activation function\n",
    "            if activation == 'ReLU':\n",
    "                z = tf.nn.relu(h)\n",
    "            elif activation == 'Tanh':\n",
    "                z = tf.nn.tanh(h)\n",
    "            elif activation == 'LeakyReLU':\n",
    "                z = tf.nn.leaky_relu(h)\n",
    "        \n",
    "        # Output layer (logits)\n",
    "        output = tf.matmul(z, self.W[-1]) + self.b[-1]\n",
    "        return output\n",
    "\n",
    "# -------------------------------\n",
    "# Character-Level Tokenizer and Preprocessing Functions\n",
    "# -------------------------------\n",
    "def char_level_tokenizer(texts, char_level, num_words=None):\n",
    "    \"\"\"\n",
    "    Create and fit a character-level tokenizer.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): List of texts.\n",
    "        num_words (int or None): Maximum number of tokens to keep.\n",
    "\n",
    "    Returns:\n",
    "        tokenizer: A fitted Tokenizer instance.\n",
    "    \"\"\"\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, char_level=char_level, lower=True)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer\n",
    "\n",
    "def texts_to_bow(tokenizer, texts):\n",
    "    \"\"\"\n",
    "    Convert texts to a bag-of-characters representation.\n",
    "\n",
    "    Args:\n",
    "        tokenizer: A fitted character-level Tokenizer.\n",
    "        texts (list of str): List of texts.\n",
    "\n",
    "    Returns:\n",
    "        Numpy array representing the binary bag-of-characters for each text.\n",
    "    \"\"\"\n",
    "    # texts_to_matrix with mode 'binary' produces a fixed-length binary vector per text.\n",
    "    matrix = tokenizer.texts_to_matrix(texts, mode='binary')\n",
    "    return matrix\n",
    "\n",
    "def one_hot_encode(labels, num_classes=2):\n",
    "    \"\"\"\n",
    "    Convert numeric labels to one-hot encoded vectors.\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "# -------------------------------\n",
    "# Load and Prepare the IMDB Dataset\n",
    "# -------------------------------\n",
    "print(\"Loading IMDB dataset...\")\n",
    "# Load the IMDB reviews dataset with the 'as_supervised' flag so that we get (text, label) pairs.\n",
    "(ds_train, ds_test), ds_info = tfds.load('imdb_reviews',\n",
    "                                           split=['train', 'test'],\n",
    "                                           as_supervised=True,\n",
    "                                           with_info=True)\n",
    "\n",
    "# Convert training dataset to lists.\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for text, label in tfds.as_numpy(ds_train):\n",
    "    # Decode byte strings to utf-8 strings.\n",
    "    train_texts.append(text.decode('utf-8'))\n",
    "    train_labels.append(label)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Create a validation set from the training data (20% for validation).\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert test dataset to lists.\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "for text, label in tfds.as_numpy(ds_test):\n",
    "    test_texts.append(text.decode('utf-8'))\n",
    "    test_labels.append(label)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(f\"Train samples: {len(train_texts)}, Validation samples: {len(val_texts)}, Test samples: {len(test_texts)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Preprocessing: Tokenization and Vectorization\n",
    "# -------------------------------\n",
    "# Build the word-level tokenizer on the training texts.\n",
    "tokenizer = char_level_tokenizer(train_texts, char_level=False)\n",
    "print(\"Tokenizer vocabulary size:\", len(tokenizer.word_index) + 1)\n",
    "\n",
    "# Convert texts to bag-of-words representation.\n",
    "X_train = texts_to_bow(tokenizer, train_texts)\n",
    "X_val   = texts_to_bow(tokenizer, val_texts)\n",
    "X_test  = texts_to_bow(tokenizer, test_texts)\n",
    "\n",
    "# record tokenization details\n",
    "tokenization_table['model'] = 'mlp'\n",
    "tokenization_table['method'] = 'word'\n",
    "tokenization_table['vocab_size'] = len(tokenizer.word_index) + 1\n",
    "tokenization_table['sequence_len'] = X_train.shape[1]\n",
    "\n",
    "\n",
    "# Convert labels to one-hot encoding.\n",
    "y_train = one_hot_encode(train_labels)\n",
    "y_val   = one_hot_encode(val_labels)\n",
    "y_test  = one_hot_encode(test_labels)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Model Setup\n",
    "# -------------------------------\n",
    "# List of dimensions in all the layers of the network\n",
    "# The input size is determined by the dimension of the bag-of-words vector.\n",
    "hidden_layers = [1, 2, 3]\n",
    "hidden_sizes = [512, 256, 128]\n",
    "output_size = 2\n",
    "\n",
    "# activation\n",
    "activations = ['ReLU', 'Tanh', 'LeakyReLU']\n",
    "\n",
    "# learning rate\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "\n",
    "# batch size\n",
    "batch_sizes = [32,64,128]\n",
    "# optimizer\n",
    "optims = ['SGD', 'Adam', 'RMSProp']\n",
    "\n",
    "# -------------------------------\n",
    "# Training Parameters and Loop\n",
    "# -------------------------------\n",
    "epochs = 10\n",
    "\n",
    "def generate_params():\n",
    "    while True:\n",
    "        n_hidden = random.choice(hidden_layers)\n",
    "        activation = random.choice(activations)\n",
    "        lr = random.choice(learning_rates)\n",
    "        optim = random.choice(optims)\n",
    "        batch_size = random.choice(batch_sizes)\n",
    "        parameters = [n_hidden, activation, lr, optim, batch_size]\n",
    "        if not parameters in visited:\n",
    "            visited.append(parameters)\n",
    "            return parameters\n",
    "\n",
    "trials = 60\n",
    "indices = np.arange(X_train.shape[0])\n",
    "while trials >=0:\n",
    "    print(f\"\\nTraining for parameter combination: {60-trials+1}, \\n\")\n",
    "    random_seed = set_new_seed(trials)\n",
    "\n",
    "    parameters = generate_params()\n",
    "    print(f\"parameters: {parameters}\")\n",
    "    nn_layers = [X_train.shape[1]] + hidden_sizes[:parameters[0]] + [2]\n",
    "    activation = parameters[1]\n",
    "    lr = parameters[2]\n",
    "    optim = parameters[3]\n",
    "    batch_size = parameters[-1]\n",
    "\n",
    "    best_test_acc = -100\n",
    "    best_precision = None\n",
    "    best_recall = None\n",
    "    best_loss = None\n",
    "    for i in range(3):\n",
    "        print(f\"trial {i+1} for current parameter setting...\")\n",
    "        # Initialize the optimizer\n",
    "        if optim == 'Adam':\n",
    "            optimizer = tf.optimizers.Adam(learning_rate=lr)\n",
    "        elif optim == 'SGD':\n",
    "            optimizer = tf.optimizers.SGD(learning_rate=lr)\n",
    "        elif optim == 'RMSProp':\n",
    "            optimizer = tf.optimizers.RMSprop(learning_rate=lr)\n",
    "            \n",
    "        # Instantiate the MLP model.\n",
    "        model = MLP(nn_layers, activation, device='gpu')\n",
    "\n",
    "        num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nTraining for trial {epoch}...\\n\")\n",
    "            # Shuffle training data at the start of each epoch.\n",
    "            np.random.shuffle(indices)\n",
    "            # X_train = X_train[indices]\n",
    "            # y_train = y_train[indices]\n",
    "\n",
    "            epoch_loss = 0\n",
    "            for i in range(num_batches):\n",
    "                start = i * batch_size\n",
    "                end = min((i+1) * batch_size, X_train.shape[0])\n",
    "                batch_indices = indices[start:end]\n",
    "                X_batch = X_train[batch_indices]\n",
    "                y_batch = y_train[batch_indices]\n",
    "\n",
    "                # Compute gradients and update weights.\n",
    "                # with tf.GradientTape() as tape:\n",
    "                #     predictions = model.forward(X_batch)\n",
    "                #     loss_value = model.loss(predictions, y_batch)\n",
    "                # grads = tape.gradient(loss_value, model.variables)\n",
    "                predictions = model.forward(X_batch)\n",
    "                loss_value = model.loss(predictions, y_batch)\n",
    "                grads = model.backward(X_batch, y_batch)\n",
    "                optimizer.apply_gradients(zip(grads, model.variables))\n",
    "                epoch_loss += loss_value.numpy() * (end - start)\n",
    "\n",
    "            epoch_loss /= X_train.shape[0]\n",
    "\n",
    "            # Evaluate on validation set.\n",
    "            val_logits = model.forward(X_val)\n",
    "            val_loss = model.loss(val_logits, y_val).numpy()\n",
    "            val_preds = np.argmax(val_logits.numpy(), axis=1)\n",
    "            true_val = np.argmax(y_val, axis=1)\n",
    "            accuracy = np.mean(val_preds == true_val)\n",
    "            precision = precision_score(true_val, val_preds)\n",
    "            recall = recall_score(true_val, val_preds)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:02d} | Training Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "                f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "\n",
    "        # -------------------------------\n",
    "        # Final Evaluation on Test Set\n",
    "        # -------------------------------\n",
    "        num_batches = int(np.ceil(X_test.shape[0] / batch_size))\n",
    "        test_precision = 0.0\n",
    "        test_recall = 0.0\n",
    "        test_accuracy = 0.0\n",
    "        true_test = []\n",
    "        test_preds = []\n",
    "        print(\"\\nEvaluating on test set...\")\n",
    "        for b in range(num_batches):\n",
    "            start = b*batch_size\n",
    "            end = min((b+1)*batch_size, X_test.shape[0])\n",
    "            X_batch = X_test[start: end]\n",
    "            test_logits = tf.nn.softmax(model.forward(X_batch), axis=1)\n",
    "            y_batch = y_test[start: end]\n",
    "            test_loss = model.loss(test_logits, y_batch).numpy()\n",
    "            predictions = np.argmax(test_logits.numpy(), axis=1)\n",
    "            test_preds.extend(predictions)\n",
    "            labels = np.argmax(y_batch, axis=1)\n",
    "            true_test.extend(labels)\n",
    "\n",
    "        test_accuracy = np.mean(np.array(test_preds) == np.array(true_test))\n",
    "        test_precision = precision_score(true_test, test_preds)\n",
    "        test_recall = recall_score(true_test, test_preds)\n",
    "\n",
    "        if test_accuracy > best_test_acc:\n",
    "            best_test_acc = test_accuracy\n",
    "            best_precision = test_precision\n",
    "            best_recall = test_recall\n",
    "            best_loss = test_loss\n",
    "\n",
    "        print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f} | \"\n",
    "            f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "    metric_log['model'].append('mlp_word_tokens')\n",
    "    metric_log['seed'].append(random_seed)\n",
    "    metric_log['layers'].append(parameters[0])\n",
    "    metric_log['activation'].append(activation)\n",
    "    metric_log['optimizer'].append(optim)\n",
    "    metric_log['learning_rate'].append(lr)\n",
    "    metric_log['test_accuracy'].append(round(best_test_acc, 4))\n",
    "    metric_log['test_loss'].append(round(best_loss, 4))\n",
    "    metric_log['precision'].append(round(best_precision, 4))\n",
    "    metric_log['recall'].append(round(best_recall, 4))\n",
    "\n",
    "    trials -= 1\n",
    "\n",
    "\n",
    "pkl.dump(tokenization_table, open('word_tokenization_details.pkl', 'wb'))\n",
    "exp_df = pd.DataFrame(metric_log)\n",
    "exp_df.to_csv('word_token_experiments_log.csv', index=False)\n",
    "print(\"experiments details:\")\n",
    "print(exp_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'mlp', 'method': 'word', 'vocab_size': 80169, 'sequence_len': 80169}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "word_tokenization = pkl.load(open('word_tokenization_details.pkl', 'rb'))\n",
    "word_tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpy6iEakUWAZ"
   },
   "source": [
    "## Random MLP on IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0MseUvkuqd0",
    "outputId": "743bfee2-02cb-4c85-8b53-a286f50d5989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 14:10:42.856333: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 20000, Validation samples: 5000, Test samples: 25000\n",
      "Tokenizer vocabulary size: 134\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6879 | Val Loss: 0.6852 | Accuracy: 0.5636 | Precision: 0.5433 | Recall: 0.6258\n",
      "Epoch 02 | Training Loss: 0.6828 | Val Loss: 0.6820 | Accuracy: 0.5704 | Precision: 0.5454 | Recall: 0.6840\n",
      "Epoch 03 | Training Loss: 0.6796 | Val Loss: 0.6796 | Accuracy: 0.5766 | Precision: 0.5514 | Recall: 0.6799\n",
      "Epoch 04 | Training Loss: 0.6775 | Val Loss: 0.6771 | Accuracy: 0.5802 | Precision: 0.5641 | Recall: 0.5903\n",
      "Epoch 05 | Training Loss: 0.6759 | Val Loss: 0.6767 | Accuracy: 0.5822 | Precision: 0.5591 | Recall: 0.6535\n",
      "Epoch 06 | Training Loss: 0.6747 | Val Loss: 0.6756 | Accuracy: 0.5854 | Precision: 0.5653 | Recall: 0.6271\n",
      "Epoch 07 | Training Loss: 0.6739 | Val Loss: 0.6749 | Accuracy: 0.5864 | Precision: 0.5675 | Recall: 0.6176\n",
      "Epoch 08 | Training Loss: 0.6731 | Val Loss: 0.6746 | Accuracy: 0.5858 | Precision: 0.5659 | Recall: 0.6254\n",
      "Epoch 09 | Training Loss: 0.6725 | Val Loss: 0.6744 | Accuracy: 0.5850 | Precision: 0.5643 | Recall: 0.6320\n",
      "Epoch 10 | Training Loss: 0.6722 | Val Loss: 0.6734 | Accuracy: 0.5840 | Precision: 0.5710 | Recall: 0.5705\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6714 | Test Accuracy: 0.5888 | Test Precision: 0.5906 | Test Recall: 0.5787\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "# -------------------------------\n",
    "# Original MLP Class Definition\n",
    "# -------------------------------\n",
    "class MLP_rnd(object):\n",
    "    def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
    "        \"\"\"\n",
    "        size_input: int, size of input layer\n",
    "        size_hidden1: int, size of the 1st hidden layer\n",
    "        size_hidden2: int, size of the 2nd hidden layer\n",
    "        size_hidden3: int, size of the 3rd hidden layer (not used in compute_output here)\n",
    "        size_output: int, size of output layer\n",
    "        device: str or None, either 'cpu' or 'gpu' or None.\n",
    "        \"\"\"\n",
    "        self.size_input = size_input\n",
    "        self.size_hidden1 = size_hidden1\n",
    "        self.size_hidden2 = size_hidden2\n",
    "        self.size_hidden3 = size_hidden3  # (Currently not used in the forward pass)\n",
    "        self.size_output = size_output\n",
    "        self.device = device\n",
    "\n",
    "        # Initialize weights and biases for first hidden layer\n",
    "        self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1], stddev=0.1))\n",
    "        self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1]))\n",
    "\n",
    "        # Initialize weights and biases for second hidden layer\n",
    "        self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2], stddev=0.1))\n",
    "        self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
    "\n",
    "        # Initialize weights and biases for output layer\n",
    "        self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_output], stddev=0.1))\n",
    "        self.b3 = tf.Variable(tf.zeros([1, self.size_output]))\n",
    "\n",
    "        # List of variables to update during backpropagation\n",
    "        #self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
    "        self.variables = [self.W3, self.b3]\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        X: Tensor, inputs.\n",
    "        \"\"\"\n",
    "        if self.device is not None:\n",
    "            with tf.device('gpu:0' if self.device == 'gpu' else 'cpu'):\n",
    "                self.y = self.compute_output(X)\n",
    "        else:\n",
    "            self.y = self.compute_output(X)\n",
    "        return self.y\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Computes the loss between predicted and true outputs.\n",
    "        y_pred: Tensor of shape (batch_size, size_output)\n",
    "        y_true: Tensor of shape (batch_size, size_output)\n",
    "        \"\"\"\n",
    "        y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
    "        y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        loss_x = cce(y_true_tf, y_pred_tf)\n",
    "        return loss_x\n",
    "\n",
    "    def backward(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients of the loss with respect to the variables.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            predicted = self.forward(X_train)\n",
    "            current_loss = self.loss(predicted, y_train)\n",
    "        grads = tape.gradient(current_loss, self.variables)\n",
    "        return grads\n",
    "\n",
    "    def compute_output(self, X):\n",
    "        \"\"\"\n",
    "        Custom method to compute the output tensor during the forward pass.\n",
    "        \"\"\"\n",
    "        # Cast X to float32\n",
    "        X_tf = tf.cast(X, dtype=tf.float32)\n",
    "        # First hidden layer\n",
    "        h1 = tf.matmul(X_tf, self.W1) + self.b1\n",
    "        z1 = tf.nn.relu(h1)\n",
    "        # Second hidden layer\n",
    "        h2 = tf.matmul(z1, self.W2) + self.b2\n",
    "        z2 = tf.nn.relu(h2)\n",
    "        # Output layer (logits)\n",
    "        output = tf.matmul(z2, self.W3) + self.b3\n",
    "        return output\n",
    "\n",
    "# -------------------------------\n",
    "# Character-Level Tokenizer and Preprocessing Functions\n",
    "# -------------------------------\n",
    "def char_level_tokenizer(texts, char_level, num_words=None):\n",
    "    \"\"\"\n",
    "    Create and fit a character-level tokenizer.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): List of texts.\n",
    "        num_words (int or None): Maximum number of tokens to keep.\n",
    "\n",
    "    Returns:\n",
    "        tokenizer: A fitted Tokenizer instance.\n",
    "    \"\"\"\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, char_level=char_level, lower=True)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer\n",
    "\n",
    "def texts_to_bow(tokenizer, texts):\n",
    "    \"\"\"\n",
    "    Convert texts to a bag-of-characters representation.\n",
    "\n",
    "    Args:\n",
    "        tokenizer: A fitted character-level Tokenizer.\n",
    "        texts (list of str): List of texts.\n",
    "\n",
    "    Returns:\n",
    "        Numpy array representing the binary bag-of-characters for each text.\n",
    "    \"\"\"\n",
    "    # texts_to_matrix with mode 'binary' produces a fixed-length binary vector per text.\n",
    "    matrix = tokenizer.texts_to_matrix(texts, mode='binary')\n",
    "    return matrix\n",
    "\n",
    "def one_hot_encode(labels, num_classes=2):\n",
    "    \"\"\"\n",
    "    Convert numeric labels to one-hot encoded vectors.\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "# -------------------------------\n",
    "# Load and Prepare the IMDB Dataset\n",
    "# -------------------------------\n",
    "print(\"Loading IMDB dataset...\")\n",
    "# Load the IMDB reviews dataset with the 'as_supervised' flag so that we get (text, label) pairs.\n",
    "(ds_train, ds_test), ds_info = tfds.load('imdb_reviews',\n",
    "                                           split=['train', 'test'],\n",
    "                                           as_supervised=True,\n",
    "                                           with_info=True)\n",
    "\n",
    "# Convert training dataset to lists.\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for text, label in tfds.as_numpy(ds_train):\n",
    "    # Decode byte strings to utf-8 strings.\n",
    "    train_texts.append(text.decode('utf-8'))\n",
    "    train_labels.append(label)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Create a validation set from the training data (20% for validation).\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert test dataset to lists.\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "for text, label in tfds.as_numpy(ds_test):\n",
    "    test_texts.append(text.decode('utf-8'))\n",
    "    test_labels.append(label)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(f\"Train samples: {len(train_texts)}, Validation samples: {len(val_texts)}, Test samples: {len(test_texts)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Preprocessing: Tokenization and Vectorization\n",
    "# -------------------------------\n",
    "# Build the character-level tokenizer on the training texts.\n",
    "tokenizer = char_level_tokenizer(train_texts, True)\n",
    "print(\"Tokenizer vocabulary size:\", len(tokenizer.word_index) + 1)\n",
    "\n",
    "# Convert texts to bag-of-characters representation.\n",
    "X_train = texts_to_bow(tokenizer, train_texts)\n",
    "X_val   = texts_to_bow(tokenizer, val_texts)\n",
    "X_test  = texts_to_bow(tokenizer, test_texts)\n",
    "\n",
    "# Convert labels to one-hot encoding.\n",
    "y_train = one_hot_encode(train_labels)\n",
    "y_val   = one_hot_encode(val_labels)\n",
    "y_test  = one_hot_encode(test_labels)\n",
    "\n",
    "# -------------------------------\n",
    "# Model Setup\n",
    "# -------------------------------\n",
    "# The input size is determined by the dimension of the bag-of-characters vector.\n",
    "size_input = X_train.shape[1]\n",
    "# Set hidden layer sizes as desired.\n",
    "size_hidden1 = 128\n",
    "size_hidden2 = 64\n",
    "size_hidden3 = 32  # Placeholder (not used in the forward pass)\n",
    "size_output  = 2\n",
    "\n",
    "# Instantiate the MLP model.\n",
    "model = MLP_rnd(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None)\n",
    "\n",
    "# Define the optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# -------------------------------\n",
    "# Training Parameters and Loop\n",
    "# -------------------------------\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle training data at the start of each epoch.\n",
    "    indices = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = X_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = min((i+1) * batch_size, X_train.shape[0])\n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]\n",
    "\n",
    "        # Compute gradients and update weights.\n",
    "        # with tf.GradientTape() as tape:\n",
    "        #     predictions = model.forward(X_batch)\n",
    "        #     loss_value = model.loss(predictions, y_batch)\n",
    "        # grads = tape.gradient(loss_value, model.variables)\n",
    "        predictions = model.forward(X_batch)\n",
    "        loss_value = model.loss(predictions, y_batch)\n",
    "        grads = model.backward(X_batch, y_batch)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables))\n",
    "        epoch_loss += loss_value.numpy() * (end - start)\n",
    "\n",
    "    epoch_loss /= X_train.shape[0]\n",
    "\n",
    "    # Evaluate on validation set.\n",
    "    val_logits = model.forward(X_val)\n",
    "    val_loss = model.loss(val_logits, y_val).numpy()\n",
    "    val_preds = np.argmax(val_logits.numpy(), axis=1)\n",
    "    true_val = np.argmax(y_val, axis=1)\n",
    "    accuracy = np.mean(val_preds == true_val)\n",
    "    precision = precision_score(true_val, val_preds)\n",
    "    recall = recall_score(true_val, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Training Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Final Evaluation on Test Set\n",
    "# -------------------------------\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_logits = model.forward(X_test)\n",
    "test_loss = model.loss(test_logits, y_test).numpy()\n",
    "test_preds = np.argmax(test_logits.numpy(), axis=1)\n",
    "true_test = np.argmax(y_test, axis=1)\n",
    "test_accuracy = np.mean(test_preds == true_test)\n",
    "test_precision = precision_score(true_test, test_preds)\n",
    "test_recall = recall_score(true_test, test_preds)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-wETEHOUGuB"
   },
   "source": [
    "## MLP with feedback alignment on IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mG5AfD2DTdNy",
    "outputId": "fbed505a-3d2e-4227-89ed-a486b8b4a942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB dataset...\n",
      "Train samples: 20000, Validation samples: 5000, Test samples: 25000\n",
      "Tokenizer vocabulary size: 134\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 01 | Training Loss: 0.6807 | Val Loss: 0.6653 | Accuracy: 0.6036 | Precision: 0.5798 | Recall: 0.6621\n",
      "Epoch 02 | Training Loss: 0.6631 | Val Loss: 0.6635 | Accuracy: 0.6084 | Precision: 0.5842 | Recall: 0.6667\n",
      "Epoch 03 | Training Loss: 0.6625 | Val Loss: 0.6629 | Accuracy: 0.6086 | Precision: 0.5799 | Recall: 0.6993\n",
      "Epoch 04 | Training Loss: 0.6607 | Val Loss: 0.6629 | Accuracy: 0.6078 | Precision: 0.5835 | Recall: 0.6671\n",
      "Epoch 05 | Training Loss: 0.6622 | Val Loss: 0.6630 | Accuracy: 0.6044 | Precision: 0.6072 | Recall: 0.5210\n",
      "Epoch 06 | Training Loss: 0.6590 | Val Loss: 0.6613 | Accuracy: 0.6066 | Precision: 0.5840 | Recall: 0.6555\n",
      "Epoch 07 | Training Loss: 0.6574 | Val Loss: 0.6604 | Accuracy: 0.6070 | Precision: 0.5851 | Recall: 0.6510\n",
      "Epoch 08 | Training Loss: 0.6552 | Val Loss: 0.6621 | Accuracy: 0.6044 | Precision: 0.5754 | Recall: 0.7021\n",
      "Epoch 09 | Training Loss: 0.6547 | Val Loss: 0.6600 | Accuracy: 0.6090 | Precision: 0.5974 | Recall: 0.5932\n",
      "Epoch 10 | Training Loss: 0.6531 | Val Loss: 0.6610 | Accuracy: 0.6046 | Precision: 0.5782 | Recall: 0.6819\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6600 | Test Accuracy: 0.6081 | Test Precision: 0.5923 | Test Recall: 0.6934\n"
     ]
    }
   ],
   "source": [
    "class MLP_FA(object):\n",
    "    def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
    "        \"\"\"\n",
    "        size_input: int, size of input layer\n",
    "        size_hidden1: int, size of the 1st hidden layer\n",
    "        size_hidden2: int, size of the 2nd hidden layer\n",
    "        size_hidden3: int, size of the 3rd hidden layer (Note: Not used in compute_output in this example)\n",
    "        size_output: int, size of output layer\n",
    "        device: str or None, either 'cpu' or 'gpu' or None.\n",
    "        \"\"\"\n",
    "        self.size_input = size_input\n",
    "        self.size_hidden1 = size_hidden1\n",
    "        self.size_hidden2 = size_hidden2\n",
    "        self.size_hidden3 = size_hidden3  # (Currently not used)\n",
    "        self.size_output = size_output\n",
    "        self.device = device\n",
    "\n",
    "        # Initialize weights and biases for first hidden layer\n",
    "        self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1], stddev=0.1))\n",
    "        self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1]))\n",
    "\n",
    "        # Initialize weights and biases for second hidden layer\n",
    "        self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2], stddev=0.1))\n",
    "        self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
    "\n",
    "        # Initialize weights and biases for output layer\n",
    "        self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_output], stddev=0.1))\n",
    "        self.b3 = tf.Variable(tf.zeros([1, self.size_output]))\n",
    "\n",
    "        # Create fixed random feedback matrices for feedback alignment:\n",
    "        # B3: used to propagate the error from the output layer to the second hidden layer.\n",
    "        # It replaces the use of W3^T. Its shape is (size_output, size_hidden2).\n",
    "        self.B3 = tf.Variable(tf.random.normal([self.size_output, self.size_hidden2]), trainable=False)\n",
    "\n",
    "        # B2: used to propagate the error from the second hidden layer to the first hidden layer.\n",
    "        # Its shape is (size_hidden2, size_hidden1).\n",
    "        self.B2 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden1]), trainable=False)\n",
    "\n",
    "        # Define variables to be updated during training\n",
    "        self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        X: Tensor, inputs.\n",
    "        \"\"\"\n",
    "        if self.device is not None:\n",
    "            with tf.device('gpu:0' if self.device == 'gpu' else 'cpu'):\n",
    "                self.y = self.compute_output(X)\n",
    "        else:\n",
    "            self.y = self.compute_output(X)\n",
    "        return self.y\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Computes the loss between predicted and true outputs.\n",
    "        y_pred - Tensor of shape (batch_size, size_output)\n",
    "        y_true - Tensor of shape (batch_size, size_output)\n",
    "        \"\"\"\n",
    "        y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
    "        y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        loss_x = cce(y_true_tf, y_pred_tf)\n",
    "        return loss_x\n",
    "\n",
    "    def backward(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Backward pass using feedback alignment.\n",
    "        Computes gradients manually using fixed random feedback matrices.\n",
    "        X_train: Input data (numpy array)\n",
    "        y_train: One-hot encoded labels (numpy array)\n",
    "        Returns: List of gradients corresponding to [dW1, dW2, dW3, db1, db2, db3]\n",
    "        \"\"\"\n",
    "        # Cast input to float32 tensor\n",
    "        X_tf = tf.cast(X_train, tf.float32)\n",
    "\n",
    "        # --- Forward Pass ---\n",
    "        # First hidden layer\n",
    "        h1 = tf.matmul(X_tf, self.W1) + self.b1\n",
    "        a1 = tf.nn.relu(h1)\n",
    "        # Second hidden layer\n",
    "        h2 = tf.matmul(a1, self.W2) + self.b2\n",
    "        a2 = tf.nn.relu(h2)\n",
    "        # Output layer (logits)\n",
    "        logits = tf.matmul(a2, self.W3) + self.b3\n",
    "        # Softmax predictions\n",
    "        y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "        # --- Compute Output Error ---\n",
    "        # For cross-entropy with softmax, the derivative is (y_pred - y_true)\n",
    "        delta3 = y_pred - tf.cast(y_train, tf.float32)  # shape: (batch, size_output)\n",
    "        batch_size = tf.cast(tf.shape(X_tf)[0], tf.float32)\n",
    "\n",
    "        # --- Gradients for Output Layer ---\n",
    "        dW3 = tf.matmul(tf.transpose(a2), delta3) / batch_size\n",
    "        db3 = tf.reduce_mean(delta3, axis=0, keepdims=True)\n",
    "\n",
    "        # --- Feedback Alignment for Second Hidden Layer ---\n",
    "        # Instead of delta2 = (delta3 dot W3^T) * ReLU'(h2), use a fixed random matrix B3.\n",
    "        relu_grad_h2 = tf.cast(h2 > 0, tf.float32)\n",
    "        # delta3 has shape (batch, size_output) and B3 has shape (size_output, size_hidden2)\n",
    "        delta2 = tf.matmul(delta3, self.B3) * relu_grad_h2  # shape: (batch, size_hidden2)\n",
    "\n",
    "        dW2 = tf.matmul(tf.transpose(a1), delta2) / batch_size\n",
    "        db2 = tf.reduce_mean(delta2, axis=0, keepdims=True)\n",
    "\n",
    "        # --- Feedback Alignment for First Hidden Layer ---\n",
    "        # Instead of delta1 = (delta2 dot W2^T) * ReLU'(h1), use a fixed random matrix B2.\n",
    "        relu_grad_h1 = tf.cast(h1 > 0, tf.float32)\n",
    "        # delta2 has shape (batch, size_hidden2) and B2 has shape (size_hidden2, size_hidden1)\n",
    "        delta1 = tf.matmul(delta2, self.B2) * relu_grad_h1  # shape: (batch, size_hidden1)\n",
    "\n",
    "        dW1 = tf.matmul(tf.transpose(X_tf), delta1) / batch_size\n",
    "        db1 = tf.reduce_mean(delta1, axis=0, keepdims=True)\n",
    "\n",
    "        return [dW1, dW2, dW3, db1, db2, db3]\n",
    "\n",
    "    def compute_output(self, X):\n",
    "        \"\"\"\n",
    "        Custom method to obtain output tensor during the forward pass.\n",
    "        \"\"\"\n",
    "        X_tf = tf.cast(X, dtype=tf.float32)\n",
    "        h1 = tf.matmul(X_tf, self.W1) + self.b1\n",
    "        z1 = tf.nn.relu(h1)\n",
    "        h2 = tf.matmul(z1, self.W2) + self.b2\n",
    "        z2 = tf.nn.relu(h2)\n",
    "        output = tf.matmul(z2, self.W3) + self.b3\n",
    "        return output\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Character-Level Tokenizer and Preprocessing Functions\n",
    "# -------------------------------\n",
    "def char_level_tokenizer(texts, char_level, num_words=None):\n",
    "    \"\"\"\n",
    "    Create and fit a character-level tokenizer.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): List of texts.\n",
    "        num_words (int or None): Maximum number of tokens to keep.\n",
    "\n",
    "    Returns:\n",
    "        tokenizer: A fitted Tokenizer instance.\n",
    "    \"\"\"\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, char_level=char_level, lower=True)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer\n",
    "\n",
    "def texts_to_bow(tokenizer, texts):\n",
    "    \"\"\"\n",
    "    Convert texts to a bag-of-characters representation.\n",
    "\n",
    "    Args:\n",
    "        tokenizer: A fitted character-level Tokenizer.\n",
    "        texts (list of str): List of texts.\n",
    "\n",
    "    Returns:\n",
    "        Numpy array representing the binary bag-of-characters for each text.\n",
    "    \"\"\"\n",
    "    # texts_to_matrix with mode 'binary' produces a fixed-length binary vector per text.\n",
    "    matrix = tokenizer.texts_to_matrix(texts, mode='binary')\n",
    "    return matrix\n",
    "\n",
    "def one_hot_encode(labels, num_classes=2):\n",
    "    \"\"\"\n",
    "    Convert numeric labels to one-hot encoded vectors.\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "# -------------------------------\n",
    "# Load and Prepare the IMDB Dataset\n",
    "# -------------------------------\n",
    "print(\"Loading IMDB dataset...\")\n",
    "# Load the IMDB reviews dataset with the 'as_supervised' flag so that we get (text, label) pairs.\n",
    "(ds_train, ds_test), ds_info = tfds.load('imdb_reviews',\n",
    "                                           split=['train', 'test'],\n",
    "                                           as_supervised=True,\n",
    "                                           with_info=True)\n",
    "\n",
    "# Convert training dataset to lists.\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for text, label in tfds.as_numpy(ds_train):\n",
    "    # Decode byte strings to utf-8 strings.\n",
    "    train_texts.append(text.decode('utf-8'))\n",
    "    train_labels.append(label)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Create a validation set from the training data (20% for validation).\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert test dataset to lists.\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "for text, label in tfds.as_numpy(ds_test):\n",
    "    test_texts.append(text.decode('utf-8'))\n",
    "    test_labels.append(label)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(f\"Train samples: {len(train_texts)}, Validation samples: {len(val_texts)}, Test samples: {len(test_texts)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Preprocessing: Tokenization and Vectorization\n",
    "# -------------------------------\n",
    "# Build the character-level tokenizer on the training texts.\n",
    "tokenizer = char_level_tokenizer(train_texts, True)\n",
    "print(\"Tokenizer vocabulary size:\", len(tokenizer.word_index) + 1)\n",
    "\n",
    "# Convert texts to bag-of-characters representation.\n",
    "X_train = texts_to_bow(tokenizer, train_texts)\n",
    "X_val   = texts_to_bow(tokenizer, val_texts)\n",
    "X_test  = texts_to_bow(tokenizer, test_texts)\n",
    "\n",
    "# Convert labels to one-hot encoding.\n",
    "y_train = one_hot_encode(train_labels)\n",
    "y_val   = one_hot_encode(val_labels)\n",
    "y_test  = one_hot_encode(test_labels)\n",
    "\n",
    "# -------------------------------\n",
    "# Model Setup\n",
    "# -------------------------------\n",
    "# The input size is determined by the dimension of the bag-of-characters vector.\n",
    "size_input = X_train.shape[1]\n",
    "# Set hidden layer sizes as desired.\n",
    "size_hidden1 = 128\n",
    "size_hidden2 = 64\n",
    "size_hidden3 = 32  # Placeholder (not used in the forward pass)\n",
    "size_output  = 2\n",
    "\n",
    "# Instantiate the MLP model.\n",
    "model = MLP_FA(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None)\n",
    "\n",
    "# Define the optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# -------------------------------\n",
    "# Training Parameters and Loop\n",
    "# -------------------------------\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle training data at the start of each epoch.\n",
    "    indices = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = X_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = min((i+1) * batch_size, X_train.shape[0])\n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]\n",
    "\n",
    "        # Compute gradients and update weights.\n",
    "        # with tf.GradientTape() as tape:\n",
    "        #     predictions = model.forward(X_batch)\n",
    "        #     loss_value = model.loss(predictions, y_batch)\n",
    "        # grads = tape.gradient(loss_value, model.variables)\n",
    "        predictions = model.forward(X_batch)\n",
    "        loss_value = model.loss(predictions, y_batch)\n",
    "        grads = model.backward(X_batch, y_batch)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables))\n",
    "        epoch_loss += loss_value.numpy() * (end - start)\n",
    "\n",
    "    epoch_loss /= X_train.shape[0]\n",
    "\n",
    "    # Evaluate on validation set.\n",
    "    val_logits = model.forward(X_val)\n",
    "    val_loss = model.loss(val_logits, y_val).numpy()\n",
    "    val_preds = np.argmax(val_logits.numpy(), axis=1)\n",
    "    true_val = np.argmax(y_val, axis=1)\n",
    "    accuracy = np.mean(val_preds == true_val)\n",
    "    precision = precision_score(true_val, val_preds)\n",
    "    recall = recall_score(true_val, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Training Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Final Evaluation on Test Set\n",
    "# -------------------------------\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_logits = model.forward(X_test)\n",
    "test_loss = model.loss(test_logits, y_test).numpy()\n",
    "test_preds = np.argmax(test_logits.numpy(), axis=1)\n",
    "true_test = np.argmax(y_test, axis=1)\n",
    "test_accuracy = np.mean(test_preds == true_test)\n",
    "test_precision = precision_score(true_test, test_preds)\n",
    "test_recall = recall_score(true_test, test_preds)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j6mv098aASE"
   },
   "source": [
    "# Assignment 2 Todos\n",
    "\n",
    "## Overview\n",
    "- **Objective:**  \n",
    "  Modify your model’s text preprocessing by changing from character-level tokenization to word-level tokenization. Compare the performance of both tokenization methods. Additionally, perform hyper-parameter optimization by experimenting with various settings (learning rate, hidden layers, hidden sizes, batch sizes, optimizers, and activation functions) and report your findings.\n",
    "\n",
    "## 1. Initial Setup\n",
    "- [x] **Set Random Seeds:**  \n",
    "  Ensure reproducibility by setting seeds for all random number generators (e.g., Python’s `random`, NumPy, TensorFlow/PyTorch).\n",
    "  \n",
    "- [x] **Prepare the Environment:**  \n",
    "  - Create a new or update an existing Jupyter Notebook.\n",
    "  - Ensure that all necessary libraries (e.g., NumPy, pandas, TensorFlow/PyTorch, matplotlib, etc.) are installed.\n",
    "  \n",
    "- [x] **Version Control:**  \n",
    "  Initialize a Git repository (if not already done) and commit your initial setup.\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "- [x] **Load Dataset:**  \n",
    "  Load your dataset into the notebook.\n",
    "  \n",
    "- [x] **Tokenization:**\n",
    "  - **Character-Level Tokenization:**  \n",
    "    - Tokenize the text data at the character level.\n",
    "    - Save and log the processed data.\n",
    "  - **Word-Level Tokenization:**  \n",
    "    - Modify the tokenization process to tokenize the text by words.\n",
    "    - Save and log the processed data.\n",
    "    \n",
    "- [x] **Comparison:**  \n",
    "  - Create a section in your notebook to compare the two tokenization approaches.\n",
    "  - Visualize or tabulate differences in vocabulary size, sequence lengths, and other relevant metrics.\n",
    "\n",
    "## 3. Model Architecture\n",
    "- [x] **Define the Model:**  \n",
    "  Develop a model (or models) that can handle both tokenization types. Include the following adjustable hyper-parameters:\n",
    "  - Learning rate\n",
    "  - Number of hidden layers\n",
    "  - Hidden sizes (neurons per layer)\n",
    "  - Batch sizes\n",
    "  - Optimizers (e.g., Adam, SGD, RMSProp)\n",
    "  - Activation functions (e.g., ReLU, Tanh, LeakyReLU)\n",
    "\n",
    "## 4. Hyper-Parameter Optimization\n",
    "- [ ] **Experiment Setup:**  \n",
    "  For each hyper-parameter configuration, perform at least 3 different tests to ensure robustness.\n",
    "  \n",
    "- [x] **Grid/Random Search:**  \n",
    "  Set up a search over the following hyper-parameter ranges (example values provided):\n",
    "  - **Learning Rate:** `[0.001, 0.0005, 0.0001]`\n",
    "  - **Hidden Layers:** `[1, 2, 3]`\n",
    "  - **Hidden Sizes:** `[128, 256, 512]`\n",
    "  - **Batch Sizes:** `[32, 64, 128]`\n",
    "  - **Optimizers:** `[Adam, SGD, RMSProp]`\n",
    "  - **Activation Functions:** `[ReLU, Tanh, LeakyReLU]`\n",
    "  \n",
    "- [x] **Logging:**  \n",
    "  Record the results (accuracy, loss, etc.) for each configuration in tables or charts.\n",
    "\n",
    "## 5. Model Training and Evaluation\n",
    "- [ ] **Training with Each Configuration:**  \n",
    "  Run experiments for both tokenization approaches with each set of hyper-parameters:\n",
    "  - Train the model at least 3 times per configuration (keeping the seed constant at this stage).\n",
    "  - Log training and validation performance.\n",
    "  \n",
    "- [ ] **Identify the Best Model:**  \n",
    "  Select the best performing configuration based on validation metrics (e.g., accuracy).\n",
    "\n",
    "## 6. Final Experiments\n",
    "- [ ] **Robustness Check:**  \n",
    "  Once the best model is identified:\n",
    "  - Re-run the experiments at least 3 times with different random seeds.\n",
    "  - Record the performance (accuracy) for each run.\n",
    "  \n",
    "- [ ] **Statistical Reporting:**  \n",
    "  - Compute the **mean accuracy** and **standard error** across these runs.\n",
    "  - Include these statistics in your report.\n",
    "\n",
    "## 7. Documentation and Reporting\n",
    "- [x] **Jupyter Notebook:**  \n",
    "  - Ensure that your notebook is well-commented and clearly documents each step.\n",
    "  - Include code cells for setting seeds, data preprocessing, model building, training, evaluation, and visualization.\n",
    "  \n",
    "- [ ] **Detailed Report (Word Document):**  \n",
    "  Prepare a report that includes:\n",
    "  - **Introduction:** Objectives and overview of the work.\n",
    "  - **Methodology:** Detailed explanation of tokenization changes and hyper-parameter optimization strategy.\n",
    "  - **Experiments and Results:**  \n",
    "    - Comparison between character-level and word-level tokenization.\n",
    "    - Tables/graphs for hyper-parameter experiments.\n",
    "    - Final model performance with mean accuracy and standard error.\n",
    "  - **Discussion:** Analysis of results, challenges encountered, and insights.\n",
    "  - **Conclusion:** Summarize the key findings.\n",
    "  \n",
    "- [ ] **Submission:**  \n",
    "  - Submit your Jupyter Notebook.\n",
    "  - Submit your Word document report.\n",
    "  - Ensure that both files are included in your repository or submission package.\n",
    "\n",
    "## 8. Final Checklist\n",
    "- [ ] All experiments have at least 3 different tests.\n",
    "- [ ] Random seeds are set before any experiment.\n",
    "- [ ] Hyper-parameter optimization covers changes in learning rate, hidden layers, hidden sizes, batch sizes, optimizers, and activation functions.\n",
    "- [ ] The best model’s performance is verified with experiments on different seeds.\n",
    "- [ ] Best model should be compared with random model shown above.\n",
    "- [ ] The report clearly documents the methodology, experiments, results, and final conclusions.\n",
    "- [ ] If experiments are shown with deeper MLP_FA with best settings (Extra credits -- 2 points)\n",
    "\n",
    "---\n",
    "\n",
    "> **Note:**  \n",
    "> Keep thorough logs and document any observations during your experiments. Clear documentation is key to reproducibility and understanding your results.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e66320306b44c65bce10ade0c4d2eeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ee8c01d75c541218b8bc09ff1f94cde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "12dc246bd54c4e3ea3747c65c2e17014": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1547a0be80f84b32a254aea474d6867a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1853768c4e554ae0b1ade9b6e62d771b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a10d0b1fd154491a8888340c8ebfe38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20a84906121842f48543c1bad206d799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb85ef2782754246b66058f75317feed",
       "IPY_MODEL_5138ab3ff1dc4cc883a434e1a7caa14a",
       "IPY_MODEL_a7ea683bf59f4687bd3eadba6298a883"
      ],
      "layout": "IPY_MODEL_d074fc35f4864f55a1e4ebdca6e07530"
     }
    },
    "21b3131b402b4b14991f046d9a3a8be0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "250a431c05cb4878a428cf415f702b36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "25795eca2fe34d14845d14f3295a9ec2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "259e6840f71c4a29b64725a4d921965f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "26b2ec9c903547f886effcacfeea8629": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e014cd8004684dd0bf2513e8dcb9e9f8",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff5c2c87b086478295f9aa8ab1b83908",
      "value": 50000
     }
    },
    "29edf5a4a8884ce5a18f71def1ae921b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "2a83a645921d4970b8ed0b4b29f123bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f96003dea1542f58a9ff716fe8713ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94a33644645a4c27a8b781908bb5c92b",
      "placeholder": "​",
      "style": "IPY_MODEL_c96784cc747c4dd6b95621289526af8a",
      "value": "Generating test examples...:  82%"
     }
    },
    "35d8ba6f21ab445e856039f4c75082b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37c4db5b41c94c99b58627004c25e12d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3aa278af5eb54745a56e4b61af3beac2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ff989a5005542a3a737c38f7959f2ce",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_37c4db5b41c94c99b58627004c25e12d",
      "value": 50000
     }
    },
    "3bdad631a663468e947008ba9a952299": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb323561a3de4b8f85a43a075d00119e",
      "placeholder": "​",
      "style": "IPY_MODEL_d704ab225ada4134bf1ce4bb830a6354",
      "value": "Generating splits...: 100%"
     }
    },
    "3c9c79a8361a48ea9128f738e67941b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3db2d29d0c1649218f2f2c604993727a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3dec77d473c84931836cfa6a0db79ecb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6ea7ea17fe443ed816de452ba64b2f1",
      "placeholder": "​",
      "style": "IPY_MODEL_5af6d5859b724a3ba77f579df40b71d4",
      "value": " 0/25000 [00:00&lt;?, ? examples/s]"
     }
    },
    "3ebcc18d220745338c4ec8de6127e48e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ec9320a7eb74e4c98b230fba6d8a2ce",
      "placeholder": "​",
      "style": "IPY_MODEL_21b3131b402b4b14991f046d9a3a8be0",
      "value": " 1/1 [00:16&lt;00:00, 16.30s/ url]"
     }
    },
    "40019e582a064de589847a3da1175eca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40845adffae1455689ad5a1559559fa0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40d486058c5d47a38ac3adb0cf2bc6d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40019e582a064de589847a3da1175eca",
      "max": 25000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7eb9b35910a64aecaa958983ea078dad",
      "value": 25000
     }
    },
    "43b6dbdb5b6a42d198d384ee7fa4dd29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "444ec309e9cc4828b3ae669d28901abc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46836bd062e74b14a9e5ae1f1d48a184": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b056533e06a48a5a81d15cf44b961b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8e3a8be14b742209b8ef74200a2cd9f",
      "placeholder": "​",
      "style": "IPY_MODEL_1853768c4e554ae0b1ade9b6e62d771b",
      "value": "Shuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.MK1RO0_1.0.0/imdb_reviews-train.tfrecord*...:   0%"
     }
    },
    "505a0b8197ab4680a3c51aff901b1569": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5138ab3ff1dc4cc883a434e1a7caa14a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_250a431c05cb4878a428cf415f702b36",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8c785ed43d84e4e856476928b2a49e9",
      "value": 1
     }
    },
    "54eef9cd5ba54636ba508be7c5e65d70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5af6d5859b724a3ba77f579df40b71d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b130b325efa49f99be9b52994686a0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9b7a63ccc5f462abb99fa20caa65cc4",
      "placeholder": "​",
      "style": "IPY_MODEL_0e66320306b44c65bce10ade0c4d2eeb",
      "value": " 18669/25000 [00:05&lt;00:01, 4882.97 examples/s]"
     }
    },
    "5e72ea42a5714ba5bf783e99af1ffe8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b411ae301a9c4cac9336c8f1bb18c135",
       "IPY_MODEL_ca846e4a00d5439b89615b29b94dd268",
       "IPY_MODEL_be89b15c9d9e48dda2b0819689faa365"
      ],
      "layout": "IPY_MODEL_e0716ea457b54fa58b4eef100fab9335"
     }
    },
    "62010f0361854b66afd987c8bd7e15f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "677c67b52ca14e2d88114d167d065797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "708aac86918f45aaa50940f7122b36ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77a48de94d2948b0ae340c92000cf7e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3bdad631a663468e947008ba9a952299",
       "IPY_MODEL_9610d42f53d441c8940e894954e11339",
       "IPY_MODEL_b36275d5ce954d7ab7b442bb60729146"
      ],
      "layout": "IPY_MODEL_aad3c5ae005a4124acd9285769a215e1"
     }
    },
    "79cd58e72bd4406698ad3979a6c9ba6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25795eca2fe34d14845d14f3295a9ec2",
      "max": 25000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0a178cf8e0d4bbdb4b521a693ccadbe",
      "value": 25000
     }
    },
    "7df5f5059e5f49c9968599942999833b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "7eb9b35910a64aecaa958983ea078dad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ec9320a7eb74e4c98b230fba6d8a2ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "816a5390057d4567915bf34ad0b54c41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "825e86dc8b6046a0b60e728a911f99f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_708aac86918f45aaa50940f7122b36ab",
      "placeholder": "​",
      "style": "IPY_MODEL_46836bd062e74b14a9e5ae1f1d48a184",
      "value": "Generating unsupervised examples...:  95%"
     }
    },
    "85cfedddc7914481a99c93ae7f349851": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88bf3f3840dd4be894756fc2474b84ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b056533e06a48a5a81d15cf44b961b7",
       "IPY_MODEL_a4903235f0f0406d9c0bee0678bf8805",
       "IPY_MODEL_3dec77d473c84931836cfa6a0db79ecb"
      ],
      "layout": "IPY_MODEL_62010f0361854b66afd987c8bd7e15f5"
     }
    },
    "8d682b2a66a14e1ab3345c27b969de1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f11f250de6448ad87a3363ffcb4e243": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "8ff989a5005542a3a737c38f7959f2ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94a33644645a4c27a8b781908bb5c92b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94e07dc24c01434aa319100832e9d21c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9610d42f53d441c8940e894954e11339": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a10d0b1fd154491a8888340c8ebfe38",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_85cfedddc7914481a99c93ae7f349851",
      "value": 3
     }
    },
    "98a5b8121fe341299996d32f52261fe6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fc72e5be2694018a37b7861ccea3ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2f96003dea1542f58a9ff716fe8713ee",
       "IPY_MODEL_79cd58e72bd4406698ad3979a6c9ba6d",
       "IPY_MODEL_ad10809f5e9045d9905cd083bb346f21"
      ],
      "layout": "IPY_MODEL_0ee8c01d75c541218b8bc09ff1f94cde"
     }
    },
    "a4903235f0f0406d9c0bee0678bf8805": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43b6dbdb5b6a42d198d384ee7fa4dd29",
      "max": 25000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_259e6840f71c4a29b64725a4d921965f",
      "value": 25000
     }
    },
    "a614a6f07a7e42baaea992036e16612e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6ea7ea17fe443ed816de452ba64b2f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7ea683bf59f4687bd3eadba6298a883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_677c67b52ca14e2d88114d167d065797",
      "placeholder": "​",
      "style": "IPY_MODEL_3db2d29d0c1649218f2f2c604993727a",
      "value": " 80/80 [00:16&lt;00:00, 11.08 MiB/s]"
     }
    },
    "a85a9cfd1b254b7b98ce7a81661b96ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a8e3a8be14b742209b8ef74200a2cd9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aad3c5ae005a4124acd9285769a215e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "ad10809f5e9045d9905cd083bb346f21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98a5b8121fe341299996d32f52261fe6",
      "placeholder": "​",
      "style": "IPY_MODEL_1547a0be80f84b32a254aea474d6867a",
      "value": " 20375/25000 [00:03&lt;00:00, 7305.65 examples/s]"
     }
    },
    "b36275d5ce954d7ab7b442bb60729146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40845adffae1455689ad5a1559559fa0",
      "placeholder": "​",
      "style": "IPY_MODEL_35d8ba6f21ab445e856039f4c75082b1",
      "value": " 3/3 [00:27&lt;00:00,  9.45s/ splits]"
     }
    },
    "b379d846511c4e17b6ca15c1f6662aae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b411ae301a9c4cac9336c8f1bb18c135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c9c79a8361a48ea9128f738e67941b4",
      "placeholder": "​",
      "style": "IPY_MODEL_12dc246bd54c4e3ea3747c65c2e17014",
      "value": "Shuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.MK1RO0_1.0.0/imdb_reviews-test.tfrecord*...:   0%"
     }
    },
    "b594fbc34d5d40d4abae1759c81972af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b6cc22bec624493cb11da8a6369b11a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b71a01539a0f4b0c89bf87eba3780fcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb323561a3de4b8f85a43a075d00119e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd5890b2ca084272990e5e16f6b81d8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3cbd7d3127f4cefb81665e7f7d7c004",
       "IPY_MODEL_40d486058c5d47a38ac3adb0cf2bc6d2",
       "IPY_MODEL_5b130b325efa49f99be9b52994686a0c"
      ],
      "layout": "IPY_MODEL_8f11f250de6448ad87a3363ffcb4e243"
     }
    },
    "be89b15c9d9e48dda2b0819689faa365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d91ce7676d13401fb58641aa4e71602c",
      "placeholder": "​",
      "style": "IPY_MODEL_a614a6f07a7e42baaea992036e16612e",
      "value": " 0/25000 [00:00&lt;?, ? examples/s]"
     }
    },
    "c96784cc747c4dd6b95621289526af8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca846e4a00d5439b89615b29b94dd268": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa3b427945774e91bbaf99d8cbdaf10d",
      "max": 25000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b379d846511c4e17b6ca15c1f6662aae",
      "value": 25000
     }
    },
    "caf08b27977a4c188e92ea34166acfc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb2ca4b8eae746b6990b7a11c90db810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df2756a1e35540abb553129c3b904709",
       "IPY_MODEL_fb9fd2e2a9be4d0d98b6f796cd5f830a",
       "IPY_MODEL_3ebcc18d220745338c4ec8de6127e48e"
      ],
      "layout": "IPY_MODEL_caf08b27977a4c188e92ea34166acfc8"
     }
    },
    "cb85ef2782754246b66058f75317feed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_444ec309e9cc4828b3ae669d28901abc",
      "placeholder": "​",
      "style": "IPY_MODEL_b594fbc34d5d40d4abae1759c81972af",
      "value": "Dl Size...: 100%"
     }
    },
    "d074fc35f4864f55a1e4ebdca6e07530": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0a178cf8e0d4bbdb4b521a693ccadbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d704ab225ada4134bf1ce4bb830a6354": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d91ce7676d13401fb58641aa4e71602c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da94d8894e6b4feabcd3d191ffbde635": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_825e86dc8b6046a0b60e728a911f99f9",
       "IPY_MODEL_26b2ec9c903547f886effcacfeea8629",
       "IPY_MODEL_e19bf5cbd5ce4377939f080e7aafa25f"
      ],
      "layout": "IPY_MODEL_7df5f5059e5f49c9968599942999833b"
     }
    },
    "df2756a1e35540abb553129c3b904709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f60316df87ba4b64bef0b47f95e8d30f",
      "placeholder": "​",
      "style": "IPY_MODEL_f212087a14d84bd7a5a91d14775a75eb",
      "value": "Dl Completed...: 100%"
     }
    },
    "df8df8420bc342369e233a8a16385efc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e236994a32f244b88030884c0495a72e",
       "IPY_MODEL_3aa278af5eb54745a56e4b61af3beac2",
       "IPY_MODEL_fa14c3851c6447c0a28ea94314a832ad"
      ],
      "layout": "IPY_MODEL_29edf5a4a8884ce5a18f71def1ae921b"
     }
    },
    "e014cd8004684dd0bf2513e8dcb9e9f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0716ea457b54fa58b4eef100fab9335": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "e19bf5cbd5ce4377939f080e7aafa25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6cc22bec624493cb11da8a6369b11a8",
      "placeholder": "​",
      "style": "IPY_MODEL_8d682b2a66a14e1ab3345c27b969de1e",
      "value": " 47326/50000 [00:09&lt;00:00, 7169.31 examples/s]"
     }
    },
    "e236994a32f244b88030884c0495a72e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_505a0b8197ab4680a3c51aff901b1569",
      "placeholder": "​",
      "style": "IPY_MODEL_94e07dc24c01434aa319100832e9d21c",
      "value": "Shuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.MK1RO0_1.0.0/imdb_reviews-unsupervised.tfrecord*...:   0%"
     }
    },
    "e8c785ed43d84e4e856476928b2a49e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e9b7a63ccc5f462abb99fa20caa65cc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec25dadc702141049913b810b7fde1c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f212087a14d84bd7a5a91d14775a75eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3cbd7d3127f4cefb81665e7f7d7c004": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b71a01539a0f4b0c89bf87eba3780fcc",
      "placeholder": "​",
      "style": "IPY_MODEL_816a5390057d4567915bf34ad0b54c41",
      "value": "Generating train examples...:  75%"
     }
    },
    "f60316df87ba4b64bef0b47f95e8d30f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa14c3851c6447c0a28ea94314a832ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54eef9cd5ba54636ba508be7c5e65d70",
      "placeholder": "​",
      "style": "IPY_MODEL_2a83a645921d4970b8ed0b4b29f123bc",
      "value": " 0/50000 [00:00&lt;?, ? examples/s]"
     }
    },
    "fa3b427945774e91bbaf99d8cbdaf10d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb9fd2e2a9be4d0d98b6f796cd5f830a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a85a9cfd1b254b7b98ce7a81661b96ed",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec25dadc702141049913b810b7fde1c7",
      "value": 1
     }
    },
    "ff5c2c87b086478295f9aa8ab1b83908": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
